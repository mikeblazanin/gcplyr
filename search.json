[{"path":"https://mikeblazanin.github.io/gcplyr/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2023 Michael Blazanin Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/analyze.html","id":"where-are-we-so-far","dir":"Articles","previous_headings":"","what":"Where are we so far?","title":"Analyzing data","text":"Introduction: vignette(\"gcplyr\") Importing transforming data: vignette(\"import_transform\") Incorporating design information: vignette(\"incorporate_designs\") Pre-processing plotting data: vignette(\"preprocess_plot\") Processing data: vignette(\"process\") Analyzing data: vignette(\"analyze\") Dealing noise: vignette(\"noise\") Statistics, merging data, resources: vignette(\"conclusion\") far, ’ve imported transformed measures, combined design information, pre-processed, processed, plotted data. Now ’re going analyze data summarizing growth curves number metrics. haven’t already, load necessary packages.","code":"library(gcplyr) #> ##  #> ## gcplyr (Version 1.5.0, Build Date: 2023-04-03) #> ## See http://github.com/mikeblazanin/gcplyr for additional documentation #> ## Please cite software as: #> ##   Blazanin, Michael. 2023. 'gcplyr: manipulate and analyze growth #> ##   curve data.' R package version 1.5.0 #> ##  library(dplyr) #>  #> Attaching package: 'dplyr' #> The following objects are masked from 'package:stats': #>  #>     filter, lag #> The following objects are masked from 'package:base': #>  #>     intersect, setdiff, setequal, union library(ggplot2) # This code was previously explained # Here we're re-running it so it's available for us to work with example_tidydata <- trans_wide_to_tidy(example_widedata_noiseless,                                        id_cols = \"Time\") example_design <- make_design(   pattern_split = \",\", nrows = 8, ncols = 12,   \"Bacteria_strain\" = make_designpattern(     values = paste(\"Strain\", 1:48),     rows = 1:8, cols = 1:6, pattern = 1:48, byrow = TRUE),   \"Bacteria_strain\" = make_designpattern(     values = paste(\"Strain\", 1:48),     rows = 1:8, cols = 7:12, pattern = 1:48, byrow = TRUE),   \"Phage\" = make_designpattern(     values = c(\"No Phage\"), rows = 1:8, cols = 1:6, pattern = \"1\"),   \"Phage\" = make_designpattern(     values = c(\"Phage Added\"), rows = 1:8, cols = 7:12, pattern = \"1\")) ex_dat_mrg <- merge_dfs(example_tidydata, example_design) #> Joining with `by = join_by(Well)` ex_dat_mrg$Well <-    factor(ex_dat_mrg$Well,          levels = paste(rep(LETTERS[1:8], each = 12), 1:12, sep = \"\")) ex_dat_mrg$Time <- ex_dat_mrg$Time/3600 #Convert time to hours ex_dat_mrg <-   mutate(group_by(ex_dat_mrg, Well, Bacteria_strain, Phage),          deriv = calc_deriv(x = Time, y = Measurements),          deriv_percap5 = calc_deriv(x = Time, y = Measurements,                                          percapita = TRUE, blank = 0,                                         window_width_n = 5, trans_y = \"log\"),          doub_time = doubling_time(y = deriv_percap5)) sample_wells <- c(\"A1\", \"F1\", \"F10\", \"E11\") # Drop unneeded columns (optional, but makes things cleaner) ex_dat_mrg <- dplyr::select(ex_dat_mrg,                             Time, Well, Measurements, Bacteria_strain, Phage,                             deriv, deriv_percap5)"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/analyze.html","id":"analyzing-data-with-summarize","dir":"Articles","previous_headings":"","what":"Analyzing data with summarize","title":"Analyzing data","text":"Ultimately, analyzing growth curves requires summarizing entire time series data metric metrics. gcplyr makes easy calculate number metrics interest, ’ve grouped categories:","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/analyze.html","id":"growth","dir":"Articles","previous_headings":"Analyzing data with summarize","what":"Growth","title":"Analyzing data","text":"initial density lag time time reach density time reach growth rate maximum per-capita growth rate (.e. minimum doubling time)","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/analyze.html","id":"saturation","dir":"Articles","previous_headings":"Analyzing data with summarize","what":"Saturation","title":"Analyzing data","text":"mid-point time inflection point maximum density (e.g. carrying capacity)","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/analyze.html","id":"total-growth","dir":"Articles","previous_headings":"Analyzing data with summarize","what":"Total growth","title":"Analyzing data","text":"area curve","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/analyze.html","id":"diauxic-growth","dir":"Articles","previous_headings":"Analyzing data with summarize","what":"Diauxic growth","title":"Analyzing data","text":"density time diauxic shift occurs maximum per-capita growth rate diauxie","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/analyze.html","id":"growth-with-antagonists-e-g--phages","dir":"Articles","previous_headings":"Analyzing data with summarize","what":"Growth with antagonists (e.g. phages)","title":"Analyzing data","text":"peak bacterial density decline (e.g. phage predation) extinction time (e.g. phage predation) following sections show can use gcplyr functions calculate metrics. first, need familiarize one dplyr function: summarize. ? upcoming gcplyr analysis functions must used within dplyr::summarize. ’re already familiar dplyr’s summarize, feel free skip primer next section. ’re familiar yet, don’t worry! Continue next section, provide primer teach need know using summarize gcplyr functions.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/analyze.html","id":"another-brief-primer-on-dplyr-summarize","dir":"Articles","previous_headings":"","what":"Another brief primer on dplyr: summarize","title":"Analyzing data","text":"’re going focus summarize function dplyr, must used group_by function covered first primer: brief primer dplyr. summarize carries user-specified calculations group grouped data.frame independently, producing new data.frame group now just single row. growth curves, means : group_by data every well group summarize well one several metrics , use group_by simply pass data.frame grouped, names columns want group . Since summarize drop columns data aren’t grouped aren’t summarized, typically want list design columns group_by, along plate name well. , make sure ’re grouping Time, Measurements, anything else varies within well, since dplyr group timepoints within well separately. , run summarize. summarize works much like mutate , specify: name variable want results saved function calculates summarized results Just like mutate, want additional summary metrics, simply add summarize. However, unlike mutate, summarize functions return just single value group. ’ll see throughout rest article, ’ll using group_by summarize calculate metrics interest. want learn , dplyr extensive documentation examples online, primer coming example sufficient analyze data gcplyr.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/analyze.html","id":"plotting-summarized-metrics","dir":"Articles","previous_headings":"","what":"Plotting summarized metrics","title":"Analyzing data","text":"’ve calculated summarized metrics, plot original data make sure everything matches expect. can plot summarized values right top original data: density rate metrics can plotted horizontal line geom_hline time metrics can plotted vertical line geom_vline pairs metrics correspond density/rate time can plotted point geom_point ’ll see examples plots throughout article.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/analyze.html","id":"init_dens","dir":"Articles","previous_headings":"","what":"Initial density","title":"Analyzing data","text":"want identify initial density bacteria, often sufficient use min_gc (works just like R’s built-min, better default settings growth curve analyses summarize). can also save time minimum occurs using which_min_gc function. which_min_gc returns index minimum value, can get Time value index save column titled min_time. (which_min_gc extr_val work just like R’s built-.min [, better default settings growth curve analyses summarize)  cases (e.g. growing phages), bacteria may later drop lower density started growth curve. case, want first local minima Measurements data, rather global minima: Note can tune sensitivity first_minima different heights widths peaks valleys using window_width, window_width_n, window_height arguments. check first_minima working data plotting , although default sensitivity works much time.","code":"ex_dat_mrg_sum <-    summarize(group_by(ex_dat_mrg, Bacteria_strain, Phage, Well),             min_dens = min_gc(Measurements, na.rm = TRUE),             min_time = extr_val(Time, which_min_gc(Measurements))) #> `summarise()` has grouped output by 'Bacteria_strain', 'Phage'. You can #> override using the `.groups` argument. head(ex_dat_mrg_sum) #> # A tibble: 6 × 5 #> # Groups:   Bacteria_strain, Phage [6] #>   Bacteria_strain Phage       Well  min_dens min_time #>   <chr>           <chr>       <fct>    <dbl>    <dbl> #> 1 Strain 1        No Phage    A1       0.002     0    #> 2 Strain 1        Phage Added A7       0.001     9.75 #> 3 Strain 10       No Phage    B4       0.002     0    #> 4 Strain 10       Phage Added B10      0.001    11    #> 5 Strain 11       No Phage    B5       0.002     0    #> 6 Strain 11       Phage Added B11      0.001     6  ggplot(data = dplyr::filter(ex_dat_mrg, Well %in% sample_wells),        aes(x = Time, y = Measurements)) +   geom_line() +   facet_wrap(~Well) +   geom_point(data = dplyr::filter(ex_dat_mrg_sum, Well %in% sample_wells),               aes(x = min_time, y = min_dens),              size = 2, color = \"red\") ex_dat_mrg_sum <-    summarize(group_by(ex_dat_mrg, Bacteria_strain, Phage, Well),             min_dens = first_minima(y = Measurements, x = Time, return = \"y\"),             min_time = first_minima(y = Measurements, x = Time, return = \"x\")) #> `summarise()` has grouped output by 'Bacteria_strain', 'Phage'. You can #> override using the `.groups` argument. head(ex_dat_mrg_sum) #> # A tibble: 6 × 5 #> # Groups:   Bacteria_strain, Phage [6] #>   Bacteria_strain Phage       Well  min_dens min_time #>   <chr>           <chr>       <fct>    <dbl>    <dbl> #> 1 Strain 1        No Phage    A1       0.002        0 #> 2 Strain 1        Phage Added A7       0.002        0 #> 3 Strain 10       No Phage    B4       0.002        0 #> 4 Strain 10       Phage Added B10      0.002        0 #> 5 Strain 11       No Phage    B5       0.002        0 #> 6 Strain 11       Phage Added B11      0.002        0"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/analyze.html","id":"lag","dir":"Articles","previous_headings":"","what":"Lag time","title":"Analyzing data","text":"Bacteria often period time reach maximum growth rate. like quantify lag time, can use lag_time function. lag_time needs x y values, well (per-capita) derivative. find maximum derivative, project tangent line slope back crosses starting density. , calculate lag time. can see visualization tangent-line calculation , also calculate max_percap, max_percap_time, max_percap_dens, min_dens, don’t .  Notice wells minimum density value isn’t initial density? can fix overriding default minimum density calculation first_minima via y0 argument lag_time.","code":"ex_dat_mrg_sum <-    summarize(group_by(ex_dat_mrg, Bacteria_strain, Phage, Well),             lag_time = lag_time(y = Measurements, x = Time,                                  deriv = deriv_percap5),             max_percap = max_gc(deriv_percap5),             max_percap_time = Time[which_max_gc(deriv_percap5)],             max_percap_dens = Measurements[which_max_gc(deriv_percap5)],             min_dens = min_gc(Measurements)) #> `summarise()` has grouped output by 'Bacteria_strain', 'Phage'. You can #> override using the `.groups` argument. head(ex_dat_mrg_sum) #> # A tibble: 6 × 8 #> # Groups:   Bacteria_strain, Phage [6] #>   Bacteria_strain Phage       Well  lag_time max_percap max_percap_time #>   <chr>           <chr>       <fct>    <dbl>      <dbl>           <dbl> #> 1 Strain 1        No Phage    A1        2.18       1.03            4.25 #> 2 Strain 1        Phage Added A7        1.51       1.03            4.25 #> 3 Strain 10       No Phage    B4        1.78       1.59            3.5  #> 4 Strain 10       Phage Added B10       1.34       1.59            3.5  #> 5 Strain 11       No Phage    B5        1.67       1.65            3.5  #> 6 Strain 11       Phage Added B11       1.24       1.65            3.5  #> # ℹ 2 more variables: max_percap_dens <dbl>, min_dens <dbl>  ggplot(data = dplyr::filter(ex_dat_mrg, Well %in% sample_wells),        aes(x = Time, y = log(Measurements))) +   geom_point() +   facet_wrap(~Well) +   geom_abline(data = dplyr::filter(ex_dat_mrg_sum, Well %in% sample_wells),               color = \"red\",               aes(slope = max_percap,                   intercept = log(max_percap_dens) - max_percap*max_percap_time)) +   geom_vline(data = dplyr::filter(ex_dat_mrg_sum, Well %in% sample_wells),              aes(xintercept = lag_time), lty = 2) +   geom_hline(data = dplyr::filter(ex_dat_mrg_sum, Well %in% sample_wells),              aes(yintercept = log(min_dens))) ex_dat_mrg_sum <-    summarize(group_by(ex_dat_mrg, Bacteria_strain, Phage, Well),             min_dens = first_minima(Measurements, return = \"y\"),             lag_time = lag_time(y = Measurements, x = Time,                                  deriv = deriv_percap5, y0 = min_dens),             max_percap = max_gc(deriv_percap5),             max_percap_time = Time[which_max_gc(deriv_percap5)],             max_percap_dens = Measurements[which_max_gc(deriv_percap5)]) #> `summarise()` has grouped output by 'Bacteria_strain', 'Phage'. You can #> override using the `.groups` argument. head(ex_dat_mrg_sum) #> # A tibble: 6 × 8 #> # Groups:   Bacteria_strain, Phage [6] #>   Bacteria_strain Phage       Well  min_dens lag_time max_percap max_percap_time #>   <chr>           <chr>       <fct>    <dbl>    <dbl>      <dbl>           <dbl> #> 1 Strain 1        No Phage    A1       0.002     2.18       1.03            4.25 #> 2 Strain 1        Phage Added A7       0.002     2.18       1.03            4.25 #> 3 Strain 10       No Phage    B4       0.002     1.78       1.59            3.5  #> 4 Strain 10       Phage Added B10      0.002     1.78       1.59            3.5  #> 5 Strain 11       No Phage    B5       0.002     1.67       1.65            3.5  #> 6 Strain 11       Phage Added B11      0.002     1.67       1.65            3.5  #> # ℹ 1 more variable: max_percap_dens <dbl>  ggplot(data = dplyr::filter(ex_dat_mrg, Well %in% sample_wells),        aes(x = Time, y = log(Measurements))) +   geom_point() +   facet_wrap(~Well) +   geom_abline(data = dplyr::filter(ex_dat_mrg_sum, Well %in% sample_wells),               color = \"red\",               aes(slope = max_percap,                   intercept = log(max_percap_dens) - max_percap*max_percap_time)) +   geom_vline(data = dplyr::filter(ex_dat_mrg_sum, Well %in% sample_wells),              aes(xintercept = lag_time), lty = 2) +   geom_hline(data = dplyr::filter(ex_dat_mrg_sum, Well %in% sample_wells),              aes(yintercept = log(min_dens)))"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/analyze.html","id":"dens_thresh","dir":"Articles","previous_headings":"","what":"Time to reach threshold density","title":"Analyzing data","text":"want quantify long takes bacteria reach threshold density, can use first_above function. example, ’ll use Measurements value 0.1 threshold.","code":"ex_dat_mrg_sum <-    summarize(group_by(ex_dat_mrg, Bacteria_strain, Phage, Well),             above_01 = first_above(y = Measurements, x = Time,                                     threshold = 0.1, return = \"x\")) #> `summarise()` has grouped output by 'Bacteria_strain', 'Phage'. You can #> override using the `.groups` argument. head(ex_dat_mrg_sum) #> # A tibble: 6 × 4 #> # Groups:   Bacteria_strain, Phage [6] #>   Bacteria_strain Phage       Well  above_01 #>   <chr>           <chr>       <fct>    <dbl> #> 1 Strain 1        No Phage    A1        6.09 #> 2 Strain 1        Phage Added A7        6.09 #> 3 Strain 10       No Phage    B4        4.25 #> 4 Strain 10       Phage Added B10       4.25 #> 5 Strain 11       No Phage    B5        4.04 #> 6 Strain 11       Phage Added B11       4.04  ggplot(data = dplyr::filter(ex_dat_mrg, Well %in% sample_wells),        aes(x = Time, y = Measurements)) +   geom_line() +   facet_wrap(~Well) +   geom_vline(data = dplyr::filter(ex_dat_mrg_sum, Well %in% sample_wells),               aes(xintercept = above_01), lty = 2, color = \"red\")"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/analyze.html","id":"percap_thresh","dir":"Articles","previous_headings":"","what":"Time to reach threshold growth rate","title":"Analyzing data","text":"want quantify long takes bacteria reach threshold per-capita growth rate, can use first_above function. example, ’ll use per-capita derivative 1 threshold.","code":"ex_dat_mrg_sum <-    summarize(group_by(ex_dat_mrg, Bacteria_strain, Phage, Well),             percap_above_1 = first_above(y = deriv_percap5, x = Time,                                     threshold = 1, return = \"x\")) #> `summarise()` has grouped output by 'Bacteria_strain', 'Phage'. You can #> override using the `.groups` argument. head(ex_dat_mrg_sum) #> # A tibble: 6 × 4 #> # Groups:   Bacteria_strain, Phage [6] #>   Bacteria_strain Phage       Well  percap_above_1 #>   <chr>           <chr>       <fct>          <dbl> #> 1 Strain 1        No Phage    A1              3.95 #> 2 Strain 1        Phage Added A7              3.95 #> 3 Strain 10       No Phage    B4              2.28 #> 4 Strain 10       Phage Added B10             2.28 #> 5 Strain 11       No Phage    B5              2.11 #> 6 Strain 11       Phage Added B11             2.11  ggplot(data = dplyr::filter(ex_dat_mrg, Well %in% sample_wells),        aes(x = Time, y = deriv_percap5)) +   geom_line() +   facet_wrap(~Well) +   geom_vline(data = dplyr::filter(ex_dat_mrg_sum, Well %in% sample_wells),              aes(xintercept = percap_above_1), lty = 2, color = \"red\") +   coord_cartesian(ylim = c(-1, NA)) #> Warning: Removed 4 rows containing missing values (`geom_line()`). #> Warning: Removed 2 rows containing missing values (`geom_vline()`)."},{"path":"https://mikeblazanin.github.io/gcplyr/articles/analyze.html","id":"max_percap","dir":"Articles","previous_headings":"","what":"Maximum growth rate and minimum doubling time","title":"Analyzing data","text":"want calculate bacterial maximum growth rate (.e. minimum doubling time), often sufficient use max_gc per-capita derivatives calculated vignette(\"process\"). (max_gc works just like R’s built-max, better default settings growth curve analyses summarize). can also save time maximum occurs using which_max_gc function. which_max_gc returns index maximum value, can get Time value index save column titled max_percap_time. (which_max_gc extr_val work just like R’s built-.max [, better default settings growth curve analyses summarize) like equivalent minimum doubling time, can simply calculate maximum growth rate convert equivalent minimum doubling time using doubling_time function.","code":"ex_dat_mrg_sum <-    summarize(group_by(ex_dat_mrg, Bacteria_strain, Phage, Well),             max_percap = max_gc(deriv_percap5, na.rm = TRUE),             max_percap_time = extr_val(Time, which_max_gc(deriv_percap5)),             doub_time = doubling_time(y = max_percap)) #> `summarise()` has grouped output by 'Bacteria_strain', 'Phage'. You can #> override using the `.groups` argument. head(ex_dat_mrg_sum) #> # A tibble: 6 × 6 #> # Groups:   Bacteria_strain, Phage [6] #>   Bacteria_strain Phage       Well  max_percap max_percap_time doub_time #>   <chr>           <chr>       <fct>      <dbl>           <dbl>     <dbl> #> 1 Strain 1        No Phage    A1          1.03            4.25     0.670 #> 2 Strain 1        Phage Added A7          1.03            4.25     0.670 #> 3 Strain 10       No Phage    B4          1.59            3.5      0.436 #> 4 Strain 10       Phage Added B10         1.59            3.5      0.436 #> 5 Strain 11       No Phage    B5          1.65            3.5      0.421 #> 6 Strain 11       Phage Added B11         1.65            3.5      0.421  ggplot(data = dplyr::filter(ex_dat_mrg, Well %in% sample_wells),        aes(x = Time, y = deriv_percap5)) +   geom_line() +   facet_wrap(~Well) +   geom_point(data = dplyr::filter(ex_dat_mrg_sum, Well %in% sample_wells),               aes(x = max_percap_time, y = max_percap),              size = 2, color = \"red\") +   coord_cartesian(ylim = c(-1, NA)) #> Warning: Removed 4 rows containing missing values (`geom_line()`)."},{"path":"https://mikeblazanin.github.io/gcplyr/articles/analyze.html","id":"midpoint","dir":"Articles","previous_headings":"","what":"Mid-point time or inflection point","title":"Analyzing data","text":"want find mid-point inflection point bacterial growth, two different approaches: Mid-point: find point density first reaches half maximum density. Inflection point: find point derivative maximum. growth curve analysis approaches using fitting symmetric function (e.g. R packages fit logistic function data), two points equivalent. However, since gcplyr model-free analyses, assume symmetry, points may similar different. mid-point, use first_above function, threshold equal maximum bacterial density divided 2. inflection point, find time deriv maximum using which_max_gc (which_max_gc extr_val work just like R’s built-.max [, better default settings growth curve analyses summarize).","code":"ex_dat_mrg_sum <-    summarize(group_by(ex_dat_mrg, Bacteria_strain, Phage, Well),             mid_point = first_above(y = Measurements, x = Time, return = \"x\",                                     threshold = max_gc(Measurements)/2),             infl_point = extr_val(Time, which_max_gc(deriv))) #> `summarise()` has grouped output by 'Bacteria_strain', 'Phage'. You can #> override using the `.groups` argument. head(ex_dat_mrg_sum) #> # A tibble: 6 × 5 #> # Groups:   Bacteria_strain, Phage [6] #>   Bacteria_strain Phage       Well  mid_point infl_point #>   <chr>           <chr>       <fct>     <dbl>      <dbl> #> 1 Strain 1        No Phage    A1         9.15       8.25 #> 2 Strain 1        Phage Added A7         7.29       8.25 #> 3 Strain 10       No Phage    B4         6.06       5.5  #> 4 Strain 10       Phage Added B10        5.67       5.5  #> 5 Strain 11       No Phage    B5         5.71       5    #> 6 Strain 11       Phage Added B11       16.7        5  ggplot(data = dplyr::filter(ex_dat_mrg, Well %in% sample_wells),        aes(x = Time, y = Measurements)) +   geom_line() +   facet_wrap(~Well) +   geom_vline(data = dplyr::filter(ex_dat_mrg_sum, Well %in% sample_wells),              aes(xintercept = mid_point), lty = 2, color = \"red\") +   geom_vline(data = dplyr::filter(ex_dat_mrg_sum, Well %in% sample_wells),              aes(xintercept = infl_point), lty = 2, color = \"blue\")"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/analyze.html","id":"maxdens","dir":"Articles","previous_headings":"","what":"Maximum density","title":"Analyzing data","text":"maximum bacterial density can measure bacterial carrying capacity given media measure bacterial growth yield/efficiency. want quantify maximum bacterial density, can use max_gc get global maxima Measurements (max_gc, which_max_gc, extr_val work just like R’s built-max, .max, [, better default settings growth curve analyses summarize). See Peak bacterial density identifying local maxima Measurements (e.g. wanted first peak Well E11 shown ).","code":"ex_dat_mrg_sum <-    summarize(group_by(ex_dat_mrg, Bacteria_strain, Phage, Well),             max_dens = max_gc(Measurements, na.rm = TRUE),             max_time = extr_val(Time, which_max_gc(Measurements))) #> `summarise()` has grouped output by 'Bacteria_strain', 'Phage'. You can #> override using the `.groups` argument. head(ex_dat_mrg_sum) #> # A tibble: 6 × 5 #> # Groups:   Bacteria_strain, Phage [6] #>   Bacteria_strain Phage       Well  max_dens max_time #>   <chr>           <chr>       <fct>    <dbl>    <dbl> #> 1 Strain 1        No Phage    A1       1.18     24    #> 2 Strain 1        Phage Added A7       0.499     8.75 #> 3 Strain 10       No Phage    B4       1.21     23.8  #> 4 Strain 10       Phage Added B10      0.962     8.5  #> 5 Strain 11       No Phage    B5       1.21     19.5  #> 6 Strain 11       Phage Added B11      1.03     24  ggplot(data = dplyr::filter(ex_dat_mrg, Well %in% sample_wells),        aes(x = Time, y = Measurements)) +   geom_line() +   facet_wrap(~Well) +   geom_point(data = dplyr::filter(ex_dat_mrg_sum, Well %in% sample_wells),               aes(x = max_time, y = max_dens),              size = 2, color = \"red\")"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/analyze.html","id":"auc","dir":"Articles","previous_headings":"","what":"Area under the curve","title":"Analyzing data","text":"area curve common metric total bacterial growth, instance presence antagonists like antibiotics phages. want calculate area curve, can use gcplyr function auc. Simply specify Time x Measurements y data whose area---curve want calculate.","code":"ex_dat_mrg_sum <-   summarize(group_by(ex_dat_mrg, Bacteria_strain, Phage, Well),             auc = auc(x = Time, y = Measurements)) #> `summarise()` has grouped output by 'Bacteria_strain', 'Phage'. You can #> override using the `.groups` argument. head(ex_dat_mrg_sum) #> # A tibble: 6 × 4 #> # Groups:   Bacteria_strain, Phage [6] #>   Bacteria_strain Phage       Well    auc #>   <chr>           <chr>       <fct> <dbl> #> 1 Strain 1        No Phage    A1    15.9  #> 2 Strain 1        Phage Added A7     1.07 #> 3 Strain 10       No Phage    B4    20.4  #> 4 Strain 10       Phage Added B10    6.15 #> 5 Strain 11       No Phage    B5    20.9  #> 6 Strain 11       Phage Added B11    7.77"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/analyze.html","id":"diauxie","dir":"Articles","previous_headings":"","what":"Diauxic shifts","title":"Analyzing data","text":"Bacteria frequently exhibit second, slower, burst growth first period rapid growth. common growth curves called diauxic growth. plot data example data wells phage added, ’ll see pattern repeatedly:  can identify time bacteria switch first period rapid growth second period finding minima derivative values. Specifically, want identify second minima (first minima occur beginning growth curve, bacteria just starting grow). Let’s look derivative values see .  can use gcplyr function find_local_extrema find minima. Specify deriv y data Time x data, want find_local_extrema return x values associated local minima. return vector x values, ’re going save just second one. time, ’re also going save density diauxic shift occurs. First, ’ll use find_local_extrema , time save index diauxic shift occurs column titled diauxie_idx. , can get Measurements value index. (Note wouldn’t work just specify return = \"y\", y values case deriv values). (extr_val works just like R’s built-[, better default settings growth curve analyses summarize).  needed, can tune sensitivity find_local_extrema different heights widths peaks valleys using window_width, window_width_n, window_height arguments.","code":"nophage_wells <- c(\"A1\", \"A4\", \"E2\", \"F1\") ggplot(data = dplyr::filter(ex_dat_mrg, Well %in% nophage_wells),        aes(x = Time, y = Measurements)) +   geom_line() +   facet_wrap(~Well, scales = \"free\") ggplot(data = dplyr::filter(ex_dat_mrg, Well %in% nophage_wells),        aes(x = Time, y = deriv)) +   geom_line() +   facet_wrap(~Well, scales = \"free\") #> Warning: Removed 1 row containing missing values (`geom_line()`). ex_dat_mrg_sum <-   summarize(group_by(ex_dat_mrg, Bacteria_strain, Phage, Well),     diauxie_time = find_local_extrema(x = Time, y = deriv, return = \"x\",                                    return_maxima = FALSE, return_minima = TRUE,                                    window_width_n = 39)[2],     diauxie_idx = find_local_extrema(x = Time, y = deriv, return = \"index\",                                    return_maxima = FALSE, return_minima = TRUE,                                    window_width_n = 39)[2],     diauxie_dens = extr_val(Measurements, diauxie_idx)) #> `summarise()` has grouped output by 'Bacteria_strain', 'Phage'. You can #> override using the `.groups` argument. head(ex_dat_mrg_sum) #> # A tibble: 6 × 6 #> # Groups:   Bacteria_strain, Phage [6] #>   Bacteria_strain Phage       Well  diauxie_time diauxie_idx diauxie_dens #>   <chr>           <chr>       <fct>        <dbl>       <int>        <dbl> #> 1 Strain 1        No Phage    A1           16             65        1.01  #> 2 Strain 1        Phage Added A7            9             37        0.379 #> 3 Strain 10       No Phage    B4            9.75          40        0.999 #> 4 Strain 10       Phage Added B10           9.25          38        0.682 #> 5 Strain 11       No Phage    B5            9.5           39        1.01  #> 6 Strain 11       Phage Added B11           5.5           23        0.346  # Plot data with a point at the moment of diauxic shift ggplot(data = dplyr::filter(ex_dat_mrg, Well %in% nophage_wells),        aes(x = Time, y = Measurements)) +   geom_line() +   facet_wrap(~Well, scales = \"free\") +   geom_point(data = dplyr::filter(ex_dat_mrg_sum, Well %in% nophage_wells),               aes(x = diauxie_time, y = diauxie_dens),              size = 2, color = \"red\")"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/analyze.html","id":"diauxic_percap","dir":"Articles","previous_headings":"","what":"Growth rate during diauxie","title":"Analyzing data","text":"previous section identified bacteria shifted second period rapid growth (‘diauxic growth’). want find peak per-capita growth rate second burst, ’ll use max subset data diauxic shift identified find_local_extrema Just previous section, ’ll use find_local_extrema save time diauxic shift occurs. , ’ll find maximum per-capita derivative shift occurs. Finally, ’ll find time post-diauxie maximum growth rate occurs. Note ’re using max_gc which_max_gc, work just like R’s built-max .max, better default settings growth curve analyses summarize.","code":"ex_dat_mrg_sum <-   summarize(     group_by(ex_dat_mrg, Bacteria_strain, Phage, Well),     diauxie_time =        find_local_extrema(x = Time, y = deriv, return = \"x\",                          return_maxima = FALSE, return_minima = TRUE,                          window_width_n = 39)[2],     diauxie_percap = max_gc(deriv_percap5[Time >= diauxie_time]),     diauxie_percap_time =        extr_val(Time[Time >= diauxie_time],                which_max_gc(deriv_percap5[Time >= diauxie_time]))   ) #> `summarise()` has grouped output by 'Bacteria_strain', 'Phage'. You can #> override using the `.groups` argument. head(ex_dat_mrg_sum) #> # A tibble: 6 × 6 #> # Groups:   Bacteria_strain, Phage [6] #>   Bacteria_strain Phage    Well  diauxie_time diauxie_percap diauxie_percap_time #>   <chr>           <chr>    <fct>        <dbl>          <dbl>               <dbl> #> 1 Strain 1        No Phage A1           16            0.0257                20   #> 2 Strain 1        Phage A… A7            9            0.832                 19.8 #> 3 Strain 10       No Phage B4            9.75         0.0398                13.2 #> 4 Strain 10       Phage A… B10           9.25         1.24                  17.8 #> 5 Strain 11       No Phage B5            9.5          0.0438                12.2 #> 6 Strain 11       Phage A… B11           5.5          1.43                  12.8  # Plot data with a point at the moment of peak diauxic growth rate ggplot(data = dplyr::filter(ex_dat_mrg, Well %in% nophage_wells),        aes(x = Time, y = deriv_percap5)) +   geom_line() +   facet_wrap(~Well, scales = \"free\") +   geom_point(data = dplyr::filter(ex_dat_mrg_sum, Well %in% nophage_wells),               aes(x = diauxie_percap_time, y = diauxie_percap),              size = 2, color = \"red\") #> Warning: Removed 4 rows containing missing values (`geom_line()`)."},{"path":"https://mikeblazanin.github.io/gcplyr/articles/analyze.html","id":"peak_dens","dir":"Articles","previous_headings":"","what":"Peak bacterial density","title":"Analyzing data","text":"previously found global maximum bacterial density using simple max_gc which_max_gc functions. first local maxima can also interest. especially true bacteria grown phages, first peak density can act proxy measure susceptibility phage. ’re interested finding first local maxima bacterial density, can use gcplyr function first_maxima. first_maxima simply requires y data want identify peak . Specify Measurements y data Time x data, want first_peak return x y values associated peak. ’ll save columns first_maxima_x first_maxima_y, respectively.  Note can tune sensitivity first_maxima different heights widths peaks valleys using window_width, window_width_n, window_height arguments, although defaults work much time.","code":"ex_dat_mrg_sum <-   summarize(group_by(ex_dat_mrg, Bacteria_strain, Phage, Well),             first_maxima_x = first_maxima(x = Time, y = Measurements,                                            return = \"x\"),             first_maxima_y = first_maxima(x = Time, y = Measurements,                                            return = \"y\")) #> `summarise()` has grouped output by 'Bacteria_strain', 'Phage'. You can #> override using the `.groups` argument. head(ex_dat_mrg_sum) #> # A tibble: 6 × 5 #> # Groups:   Bacteria_strain, Phage [6] #>   Bacteria_strain Phage       Well  first_maxima_x first_maxima_y #>   <chr>           <chr>       <fct>          <dbl>          <dbl> #> 1 Strain 1        No Phage    A1             24             1.18  #> 2 Strain 1        Phage Added A7              8.75          0.499 #> 3 Strain 10       No Phage    B4             19.8           1.21  #> 4 Strain 10       Phage Added B10             8.5           0.962 #> 5 Strain 11       No Phage    B5             19.5           1.21  #> 6 Strain 11       Phage Added B11             5.25          0.439  ggplot(data = dplyr::filter(ex_dat_mrg, Well %in% sample_wells),         aes(x = Time, y = Measurements)) +   geom_line() +   facet_wrap(~Well) +   geom_point(data = dplyr::filter(ex_dat_mrg_sum, Well %in% sample_wells),               aes(x = first_maxima_x, y = first_maxima_y),               color = \"red\", size = 1.5)"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/analyze.html","id":"extin_time","dir":"Articles","previous_headings":"","what":"Extinction time","title":"Analyzing data","text":"time bacterial density falls threshold can also interest. especially true bacteria grown phages, ‘extinction time’ can act proxy measure susceptibility phage. ’re interested finding extinction time, can use gcplyr function first_below. example, ’ll use Measurements value 0.15 threshold.","code":"ex_dat_mrg_sum <-   summarize(     group_by(ex_dat_mrg, Bacteria_strain, Phage, Well),     extin_time = first_below(x = Time, y = Measurements, threshold = 0.15,                              return = \"x\", return_endpoints = FALSE)) #> `summarise()` has grouped output by 'Bacteria_strain', 'Phage'. You can #> override using the `.groups` argument. head(ex_dat_mrg_sum) #> # A tibble: 6 × 4 #> # Groups:   Bacteria_strain, Phage [6] #>   Bacteria_strain Phage       Well  extin_time #>   <chr>           <chr>       <fct>      <dbl> #> 1 Strain 1        No Phage    A1         NA    #> 2 Strain 1        Phage Added A7          9.18 #> 3 Strain 10       No Phage    B4         NA    #> 4 Strain 10       Phage Added B10         9.71 #> 5 Strain 11       No Phage    B5         NA    #> 6 Strain 11       Phage Added B11         5.64  phage_wells <- c(\"A7\", \"B10\", \"F10\", \"H8\") ggplot(data = dplyr::filter(ex_dat_mrg, Well %in% phage_wells),        aes(x = Time, y = Measurements)) +   geom_line() +   facet_wrap(~Well) +   geom_vline(data = dplyr::filter(ex_dat_mrg_sum, Well %in% phage_wells),              aes(xintercept = extin_time), lty = 2)"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/analyze.html","id":"whats-next","dir":"Articles","previous_headings":"","what":"What’s next?","title":"Analyzing data","text":"Now ’ve analyzed data, can read approaches deal noise growth curve data, can read concluding notes best practices running statistics, merging growth curve analyses data, additional resources analyzing growth curves. Introduction: vignette(\"gcplyr\") Importing transforming data: vignette(\"import_transform\") Incorporating design information: vignette(\"incorporate_designs\") Pre-processing plotting data: vignette(\"preprocess_plot\") Processing data: vignette(\"process\") Analyzing data: vignette(\"analyze\") Dealing noise: vignette(\"noise\") Statistics, merging data, resources: vignette(\"conclusion\")","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/conclusion.html","id":"where-are-we-so-far","dir":"Articles","previous_headings":"","what":"Where are we so far?","title":"Statistics, merging other data, and other resources","text":"Introduction: vignette(\"gcplyr\") Importing transforming data: vignette(\"import_transform\") Incorporating design information: vignette(\"incorporate_designs\") Pre-processing plotting data: vignette(\"preprocess_plot\") Processing data: vignette(\"process\") Analyzing data: vignette(\"analyze\") Dealing noise: vignette(\"noise\") Statistics, merging data, resources: vignette(\"conclusion\") far, ’ve imported transformed measures, combined design information, pre-processed, processed, plotted, analyzed data. things left notes best practices running statistics, merging growth curve analyses data, additional resources analyzing growth curves. haven’t already, load necessary packages.","code":"library(gcplyr) #> ##  #> ## gcplyr (Version 1.5.0, Build Date: 2023-04-03) #> ## See http://github.com/mikeblazanin/gcplyr for additional documentation #> ## Please cite software as: #> ##   Blazanin, Michael. 2023. 'gcplyr: manipulate and analyze growth #> ##   curve data.' R package version 1.5.0 #> ##  library(dplyr) #>  #> Attaching package: 'dplyr' #> The following objects are masked from 'package:stats': #>  #>     filter, lag #> The following objects are masked from 'package:base': #>  #>     intersect, setdiff, setequal, union library(ggplot2) # This code was previously explained # Here we're re-running it so it's available for us to work with example_tidydata <- trans_wide_to_tidy(example_widedata_noiseless,                                        id_cols = \"Time\") example_design <- make_design(   pattern_split = \",\", nrows = 8, ncols = 12,   \"Bacteria_strain\" = make_designpattern(     values = paste(\"Strain\", 1:48),     rows = 1:8, cols = 1:6, pattern = 1:48, byrow = TRUE),   \"Bacteria_strain\" = make_designpattern(     values = paste(\"Strain\", 1:48),     rows = 1:8, cols = 7:12, pattern = 1:48, byrow = TRUE),   \"Phage\" = make_designpattern(     values = c(\"No Phage\"), rows = 1:8, cols = 1:6, pattern = \"1\"),   \"Phage\" = make_designpattern(     values = c(\"Phage Added\"), rows = 1:8, cols = 7:12, pattern = \"1\")) ex_dat_mrg <- merge_dfs(example_tidydata, example_design) #> Joining with `by = join_by(Well)` ex_dat_mrg$Well <-    factor(ex_dat_mrg$Well,          levels = paste(rep(LETTERS[1:8], each = 12), 1:12, sep = \"\")) ex_dat_mrg <- group_by(ex_dat_mrg, Well, Bacteria_strain, Phage)  ex_dat_mrg <-   mutate(ex_dat_mrg,          smoothed_med3 =             smooth_data(x = Time, y = Measurements,                        sm_method = \"moving-median\", window_width_n = 3),          # Note that for the second round, we're using the           # first smoothing as the input y          smoothed =             smooth_data(x = Time, y = smoothed_med3,                        sm_method = \"moving-average\", window_width_n = 3))"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/conclusion.html","id":"statistical-analyses-of-growth-curves-data","dir":"Articles","previous_headings":"","what":"Statistical analyses of growth curves data","title":"Statistics, merging other data, and other resources","text":"point, ’ve now summarized growth curves data metrics. can best go drawing statistical conclusions data?","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/conclusion.html","id":"when-should-we-average-replicates","dir":"Articles","previous_headings":"Statistical analyses of growth curves data","what":"When should we average replicates?","title":"Statistics, merging other data, and other resources","text":"dig next, want emphasize something workflow: averaging different wells together summarization. opinion, averaging occur summarization, . ? Even wells contents (.e. technical replicates) can still differ growth due biological variation (e.g. stochastic growth dynamics). average density values beginning, may introduce bias ability visualize assess biological variation present data. Let’s look simple example demonstrate point. ’m going simulate bacterial growth using Baranyi-Roberts mathematical model growth, logistic growth period acclimation beginning: \\[\\frac{dN}{dt} = \\frac{q_{0}}{q_{0} + e^{-mt}} * r N\\left(1-\\frac{N}{k}\\right)\\] \\(N\\) population size, \\(q_{0}\\) parameter controlling initial acclimatization state population, \\(m\\) rate acclimation, \\(r\\) rate growth, \\(k\\) carrying capacity population. code , simulate growth 96 different wells bacteria. bacteria identical, except differ rate acclimate.  ’ve plotted individual well black, “average well” plotted red. can clearly see different wells varying quickly ’re acclimating. average well appears reflect data pretty well, give good measure average maximum per-capita growth rate?  can see maximum growth rate “average well” (red line) true average maximum growth rate wells (dashed line). bias might seem small, fact consistent: ran simulation many times, “average well” growth rate nearly always lower true average growth rate. Moreover, bias extends many statistics well. Thus, recommend averaging wells together summarizing, since often introduces bias eliminates ability visualize variation replicates.","code":"# Define the function that calculates density according to Baranyi-Roberts eq baranyi_gr <- function(r, k, q0, m, init_dens, times) {   # Note: these eqs are the integral of the dN/dt eq in the text above   # Acclimation function   a <- times + 1/m*log((exp(-m*times)+q0)/(1+q0))   # Density function   return(k/(1-(1-(k/init_dens))*exp(-r*a))) }  # Set up our wide-shaped data frame times <- seq(from = 0, to = 24*60, by = 15) sim_dat <- as.data.frame(matrix(NA, nrow = length(times), ncol = 98)) sim_dat[, 1] <- times colnames(sim_dat) <- c(\"time\", \"averaged\", paste(\"Well\", 1:96, sep = \"\"))  # Simulate growth for (i in 3:ncol(sim_dat)) {   sim_dat[, i] <- baranyi_gr(times = sim_dat$time,                               r = 0.02, k = 1, q0 = 0.01,                              m = runif(1, min = 0.01, max = 0.02),                              #m = rgamma(n = 1, shape = 2, scale = 0.02/2),                              init_dens = 0.001) }  # Calculate the \"average well\" sim_dat[, \"averaged\"] <- rowMeans(sim_dat[, 3:ncol(sim_dat)])  # Transform to tidy and calculate per-capita growth rate                   sim_dat_tdy <- trans_wide_to_tidy(sim_dat, id_cols = \"time\") sim_dat_tdy <- mutate(group_by(sim_dat_tdy, Well),                       percap_deriv = calc_deriv(y = Measurements, x = time,                                                 percapita = TRUE, blank = 0))  # Plot the growth in our wells ggplot(data = filter(sim_dat_tdy, Well != \"averaged\"),         aes(x = time, y = Measurements, group = Well)) +   geom_line(alpha = 0.1) +   geom_line(data = filter(sim_dat_tdy, Well == \"averaged\"), color = \"red\") +   scale_y_continuous(trans = \"log10\") # Summarize our data sim_dat_sum <- summarize(group_by(sim_dat_tdy, Well),                          max_growth_rate = max(percap_deriv, na.rm = TRUE))  # Plot the maximum per-capita growth rates of each well #  Add a red line for the max growth rate of the \"average well\" #  Add a dashed line for the average growth rate of all the wells ggplot(data = filter(sim_dat_sum, Well != \"averaged\"),         aes(x = max_growth_rate)) +   geom_histogram() +   geom_vline(data = filter(sim_dat_sum, Well == \"averaged\"),               aes(xintercept = max_growth_rate), color = \"red\") +   geom_vline(xintercept =                 mean(filter(sim_dat_sum, Well != \"averaged\")$max_growth_rate),              lty = 2) #> `stat_bin()` using `bins = 30`. Pick better value with `binwidth`."},{"path":"https://mikeblazanin.github.io/gcplyr/articles/conclusion.html","id":"carrying-out-statistical-testing","dir":"Articles","previous_headings":"Statistical analyses of growth curves data","what":"Carrying out statistical testing","title":"Statistics, merging other data, and other resources","text":"go running statistics analyzed growth curve data? Typically, growth curves experiments highly nested structure. probably multiple wells contents (.e. technical replicates) plate. may also multiple plates different runs (creating possibility batch effects). order pull apart effects test differences treatments, ’ll likely need mixed-effects modeling. Unfortunately, ’s beyond scope vignette provide sufficient explanation mixed-effects statistics. However, can provide guidance: frequentist statistics, R package lme4 one -popular implementations mixed-effects modeling. Bayesian statistics, R packages brms rstanarm popular implementations can incorporate mixed-effects modeling. Regardless approach, : use summarized statistics (e.g. auc, max_growth_rate, lag_time, etc.) response variable use design elements (e.g. Bacteria_strain, Phage) explanatory variables (.e. fixed effects) incorporate random effects technical replicates incorporate random effects potential batch effects -play number excellent resources learn sort mixed-effects modeling, including think good introductory guide process Michael Clark.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/conclusion.html","id":"combining-growth-curves-data-with-other-data","dir":"Articles","previous_headings":"","what":"Combining growth curves data with other data","title":"Statistics, merging other data, and other resources","text":"approach end growth curves analyses, summarized dynamics growth curves one metrics. point, may wish pull sources data compare growth curves metrics. Just like merging multiple growth curves data frames together, can achieved merge_dfs. ’ll focus area---curve metric, just bacteria grown absence phages. Imagine , separately, ’ve measured resistance example bacteria antibiotics, want know ’s relationship antibiotic resistance bacteria growth. ’ll generate mock antibiotic resistance data. Importantly, data must matching headers growth curve data merge_dfs knows merge data.frame’s. ’ll put whether strain resistant antibiotic Antibiotic_resis column, TRUE resistance, FALSE sensitivity. Don’t worry exactly code works, since ’s just simulating data collected lab. Great, now merge two data frames see ’s relationship.  ! can see antibiotic resistant strains (TRUE) smaller area---curve antibiotic sensitive strains (FALSE) (although, fair, simulate data ’d get result).","code":"ex_dat_mrg_sum <-   summarize(dplyr::filter(ex_dat_mrg, Phage == \"No Phage\"),              auc = auc(x = Time, y = smoothed)) #> `summarise()` has grouped output by 'Well', 'Bacteria_strain'. You can override #> using the `.groups` argument. set.seed(123) antibiotic_dat <-    data.frame(Bacteria_strain = paste(\"Strain\", 1:48),              Antibiotic_resis =                 ex_dat_mrg_sum$auc[                  match(paste(\"Strain\", 1:48),                         ex_dat_mrg_sum$Bacteria_strain)] *                 runif(48, 0.5, 1.5) < mean(ex_dat_mrg_sum$auc))  head(antibiotic_dat) #>   Bacteria_strain Antibiotic_resis #> 1        Strain 1             TRUE #> 2        Strain 2            FALSE #> 3        Strain 3             TRUE #> 4        Strain 4            FALSE #> 5        Strain 5            FALSE #> 6        Strain 6             TRUE growth_and_antibiotics <-    merge_dfs(ex_dat_mrg_sum, antibiotic_dat) #> Joining with `by = join_by(Bacteria_strain)` head(growth_and_antibiotics) #> # A tibble: 6 × 5 #> # Groups:   Well, Bacteria_strain [6] #>   Well  Bacteria_strain Phage       auc Antibiotic_resis #>   <fct> <chr>           <chr>     <dbl> <lgl>            #> 1 A1    Strain 1        No Phage 55172. TRUE             #> 2 A2    Strain 2        No Phage 67181. FALSE            #> 3 A3    Strain 3        No Phage 52392  TRUE             #> 4 A4    Strain 4        No Phage 70101. FALSE            #> 5 A5    Strain 5        No Phage 70932. FALSE            #> 6 A6    Strain 6        No Phage 44079. TRUE  ggplot(data = growth_and_antibiotics,         aes(x = Antibiotic_resis, y = auc)) +   geom_point()"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/conclusion.html","id":"other-growth-curve-analysis-packages","dir":"Articles","previous_headings":"","what":"Other growth curve analysis packages","title":"Statistics, merging other data, and other resources","text":"number R packages besides gcplyr facilitate analysis growth curves data. , broadly speaking, two ways analyze growth curves data: directly quantify attributes growth dynamics fit growth dynamics mathematical model, extract parameters fitted model gcplyr focuses manipulation growth curves data first analysis approach (direct quantification growth curves dynamics), many R packages focus fitting growth dynamics mathematical model. Generally, fitting growth dynamics model greater power accurately quantify underlying traits. However, also takes much effort rigorous fitting data model. carefully choose model whose assumptions data meet. also evaluate fits ensure optimization algorithms arrived reasonable solutions. number R packages implement fitting-style approaches, list readers explore . point future, hope incorporate direct examples use tidy-shaped data imported manipulated gcplyr packages. growthcurver QurvE AUDIT (including growr mtpview1) growthrates drc opm grofit R-Biolog growthmodels cellGrowth grofit GCAT CarboLogR biogrowth Additionally, one R package doesn’t implement fitting-style approaches, contain useful functionality plate-reader data analysis: plater","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/conclusion.html","id":"whats-next","dir":"Articles","previous_headings":"","what":"What’s next?","title":"Statistics, merging other data, and other resources","text":"’ve finished documentation. Congratulations! gcplyr powerful framework build additional analyses , since data nicely organized. Feel free reach questions, comments, concerns might . ’d love continue making gcplyr useful others scientific community . can reach mikeblazanin [] gmail [dot] com. Introduction: vignette(\"gcplyr\") Importing transforming data: vignette(\"import_transform\") Incorporating design information: vignette(\"incorporate_designs\") Pre-processing plotting data: vignette(\"preprocess_plot\") Processing data: vignette(\"process\") Analyzing data: vignette(\"analyze\") Dealing noise: vignette(\"noise\") Statistics, merging data, resources: vignette(\"conclusion\")","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gcplyr.html","id":"getting-started","dir":"Articles","previous_headings":"","what":"Getting started","title":"Introduction to using gcplyr","text":"gcplyr package implements number functions make easier import, manipulate, analyze microbial growth data collected multiwell plate readers (“growth curves”). Without gcplyr, importing analyzing plate reader data can complicated process tailored experiment, requiring many lines code. gcplyr many steps now just single line code. document gives introduction use gcplyr step growth curve analysis. get started, need growth curve data file saved computer (.csv, .xls, .xlsx). Users often want combine data information experimental design plate(s). can save information tabular file well, can just keep handy enter directly R (see vignette(\"incorporate_designs\")). Let’s get started loading gcplyr. ’re also going load couple packages ’ll need.","code":"library(gcplyr) #> ##  #> ## gcplyr (Version 1.5.0, Build Date: 2023-04-03) #> ## See http://github.com/mikeblazanin/gcplyr for additional documentation #> ## Please cite software as: #> ##   Blazanin, Michael. 2023. 'gcplyr: manipulate and analyze growth #> ##   curve data.' R package version 1.5.0 #> ##  library(dplyr) #>  #> Attaching package: 'dplyr' #> The following objects are masked from 'package:stats': #>  #>     filter, lag #> The following objects are masked from 'package:base': #>  #>     intersect, setdiff, setequal, union library(ggplot2)"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gcplyr.html","id":"a-quick-demo-of-gcplyr","dir":"Articles","previous_headings":"","what":"A quick demo of gcplyr","title":"Introduction to using gcplyr","text":"digging details, ’s simple demonstration final gcplyr script can look like. script: imports data files created plate reader combines design files created user calculates maximum growth rate area---curve Don’t worry understanding details code works right now. steps explained depth later articles.","code":"# Read in our data #  (our plate reader data is saved in \"widedata.csv\") data_wide <- read_wides(files = \"widedata.csv\")  # Transform our data to be tidy-shaped data_tidy <-    trans_wide_to_tidy(wides = data_wide, id_cols = c(\"file\", \"Time\"))  # Convert our time into hours data_tidy$Time <- as.numeric(data_tidy$Time)/3600  # Import our designs #  (saved in the files Bacteria_strain.csv and Phage.csv) designs <- import_blockdesigns(files = c(\"Bacteria_strain.csv\", \"Phage.csv\"))  # Merge our designs and data data_merged <- merge_dfs(data_tidy, designs) #> Joining with `by = join_by(Well)`  # Plot the data ggplot(data = data_merged,        aes(x = Time, y = Measurements, color = Well)) +   geom_line(aes(lty = Phage)) +    guides(color = \"none\") # Voila! 8 lines of code and all your data is imported & plotted!  # Calculate the per-capita growth rate over time in each well data_merged <- mutate(   group_by(data_merged, Well),   percap_deriv = calc_deriv(y = Measurements, x = Time, percapita = TRUE,                              blank = 0, window_width_n = 5))  # Calculate two common metrics of bacterial growth: #  the maximum growth rate, saving it to a column named max_percap #  the area-under-the-curve, saving it to a column named 'auc' data_sum <- summarize(   group_by(data_merged, Well, Bacteria_strain, Phage),   max_percap = max(percap_deriv, na.rm = TRUE),   auc = auc(y = Measurements, x = as.numeric(Time))) #> `summarise()` has grouped output by 'Well', 'Bacteria_strain'. You can override #> using the `.groups` argument.  # Print some of the max growth rates and auc's head(data_sum) #> # A tibble: 6 × 5 #> # Groups:   Well, Bacteria_strain [6] #>   Well  Bacteria_strain Phage       max_percap    auc #>   <chr> <chr>           <chr>            <dbl>  <dbl> #> 1 A1    Strain 1        No Phage         1.00  15.9   #> 2 A10   Strain 4        Phage Added      1.43   5.57  #> 3 A11   Strain 5        Phage Added      1.47   5.99  #> 4 A12   Strain 6        Phage Added      0.789  0.395 #> 5 A2    Strain 2        No Phage         1.31  19.3   #> 6 A3    Strain 3        No Phage         0.915 15.1  # Plot the results for max growth rate and area under the curve in  #  presence vs absence of phage ggplot(data = data_sum,        aes(x = max_percap, y = auc, color = Phage)) +   geom_point()"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gcplyr.html","id":"whats-next","dir":"Articles","previous_headings":"","what":"What’s next?","title":"Introduction to using gcplyr","text":"Generally, working gcplyr follow number steps, likely one lines code final script. ’ve explained steps page linked . start, ’ll learn import data R transform convenient format. Introduction: vignette(\"gcplyr\") Importing transforming data: vignette(\"import_transform\") Incorporating design information: vignette(\"incorporate_designs\") Pre-processing plotting data: vignette(\"preprocess_plot\") Processing data: vignette(\"process\") Analyzing data: vignette(\"analyze\") Dealing noise: vignette(\"noise\") Statistics, merging data, resources: vignette(\"conclusion\")","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/import_transform.html","id":"where-are-we-so-far","dir":"Articles","previous_headings":"","what":"Where are we so far?","title":"Importing and transforming data","text":"Introduction: vignette(\"gcplyr\") Importing transforming data: vignette(\"import_transform\") Incorporating design information: vignette(\"incorporate_designs\") Pre-processing plotting data: vignette(\"preprocess_plot\") Processing data: vignette(\"process\") Analyzing data: vignette(\"analyze\") Dealing noise: vignette(\"noise\") Statistics, merging data, resources: vignette(\"conclusion\") Previously, gave quick demonstration gcplyr can . , ’re going detail import data R transform better layout. haven’t already, load necessary packages.","code":"library(gcplyr) #> ##  #> ## gcplyr (Version 1.5.0, Build Date: 2023-04-03) #> ## See http://github.com/mikeblazanin/gcplyr for additional documentation #> ## Please cite software as: #> ##   Blazanin, Michael. 2023. 'gcplyr: manipulate and analyze growth #> ##   curve data.' R package version 1.5.0 #> ##"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/import_transform.html","id":"data-layouts","dir":"Articles","previous_headings":"","what":"Data layouts","title":"Importing and transforming data","text":"Growth curve data designs can organized one three different layouts: block-shaped, wide-shaped, tidy-shaped, described . Tidy-shaped data best layout analyses, plate readers output block-shaped wide-shaped data, user-created design files block-shaped. Thus, gcplyr works reshaping block-shaped wide-shaped data tidy-shaped data, running analyses. , can tell layout data ? Block-shaped block-shaped data, organization data corresponds directly layout physical multi-well plate generated . instance, data point third row fourth column data.frame well third row fourth column physical plate. timeseries growth curve data block-shaped consist many separate block-shaped data.frames, corresponding single timepoint. example, block-shaped data.frame 96-well plate (“…” indicating Columns 4 - 10, shown). example, data shown single timepoint. Wide-shaped wide-shaped data, column dataframe corresponds single well plate, row dataframe corresponds single timepoint. Typically, headers contain well names. example, wide-shaped dataframe 96-well plate (, “…” indicates 91 columns A4 - H10, shown). row dataframe corresponds single timepoint. Tidy-shaped tidy-shaped data, single column contains plate reader measurements, unique measurement row. Additional columns specify timepoint, well data comes , design elements. Note , tidy-shaped data, number rows equals number wells times number timepoints. Yes, ’s lot rows! tidy-shaped data best format analyses, common number R packages, including ggplot, ’s sometimes called “long” format.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/import_transform.html","id":"importing-data","dir":"Articles","previous_headings":"","what":"Importing data","title":"Importing and transforming data","text":"’ve determined format data , can begin importing using read_* import_* functions gcplyr. data block-shaped: use import_blockmeasures start next section: Importing block-shaped data data wide-shaped: use read_wides skip Importing wide-shaped data section data already tidy-shaped: use read_tidys skip Importing tidy-shaped data section.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/import_transform.html","id":"importing-block-shaped-data","dir":"Articles","previous_headings":"","what":"Importing block-shaped data","title":"Importing and transforming data","text":"import block-shaped data, use import_blockmeasures function. import_blockmeasures requires list filenames (relative file paths) return wide-shaped data.frame can save R.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/import_transform.html","id":"a-basic-example","dir":"Articles","previous_headings":"Importing block-shaped data","what":"A basic example","title":"Importing and transforming data","text":"’s simple example. First, need create series example block-shaped .csv files. Don’t worry code works. working real growth curve data, files output plate reader. need put file names R vector, ’ve stored file names temp_filenames. ’ve saved files single folder, can easily get vector names using list.files. folder contains files, can specify regular expression pattern limit just want import: ’s one files looks like (values absorbance/optical density): file corresponds reads single plate taken first timepoint. can see second row file contains metadata timepoint plate read read taken. , data starts column headers row 4 rownames column 1. want read files R, simply provide import_blockmeasures vector file names, save result R object (, imported_blockdata). import_blockmeasures assumes data starts first row column, ends last row column, unless specify otherwise. can see import_blockmeasures created wide-shaped R object containing data reads. also added file names block_name column, can easily track row came file. ’re looking data Excel similar spreadsheet program, ’ll notice columns coded letter. import_blockmeasures allows specify column letter .","code":"# This code just creates a series of block-shaped example files # Don't worry about how it works - when working with real growth # curves data, all these files would be created by the plate reader temp_filenames <-    paste(\"Plate1-\",          paste(example_widedata_noiseless$Time %/% 3600,               formatC((example_widedata_noiseless$Time %% 3600) %/% 60,                        width = 2, flag = 0),               formatC((example_widedata_noiseless$Time %% 3600) %% 60,                       width = 2, flag = 0),               sep = \"_\"), \".csv\", sep = \"\") for (i in 1:length(temp_filenames)) {   temp_filenames[i] <- strsplit(temp_filenames[i], split = \"\\\\\\\\\")[[1]][     length(strsplit(temp_filenames[i], split = \"\\\\\\\\\")[[1]])] } for (i in 1:length(temp_filenames)) {   write.table(     cbind(       matrix(c(\"\", \"\", \"\", \"\", \"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\"),               nrow = 12),       rbind(rep(\"\", 12),             matrix(c(\"Time\", example_widedata_noiseless$Time[i], rep(\"\", 10)),                     ncol = 12),             rep(\"\", 12),             matrix(1:12, ncol = 12),             matrix(               example_widedata_noiseless[i, 2:ncol(example_widedata_noiseless)],               ncol = 12))     ),      file = temp_filenames[i], quote = FALSE, row.names = FALSE, sep = \",\",     col.names = FALSE) } # Here we print all the files we're going to read list.files(pattern = \"Plate1.*csv\") #>  [1] \"Plate1-0_00_00.csv\"  \"Plate1-0_15_00.csv\"  \"Plate1-0_30_00.csv\"  #>  [4] \"Plate1-0_45_00.csv\"  \"Plate1-1_00_00.csv\"  \"Plate1-1_15_00.csv\"  #>  [7] \"Plate1-1_30_00.csv\"  \"Plate1-1_45_00.csv\"  \"Plate1-10_00_00.csv\" #> [10] \"Plate1-10_15_00.csv\" \"Plate1-10_30_00.csv\" \"Plate1-10_45_00.csv\" #> [13] \"Plate1-11_00_00.csv\" \"Plate1-11_15_00.csv\" \"Plate1-11_30_00.csv\" #> [16] \"Plate1-11_45_00.csv\" \"Plate1-12_00_00.csv\" \"Plate1-12_15_00.csv\" #> [19] \"Plate1-12_30_00.csv\" \"Plate1-12_45_00.csv\" \"Plate1-13_00_00.csv\" #> [22] \"Plate1-13_15_00.csv\" \"Plate1-13_30_00.csv\" \"Plate1-13_45_00.csv\" #> [25] \"Plate1-14_00_00.csv\" \"Plate1-14_15_00.csv\" \"Plate1-14_30_00.csv\" #> [28] \"Plate1-14_45_00.csv\" \"Plate1-15_00_00.csv\" \"Plate1-15_15_00.csv\" #> [31] \"Plate1-15_30_00.csv\" \"Plate1-15_45_00.csv\" \"Plate1-16_00_00.csv\" #> [34] \"Plate1-16_15_00.csv\" \"Plate1-16_30_00.csv\" \"Plate1-16_45_00.csv\" #> [37] \"Plate1-17_00_00.csv\" \"Plate1-17_15_00.csv\" \"Plate1-17_30_00.csv\" #> [40] \"Plate1-17_45_00.csv\" \"Plate1-18_00_00.csv\" \"Plate1-18_15_00.csv\" #> [43] \"Plate1-18_30_00.csv\" \"Plate1-18_45_00.csv\" \"Plate1-19_00_00.csv\" #> [46] \"Plate1-19_15_00.csv\" \"Plate1-19_30_00.csv\" \"Plate1-19_45_00.csv\" #> [49] \"Plate1-2_00_00.csv\"  \"Plate1-2_15_00.csv\"  \"Plate1-2_30_00.csv\"  #> [52] \"Plate1-2_45_00.csv\"  \"Plate1-20_00_00.csv\" \"Plate1-20_15_00.csv\" #> [55] \"Plate1-20_30_00.csv\" \"Plate1-20_45_00.csv\" \"Plate1-21_00_00.csv\" #> [58] \"Plate1-21_15_00.csv\" \"Plate1-21_30_00.csv\" \"Plate1-21_45_00.csv\" #> [61] \"Plate1-22_00_00.csv\" \"Plate1-22_15_00.csv\" \"Plate1-22_30_00.csv\" #> [64] \"Plate1-22_45_00.csv\" \"Plate1-23_00_00.csv\" \"Plate1-23_15_00.csv\" #> [67] \"Plate1-23_30_00.csv\" \"Plate1-23_45_00.csv\" \"Plate1-24_00_00.csv\" #> [70] \"Plate1-3_00_00.csv\"  \"Plate1-3_15_00.csv\"  \"Plate1-3_30_00.csv\"  #> [73] \"Plate1-3_45_00.csv\"  \"Plate1-4_00_00.csv\"  \"Plate1-4_15_00.csv\"  #> [76] \"Plate1-4_30_00.csv\"  \"Plate1-4_45_00.csv\"  \"Plate1-5_00_00.csv\"  #> [79] \"Plate1-5_15_00.csv\"  \"Plate1-5_30_00.csv\"  \"Plate1-5_45_00.csv\"  #> [82] \"Plate1-6_00_00.csv\"  \"Plate1-6_15_00.csv\"  \"Plate1-6_30_00.csv\"  #> [85] \"Plate1-6_45_00.csv\"  \"Plate1-7_00_00.csv\"  \"Plate1-7_15_00.csv\"  #> [88] \"Plate1-7_30_00.csv\"  \"Plate1-7_45_00.csv\"  \"Plate1-8_00_00.csv\"  #> [91] \"Plate1-8_15_00.csv\"  \"Plate1-8_30_00.csv\"  \"Plate1-8_45_00.csv\"  #> [94] \"Plate1-9_00_00.csv\"  \"Plate1-9_15_00.csv\"  \"Plate1-9_30_00.csv\"  #> [97] \"Plate1-9_45_00.csv\"  # Here we save them to the temp_filenames variable temp_filenames <- list.files(pattern = \"Plate1.*csv\") print_df(read.csv(temp_filenames[1], header = FALSE, colClasses = \"character\")) #>                                                                           #>    Time     0                                                             #>                                                                           #>       1     2     3     4     5     6     7     8     9    10    11    12 #> A 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 #> B 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 #> C 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 #> D 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 #> E 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 #> F 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 #> G 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 #> H 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 # Now let's read it with import_blockmeasures imported_blockdata <- import_blockmeasures(   files = temp_filenames, startrow = 4)  head(imported_blockdata, c(6, 8)) #>       block_name    A1    A2    A3    A4    A5    A6    A7 #> 1 Plate1-0_00_00 0.002 0.002 0.002 0.002 0.002 0.002 0.002 #> 2 Plate1-0_15_00 0.002 0.002 0.002 0.002 0.002 0.002 0.002 #> 3 Plate1-0_30_00 0.002 0.002 0.002 0.002 0.002 0.002 0.002 #> 4 Plate1-0_45_00 0.002 0.002 0.002 0.002 0.002 0.002 0.002 #> 5 Plate1-1_00_00 0.002 0.002 0.002 0.002 0.002 0.002 0.002 #> 6 Plate1-1_15_00 0.002 0.003 0.002 0.003 0.003 0.002 0.002 # We can specify rows or columns by Excel-style letters too imported_blockdata <- import_blockmeasures(   files = temp_filenames,   startrow = 4, startcol = \"A\")"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/import_transform.html","id":"specifying-metadata","dir":"Articles","previous_headings":"Importing block-shaped data","what":"Specifying metadata","title":"Importing and transforming data","text":"Sometimes, input files information want import ’s included main block data. instance, block-shaped data timepoint nearly always specified somewhere input file. import_blockmeasures can include information well via metadata argument. example, let’s return -recent example files: files, timepoint information located 2nd row 3rd column. ’s specify metadata import_blockmeasures command: can see metadata specified added column output data.frame. specifying metadata, metadata argument must list named vectors. vector two elements specifying location metadata input files: first element row, second element column. can also specify location metadata Excel-style lettering.","code":"print_df(read.csv(temp_filenames[1], header = FALSE, colClasses = \"character\")) #>                                                                           #>    Time     0                                                             #>                                                                           #>       1     2     3     4     5     6     7     8     9    10    11    12 #> A 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 #> B 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 #> C 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 #> D 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 #> E 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 #> F 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 #> G 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 #> H 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 # Reading the blockcurves files with metadata included imported_blockdata <- import_blockmeasures(   files = temp_filenames,   startrow = 4,   metadata = list(\"time\" = c(2, 3)))  head(imported_blockdata, c(6, 8)) #>       block_name time    A1    A2    A3    A4    A5    A6 #> 1 Plate1-0_00_00    0 0.002 0.002 0.002 0.002 0.002 0.002 #> 2 Plate1-0_15_00  900 0.002 0.002 0.002 0.002 0.002 0.002 #> 3 Plate1-0_30_00 1800 0.002 0.002 0.002 0.002 0.002 0.002 #> 4 Plate1-0_45_00 2700 0.002 0.002 0.002 0.002 0.002 0.002 #> 5 Plate1-1_00_00 3600 0.002 0.002 0.002 0.002 0.002 0.002 #> 6 Plate1-1_15_00 4500 0.002 0.003 0.002 0.003 0.003 0.002 # Reading the blockcurves files with metadata included imported_blockdata <- import_blockmeasures(   files = temp_filenames,   startrow = 4,   metadata = list(\"time\" = c(2, \"C\")))"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/import_transform.html","id":"reading-multiple-blocks-from-a-single-file","dir":"Articles","previous_headings":"Importing block-shaped data","what":"Reading multiple blocks from a single file","title":"Importing and transforming data","text":"import_blockmeasures can also import multiple blocks single file, plate readers may output. case, simply specify vector rows columns define location block within file. First, let’s create example file. Don’t worry code works, normally file created plate reader. Let’s take look file looks like: can see first block metadata , block data . ’s empty row next block starts. fact, look whole file, ’ll notice blocks go column 1 (“” Excel) column 13 (“M” Excel), start rows 3, 15, 27, 39, etc, end rows 11, 23, 35, 47, etc. look file, can also see last block starts row 1155 ends row 1163. Let’s read information using import_blockmeasures: ’ve used built-R function seq generate full vector startrows endrows. take look, can see ’s read successfully: Now let’s add metadata. ’re reading single file, need specify metadata slightly differently. Instead metadata single vector c(row,column) location, ’s going list two vectors, one row numbers, one column numbers. Going back file, can see time block saved second column, rows 2, 14, 26, 38, … 1154. now take look resulting object, can see time metadata incorporated.","code":"# This code just creates an example file with multiple blocks # Don't worry about how it works - when working with real growth # curves data, this would be created by the plate reader write_blocks(read_blocks(files = temp_filenames,                          startrow = 4,                          metadata = list(\"time\" = c(2, \"C\"))),              file = \"blocks_single.csv\",              output_format = \"single\",              block_name_location = \"file\") print_df(head(read.csv(\"blocks_single.csv\", header = FALSE,                         colClasses = \"character\"),               c(20, 8))) #> block_name Plate1-0_00_00                                     #>       time              0                                     #>                         1     2     3     4     5     6     7 #>          A          0.002 0.002 0.002 0.002 0.002 0.002 0.002 #>          B          0.002 0.002 0.002 0.002 0.002 0.002 0.002 #>          C          0.002 0.002 0.002 0.002 0.002 0.002 0.002 #>          D          0.002 0.002 0.002 0.002 0.002 0.002 0.002 #>          E          0.002 0.002 0.002 0.002 0.002 0.002 0.002 #>          F          0.002 0.002 0.002 0.002 0.002 0.002 0.002 #>          G          0.002 0.002 0.002 0.002 0.002 0.002 0.002 #>          H          0.002 0.002 0.002 0.002 0.002 0.002 0.002 #>                                                               #> block_name Plate1-0_15_00                                     #>       time            900                                     #>                         1     2     3     4     5     6     7 #>          A          0.002 0.002 0.002 0.002 0.002 0.002 0.002 #>          B          0.002 0.002 0.002 0.002 0.002 0.002 0.002 #>          C          0.002 0.002 0.002 0.002 0.002 0.002 0.002 #>          D          0.002 0.002 0.002 0.002 0.002 0.002 0.002 #>          E          0.002 0.002 0.002 0.002 0.002 0.002 0.002 imported_blockdata <- import_blockmeasures(   \"blocks_single.csv\",   startrow = seq(from = 3, to = 1155, by = 12),   endrow = seq(from = 11, to = 1163, by = 12),   startcol = 1, endcol = 13) head(imported_blockdata, c(6, 8)) #>      block_name    A1    A2    A3    A4    A5    A6    A7 #> 1 blocks_single 0.002 0.002 0.002 0.002 0.002 0.002 0.002 #> 2 blocks_single 0.002 0.002 0.002 0.002 0.002 0.002 0.002 #> 3 blocks_single 0.002 0.002 0.002 0.002 0.002 0.002 0.002 #> 4 blocks_single 0.002 0.002 0.002 0.002 0.002 0.002 0.002 #> 5 blocks_single 0.002 0.002 0.002 0.002 0.002 0.002 0.002 #> 6 blocks_single 0.002 0.003 0.002 0.003 0.003 0.002 0.002 imported_blockdata <- import_blockmeasures(   \"blocks_single.csv\",   startrow = seq(from = 3, to = 1155, by = 12),   endrow = seq(from = 11, to = 1163, by = 12),   startcol = 1, endcol = 13,   metadata = list(\"time\" = list(seq(from = 2, to = 1154, by = 12), 2))) head(imported_blockdata, c(6, 8)) #>      block_name time    A1    A2    A3    A4    A5    A6 #> 1 blocks_single    0 0.002 0.002 0.002 0.002 0.002 0.002 #> 2 blocks_single  900 0.002 0.002 0.002 0.002 0.002 0.002 #> 3 blocks_single 1800 0.002 0.002 0.002 0.002 0.002 0.002 #> 4 blocks_single 2700 0.002 0.002 0.002 0.002 0.002 0.002 #> 5 blocks_single 3600 0.002 0.002 0.002 0.002 0.002 0.002 #> 6 blocks_single 4500 0.002 0.003 0.002 0.003 0.003 0.002"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/import_transform.html","id":"what-to-do-next","dir":"Articles","previous_headings":"Importing block-shaped data","what":"What to do next","title":"Importing and transforming data","text":"Now ’ve imported block-shaped data, ’ll need transform later analyses. Jump directly Transforming data section.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/import_transform.html","id":"importing-wide-shaped-data","dir":"Articles","previous_headings":"","what":"Importing wide-shaped data","title":"Importing and transforming data","text":"import wide-shaped data, use read_wides function. read_wides requires filename (vector filenames, relative file paths) return data.frame (list data.frames) can save R.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/import_transform.html","id":"a-basic-example-1","dir":"Articles","previous_headings":"Importing wide-shaped data","what":"A basic example","title":"Importing and transforming data","text":"’s simple example. First, need create example wide-shaped .csv file. Don’t worry code works. working real growth curve data, files output plate reader. need know file name(s) put R code. example, file name widedata.csv. ’s start file looks like (values absorbance/optical density): file contains reads single plate taken across timepoints. can see first two rows contain metadata saved plate reader, like name experiment date experiment. , can see data starts 5th row header. first column contains timepoint information, subsequent column corresponds well plate. want read file R, simply provide read_wides file name, save result R object (, imported_widedata). read_wides assumes data starts first row column, ends last row column, unless specify otherwise. resulting data.frame looks like : Note read_wides automatically saves filename data imported first column output data.frame. done ensure later , data.frames multiple plates can combined without fear losing identity plate. ’re looking data Excel similar spreadsheet program, ’ll notice columns coded letter. read_wides allows specify column letter . Note multiple files ’d like read , can directly single read_wides command. case, read_wides return list containing data.frames:","code":"# This code just creates a wide-shaped example file where the data doesn't # start on the first row. # Don't worry about how it works - when working with real growth # curves data, this file would be created by the plate reader temp_example_widedata <- example_widedata_noiseless colnames(temp_example_widedata) <- paste(\"V\", 1:ncol(temp_example_widedata),                                          sep = \"\") modified_example_widedata <-   rbind(     as.data.frame(matrix(\"\", nrow = 4, ncol = ncol(example_widedata_noiseless))),     colnames(example_widedata_noiseless),     temp_example_widedata) modified_example_widedata[1:2, 1:2] <-    c(\"Experiment name\", \"Start date\", \"Experiment_1\", as.character(Sys.Date()))  write.table(modified_example_widedata, file = \"widedata.csv\",            row.names = FALSE, col.names = FALSE, sep = \",\") write.table(modified_example_widedata, file = \"widedata2.csv\",            row.names = FALSE, col.names = FALSE, sep = \",\") # Let's take a peek at what this file looks like print_df(head(read.csv(\"widedata.csv\", header = FALSE,                         colClasses = \"character\"),                c(10, 10))) #> Experiment name Experiment_1                                                 #>      Start date   2023-04-03                                                 #>                                                                              #>                                                                              #>            Time           A1    B1    C1    D1    E1    F1    G1    H1    A2 #>               0        0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 #>             900        0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 #>            1800        0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 #>            2700        0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 #>            3600        0.002 0.002 0.002 0.003 0.003 0.002 0.002 0.003 0.002 imported_widedata <- read_wides(files = \"widedata.csv\", startrow = 5) head(imported_widedata, c(6, 10)) #>        file Time    A1    B1    C1    D1    E1    F1    G1    H1 #> 6  widedata    0 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 #> 7  widedata  900 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 #> 8  widedata 1800 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 #> 9  widedata 2700 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 #> 10 widedata 3600 0.002 0.002 0.002 0.003 0.003 0.002 0.002 0.003 #> 11 widedata 4500 0.002 0.003 0.002 0.003 0.003 0.002 0.003 0.003 imported_widedata <- read_wides(files = \"widedata.csv\",                                 startrow = 5, startcol = \"A\") # If we had multiple wide-shaped data files to import imported_widedata <- read_wides(files = c(\"widedata.csv\", \"widedata2.csv\"))"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/import_transform.html","id":"specifying-metadata-1","dir":"Articles","previous_headings":"Importing wide-shaped data","what":"Specifying metadata","title":"Importing and transforming data","text":"Sometimes, input files information want import ’s included main block data. read_wides can include information well via metadata argument. metadata argument list named vectors. vector length 2, first entry specifying row second entry specifying column metadata located. example, previous example files, experiment name located 2nd row, 2nd column, start date located 3rd row, 2nd column. ’s specify metadata: can also specify location metadata Excel-style lettering.","code":"imported_widedata <- read_wides(files = \"widedata.csv\",                                 startrow = 5,                                 metadata = list(\"experiment_name\" = c(1, 2),                                                 \"start_date\" = c(2, 2))) head(imported_widedata, c(6, 8)) #>        file experiment_name start_date Time    A1    B1    C1    D1 #> 6  widedata    Experiment_1 2023-04-03    0 0.002 0.002 0.002 0.002 #> 7  widedata    Experiment_1 2023-04-03  900 0.002 0.002 0.002 0.002 #> 8  widedata    Experiment_1 2023-04-03 1800 0.002 0.002 0.002 0.002 #> 9  widedata    Experiment_1 2023-04-03 2700 0.002 0.002 0.002 0.002 #> 10 widedata    Experiment_1 2023-04-03 3600 0.002 0.002 0.002 0.003 #> 11 widedata    Experiment_1 2023-04-03 4500 0.002 0.003 0.002 0.003 imported_widedata <- read_wides(files = \"widedata.csv\",                                 startrow = 5,                                 metadata = list(\"experiment_name\" = c(1, \"B\"),                                                 \"start_date\" = c(2, \"B\")))"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/import_transform.html","id":"reading-multiple-wides-from-a-single-file","dir":"Articles","previous_headings":"Importing wide-shaped data","what":"Reading multiple wides from a single file","title":"Importing and transforming data","text":"read_wides can read multiple wide-shaped datasets single file. Refer earlier section Reading multiple blocks single file, since syntax operations read_wides import_blockmeasures.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/import_transform.html","id":"what-to-do-next-1","dir":"Articles","previous_headings":"Importing wide-shaped data","what":"What to do next","title":"Importing and transforming data","text":"Now ’ve imported wide-shaped data, ’ll need transform later analyses. Continue Transforming data section.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/import_transform.html","id":"importing-tidy-shaped-data","dir":"Articles","previous_headings":"","what":"Importing tidy-shaped data","title":"Importing and transforming data","text":"import tidy-shaped data, use built-R functions like read.table. However, need options, can use gcplyr function read_tidys. Unlike built-option, read_tidys can import multiple tidy-shaped files , can add filename column resulting data.frame, can handle files tidy-shaped information doesn’t start first row column. read_tidys requires filename (vector filenames, relative file paths) return data.frame (list data.frames) can save R. ’ve read tidy-shaped data, won’t need transform , can skip ’s next? section.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/import_transform.html","id":"transforming-data","dir":"Articles","previous_headings":"","what":"Transforming data","title":"Importing and transforming data","text":"Now ’ve gotten data R environment, need transform can analyses. reiterate, necessary plate readers generate growth curve data outputs block-shaped wide-shaped files, tidy-shaped data.frames best shape analyses required gcplyr. can transform data.frames using trans_* functions gcplyr.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/import_transform.html","id":"transforming-from-wide-shaped-to-tidy-shaped","dir":"Articles","previous_headings":"Transforming data","what":"Transforming from wide-shaped to tidy-shaped","title":"Importing and transforming data","text":"data ’ve read theRenvironment wide-shaped (’ve gotten wide-shaped data transforming originally block-shaped data), ’ll transform tidy-shaped using trans_wide_to_tidy. First, need provide trans_wide_to_tidy theRobject created read_wides trans_block_to_wide. , specify one : * columns data (spectrophotometric measures) via data_cols * columns non-data (e.g. time information) via id_cols","code":"imported_blocks_now_tidy <- trans_wide_to_tidy(   wides = imported_blockdata,   id_cols = c(\"block_name\", \"time\"))  imported_wides_now_tidy <- trans_wide_to_tidy(   wides = imported_widedata,   id_cols = c(\"file\", \"experiment_name\", \"start_date\", \"Time\"))  print(head(imported_blocks_now_tidy), row.names = FALSE) #>     block_name time Well Measurements #>  blocks_single    0   A1        0.002 #>  blocks_single    0   A2        0.002 #>  blocks_single    0   A3        0.002 #>  blocks_single    0   A4        0.002 #>  blocks_single    0   A5        0.002 #>  blocks_single    0   A6        0.002"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/import_transform.html","id":"whats-next","dir":"Articles","previous_headings":"","what":"What’s next?","title":"Importing and transforming data","text":"Now ’ve imported transformed data tidy-shaped, likely want incorporate design information went well (plate). Alternatively, ’d like skip step now, can go directly pre-processing plotting data Introduction: vignette(\"gcplyr\") Importing transforming data: vignette(\"import_transform\") Incorporating design information: vignette(\"incorporate_designs\") Pre-processing plotting data: vignette(\"preprocess_plot\") Processing data: vignette(\"process\") Analyzing data: vignette(\"analyze\") Dealing noise: vignette(\"noise\") Statistics, merging data, resources: vignette(\"conclusion\")","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/incorporate_designs.html","id":"where-are-we-so-far","dir":"Articles","previous_headings":"","what":"Where are we so far?","title":"Incorporating design information","text":"Introduction: vignette(\"gcplyr\") Importing transforming data: vignette(\"import_transform\") Incorporating design information: vignette(\"incorporate_designs\") Pre-processing plotting data: vignette(\"preprocess_plot\") Processing data: vignette(\"process\") Analyzing data: vignette(\"analyze\") Dealing noise: vignette(\"noise\") Statistics, merging data, resources: vignette(\"conclusion\") far, ’ve imported transformed measures data R. Now ’re going address incorporate experimental design. haven’t already, load necessary packages.","code":"library(gcplyr) #> ##  #> ## gcplyr (Version 1.5.0, Build Date: 2023-04-03) #> ## See http://github.com/mikeblazanin/gcplyr for additional documentation #> ## Please cite software as: #> ##   Blazanin, Michael. 2023. 'gcplyr: manipulate and analyze growth #> ##   curve data.' R package version 1.5.0 #> ##"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/incorporate_designs.html","id":"including-design-elements","dir":"Articles","previous_headings":"","what":"Including design elements","title":"Incorporating design information","text":"often want combine information experimental design data. gcplyr enables incorporation design elements two ways: Designs can imported files Designs can generated R using make_design","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/incorporate_designs.html","id":"reading-design-elements-from-files","dir":"Articles","previous_headings":"","what":"Reading design elements from files","title":"Incorporating design information","text":"Users can read block-shaped tidy-shaped design files: design files block-shaped, can read import_blockdesigns design files tidy-shaped, can simply read read_tidys","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/incorporate_designs.html","id":"importing-block-shaped-design-files","dir":"Articles","previous_headings":"Reading design elements from files","what":"Importing block-shaped design files","title":"Incorporating design information","text":"import block-shaped design files, use import_blockdesigns, return tidy-shaped designs data frame (list data frames). import_blockdesigns requires list filenames (relative file paths) return data.frame (list data frames) tidy format can save R.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/incorporate_designs.html","id":"a-basic-example","dir":"Articles","previous_headings":"Reading design elements from files > Importing block-shaped design files","what":"A basic example","title":"Incorporating design information","text":"Let’s look example. First, need create example file sake tutorial. Don’t worry code works, just imagine ’ve created file Excel. Now let’s take look file looks like: can see design Treatment 1 left-hand side plate (wells columns 1 6), Treatment 2 right-hand side plate (wells columns 7 12). Let’s import design using import_blockdesigns saving column name Treatment_numbers.","code":"write.csv(   file = \"mydesign.csv\",   x = matrix(rep(c(\"Tr1\", \"Tr2\"), each = 48),              nrow = 8, ncol = 12, dimnames = list(LETTERS[1:8], 1:12))) print_df(read.csv(\"mydesign.csv\", header = FALSE, colClasses = \"character\")) #>     1   2   3   4   5   6   7   8   9  10  11  12 #> A Tr1 Tr1 Tr1 Tr1 Tr1 Tr1 Tr2 Tr2 Tr2 Tr2 Tr2 Tr2 #> B Tr1 Tr1 Tr1 Tr1 Tr1 Tr1 Tr2 Tr2 Tr2 Tr2 Tr2 Tr2 #> C Tr1 Tr1 Tr1 Tr1 Tr1 Tr1 Tr2 Tr2 Tr2 Tr2 Tr2 Tr2 #> D Tr1 Tr1 Tr1 Tr1 Tr1 Tr1 Tr2 Tr2 Tr2 Tr2 Tr2 Tr2 #> E Tr1 Tr1 Tr1 Tr1 Tr1 Tr1 Tr2 Tr2 Tr2 Tr2 Tr2 Tr2 #> F Tr1 Tr1 Tr1 Tr1 Tr1 Tr1 Tr2 Tr2 Tr2 Tr2 Tr2 Tr2 #> G Tr1 Tr1 Tr1 Tr1 Tr1 Tr1 Tr2 Tr2 Tr2 Tr2 Tr2 Tr2 #> H Tr1 Tr1 Tr1 Tr1 Tr1 Tr1 Tr2 Tr2 Tr2 Tr2 Tr2 Tr2 my_design <- import_blockdesigns(files = \"mydesign.csv\",                                   block_names = \"Treatment_numbers\") head(my_design, 20) #>    Well Treatment_numbers #> 1    A1               Tr1 #> 2    A2               Tr1 #> 3    A3               Tr1 #> 4    A4               Tr1 #> 5    A5               Tr1 #> 6    A6               Tr1 #> 7    A7               Tr2 #> 8    A8               Tr2 #> 9    A9               Tr2 #> 10  A10               Tr2 #> 11  A11               Tr2 #> 12  A12               Tr2 #> 13   B1               Tr1 #> 14   B2               Tr1 #> 15   B3               Tr1 #> 16   B4               Tr1 #> 17   B5               Tr1 #> 18   B6               Tr1 #> 19   B7               Tr2 #> 20   B8               Tr2"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/incorporate_designs.html","id":"importing-multiple-block-shaped-design-elements","dir":"Articles","previous_headings":"Reading design elements from files > Importing block-shaped design files","what":"Importing multiple block-shaped design elements","title":"Incorporating design information","text":"multiple designs? instance, several strains several treatments? case, simply save design component separate file, import one go import_blockdesigns. First, let’s create another example designs file. , don’t worry code works, just imagine ’ve created file Excel. Now let’s take look file looks like: can see design Strain first two rows, Strain B next two rows, . Let’s now import designs using import_blockdesigns, saving columns named Treatment_numbers Strain_letters.","code":"write.csv(   file = \"mydesign2.csv\",   x = matrix(rep(c(\"StrA\", \"StrB\", \"StrC\", \"StrD\"), each = 24),              nrow = 8, ncol = 12, dimnames = list(LETTERS[1:8], 1:12),              byrow = TRUE)) print_df(read.csv(\"mydesign2.csv\", header = FALSE, colClasses = \"character\")) #>      1    2    3    4    5    6    7    8    9   10   11   12 #> A StrA StrA StrA StrA StrA StrA StrA StrA StrA StrA StrA StrA #> B StrA StrA StrA StrA StrA StrA StrA StrA StrA StrA StrA StrA #> C StrB StrB StrB StrB StrB StrB StrB StrB StrB StrB StrB StrB #> D StrB StrB StrB StrB StrB StrB StrB StrB StrB StrB StrB StrB #> E StrC StrC StrC StrC StrC StrC StrC StrC StrC StrC StrC StrC #> F StrC StrC StrC StrC StrC StrC StrC StrC StrC StrC StrC StrC #> G StrD StrD StrD StrD StrD StrD StrD StrD StrD StrD StrD StrD #> H StrD StrD StrD StrD StrD StrD StrD StrD StrD StrD StrD StrD my_design <-    import_blockdesigns(files = c(\"mydesign.csv\", \"mydesign2.csv\"),                        block_names = c(\"Treatment_numbers\", \"Strain_letters\")) head(my_design, 20) #>    Well Treatment_numbers Strain_letters #> 1    A1               Tr1           StrA #> 2    A2               Tr1           StrA #> 3    A3               Tr1           StrA #> 4    A4               Tr1           StrA #> 5    A5               Tr1           StrA #> 6    A6               Tr1           StrA #> 7    A7               Tr2           StrA #> 8    A8               Tr2           StrA #> 9    A9               Tr2           StrA #> 10  A10               Tr2           StrA #> 11  A11               Tr2           StrA #> 12  A12               Tr2           StrA #> 13   B1               Tr1           StrA #> 14   B2               Tr1           StrA #> 15   B3               Tr1           StrA #> 16   B4               Tr1           StrA #> 17   B5               Tr1           StrA #> 18   B6               Tr1           StrA #> 19   B7               Tr2           StrA #> 20   B8               Tr2           StrA"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/incorporate_designs.html","id":"importing-tidy-shaped-design-files","dir":"Articles","previous_headings":"Reading design elements from files","what":"Importing tidy-shaped design files","title":"Incorporating design information","text":"can import tidy-shaped designs read_tidys. read_tidys requires filename (vector filenames, relative file paths) return data.frame (list data.frames) can save R. design elements read R environment, won’t need transform . can skip learning merge data Merging spectrophotometric design data section.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/incorporate_designs.html","id":"generating-designs-in-r","dir":"Articles","previous_headings":"","what":"Generating designs in R","title":"Incorporating design information","text":"’d rather make design data.frames R, make_design can create: block-shaped data.frames design information (saving files) tidy-shaped data.frames design information (saving files merging tidy-shaped data)","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/incorporate_designs.html","id":"an-example-with-a-single-design","dir":"Articles","previous_headings":"Generating designs in R","what":"An example with a single design","title":"Incorporating design information","text":"Let’s start simple design. Imagine 96 well plate (12 columns 8 rows) different bacterial strain row, leaving first last rows columns empty. Typing design like manually spreadsheet can tedious. generating make_design easier. make_design first needs general information, like nrows ncols plate, output_format ’d like (typically blocks tidy). , different design component, make_design needs five different pieces information: vector containing possible values vector specifying rows values applied vector specifying columns values applied string vector pattern values Boolean whether pattern filled byrow (defaults TRUE) example , can see: possible values c(\"Strain 1\", \"Strain 2\", \"Strain 3\", \"Strain 4\", \"Strain 5\", \"Strain 6\") rows values applied 2:7 columns values applied 2:11 pattern values filled \"123456\" values filled row (filled column) produces data.frame Bacteria block_name metadata. save design file transform tidy-shaped, block_name metadata come handy.","code":"my_design_blk <- make_design(   output_format = \"blocks\",   nrows = 8, ncols = 12,    Bacteria = list(c(\"Str1\", \"Str2\", \"Str3\", \"Str4\", \"Str5\", \"Str6\"),                   2:7,                   2:11,                   \"123456\",                   FALSE) ) my_design_blk #> [[1]] #> [[1]]$data #>   1  2      3      4      5      6      7      8      9      10     11     12 #> A NA NA     NA     NA     NA     NA     NA     NA     NA     NA     NA     NA #> B NA \"Str1\" \"Str1\" \"Str1\" \"Str1\" \"Str1\" \"Str1\" \"Str1\" \"Str1\" \"Str1\" \"Str1\" NA #> C NA \"Str2\" \"Str2\" \"Str2\" \"Str2\" \"Str2\" \"Str2\" \"Str2\" \"Str2\" \"Str2\" \"Str2\" NA #> D NA \"Str3\" \"Str3\" \"Str3\" \"Str3\" \"Str3\" \"Str3\" \"Str3\" \"Str3\" \"Str3\" \"Str3\" NA #> E NA \"Str4\" \"Str4\" \"Str4\" \"Str4\" \"Str4\" \"Str4\" \"Str4\" \"Str4\" \"Str4\" \"Str4\" NA #> F NA \"Str5\" \"Str5\" \"Str5\" \"Str5\" \"Str5\" \"Str5\" \"Str5\" \"Str5\" \"Str5\" \"Str5\" NA #> G NA \"Str6\" \"Str6\" \"Str6\" \"Str6\" \"Str6\" \"Str6\" \"Str6\" \"Str6\" \"Str6\" \"Str6\" NA #> H NA NA     NA     NA     NA     NA     NA     NA     NA     NA     NA     NA #>  #> [[1]]$metadata #> block_name  #> \"Bacteria\""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/incorporate_designs.html","id":"a-few-notes-on-the-pattern","dir":"Articles","previous_headings":"Generating designs in R","what":"A few notes on the pattern","title":"Incorporating design information","text":"pattern make_design flexible make easy input designs. “0” character reserved NA values, can put pattern anywhere ’d like value NA previous examples, used numbers 1 6 correspond values. 9 values, can use letters . default, order numbers first, uppercase letters, lowercase letters (“” 10th index). However, ’d like use letters, can simply specify different lookup_tbl_start make_design knows letter ’re using 1 index. can also specify pattern vector rather string.","code":"my_design_blk <- make_design(   output_format = \"blocks\",   nrows = 8, ncols = 12,    Bacteria = list(c(\"Str1\", \"Str2\", \"Str3\",                      \"Str4\", \"Str5\", \"Str6\"),                   2:7,                   2:11,                   \"123056\",                   FALSE) ) my_design_blk #> [[1]] #> [[1]]$data #>   1  2      3      4      5      6      7      8      9      10     11     12 #> A NA NA     NA     NA     NA     NA     NA     NA     NA     NA     NA     NA #> B NA \"Str1\" \"Str1\" \"Str1\" \"Str1\" \"Str1\" \"Str1\" \"Str1\" \"Str1\" \"Str1\" \"Str1\" NA #> C NA \"Str2\" \"Str2\" \"Str2\" \"Str2\" \"Str2\" \"Str2\" \"Str2\" \"Str2\" \"Str2\" \"Str2\" NA #> D NA \"Str3\" \"Str3\" \"Str3\" \"Str3\" \"Str3\" \"Str3\" \"Str3\" \"Str3\" \"Str3\" \"Str3\" NA #> E NA NA     NA     NA     NA     NA     NA     NA     NA     NA     NA     NA #> F NA \"Str5\" \"Str5\" \"Str5\" \"Str5\" \"Str5\" \"Str5\" \"Str5\" \"Str5\" \"Str5\" \"Str5\" NA #> G NA \"Str6\" \"Str6\" \"Str6\" \"Str6\" \"Str6\" \"Str6\" \"Str6\" \"Str6\" \"Str6\" \"Str6\" NA #> H NA NA     NA     NA     NA     NA     NA     NA     NA     NA     NA     NA #>  #> [[1]]$metadata #> block_name  #> \"Bacteria\" my_design_blk <- make_design(   output_format = \"blocks\",   nrows = 8, ncols = 12, lookup_tbl_start = \"A\",   Bacteria = list(     c(\"Str1\", \"Str2\", \"Str3\", \"Str4\", \"Str5\", \"Str6\"),     2:7,     2:11,     \"ABCDEF\",     FALSE) ) my_design_blk <- make_design(   output_format = \"blocks\",   nrows = 8, ncols = 12,   Bacteria = list(     c(\"Str1\", \"Str2\", \"Str3\", \"Str4\", \"Str5\", \"Str6\"),     2:7,     2:11,     c(1,2,3,4,5,6),     FALSE) )"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/incorporate_designs.html","id":"continuing-with-the-example-multiple-designs","dir":"Articles","previous_headings":"Generating designs in R","what":"Continuing with the example: multiple designs","title":"Incorporating design information","text":"Now let’s return example growth curve experiment. addition different bacterial strain row, now also different media column plate. can generate designs make_design: However, real strength make_design limited simple alternating patterns. make_design can use irregular patterns , replicating needed fill wells. also optional helper function called make_designpattern. make_designpattern just reminds us arguments necessary design. example: merging designs plate reader data, need tidy-shaped, just need change output_format tidy.","code":"my_design_blk <- make_design(   output_format = \"blocks\",   nrows = 8, ncols = 12, lookup_tbl_start = \"a\",   Bacteria = list(c(\"Str1\", \"Str2\", \"Str3\",                      \"Str4\", \"Str5\", \"Str6\"),                   2:7,                   2:11,                   \"abcdef\",                   FALSE),   Media = list(c(\"Med1\", \"Med2\", \"Med3\",                  \"Med4\", \"Med5\", \"Med6\",                  \"Med7\", \"Med8\", \"Med9\",                  \"Med10\", \"Med11\", \"Med12\"),                2:7,                2:11,                \"abcdefghij\")   )  my_design_blk #> [[1]] #> [[1]]$data #>   1  2      3      4      5      6      7      8      9      10     11     12 #> A NA NA     NA     NA     NA     NA     NA     NA     NA     NA     NA     NA #> B NA \"Str1\" \"Str1\" \"Str1\" \"Str1\" \"Str1\" \"Str1\" \"Str1\" \"Str1\" \"Str1\" \"Str1\" NA #> C NA \"Str2\" \"Str2\" \"Str2\" \"Str2\" \"Str2\" \"Str2\" \"Str2\" \"Str2\" \"Str2\" \"Str2\" NA #> D NA \"Str3\" \"Str3\" \"Str3\" \"Str3\" \"Str3\" \"Str3\" \"Str3\" \"Str3\" \"Str3\" \"Str3\" NA #> E NA \"Str4\" \"Str4\" \"Str4\" \"Str4\" \"Str4\" \"Str4\" \"Str4\" \"Str4\" \"Str4\" \"Str4\" NA #> F NA \"Str5\" \"Str5\" \"Str5\" \"Str5\" \"Str5\" \"Str5\" \"Str5\" \"Str5\" \"Str5\" \"Str5\" NA #> G NA \"Str6\" \"Str6\" \"Str6\" \"Str6\" \"Str6\" \"Str6\" \"Str6\" \"Str6\" \"Str6\" \"Str6\" NA #> H NA NA     NA     NA     NA     NA     NA     NA     NA     NA     NA     NA #>  #> [[1]]$metadata #> block_name  #> \"Bacteria\"  #>  #>  #> [[2]] #> [[2]]$data #>   1  2      3      4      5      6      7      8      9      10     11      12 #> A NA NA     NA     NA     NA     NA     NA     NA     NA     NA     NA      NA #> B NA \"Med1\" \"Med2\" \"Med3\" \"Med4\" \"Med5\" \"Med6\" \"Med7\" \"Med8\" \"Med9\" \"Med10\" NA #> C NA \"Med1\" \"Med2\" \"Med3\" \"Med4\" \"Med5\" \"Med6\" \"Med7\" \"Med8\" \"Med9\" \"Med10\" NA #> D NA \"Med1\" \"Med2\" \"Med3\" \"Med4\" \"Med5\" \"Med6\" \"Med7\" \"Med8\" \"Med9\" \"Med10\" NA #> E NA \"Med1\" \"Med2\" \"Med3\" \"Med4\" \"Med5\" \"Med6\" \"Med7\" \"Med8\" \"Med9\" \"Med10\" NA #> F NA \"Med1\" \"Med2\" \"Med3\" \"Med4\" \"Med5\" \"Med6\" \"Med7\" \"Med8\" \"Med9\" \"Med10\" NA #> G NA \"Med1\" \"Med2\" \"Med3\" \"Med4\" \"Med5\" \"Med6\" \"Med7\" \"Med8\" \"Med9\" \"Med10\" NA #> H NA NA     NA     NA     NA     NA     NA     NA     NA     NA     NA      NA #>  #> [[2]]$metadata #> block_name  #>    \"Media\" my_design_blk <- make_design(   output_format = \"blocks\",   nrows = 8, ncols = 12, lookup_tbl_start = \"a\",   Bacteria = list(c(\"Str1\", \"Str2\"),                   2:7,                   2:11,                   \"abaaabbbab\",                   FALSE),   Media = list(c(\"Med1\", \"Med2\", \"Med3\"),                2:7,                2:11,                \"aabbbc000abc\"))  my_design_blk #> [[1]] #> [[1]]$data #>   1  2      3      4      5      6      7      8      9      10     11     12 #> A NA NA     NA     NA     NA     NA     NA     NA     NA     NA     NA     NA #> B NA \"Str1\" \"Str2\" \"Str1\" \"Str1\" \"Str1\" \"Str1\" \"Str2\" \"Str1\" \"Str1\" \"Str1\" NA #> C NA \"Str2\" \"Str2\" \"Str1\" \"Str2\" \"Str2\" \"Str2\" \"Str2\" \"Str1\" \"Str2\" \"Str2\" NA #> D NA \"Str1\" \"Str1\" \"Str1\" \"Str1\" \"Str2\" \"Str1\" \"Str1\" \"Str1\" \"Str1\" \"Str2\" NA #> E NA \"Str1\" \"Str2\" \"Str2\" \"Str2\" \"Str2\" \"Str1\" \"Str2\" \"Str2\" \"Str2\" \"Str2\" NA #> F NA \"Str1\" \"Str1\" \"Str2\" \"Str1\" \"Str1\" \"Str1\" \"Str1\" \"Str2\" \"Str1\" \"Str1\" NA #> G NA \"Str2\" \"Str2\" \"Str2\" \"Str1\" \"Str2\" \"Str2\" \"Str2\" \"Str2\" \"Str1\" \"Str2\" NA #> H NA NA     NA     NA     NA     NA     NA     NA     NA     NA     NA     NA #>  #> [[1]]$metadata #> block_name  #> \"Bacteria\"  #>  #>  #> [[2]] #> [[2]]$data #>   1  2      3      4      5      6      7      8      9      10     11     12 #> A NA NA     NA     NA     NA     NA     NA     NA     NA     NA     NA     NA #> B NA \"Med1\" \"Med1\" \"Med2\" \"Med2\" \"Med2\" \"Med3\" NA     NA     NA     \"Med1\" NA #> C NA \"Med2\" \"Med3\" \"Med1\" \"Med1\" \"Med2\" \"Med2\" \"Med2\" \"Med3\" NA     NA     NA #> D NA NA     \"Med1\" \"Med2\" \"Med3\" \"Med1\" \"Med1\" \"Med2\" \"Med2\" \"Med2\" \"Med3\" NA #> E NA NA     NA     NA     \"Med1\" \"Med2\" \"Med3\" \"Med1\" \"Med1\" \"Med2\" \"Med2\" NA #> F NA \"Med2\" \"Med3\" NA     NA     NA     \"Med1\" \"Med2\" \"Med3\" \"Med1\" \"Med1\" NA #> G NA \"Med2\" \"Med2\" \"Med2\" \"Med3\" NA     NA     NA     \"Med1\" \"Med2\" \"Med3\" NA #> H NA NA     NA     NA     NA     NA     NA     NA     NA     NA     NA     NA #>  #> [[2]]$metadata #> block_name  #>    \"Media\" my_design_blk <- make_design(   output_format = \"blocks\",   nrows = 8, ncols = 12, lookup_tbl_start = \"a\",   Bacteria = make_designpattern(     values = c(\"Str1\", \"Str2\", \"Str3\",                 \"Str4\", \"Str5\", \"Str6\"),     rows = 2:7, cols = 2:11, pattern = \"abc0ef\",     byrow = FALSE),   Media = make_designpattern(     values = c(\"Med1\", \"Med2\", \"Med3\",                \"Med4\", \"Med5\", \"Med6\",                \"Med7\", \"Med8\", \"Med9\",                \"Med10\", \"Med11\", \"Med12\"),     rows = 2:7, cols = 2:11, pattern = \"abcde0ghij\"))  my_design_blk #> [[1]] #> [[1]]$data #>   1  2      3      4      5      6      7      8      9      10     11     12 #> A NA NA     NA     NA     NA     NA     NA     NA     NA     NA     NA     NA #> B NA \"Str1\" \"Str1\" \"Str1\" \"Str1\" \"Str1\" \"Str1\" \"Str1\" \"Str1\" \"Str1\" \"Str1\" NA #> C NA \"Str2\" \"Str2\" \"Str2\" \"Str2\" \"Str2\" \"Str2\" \"Str2\" \"Str2\" \"Str2\" \"Str2\" NA #> D NA \"Str3\" \"Str3\" \"Str3\" \"Str3\" \"Str3\" \"Str3\" \"Str3\" \"Str3\" \"Str3\" \"Str3\" NA #> E NA NA     NA     NA     NA     NA     NA     NA     NA     NA     NA     NA #> F NA \"Str5\" \"Str5\" \"Str5\" \"Str5\" \"Str5\" \"Str5\" \"Str5\" \"Str5\" \"Str5\" \"Str5\" NA #> G NA \"Str6\" \"Str6\" \"Str6\" \"Str6\" \"Str6\" \"Str6\" \"Str6\" \"Str6\" \"Str6\" \"Str6\" NA #> H NA NA     NA     NA     NA     NA     NA     NA     NA     NA     NA     NA #>  #> [[1]]$metadata #> block_name  #> \"Bacteria\"  #>  #>  #> [[2]] #> [[2]]$data #>   1  2      3      4      5      6      7  8      9      10     11      12 #> A NA NA     NA     NA     NA     NA     NA NA     NA     NA     NA      NA #> B NA \"Med1\" \"Med2\" \"Med3\" \"Med4\" \"Med5\" NA \"Med7\" \"Med8\" \"Med9\" \"Med10\" NA #> C NA \"Med1\" \"Med2\" \"Med3\" \"Med4\" \"Med5\" NA \"Med7\" \"Med8\" \"Med9\" \"Med10\" NA #> D NA \"Med1\" \"Med2\" \"Med3\" \"Med4\" \"Med5\" NA \"Med7\" \"Med8\" \"Med9\" \"Med10\" NA #> E NA \"Med1\" \"Med2\" \"Med3\" \"Med4\" \"Med5\" NA \"Med7\" \"Med8\" \"Med9\" \"Med10\" NA #> F NA \"Med1\" \"Med2\" \"Med3\" \"Med4\" \"Med5\" NA \"Med7\" \"Med8\" \"Med9\" \"Med10\" NA #> G NA \"Med1\" \"Med2\" \"Med3\" \"Med4\" \"Med5\" NA \"Med7\" \"Med8\" \"Med9\" \"Med10\" NA #> H NA NA     NA     NA     NA     NA     NA NA     NA     NA     NA      NA #>  #> [[2]]$metadata #> block_name  #>    \"Media\" my_design_tdy <- make_design(   output_format = \"tidy\",   nrows = 8, ncols = 12, lookup_tbl_start = \"a\",   Bacteria = make_designpattern(     values = c(\"Str1\", \"Str2\", \"Str3\",                 \"Str4\", \"Str5\", \"Str6\"),     rows = 2:7, cols = 2:11, pattern = \"abc0ef\",     byrow = FALSE),   Media = make_designpattern(     values = c(\"Med1\", \"Med2\", \"Med3\",                \"Med4\", \"Med5\", \"Med6\",                \"Med7\", \"Med8\", \"Med9\",                \"Med10\", \"Med11\", \"Med12\"),     rows = 2:7, cols = 2:11, pattern = \"abcde0ghij\"))  head(my_design_tdy, 20) #>    Well Bacteria Media #> 1    A1     <NA>  <NA> #> 2    A2     <NA>  <NA> #> 3    A3     <NA>  <NA> #> 4    A4     <NA>  <NA> #> 5    A5     <NA>  <NA> #> 6    A6     <NA>  <NA> #> 7    A7     <NA>  <NA> #> 8    A8     <NA>  <NA> #> 9    A9     <NA>  <NA> #> 10  A10     <NA>  <NA> #> 11  A11     <NA>  <NA> #> 12  A12     <NA>  <NA> #> 13   B1     <NA>  <NA> #> 14   B2     Str1  Med1 #> 15   B3     Str1  Med2 #> 16   B4     Str1  Med3 #> 17   B5     Str1  Med4 #> 18   B6     Str1  Med5 #> 19   B7     Str1  <NA> #> 20   B8     Str1  Med7"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/incorporate_designs.html","id":"saving-designs-to-files","dir":"Articles","previous_headings":"Generating designs in R","what":"Saving designs to files","title":"Incorporating design information","text":"’d like save designs ’ve created make_design files, just need decide ’d like tidy-shaped block-shaped. formats can easily read back R gcplyr.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/incorporate_designs.html","id":"saving-tidy-shaped-designs","dir":"Articles","previous_headings":"Generating designs in R > Saving designs to files","what":"Saving tidy-shaped designs","title":"Incorporating design information","text":"design files less human-readable, easier import merge. Additionally, tidy-shaped files often better data repositories, like Dryad. save tidy-shaped designs, simply use built-write.csv function.","code":"#See the previous section where we created my_design_tdy write.csv(x = my_design_tdy, file = \"tidy_design.csv\",           row.names = FALSE)"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/incorporate_designs.html","id":"saving-block-shaped-designs","dir":"Articles","previous_headings":"Generating designs in R > Saving designs to files","what":"Saving block-shaped designs","title":"Incorporating design information","text":"design files human-readable slightly computationally involved import merge. , use gcplyr function write_blocks. Typically, ’ll use write_blocks save files one two formats: multiple - block saved .csv file single - blocks saved single .csv file, empty row ","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/incorporate_designs.html","id":"saving-block-shaped-designs-to-multiple-files","dir":"Articles","previous_headings":"Generating designs in R > Saving designs to files > Saving block-shaped designs","what":"Saving block-shaped designs to multiple files","title":"Incorporating design information","text":"default setting write_blocks output_format = 'multiple'. creates one csv file block. set file = NULL, default name files according block_names metadata.","code":"# See the previous section where we created my_design_blk write_blocks(my_design_blk, file = NULL)  # Let's see what the files look like print_df(read.csv(\"Bacteria.csv\", header = FALSE, colClasses = \"character\")) #>   1    2    3    4    5    6    7    8    9   10   11 12 #> A                                                        #> B   Str1 Str1 Str1 Str1 Str1 Str1 Str1 Str1 Str1 Str1    #> C   Str2 Str2 Str2 Str2 Str2 Str2 Str2 Str2 Str2 Str2    #> D   Str3 Str3 Str3 Str3 Str3 Str3 Str3 Str3 Str3 Str3    #> E                                                        #> F   Str5 Str5 Str5 Str5 Str5 Str5 Str5 Str5 Str5 Str5    #> G   Str6 Str6 Str6 Str6 Str6 Str6 Str6 Str6 Str6 Str6    #> H  print_df(read.csv(\"Media.csv\", header = FALSE, colClasses = \"character\")) #>   1    2    3    4    5    6 7    8    9   10    11 12 #> A                                                      #> B   Med1 Med2 Med3 Med4 Med5   Med7 Med8 Med9 Med10    #> C   Med1 Med2 Med3 Med4 Med5   Med7 Med8 Med9 Med10    #> D   Med1 Med2 Med3 Med4 Med5   Med7 Med8 Med9 Med10    #> E   Med1 Med2 Med3 Med4 Med5   Med7 Med8 Med9 Med10    #> F   Med1 Med2 Med3 Med4 Med5   Med7 Med8 Med9 Med10    #> G   Med1 Med2 Med3 Med4 Med5   Med7 Med8 Med9 Med10    #> H"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/incorporate_designs.html","id":"saving-block-shaped-designs-to-a-single-file","dir":"Articles","previous_headings":"Generating designs in R > Saving designs to files > Saving block-shaped designs","what":"Saving block-shaped designs to a single file","title":"Incorporating design information","text":"setting write_blocks output_format = 'single'. creates single csv file contains blocks, putting metadata like block_names rows precede block. Let’s take look single output format looks like: can see design information saved single file, metadata added rows block.","code":"# See the previous section where we created my_design_blk write_blocks(my_design_blk, file = \"Design.csv\", output_format = \"single\")  # Let's see what the file looks like print_df(read.csv(\"Design.csv\", header = FALSE, colClasses = \"character\")) #> block_name Bacteria                                                       #>                   1    2    3    4    5    6    7    8    9   10    11 12 #>          A                                                                #>          B          Str1 Str1 Str1 Str1 Str1 Str1 Str1 Str1 Str1  Str1    #>          C          Str2 Str2 Str2 Str2 Str2 Str2 Str2 Str2 Str2  Str2    #>          D          Str3 Str3 Str3 Str3 Str3 Str3 Str3 Str3 Str3  Str3    #>          E                                                                #>          F          Str5 Str5 Str5 Str5 Str5 Str5 Str5 Str5 Str5  Str5    #>          G          Str6 Str6 Str6 Str6 Str6 Str6 Str6 Str6 Str6  Str6    #>          H                                                                #>                                                                           #> block_name    Media                                                       #>                   1    2    3    4    5    6    7    8    9   10    11 12 #>          A                                                                #>          B          Med1 Med2 Med3 Med4 Med5      Med7 Med8 Med9 Med10    #>          C          Med1 Med2 Med3 Med4 Med5      Med7 Med8 Med9 Med10    #>          D          Med1 Med2 Med3 Med4 Med5      Med7 Med8 Med9 Med10    #>          E          Med1 Med2 Med3 Med4 Med5      Med7 Med8 Med9 Med10    #>          F          Med1 Med2 Med3 Med4 Med5      Med7 Med8 Med9 Med10    #>          G          Med1 Med2 Med3 Med4 Med5      Med7 Med8 Med9 Med10    #>          H"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/incorporate_designs.html","id":"merging-spectrophotometric-and-design-data","dir":"Articles","previous_headings":"","what":"Merging spectrophotometric and design data","title":"Incorporating design information","text":"design data theRenvironment tidy-shaped, can merge using merge_dfs. , ’ll use data example_widedata_noiseless dataset included gcplyr, source previous examples import_blockmeasures read_wides. example_widedata_noiseless dataset, 48 different bacterial strains. left side plate 48 strains single well , right side plate also 48 strains single well : , right hand side plate phage also inoculated (left hand side remained bacteria-): Let’s generate design: ’s resulting data.frame looks like: Now let’s transform example_widedata_noiseless tidy-shaped. finally, merge two using merge_dfs, saving result ex_dat_mrg, short example_data_merged. merge_dfs merges using columns name two data.frames.","code":"example_design <- make_design(   nrows = 8, ncols = 12,   \"Bacteria_strain\" = make_designpattern(     values = paste(\"Strain\", 1:48),     rows = 1:8, cols = 1:6,     pattern = 1:48,     byrow = TRUE),   \"Bacteria_strain\" = make_designpattern(     values = paste(\"Strain\", 1:48),     rows = 1:8, cols = 7:12,     pattern = 1:48,     byrow = TRUE),   \"Phage\" = make_designpattern(     values = c(\"No Phage\"),     rows = 1:8, cols = 1:6,     pattern = \"1\"),   \"Phage\" = make_designpattern(     values = c(\"Phage Added\"),     rows = 1:8, cols = 7:12,     pattern = \"1\")) head(example_design, 20) #>    Well Bacteria_strain       Phage #> 1    A1        Strain 1    No Phage #> 2    A2        Strain 2    No Phage #> 3    A3        Strain 3    No Phage #> 4    A4        Strain 4    No Phage #> 5    A5        Strain 5    No Phage #> 6    A6        Strain 6    No Phage #> 7    A7        Strain 1 Phage Added #> 8    A8        Strain 2 Phage Added #> 9    A9        Strain 3 Phage Added #> 10  A10        Strain 4 Phage Added #> 11  A11        Strain 5 Phage Added #> 12  A12        Strain 6 Phage Added #> 13   B1        Strain 7    No Phage #> 14   B2        Strain 8    No Phage #> 15   B3        Strain 9    No Phage #> 16   B4       Strain 10    No Phage #> 17   B5       Strain 11    No Phage #> 18   B6       Strain 12    No Phage #> 19   B7        Strain 7 Phage Added #> 20   B8        Strain 8 Phage Added example_tidydata <- trans_wide_to_tidy(example_widedata_noiseless,                                        id_cols = \"Time\") ex_dat_mrg <- merge_dfs(example_tidydata, example_design) #> Joining with `by = join_by(Well)`  head(ex_dat_mrg) #>   Time Well Measurements Bacteria_strain    Phage #> 1    0   A1        0.002        Strain 1 No Phage #> 2    0   B1        0.002        Strain 7 No Phage #> 3    0   C1        0.002       Strain 13 No Phage #> 4    0   D1        0.002       Strain 19 No Phage #> 5    0   E1        0.002       Strain 25 No Phage #> 6    0   F1        0.002       Strain 31 No Phage"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/incorporate_designs.html","id":"whats-next","dir":"Articles","previous_headings":"","what":"What’s next?","title":"Incorporating design information","text":"Now ’ve merged data designs, can pre-process plot data Introduction: vignette(\"gcplyr\") Importing transforming data: vignette(\"import_transform\") Incorporating design information: vignette(\"incorporate_designs\") Pre-processing plotting data: vignette(\"preprocess_plot\") Processing data: vignette(\"process\") Analyzing data: vignette(\"analyze\") Dealing noise: vignette(\"noise\") Statistics, merging data, resources: vignette(\"conclusion\")","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/noise.html","id":"where-are-we-so-far","dir":"Articles","previous_headings":"","what":"Where are we so far?","title":"Dealing with noise","text":"Introduction: vignette(\"gcplyr\") Importing transforming data: vignette(\"import_transform\") Incorporating design information: vignette(\"incorporate_designs\") Pre-processing plotting data: vignette(\"preprocess_plot\") Processing data: vignette(\"process\") Analyzing data: vignette(\"analyze\") Dealing noise: vignette(\"noise\") Statistics, merging data, resources: vignette(\"conclusion\") far, ’ve imported transformed measures, combined design information, pre-processed, processed, plotted, analyzed data. , ’re going learn potential strategies dealing noise growth curve data. haven’t already, load necessary packages.","code":"library(gcplyr) #> ##  #> ## gcplyr (Version 1.5.0, Build Date: 2023-04-03) #> ## See http://github.com/mikeblazanin/gcplyr for additional documentation #> ## Please cite software as: #> ##   Blazanin, Michael. 2023. 'gcplyr: manipulate and analyze growth #> ##   curve data.' R package version 1.5.0 #> ##  library(dplyr) #>  #> Attaching package: 'dplyr' #> The following objects are masked from 'package:stats': #>  #>     filter, lag #> The following objects are masked from 'package:base': #>  #>     intersect, setdiff, setequal, union library(ggplot2) # This code was previously explained # Here we're re-running it so it's available for us to work with example_design <- make_design(   pattern_split = \",\", nrows = 8, ncols = 12,   \"Bacteria_strain\" = make_designpattern(     values = paste(\"Strain\", 1:48),     rows = 1:8, cols = 1:6, pattern = 1:48, byrow = TRUE),   \"Bacteria_strain\" = make_designpattern(     values = paste(\"Strain\", 1:48),     rows = 1:8, cols = 7:12, pattern = 1:48, byrow = TRUE),   \"Phage\" = make_designpattern(     values = c(\"No Phage\"), rows = 1:8, cols = 1:6, pattern = \"1\"),   \"Phage\" = make_designpattern(     values = c(\"Phage Added\"), rows = 1:8, cols = 7:12, pattern = \"1\"))  sample_wells <- c(\"A1\", \"F1\", \"F10\", \"E11\")"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/noise.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Dealing with noise","text":"Oftentimes, growth curve data produced plate reader noise . model-fitting analysis growth curves implemented packages, effect noise often eliminated fitting step. However, since gcplyr model-free analyses, approach can sometimes sensitive noise, necessitating steps reduce effects noise. assessing effects noise data, one first steps simply visualize data. particular, want visualize raw data, also derivatives ’ll using analyses. especially important per-capita derivatives often sensitive noise, especially bacterial population sizes small. visualizing data, can assess whether density, derivative, per-capita derivative changing smoothly, expect. , instead, observe spikes rapid fluctuations, know noise likely throw estimates maxima minima data derivatives. Broadly speaking, three strategies can use deal noise: Using fitting derivative calculations Smooth raw data Analyze less-noisy subsets data Let’s start pulling example data. Luckily us, version example data ’ve working simulated noise added .   Great! can see noisy noiseless data compare. ’ve plotted data linear axes log-transformed y-axes. log axes useful exponential growth straight line plotted log scale, case also helps highlight higher relative noise low densities compared high densities. fact, common occurrence: low densities, random noise tends much larger effect high densities. level noise doesn’t seem like mess calculations maximum density area curve much, ’s enough reason smooth. let’s look derivatives look like.   values jumping place, including growth rate calculated infinite! Let’s see can address .","code":"# This is the data we've been working with previously noiseless_data <-    trans_wide_to_tidy(example_widedata_noiseless, id_cols = \"Time\") # This is the same data but with simulated noise added noisy_data <- trans_wide_to_tidy(example_widedata, id_cols = \"Time\") # We'll add some identifiers and then merge them together noiseless_data <- mutate(noiseless_data, noise = \"No\") noisy_data <- mutate(noisy_data, noise = \"Yes\") ex_dat_mrg <- merge_dfs(noisy_data, noiseless_data) #> Joining with `by = join_by(Time, Well, Measurements, noise)` #> Warning in merge_dfs(noisy_data, noiseless_data):  #> merged_df has more rows than x or y, this may indicate #>                mis-matched values in the shared column(s) used to merge  #>               (e.g. 'Well') ex_dat_mrg <- merge_dfs(ex_dat_mrg, example_design) #> Joining with `by = join_by(Well)`  ex_dat_mrg$Well <-    factor(ex_dat_mrg$Well,          levels = paste(rep(LETTERS[1:8], each = 12), 1:12, sep = \"\")) ex_dat_mrg$Time <- ex_dat_mrg$Time/3600 #Convert time to hours  # For computational speed, let's just keep the wells we'll be focusing on #  (for your own analyses, you should skip this step and continue using #  all of your data) ex_dat_mrg <- dplyr::filter(ex_dat_mrg, Well %in% sample_wells)  # Plot with a linear y-axis ggplot(data = dplyr::filter(ex_dat_mrg, Well %in% sample_wells),        aes(x = Time, y = Measurements, color = noise)) +   geom_point(alpha = 0.5) +   facet_wrap(~Well) # Plot with a log y-axis ggplot(data = dplyr::filter(ex_dat_mrg, Well %in% sample_wells),        aes(x = Time, y = Measurements, color = noise)) +   geom_point(alpha = 0.5) +   facet_wrap(~Well) +   scale_y_continuous(trans = \"log10\") #> Warning: Transformation introduced infinite values in continuous y-axis ex_dat_mrg <-    mutate(group_by(ex_dat_mrg, Well, Bacteria_strain, Phage, noise),          deriv = calc_deriv(x = Time, y = Measurements),          deriv_percap = calc_deriv(x = Time, y = Measurements,                                    percapita = TRUE, blank = 0))  # Plot derivative ggplot(data = dplyr::filter(ex_dat_mrg, Well %in% sample_wells),        aes(x = Time, y = deriv, color = noise)) +   geom_point(alpha = 0.5) +   facet_wrap(~Well, scales = \"free_y\") #> Warning: Removed 8 rows containing missing values (`geom_point()`). # Plot per-capita derivative ggplot(data = dplyr::filter(ex_dat_mrg, Well %in% sample_wells),        aes(x = Time, y = deriv_percap, color = noise)) +   geom_point(alpha = 0.5) +   facet_wrap(~Well, scales = \"free_y\") #> Warning: Removed 12 rows containing missing values (`geom_point()`)."},{"path":"https://mikeblazanin.github.io/gcplyr/articles/noise.html","id":"FittingDeriv","dir":"Articles","previous_headings":"","what":"Fitting during derivative calculation","title":"Dealing with noise","text":"One thing can actually something already Calculating Derivatives article (vignette(\"process\")): instead calculating derivative point relative next, can use moving window two points fit linear regression data. earlier situation used two points limited resolution low densities. However, solution can apply . calculating derivatives fitting many points instead just two, effect single noisy point reduced. use fitting functionality calc_deriv, need specify either window_width parameter, window_width_n parameter. window_width specifies wide window used include points fitting units x, window_width_n specifies number data points. , ’ll demonstrate use fitting regressions data points. Note using calc_deriv way, use points necessary analyses work, visualize different window widths choose smallest one sufficient analyses succeed.     Great! can see, increasing number points derivative calculation reduces amount noise gets result closer ‘true’ noiseless data. However, may also noticed biases results slightly, making peaks less high valleys less deep. Moreover, derivatives, especially per-capita derivative, noise remains. next two sections, ’ll explore smoothing raw data analyzing just subset data can reduce effects noise analyses.","code":"ex_dat_mrg <-    mutate(group_by(ex_dat_mrg, Well, Bacteria_strain, Phage, noise),          deriv5 = calc_deriv(x = Time, y = Measurements,                             window_width_n = 5),          deriv_percap5 = calc_deriv(x = Time, y = Measurements,                                    percapita = TRUE, blank = 0,                                    window_width_n = 5),          deriv9 = calc_deriv(x = Time, y = Measurements,                             window_width_n = 9),          deriv_percap9 = calc_deriv(x = Time, y = Measurements,                                    percapita = TRUE, blank = 0,                                    window_width_n = 9))  # Plot derivative 5 ggplot(data = dplyr::filter(ex_dat_mrg, Well %in% sample_wells),        aes(x = Time, y = deriv, color = noise)) +   geom_point(alpha = 0.75, size = 0.75) +   geom_line(linewidth = 1.25, alpha = 0.5, aes(y = deriv5)) +   facet_wrap(~Well, scales = \"free_y\") +   ggtitle(\"window_width_n = 5\") #> Warning: Removed 8 rows containing missing values (`geom_point()`). #> Warning: Removed 8 rows containing missing values (`geom_line()`). # Plot derivative 9 ggplot(data = dplyr::filter(ex_dat_mrg, Well %in% sample_wells),        aes(x = Time, y = deriv, color = noise)) +   geom_point(alpha = 0.75, size = 0.75) +   geom_line(linewidth = 1.25, alpha = 0.5, aes(y = deriv9)) +   facet_wrap(~Well, scales = \"free_y\") +   ggtitle(\"window_width_n = 9\") #> Warning: Removed 8 rows containing missing values (`geom_point()`). #> Warning: Removed 16 rows containing missing values (`geom_line()`). # Plot per-capita derivative 5 ggplot(data = dplyr::filter(ex_dat_mrg, Well %in% sample_wells),        aes(x = Time, y = deriv_percap, color = noise)) +   geom_point(alpha = 0.75, size = 0.75) +   geom_line(linewidth = 1.25, alpha = 0.5, aes(y = deriv_percap5)) +   facet_wrap(~Well, scales = \"free_y\") +   ggtitle(\"window_width_n = 5\") +   ylim(NA, 10) #> Warning: Removed 22 rows containing missing values (`geom_point()`). #> Warning: Removed 8 rows containing missing values (`geom_line()`). # Plot per-capita derivative 9 ggplot(data = dplyr::filter(ex_dat_mrg, Well %in% sample_wells),        aes(x = Time, y = deriv_percap, color = noise)) +   geom_point(alpha = 0.75, size = 0.75) +   geom_line(linewidth = 1.25, alpha = 0.5, aes(y = deriv_percap9)) +   facet_wrap(~Well, scales = \"free_y\") +   ggtitle(\"window_width_n = 9\") +   ylim(NA, 10) #> Warning: Removed 22 rows containing missing values (`geom_point()`). #> Warning: Removed 16 rows containing missing values (`geom_line()`)."},{"path":"https://mikeblazanin.github.io/gcplyr/articles/noise.html","id":"Smoothing","dir":"Articles","previous_headings":"","what":"Smoothing raw data","title":"Dealing with noise","text":"One obvious approaches deal noise raw data use smoothing algorithm. gcplyr smooth_data function can carry smoothing. Note using smooth_data, generally carry little smoothing necessary analyses work, visualize different degrees smoothing choose least smoothed one sufficient analyses succeed. smooth_data four different smoothing algorithms choose : moving-average, moving-median, loess, gam. moving-average simple smoothing algorithm primarily acts reduce effects outliers data moving-median another simple smoothing algorithm primarily acts reduce effects outliers data loess spline-fitting approach uses polynomial-like curves, produces curves smoothly changing derivatives, can cases create curvature artifacts present original data gam also spline-fitting approach uses polynomial-like curves, produces curves smoothly changing derivatives, can cases create curvature artifacts present original data Additionally, four smoothing algorithms tuning parameter controls “smoothed” data . whichever smoothing method ’re using, plot smoothing multiple different tuning parameter values, choose value smooths data little necessary reduce noise. Make sure plot smoothing every well data, ’re choosing best setting data just one well. Smoothing data step alters values analyze. , many options smooth data, step can rife pitfalls. recommend starting simplest least “smoothed” smoothing, plotting results, increasing smoothing much needed enable downstream analyses. Additionally, sharing findings, ’s important transparent sharing raw data smoothing methods, rather treating smoothed data source. use smooth_data, pass x y values, method choice, additional arguments needed method. return vector smoothed y values.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/noise.html","id":"smoothing-with-moving-average","dir":"Articles","previous_headings":"Smoothing raw data","what":"Smoothing with moving-average","title":"Dealing with noise","text":"moving-average, two tuning parameters choose : window_width specifies wide moving window used calculate average units x. window_width_n specifies many data points wide moving window used calculate average . Specifying window_width window_width_n required, larger values “smoothed”. Think carefully whether want hold amount time number data points window constant (data collected constant intervals, difference). , ’ll show moving averages window_width_n values 5 9 data points wide (window centered data point, window_width_n must odd number data points wide). Note moving-average returns NA data points start end data window extends beyond domain data.   can see moving-average helped reduce effects early noise. However, window width gets larger, also starts underrepresenting maximum density peaks. Based , ’d probably want use window_width_n less 9. Unfortunately, smaller window_width_n early data still affected early noise, explore smoothing methods, try combining multiple smoothing methods.","code":"ex_dat_mrg <-   mutate(group_by(ex_dat_mrg, Well, Bacteria_strain, Phage, noise),          smoothed5 = smooth_data(x = Time, y = Measurements,               sm_method = \"moving-average\", window_width_n = 5),          smoothed9 = smooth_data(x = Time, y = Measurements,               sm_method = \"moving-average\", window_width_n = 9))  # What does the smoothed data look like compared to the 'true' noiseless data? ggplot(data = dplyr::filter(ex_dat_mrg, Well %in% sample_wells),        aes(x = Time, y = Measurements, color = noise)) +   geom_point(alpha = 0.75, size = 0.75) +   geom_line(linewidth = 1.25, alpha = 0.5, aes(y = smoothed5)) +   facet_wrap(~Well, scales = \"free_y\") +   ggtitle(\"window_width_n = 5\") +   scale_y_log10() #> Warning: Transformation introduced infinite values in continuous y-axis #> Warning: Removed 8 rows containing missing values (`geom_line()`). # What does the smoothed data look like compared to the 'true' noiseless data? ggplot(data = dplyr::filter(ex_dat_mrg, Well %in% sample_wells),        aes(x = Time, y = Measurements, color = noise)) +   geom_point(alpha = 0.75, size = 0.75) +   geom_line(linewidth = 1.25, alpha = 0.5, aes(y = smoothed9)) +   facet_wrap(~Well, scales = \"free_y\") +   ggtitle(\"window_width_n = 9\") +   scale_y_log10() #> Warning: Transformation introduced infinite values in continuous y-axis #> Warning: Removed 16 rows containing missing values (`geom_line()`)."},{"path":"https://mikeblazanin.github.io/gcplyr/articles/noise.html","id":"smoothing-with-moving-median","dir":"Articles","previous_headings":"Smoothing raw data","what":"Smoothing with moving-median","title":"Dealing with noise","text":"moving-median, two tuning parameters: window_width specifies wide moving window used calculate average units x. window_width_n specifies many data points wide moving window used calculate average . Specifying window_width window_width_n required, larger values “smoothed”. Think carefully whether want hold amount time number data points window constant (data collected constant intervals, difference). , ’ll show moving medians windows 5 9 data points wide (window centered data point, must odd number data points wide). Note moving-median returns NA data points start end data window extends beyond domain data.   can see moving-median done great job excluded low-density noise, even smallest window_width_n = 5. Additionally, moving-median bias larger data hardly , except widest window_width_n. However, produced smoothed density fairly “jumpy”, something wider window_width_n fix. common moving-median, often may need try smoothing methods combining moving-median methods.","code":"ex_dat_mrg <-   mutate(group_by(ex_dat_mrg, Well, Bacteria_strain, Phage, noise),          smoothed5 =             smooth_data(x = Time, y = Measurements,                        sm_method = \"moving-median\", window_width_n = 5),          smoothed9 =             smooth_data(x = Time, y = Measurements,                        sm_method = \"moving-median\", window_width_n = 9))  # What does the smoothed data look like compared to the 'true' noiseless data? ggplot(data = dplyr::filter(ex_dat_mrg, Well %in% sample_wells),        aes(x = Time, y = Measurements, color = noise)) +   geom_point(alpha = 0.75, size = 0.75) +   geom_line(linewidth = 1.25, alpha = 0.5, aes(y = smoothed5)) +   facet_wrap(~Well, scales = \"free_y\") +   ggtitle(\"window_width_n = 5\") +   scale_y_log10() #> Warning: Transformation introduced infinite values in continuous y-axis #> Transformation introduced infinite values in continuous y-axis #> Warning: Removed 8 rows containing missing values (`geom_line()`). # What does the smoothed data look like compared to the 'true' noiseless data? ggplot(data = dplyr::filter(ex_dat_mrg, Well %in% sample_wells),        aes(x = Time, y = Measurements, color = noise)) +   geom_point(alpha = 0.75, size = 0.75) +   geom_line(linewidth = 1.25, alpha = 0.5, aes(y = smoothed9)) +   facet_wrap(~Well, scales = \"free_y\") +   ggtitle(\"window_width_n = 9\") +   scale_y_log10() #> Warning: Transformation introduced infinite values in continuous y-axis #> Warning: Transformation introduced infinite values in continuous y-axis #> Warning: Removed 16 rows containing missing values (`geom_line()`)."},{"path":"https://mikeblazanin.github.io/gcplyr/articles/noise.html","id":"smoothing-with-loess","dir":"Articles","previous_headings":"Smoothing raw data","what":"Smoothing with LOESS","title":"Dealing with noise","text":"loess, tuning parameter span argument. loess works fits subset windows data centered data point. fits can linear (degree = 1) polynomial (typically degree = 2). span width window, fraction data points. instance, default span 0.75, 75% data points included window. Thus, span values typically 0 1 (although see ?loess use span values greater 1), larger values “smoothed”. , ’ll show loess smoothing spans 0.15 0.35 degree = 1.   can see loess smaller spans smoothed data somewhat still sensitive outliers. However, loess larger span introduced significant bias. fix , might explore smoothing methods, combining loess smoothing methods.","code":"ex_dat_mrg <-   mutate(group_by(ex_dat_mrg, Well, Bacteria_strain, Phage, noise),          smoothed15 = smooth_data(x = Time, y = Measurements,                                  sm_method = \"loess\", span = .15, degree = 1),          smoothed35 = smooth_data(x = Time, y = Measurements,                                  sm_method = \"loess\", span = .35, degree = 1))  # What does the smoothed data look like compared to the 'true' noiseless data? ggplot(data = dplyr::filter(ex_dat_mrg, Well %in% sample_wells),        aes(x = Time, y = Measurements, color = noise)) +   geom_point(alpha = 0.75, size = 0.75) +   geom_line(linewidth = 1.25, alpha = 0.5, aes(y = smoothed15)) +   facet_wrap(~Well, scales = \"free_y\") +   ggtitle(\"span = 0.15\") +   scale_y_log10() #> Warning: Transformation introduced infinite values in continuous y-axis # What does the smoothed data look like compared to the 'true' noiseless data? ggplot(data = dplyr::filter(ex_dat_mrg, Well %in% sample_wells),        aes(x = Time, y = Measurements, color = noise)) +   geom_point(alpha = 0.75, size = 0.75) +   geom_line(linewidth = 1.25, alpha = 0.5, aes(y = smoothed35)) +   facet_wrap(~Well, scales = \"free_y\") +   ggtitle(\"span = 0.35\") +   scale_y_log10() #> Warning: Transformation introduced infinite values in continuous y-axis #> Warning in self$trans$transform(x): NaNs produced #> Warning: Transformation introduced infinite values in continuous y-axis #> Warning: Removed 8 rows containing missing values (`geom_line()`)."},{"path":"https://mikeblazanin.github.io/gcplyr/articles/noise.html","id":"smoothing-with-gam","dir":"Articles","previous_headings":"Smoothing raw data","what":"Smoothing with GAM","title":"Dealing with noise","text":"gam, primary tuning parameter k argument. gam works fits subsets data linking fits together. k determines many link points (“knots”) can use. specified, default k value smoothing time series 10, smaller values “smoothed” (note opposite trend smoothing methods). However, unlike earlier methods, k values large also problematic, tend ‘overfit’ data. k larger number data points, usually substantially smaller . Also note gam can sometimes create artifacts, especially oscillations density derivatives. check gam carrying analyses. , ’ll show gam smoothing k values 8 15.   can see gam alright working phage-added wells (A1 F1): higher k values smoothed data still sensitive early outliers, lower k values introduced significant bias. However, gam struggling phage added (E11 F10). Across k values added many fluctuations often dips values 0 lower (plotted breaks line, since log numbers <= 0 undefined). fix , might explore smoothing methods combining gam smoothing methods.","code":"ex_dat_mrg <-   mutate(group_by(ex_dat_mrg, Well, Bacteria_strain, Phage, noise),          smoothed15 = smooth_data(x = Time, y = Measurements,                                   sm_method = \"gam\", k = 15),          smoothed8 = smooth_data(x = Time, y = Measurements,                                  sm_method = \"gam\", k = 8))  # What does the smoothed data look like compared to the 'true' noiseless data? ggplot(data = dplyr::filter(ex_dat_mrg, Well %in% sample_wells),        aes(x = Time, y = Measurements, color = noise)) +   geom_point(alpha = 0.75, size = 0.75) +   geom_line(linewidth = 1.25, alpha = 0.5, aes(y = smoothed15)) +   facet_wrap(~Well, scales = \"free_y\") +   ggtitle(\"k = 15\") +   scale_y_log10() #> Warning: Transformation introduced infinite values in continuous y-axis #> Warning in self$trans$transform(x): NaNs produced #> Warning: Transformation introduced infinite values in continuous y-axis #> Warning: Removed 1 row containing missing values (`geom_line()`). # What does the smoothed data look like compared to the 'true' noiseless data? ggplot(data = dplyr::filter(ex_dat_mrg, Well %in% sample_wells),        aes(x = Time, y = Measurements, color = noise)) +   geom_point(alpha = 0.75, size = 0.75) +   geom_line(linewidth = 1.25, alpha = 0.5, aes(y = smoothed8)) +   facet_wrap(~Well, scales = \"free_y\") +   ggtitle(\"k = 8\") +   scale_y_log10() #> Warning: Transformation introduced infinite values in continuous y-axis #> Warning in self$trans$transform(x): NaNs produced #> Warning: Transformation introduced infinite values in continuous y-axis #> Warning: Removed 2 rows containing missing values (`geom_line()`)."},{"path":"https://mikeblazanin.github.io/gcplyr/articles/noise.html","id":"combining-multiple-smoothing-methods","dir":"Articles","previous_headings":"Smoothing raw data","what":"Combining multiple smoothing methods","title":"Dealing with noise","text":"Often, combining multiple smoothing methods can provide improved results. instance, moving-median particularly good removing outliers, good producing continuously smooth data. contrast, moving-average, loess, gam work better producing continuously smooth data, aren’t good removing outliers. ’s example using strengths moving-median moving-average. (Note earlier columns created mutate available creation later columns, can done one step):  can see combination minimal moving-median moving-average smoothing produced curve noise removed minimal introduction bias. (Note first last 2 data points now NA smoothing)","code":"ex_dat_mrg <-   mutate(group_by(ex_dat_mrg, Well, Bacteria_strain, Phage, noise),          smoothed_med3 =             smooth_data(x = Time, y = Measurements,                        sm_method = \"moving-median\", window_width_n = 3),          #Note that for the second round, we're using the           #first smoothing as the input y          smoothed =             smooth_data(x = Time, y = smoothed_med3,                        sm_method = \"moving-average\", window_width_n = 3))  # What does the smoothed data look like compared to the 'true' noiseless data? ggplot(data = dplyr::filter(ex_dat_mrg, Well %in% sample_wells),        aes(x = Time, y = Measurements, color = noise)) +   geom_point(alpha = 0.75, size = 0.75) +   geom_line(linewidth = 1.25, alpha = 0.5, aes(y = smoothed)) +   facet_wrap(~Well, scales = \"free_y\") +   ggtitle(\"median then average smoothing\") +   scale_y_log10() #> Warning: Transformation introduced infinite values in continuous y-axis #> Transformation introduced infinite values in continuous y-axis #> Warning: Removed 8 rows containing missing values (`geom_line()`)."},{"path":"https://mikeblazanin.github.io/gcplyr/articles/noise.html","id":"DerivsOfSmoothed","dir":"Articles","previous_headings":"","what":"Calculating derivatives of smoothed data","title":"Dealing with noise","text":"’ve smoothed data, can calculate derivatives using smoothed data. Combining smoothing raw data fitting using multiple points calculating derivatives can powerful combination reducing effects noise minimizing introduction bias.     can see smoothing raw data improved derivatives dramatically. top , combination smoothing raw data points smoothing derivative calculations can even lead less noisy derivatives. However, per-capita derivatives still somewhat noisy cases (like Well F10). next section, ’ll discuss final strategy dealing sort per-capita derivative specific noise.","code":"# Note here that we're calculating derivatives of the smoothed column generated #  in the previous section by combining moving median and moving average smoothing ex_dat_mrg <-    mutate(group_by(ex_dat_mrg, Well, Bacteria_strain, Phage, noise),          deriv_raw = calc_deriv(x = Time, y = Measurements),          deriv_percap_raw = calc_deriv(x = Time, y = Measurements,                                        percapita = TRUE, blank = 0),          deriv = calc_deriv(x = Time, y = smoothed),          deriv_percap = calc_deriv(x = Time, y = smoothed,                                    percapita = TRUE, blank = 0),          deriv3 = calc_deriv(x = Time, y = smoothed, window_width_n = 3),          deriv_percap3 = calc_deriv(x = Time, y = smoothed, percapita = TRUE,                                      blank = 0, window_width_n = 3))  # Plot derivative of smoothed data ggplot(data = dplyr::filter(ex_dat_mrg, Well %in% sample_wells),        aes(x = Time, y = deriv_raw, color = noise)) +   geom_point(alpha = 0.75, size = 0.75) +   geom_line(linewidth = 1.25, alpha = 0.5, aes(y = deriv)) +   facet_wrap(~Well, scales = \"free_y\") +   ggtitle(\"smoothed raw data\") #> Warning: Removed 8 rows containing missing values (`geom_point()`). #> Warning: Removed 10 rows containing missing values (`geom_line()`). # Plot derivative of smoothed data with smoothing during calc_deriv ggplot(data = dplyr::filter(ex_dat_mrg, Well %in% sample_wells),        aes(x = Time, y = deriv_raw, color = noise)) +   geom_point(alpha = 0.75, size = 0.75) +   geom_line(linewidth = 1.25, alpha = 0.5, aes(y = deriv3)) +   facet_wrap(~Well, scales = \"free_y\") +   ggtitle(\"smoothed data and calc_deriv window_width_n = 3\") #> Warning: Removed 8 rows containing missing values (`geom_point()`). #> Warning: Removed 12 rows containing missing values (`geom_line()`). # Plot per-capita derivative of smoothed data ggplot(data = dplyr::filter(ex_dat_mrg, Well %in% sample_wells),        aes(x = Time, y = deriv_percap_raw, color = noise)) +   geom_point(alpha = 0.75, size = 0.75) +   geom_line(linewidth = 1.25, alpha = 0.5, aes(y = deriv_percap)) +   facet_wrap(~Well, scales = \"free_y\") +   ggtitle(\"smoothed raw data\") +   ylim(NA, 10) #> Warning: Removed 22 rows containing missing values (`geom_point()`). #> Warning: Removed 10 rows containing missing values (`geom_line()`). # Plot per-capita derivative of smoothed data with smoothing during calc_deriv ggplot(data = dplyr::filter(ex_dat_mrg, Well %in% sample_wells),        aes(x = Time, y = deriv_percap_raw, color = noise)) +   geom_point(alpha = 0.75, size = 0.75) +   geom_line(linewidth = 1.25, alpha = 0.5, aes(y = deriv_percap3)) +   facet_wrap(~Well, scales = \"free_y\") +   ggtitle(\"smoothed data and calc_deriv window_width_n = 3\") +   ylim(NA, 10) #> Warning: Removed 22 rows containing missing values (`geom_point()`). #> Warning: Removed 12 rows containing missing values (`geom_line()`)."},{"path":"https://mikeblazanin.github.io/gcplyr/articles/noise.html","id":"SubsetAnalysis","dir":"Articles","previous_headings":"","what":"Summarizing on subsets of derivatives","title":"Dealing with noise","text":"one final strategy can employ dealing noisy data: since noise often relatively stronger effects densities near 0, can simply exclude data points density near 0. Let’s look smoothed per-capita growth rates:  now let’s compare density plots:  Clearly can see noise per-capita growth rate occurs bacterial population density low. Indeed, common per-capita growth rates, sensitive noise low densities. can ? can simply exclude values density really low. Let’s plot per-capita growth rate data different cutoffs minimum density bacteria:    can see, limit analyses data points bacterial population cutoff density, many noisy points disappear, noisy derivative curves look increasingly similar noiseless derivative curves. take final step, can use cutoffs summarize commands calculate maximum growth rate bacteria density least 0.01. now can visualize findings:  can see limiting analyses just subset data, maximum per-capita growth rate now become nearly identical noisy noiseless data three example wells. Unfortunately, F1 haven’t able eliminate noise. Hopefully doesn’t happen data! , continue try alternate smoothing, derivative calculating, subset strategies try reduce effects noise findings.","code":"# Plot per-capita derivative of smoothed data with smoothing during calc_deriv ggplot(data = dplyr::filter(ex_dat_mrg, Well %in% sample_wells),        aes(x = Time, y = deriv_percap_raw, color = noise)) +   geom_point(alpha = 0.75, size = 0.75) +   geom_line(linewidth = 1.25, alpha = 0.5, aes(y = deriv_percap3)) +   facet_wrap(~Well, scales = \"free_y\") +   ggtitle(\"smoothed data and calc_deriv window_width_n = 3\") +   ylim(NA, 10) #> Warning: Removed 22 rows containing missing values (`geom_point()`). #> Warning: Removed 12 rows containing missing values (`geom_line()`). ggplot(data = dplyr::filter(ex_dat_mrg, Well %in% sample_wells),        aes(x = Time, y = Measurements, color = noise)) +   geom_point(alpha = 0.75, size = 0.75) +   geom_line(linewidth = 1.25, alpha = 0.5, aes(y = smoothed)) +   facet_wrap(~Well, scales = \"free_y\") #> Warning: Removed 8 rows containing missing values (`geom_line()`). for (my_well in sample_wells) {   # Title   title <- cowplot::ggdraw() +      cowplot::draw_label(paste(\"Well\", my_well),                          fontface = \"bold\", x = 0, hjust = 0) +     theme(plot.margin = margin(0, 0, 0, 7))      # Save x and y limits for all plots so they're all on the same axes   xdat <- dplyr::filter(ex_dat_mrg, Well == my_well)$Time   ydat <- dplyr::filter(ex_dat_mrg, Well == my_well)$deriv_percap3   xlims <- c(min(xdat[is.finite(xdat)], na.rm = TRUE),              max(xdat[is.finite(xdat)], na.rm = TRUE))   ylims <- c(min(ydat[is.finite(ydat)], na.rm = TRUE),              max(ydat[is.finite(ydat)], na.rm = TRUE))      # Plot unfiltered data   p1 <- ggplot(data = dplyr::filter(ex_dat_mrg, Well == my_well),                aes(x = Time, y = deriv_percap3, color = noise)) +     geom_point(alpha = 0.5) + facet_wrap(~Well, scales = \"free\") +     ggtitle(\"all data\") +     xlim(xlims[1], xlims[2]) + ylim(ylims[1], ylims[2])      # Plot data with filters for density   p2 <- ggplot(data = dplyr::filter(ex_dat_mrg,                                      Well == my_well, smoothed > 0.001),                aes(x = Time, y = deriv_percap3, color = noise)) +     geom_point(alpha = 0.5) + facet_wrap(~Well, scales = \"free\") +     ggtitle(\"data where Abs > 0.001\") +     xlim(xlims[1], xlims[2]) + ylim(ylims[1], ylims[2])   p3 <- ggplot(data = dplyr::filter(ex_dat_mrg,                                      Well == my_well, smoothed > 0.005),                aes(x = Time, y = deriv_percap3, color = noise)) +     geom_point(alpha = 0.5) + facet_wrap(~Well, scales = \"free\") +     ggtitle(\"data where Abs > 0.005\") +     xlim(xlims[1], xlims[2]) + ylim(ylims[1], ylims[2])   p4 <- ggplot(data = dplyr::filter(ex_dat_mrg,                                      Well == my_well, smoothed > 0.01),                aes(x = Time, y = deriv_percap3, color = noise)) +     geom_point(alpha = 0.5) + facet_wrap(~Well, scales = \"free\") +     ggtitle(\"data where Abs > 0.01\") +     xlim(xlims[1], xlims[2]) + ylim(ylims[1], ylims[2])      print(cowplot::plot_grid(title, cowplot::plot_grid(p1, p2, p3, p4, ncol = 2),                            ncol = 1, rel_heights = c(0.1, 1))) } #> Warning: Removed 12 rows containing missing values (`geom_point()`). #> Warning: Removed 4 rows containing missing values (`geom_point()`). #> Warning: Removed 2 rows containing missing values (`geom_point()`). #> Removed 2 rows containing missing values (`geom_point()`). #> Warning: Removed 12 rows containing missing values (`geom_point()`). #> Warning: Removed 4 rows containing missing values (`geom_point()`). #> Warning: Removed 2 rows containing missing values (`geom_point()`). #> Removed 2 rows containing missing values (`geom_point()`). #> Warning: Removed 14 rows containing missing values (`geom_point()`). #> Warning: Removed 3 rows containing missing values (`geom_point()`). #> Warning: Removed 12 rows containing missing values (`geom_point()`). #> Warning: Removed 4 rows containing missing values (`geom_point()`). #> Warning: Removed 3 rows containing missing values (`geom_point()`). #> Warning: Removed 2 rows containing missing values (`geom_point()`). ex_dat_mrg_sum <-   summarize(group_by(ex_dat_mrg, Well, Bacteria_strain, Phage, noise),             max_growth_rate = max(deriv_percap3[smoothed > 0.01],                                    na.rm = TRUE)) #> `summarise()` has grouped output by 'Well', 'Bacteria_strain', 'Phage'. You can #> override using the `.groups` argument. head(ex_dat_mrg_sum) #> # A tibble: 6 × 5 #> # Groups:   Well, Bacteria_strain, Phage [3] #>   Well  Bacteria_strain Phage       noise max_growth_rate #>   <fct> <chr>           <chr>       <chr>           <dbl> #> 1 A1    Strain 1        No Phage    No              1.02  #> 2 A1    Strain 1        No Phage    Yes             1.02  #> 3 E11   Strain 29       Phage Added No              1.60  #> 4 E11   Strain 29       Phage Added Yes             1.65  #> 5 F1    Strain 31       No Phage    No              0.609 #> 6 F1    Strain 31       No Phage    Yes             0.788 ggplot(data = dplyr::filter(ex_dat_mrg,                              Well %in% sample_wells, smoothed >= 0.01),        aes(x = Time, y = deriv_percap3, color = noise)) +   geom_point() +   facet_wrap(~Well, scales = \"free\") +   ggtitle(\"data where smoothed density > 0.01\") +   geom_hline(data = dplyr::filter(ex_dat_mrg_sum, Well %in% sample_wells),               aes(yintercept = max_growth_rate, color = noise), lty = 2) #> Warning: Removed 6 rows containing missing values (`geom_point()`)."},{"path":"https://mikeblazanin.github.io/gcplyr/articles/noise.html","id":"whats-next","dir":"Articles","previous_headings":"","what":"What’s next?","title":"Dealing with noise","text":"Now ’ve analyzed data dealt noise, ’s just concluding notes best practices running statistics, merging growth curve analyses data, additional resources analyzing growth curves. Introduction: vignette(\"gcplyr\") Importing transforming data: vignette(\"import_transform\") Incorporating design information: vignette(\"incorporate_designs\") Pre-processing plotting data: vignette(\"preprocess_plot\") Processing data: vignette(\"process\") Analyzing data: vignette(\"analyze\") Dealing noise: vignette(\"noise\") Statistics, merging data, resources: vignette(\"conclusion\")","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/preprocess_plot.html","id":"where-are-we-so-far","dir":"Articles","previous_headings":"","what":"Where are we so far?","title":"Pre-processing and plotting data","text":"Introduction: vignette(\"gcplyr\") Importing transforming data: vignette(\"import_transform\") Incorporating design information: vignette(\"incorporate_designs\") Pre-processing plotting data: vignette(\"preprocess_plot\") Processing data: vignette(\"process\") Analyzing data: vignette(\"analyze\") Dealing noise: vignette(\"noise\") Statistics, merging data, resources: vignette(\"conclusion\") far, ’ve imported transformed measures, combined design information. Now ’re going final pre-processing steps show easily plot data ggplot. haven’t already, load necessary packages.","code":"library(gcplyr) #> ##  #> ## gcplyr (Version 1.5.0, Build Date: 2023-04-03) #> ## See http://github.com/mikeblazanin/gcplyr for additional documentation #> ## Please cite software as: #> ##   Blazanin, Michael. 2023. 'gcplyr: manipulate and analyze growth #> ##   curve data.' R package version 1.5.0 #> ##  library(dplyr) #>  #> Attaching package: 'dplyr' #> The following objects are masked from 'package:stats': #>  #>     filter, lag #> The following objects are masked from 'package:base': #>  #>     intersect, setdiff, setequal, union library(ggplot2) library(lubridate) #>  #> Attaching package: 'lubridate' #> The following objects are masked from 'package:base': #>  #>     date, intersect, setdiff, union # This code was previously explained # Here we're re-running it so it's available for us to work with example_tidydata <- trans_wide_to_tidy(example_widedata_noiseless,                                        id_cols = \"Time\") example_design <- make_design(   pattern_split = \",\", nrows = 8, ncols = 12,   \"Bacteria_strain\" = make_designpattern(     values = paste(\"Strain\", 1:48),     rows = 1:8, cols = 1:6, pattern = 1:48, byrow = TRUE),   \"Bacteria_strain\" = make_designpattern(     values = paste(\"Strain\", 1:48),     rows = 1:8, cols = 7:12, pattern = 1:48, byrow = TRUE),   \"Phage\" = make_designpattern(     values = c(\"No Phage\"), rows = 1:8, cols = 1:6, pattern = \"1\"),   \"Phage\" = make_designpattern(     values = c(\"Phage Added\"), rows = 1:8, cols = 7:12, pattern = \"1\")) ex_dat_mrg <- merge_dfs(example_tidydata, example_design) #> Joining with `by = join_by(Well)`"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/preprocess_plot.html","id":"pre-processing","dir":"Articles","previous_headings":"","what":"Pre-processing","title":"Pre-processing and plotting data","text":"Now data designs merged, ’re almost ready start processing analyzing . However, first need carry necessary pre-processing steps, like excluding wells contaminated empty, converting time formats numeric.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/preprocess_plot.html","id":"pre-processing-excluding-data","dir":"Articles","previous_headings":"Pre-processing","what":"Pre-processing: excluding data","title":"Pre-processing and plotting data","text":"cases, want remove wells growth curves data carry downstream analyses. instance, may left empty, contained negative controls, contaminated. can use dplyr’s filter function remove wells meet criteria want exclude. instance, let’s imagine realized put wrong media Well B1, strain 13 contaminated. exclude analyses, can simply:","code":"example_data_and_designs_filtered <-    filter(ex_dat_mrg,           Well != \"B1\", Bacteria_strain != \"Strain 13\") head(example_data_and_designs_filtered) #>   Time Well Measurements Bacteria_strain    Phage #> 1    0   A1        0.002        Strain 1 No Phage #> 2    0   D1        0.002       Strain 19 No Phage #> 3    0   E1        0.002       Strain 25 No Phage #> 4    0   F1        0.002       Strain 31 No Phage #> 5    0   G1        0.002       Strain 37 No Phage #> 6    0   H1        0.002       Strain 43 No Phage"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/preprocess_plot.html","id":"pre-processing-converting-dates-times-into-numeric","dir":"Articles","previous_headings":"Pre-processing","what":"Pre-processing: converting dates & times into numeric","title":"Pre-processing and plotting data","text":"Growth curve data produced plate reader often encodes timestamp information string (e.g. “2:45:11” 2 hours, 45 minutes, 11 seconds), downstream analyses need timestamp information numeric (e.g. number seconds elapsed). Luckily, others written great packages make easy convert common date-time text formats plain numeric formats. , ’ll see use lubridate : First create data frame time saved might plate reader. can see Time aren’t written easy numeric. Instead, ’re format ’s easy human understand (unfortunately usable analysis). Let’s use lubridate convert text usable format. lubridate whole family functions can parse text hour, minute, /second components. can use hms text contains hour, minute, second information, hm contains hour minute information, ms contains minute second information. hms parsed text, ’ll use time_length convert output hms pure numeric value. default, time_length returns units seconds, can change changing unit argument time_length. now can see ’ve gotten nice numeric Time values! can proceed next steps analysis.","code":"#Don't worry how this code works, it's just creating an example file # in the same format that a plate reader would ex_dat_mrg$Time <-   paste(ex_dat_mrg$Time %/% 3600,         formatC((ex_dat_mrg$Time %% 3600) %/% 60,                  width = 2, flag = 0),         formatC((ex_dat_mrg$Time %% 3600) %% 60,                 width = 2, flag = 0),         sep = \":\")  head(ex_dat_mrg) #>      Time Well Measurements Bacteria_strain    Phage #> 1 0:00:00   A1        0.002        Strain 1 No Phage #> 2 0:00:00   B1        0.002        Strain 7 No Phage #> 3 0:00:00   C1        0.002       Strain 13 No Phage #> 4 0:00:00   D1        0.002       Strain 19 No Phage #> 5 0:00:00   E1        0.002       Strain 25 No Phage #> 6 0:00:00   F1        0.002       Strain 31 No Phage # We have previously loaded lubridate, but if you haven't already then # make sure to add the line: #    library(lubridate)  ex_dat_mrg$Time <- time_length(hms(ex_dat_mrg$Time), unit = \"hour\")  head(ex_dat_mrg) #>   Time Well Measurements Bacteria_strain    Phage #> 1    0   A1        0.002        Strain 1 No Phage #> 2    0   B1        0.002        Strain 7 No Phage #> 3    0   C1        0.002       Strain 13 No Phage #> 4    0   D1        0.002       Strain 19 No Phage #> 5    0   E1        0.002       Strain 25 No Phage #> 6    0   F1        0.002       Strain 31 No Phage"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/preprocess_plot.html","id":"plotting-your-data","dir":"Articles","previous_headings":"","what":"Plotting your data","title":"Pre-processing and plotting data","text":"data merged times converted numeric, can easily plot data using ggplot2 package. ’s ggplot2 specifically built assumption data tidy-shaped, ! won’t go depth use ggplot , three main commands plot : ggplot - ggplot function specify data.frame like use aesthetics plot (x y axes like) geom_line - tells ggplot like plot data, case line (another common geom time-series data geom_point) facet_wrap - tells ggplot plot Well separate facet ’ll using format plot data throughout remainder vignette  Generally speaking, plot data frequently, every way can think ! every processing analysis step, visualize input data output data understand processing analysis steps whether right choices particular data (vignette !)","code":"# We have previously loaded ggplot2, but if you haven't already then # make sure to add the line: #     library(ggplot2)  # First, we'll reorder the Well levels so they plot in the correct order ex_dat_mrg$Well <-    factor(ex_dat_mrg$Well,          levels = paste(rep(LETTERS[1:8], each = 12), 1:12, sep = \"\"))  ggplot(data = ex_dat_mrg, aes(x = Time, y = Measurements)) +   geom_line() +   facet_wrap(~Well, nrow = 8, ncol = 12)"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/preprocess_plot.html","id":"whats-next","dir":"Articles","previous_headings":"","what":"What’s next?","title":"Pre-processing and plotting data","text":"Now ’ve pre-processed visualized data, ’s time process (cases) analyze (pretty much always) ! Introduction: vignette(\"gcplyr\") Importing transforming data: vignette(\"import_transform\") Incorporating design information: vignette(\"incorporate_designs\") Pre-processing plotting data: vignette(\"preprocess_plot\") Processing data: vignette(\"process\") Analyzing data: vignette(\"analyze\") Dealing noise: vignette(\"noise\") Statistics, merging data, resources: vignette(\"conclusion\")","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/process.html","id":"where-are-we-so-far","dir":"Articles","previous_headings":"","what":"Where are we so far?","title":"Processing data","text":"Introduction: vignette(\"gcplyr\") Importing transforming data: vignette(\"import_transform\") Incorporating design information: vignette(\"incorporate_designs\") Pre-processing plotting data: vignette(\"preprocess_plot\") Processing data: vignette(\"process\") Analyzing data: vignette(\"analyze\") Dealing noise: vignette(\"noise\") Statistics, merging data, resources: vignette(\"conclusion\") far, ’ve imported transformed measures, combined design information, pre-processed plotted data. Now ’re going processing raw data: calculating derivatives. haven’t already, load necessary packages.","code":"library(gcplyr) #> ##  #> ## gcplyr (Version 1.5.0, Build Date: 2023-04-03) #> ## See http://github.com/mikeblazanin/gcplyr for additional documentation #> ## Please cite software as: #> ##   Blazanin, Michael. 2023. 'gcplyr: manipulate and analyze growth #> ##   curve data.' R package version 1.5.0 #> ##  library(dplyr) #>  #> Attaching package: 'dplyr' #> The following objects are masked from 'package:stats': #>  #>     filter, lag #> The following objects are masked from 'package:base': #>  #>     intersect, setdiff, setequal, union library(ggplot2) # This code was previously explained # Here we're re-running it so it's available for us to work with example_tidydata <- trans_wide_to_tidy(example_widedata_noiseless,                                        id_cols = \"Time\") example_design <- make_design(   pattern_split = \",\", nrows = 8, ncols = 12,   \"Bacteria_strain\" = make_designpattern(     values = paste(\"Strain\", 1:48),     rows = 1:8, cols = 1:6, pattern = 1:48, byrow = TRUE),   \"Bacteria_strain\" = make_designpattern(     values = paste(\"Strain\", 1:48),     rows = 1:8, cols = 7:12, pattern = 1:48, byrow = TRUE),   \"Phage\" = make_designpattern(     values = c(\"No Phage\"), rows = 1:8, cols = 1:6, pattern = \"1\"),   \"Phage\" = make_designpattern(     values = c(\"Phage Added\"), rows = 1:8, cols = 7:12, pattern = \"1\")) ex_dat_mrg <- merge_dfs(example_tidydata, example_design) #> Joining with `by = join_by(Well)` ex_dat_mrg$Well <-    factor(ex_dat_mrg$Well,          levels = paste(rep(LETTERS[1:8], each = 12), 1:12, sep = \"\")) #Convert time to hours ex_dat_mrg$Time <- ex_dat_mrg$Time/3600"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/process.html","id":"how-to-process-and-analyze-your-data","dir":"Articles","previous_headings":"","what":"How to process and analyze your data","title":"Processing data","text":"data design information pre-processed, dataset now organized way ’s easy export analyze. Broadly speaking, two main approaches analyzing growth curves data: directly quantify attributes growth dynamics - gcplyr facilitates fit growth dynamics mathematical model, extract parameters fitted model - check growth curve analysis packages section vignette(“conclusion”) ’re interesting exploring approach point, since data now well-organized, advanced users may also decide want write custom analyses (lieu , alongside, gcplyr-based /fitting-based analyses). , directly quantify attributes growth curves? Generally, find features density data derivatives. Different projects may desire different analyses, article Analyzing Data Dealing Noise articles written highlight common analyses, rather prescribing everyone . list common metrics require derivatives calculated. intend calculate metrics, just want calculate plot derivatives, continue reading. Otherwise, feel free skip right Analyzing Data article. Metrics requiring derivatives: lag time time reach growth rate maximum per-capita growth rate (.e. minimum doubling time) inflection point density time diauxic shift occurs maximum per-capita growth rate diauxie dig calculating derivatives, first need familiarize dplyr package functions group_by mutate. ? upcoming gcplyr processing functions best used within dplyr::mutate. ’re already familiar dplyr, feel free skip straight Calculating Derivatives. ’re familiar yet, primer teach need know use gcplyr.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/process.html","id":"a-brief-primer-on-dplyr","dir":"Articles","previous_headings":"How to process and analyze your data","what":"A brief primer on dplyr","title":"Processing data","text":"R package dplyr provides “grammar data manipulation” useful broad array data analysis tasks (fact, dplyr direct inspiration name gcplyr!) purposes, ’re going focus two functions: group_by mutate. mutate function dplyr allows users easily create new columns data.frame’s. us, ’re going use mutate create columns derivatives calculate. However, want make sure derivative-calculating done unique well independently. order , ’re first going use group_by function, allows users group rows data.frame’s groups mutate treat independently. growth curves, means : group_by data every unique well group mutate create new columns calculated derivatives group_by, need specify data.frame grouped, want list columns needed identify unique well dataset. Typically, includes design columns along plate name well name. Make sure ’re grouping Time, Absorbance, anything else varies within well, since dplyr group timepoints within well separately. use mutate, simply specify: name variable want results saved function calculates new column want additional columns, simply add mutate. ’ll see throughout rest article, ’ll using group_by mutate calculate derivatives. want learn , dplyr extensive documentation examples online, primer coming examples sufficient calculate derivatives gcplyr.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/process.html","id":"CalculatingDerivatives","dir":"Articles","previous_headings":"","what":"Processing data: calculating derivatives","title":"Processing data","text":"two derivatives primarily interested calculating: plain derivative - slope original density data per-capita derivative - growth rate cells gcplyr includes calc_deriv calculate .","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/process.html","id":"a-simple-derivative","dir":"Articles","previous_headings":"Processing data: calculating derivatives","what":"A simple derivative","title":"Processing data","text":"calculate simple derivative (slope original data) using calc_deriv, simply provide x y values. Note growth rate cells, rather measure quickly whole population growing time point. visualize results, let’s look wells representative overall diversity dynamics example data. (code, visualize data).  might notice lines aren’t super smooth. ? plate reader data limited resolution, nearest 0.001, causing derivative “jump” reading increases.","code":"ex_dat_mrg <- mutate(group_by(ex_dat_mrg, Well, Bacteria_strain, Phage),                      deriv = calc_deriv(x = Time, y = Measurements)) sample_wells <- c(\"A1\", \"F1\", \"F10\", \"E11\")  # Now let's plot the derivative ggplot(data = dplyr::filter(ex_dat_mrg, Well %in% sample_wells),        aes(x = Time, y = deriv)) +   geom_line() +   facet_wrap(~Well, scales = \"free\") #> Warning: Removed 1 row containing missing values (`geom_line()`)."},{"path":"https://mikeblazanin.github.io/gcplyr/articles/process.html","id":"per-capita-derivative","dir":"Articles","previous_headings":"Processing data: calculating derivatives","what":"Per-capita derivative","title":"Processing data","text":"calculate per-capita derivative, simply modify use calc_deriv argument percapita = TRUE. Note case, required specify blank value, .e. value Measurements corresponds population density 0. data already normalized, simply add blank = 0.  derivatives jumpy. ? limited resolution plate reader amplified effect per-capita derivative densities close 0. Luckily, calc_deriv can calculate derives fitting linear regression multiple points, reducing jumpiness derivative. use fitting functionality calc_deriv, specify either window_width window_width_n parameter. window_width specifies wide window used include points fitting units x, window_width_n specifies number data points. , ’ll demonstrate five data points. best practice, recommend fitting log-transformed y values, since exponentially growing density values linear log-transformed. can achieve simply setting trans_y = 'log'. log-transformation, note calc_deriv return NA data points reading equal blank value.  Great! jumpiness reduced immensely.","code":"ex_dat_mrg <- mutate(group_by(ex_dat_mrg, Well, Bacteria_strain, Phage),                      deriv_percap = calc_deriv(x = Time, y = Measurements,                                         percapita = TRUE, blank = 0))  # Now let's plot the per-capita derivative ggplot(data = dplyr::filter(ex_dat_mrg, Well %in% sample_wells),        aes(x = Time, y = deriv_percap)) +   geom_line() +   facet_wrap(~Well, scales = \"free\") #> Warning: Removed 1 row containing missing values (`geom_line()`). ex_dat_mrg <- mutate(group_by(ex_dat_mrg, Well, Bacteria_strain, Phage),                      deriv_percap5 = calc_deriv(x = Time, y = Measurements,                                          percapita = TRUE, blank = 0,                                         window_width_n = 5, trans_y = \"log\"))  # Now let's plot the derivative ggplot(data = dplyr::filter(ex_dat_mrg, Well %in% sample_wells),        aes(x = Time, y = deriv_percap5)) +   geom_line() +   facet_wrap(~Well, scales = \"free\") #> Warning: Removed 4 rows containing missing values (`geom_line()`)."},{"path":"https://mikeblazanin.github.io/gcplyr/articles/process.html","id":"converting-per-capita-growth-rates-into-doubling-times","dir":"Articles","previous_headings":"Processing data: calculating derivatives","what":"Converting per-capita growth rates into doubling times","title":"Processing data","text":"’d rather express per-capita growth rates doubling time, simply use doubling_time function convert per-capita growth rates equivalent doubling times.","code":"ex_dat_mrg <- mutate(group_by(ex_dat_mrg, Well, Bacteria_strain, Phage),                      deriv_percap5 = calc_deriv(x = Time, y = Measurements,                                          percapita = TRUE, blank = 0,                                         window_width_n = 5, trans_y = \"log\"),                      doub_time = doubling_time(y = deriv_percap5)) head(ex_dat_mrg) #> # A tibble: 6 × 9 #> # Groups:   Well, Bacteria_strain, Phage [4] #>    Time Well  Measurements Bacteria_strain Phage       deriv deriv_percap #>   <dbl> <fct>        <dbl> <chr>           <chr>       <dbl>        <dbl> #> 1  0    A1           0.002 Strain 1        No Phage        0            0 #> 2  0    F1           0.002 Strain 31       No Phage        0            0 #> 3  0    F10          0.002 Strain 34       Phage Added     0            0 #> 4  0    E11          0.002 Strain 29       Phage Added     0            0 #> 5  0.25 A1           0.002 Strain 1        No Phage        0            0 #> 6  0.25 F1           0.002 Strain 31       No Phage        0            0 #> # ℹ 2 more variables: deriv_percap5 <dbl>, doub_time <dbl>"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/process.html","id":"whats-next","dir":"Articles","previous_headings":"","what":"What’s next?","title":"Processing data","text":"Now ’ve processed data, ’re ready analyze ! Introduction: vignette(\"gcplyr\") Importing transforming data: vignette(\"import_transform\") Incorporating design information: vignette(\"incorporate_designs\") Pre-processing plotting data: vignette(\"preprocess_plot\") Processing data: vignette(\"process\") Analyzing data: vignette(\"analyze\") Dealing noise: vignette(\"noise\") Statistics, merging data, resources: vignette(\"conclusion\")","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Mike Blazanin. Author, maintainer.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Blazanin, Michael. 2023. 'gcplyr: manipulate analyze growth curve data.' R package version 1.5.0","code":"@Manual{,   title = {{gcplyr}: manipulate and analyze growth curve data},   author = {Michael Blazanin},   year = {2023},   note = {version 1.5.0},   url = {https://github.com/mikeblazanin/gcplyr/}, }"},{"path":[]},{"path":"https://mikeblazanin.github.io/gcplyr/index.html","id":"what-this-package-can-do","dir":"","previous_headings":"","what":"What this package can do","title":"Manipulate and Analyze Growth Curve Data","text":"gcplyr created make easier import, wrangle, model-free analyses microbial growth curve data, commonly output plate readers. gcplyr can flexibly import common data formats output plate readers reshape ‘tidy’ formats analyses. gcplyr can import experimental designs files directly R, merge design information density data. merged tidy-shaped data easy work plot using functions gcplyr popular packages dplyr ggplot2. gcplyr can calculate plain per-capita derivatives density data. gcplyr several methods deal noise density derivatives data. gcplyr can extract parameters like growth rate/doubling time, carrying capacity, diauxic shifts, extinction, without fitting equation growth data. Please send questions, requests, comments, bugs mikeblazanin [] gmail [dot] com","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Manipulate and Analyze Growth Curve Data","text":"can install recently-released version GitHub running following lines R: can install version -recently released CRAN running following line R:","code":"install.packages(\"devtools\") devtools::install_github(\"mikeblazanin/gcplyr\") install.packages(\"gcplyr\")"},{"path":"https://mikeblazanin.github.io/gcplyr/index.html","id":"getting-started","dir":"","previous_headings":"","what":"Getting Started","title":"Manipulate and Analyze Growth Curve Data","text":"best way get started read articles series, breaks typical workflow using gcplyr start finish, starting introduction: Introduction: vignette(\"gcplyr\") Importing transforming data: vignette(\"import_transform\") Incorporating design information: vignette(\"incorporate_designs\") Pre-processing plotting data: vignette(\"preprocess_plot\") Processing data: vignette(\"process\") Analyzing data: vignette(\"analyze\") Dealing noise: vignette(\"noise\") Statistics, merging data, resources: vignette(\"conclusion\")","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/index.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Manipulate and Analyze Growth Curve Data","text":"Please cite software : Blazanin, Michael. 2023. ‘gcplyr: manipulate analyze growth curve data.’ R package version 1.5.0","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/ExtremaFunctions.html","id":null,"dir":"Reference","previous_headings":"","what":"Find local extrema of a numeric vector — ExtremaFunctions","title":"Find local extrema of a numeric vector — ExtremaFunctions","text":"functions take vector y values identify local extrema.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/ExtremaFunctions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find local extrema of a numeric vector — ExtremaFunctions","text":"","code":"find_local_extrema(   y,   x = NULL,   window_width = NULL,   window_width_n = NULL,   window_height = NULL,   return = \"index\",   return_maxima = TRUE,   return_minima = TRUE,   return_endpoints = TRUE,   subset = NULL,   na.rm = TRUE,   width_limit = NULL,   width_limit_n = NULL,   height_limit = NULL )  first_maxima(   y,   x = NULL,   window_width = NULL,   window_width_n = NULL,   window_height = NULL,   return = \"index\",   return_endpoints = TRUE,   ... )  first_minima(   y,   x = NULL,   window_width = NULL,   window_width_n = NULL,   window_height = NULL,   return = \"index\",   return_endpoints = TRUE,   ... )"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/ExtremaFunctions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Find local extrema of a numeric vector — ExtremaFunctions","text":"y Numeric vector y values identify local extrema x Optional numeric vector corresponding x values window_width Width window (units x) used search local extrema. narrower width sensitive narrow local maxima/minima, wider width less sensitive local maxima/minima. window_width_n maximum number data points single  extrema-search step allowed take. example, maxima-finding, function pass valley consisting window_width_n data points. smaller window_width_n sensitive  narrow local maxima/minima, larger  window_width_n less sensitive  narrow local maxima/minima. window_height maximum change y single extrema-search step allowed take.  example,  maxima-finding, function pass valley deeper window_height. smaller window_height sensitive  shallow local maxima/minima, larger  window_height less sensitive  shallow maxima/minima. return One c(\"index\", \"x\", \"y\"), determining whether function return index, x value, y value associated identified extremas return_maxima, return_minima logical classes local extrema return return_endpoints first last values y included returned  vector extrema? subset vector logical values indicating x y values included (TRUE) excluded (FALSE). return = \"index\", index whole  vector subset vector na.rm logical whether NA's removed analyzing width_limit Deprecated, use window_width instead width_limit_n Deprecated, use window_width_n instead height_limit Deprecated, use window_height instead ... (first_maxima first_minima),  parameters pass find_local_extrema","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/ExtremaFunctions.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Find local extrema of a numeric vector — ExtremaFunctions","text":"find_local_extrema returns vector corresponding     found local extrema.  first_maxima returns first maxima, shortcut  find_local_extrema(return_maxima = TRUE, return_minima = FALSE)[1]  first_minima returns first minima, shortcut  find_local_extrema(return_maxima = FALSE, return_minima = TRUE)[1] return = \"index\", returned value(s) indices    corresponding local extrema data return = \"x\", returned value(s) x value(s)     corresponding local extrema data return = \"y\", returned value(s) y value(s)    corresponding local extrema data","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/ExtremaFunctions.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Find local extrema of a numeric vector — ExtremaFunctions","text":"find_local_extrema, one window_width,  window_width_n, window_height must provided. first_minima first_maxima, none  window_width, window_width_n, window_height  provided, window_width_n set 20 multiple window_width, window_width_n,  window_height provided, steps limited conservatively  (single step must meet criteria) function designed compatible use within  dplyr::group_by dplyr::summarize case exact ties y values within window,  first local extrema returned.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/MinMaxGC.html","id":null,"dir":"Reference","previous_headings":"","what":"Maxima and Minima — MinMaxGC","title":"Maxima and Minima — MinMaxGC","text":"Returns maxima minima input values.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/MinMaxGC.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Maxima and Minima — MinMaxGC","text":"","code":"max_gc(..., na.rm = TRUE, allmissing_NA = TRUE)  min_gc(..., na.rm = TRUE, allmissing_NA = TRUE)"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/MinMaxGC.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Maxima and Minima — MinMaxGC","text":"... numeric character arguments na.rm logical indicating whether missing values removed. allmissing_NA logical indicating whether NA returned non-missing arguments passed min max (often na.rm = TRUE values NA)","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/MinMaxGC.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Maxima and Minima — MinMaxGC","text":"allmissing_NA = FALSE, identical min  max. allmissing_NA = TRUE, identical min  max except , cases min  max return infinite value raise warning    non-missing arguments, min_gc  max_gc return NA","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/MinMaxGC.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Maxima and Minima — MinMaxGC","text":"functions wrappers min max, additional argument allmissing_NA.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/ThresholdFunctions.html","id":null,"dir":"Reference","previous_headings":"","what":"Find point(s) when a numeric vector crosses some threshold — ThresholdFunctions","title":"Find point(s) when a numeric vector crosses some threshold — ThresholdFunctions","text":"functions take vector y values identify points y values cross threshold y value.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/ThresholdFunctions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find point(s) when a numeric vector crosses some threshold — ThresholdFunctions","text":"","code":"find_threshold_crosses(   y,   x = NULL,   threshold,   return = \"index\",   return_rising = TRUE,   return_falling = TRUE,   return_endpoints = TRUE,   subset = NULL,   na.rm = TRUE )  first_below(   y,   x = NULL,   threshold,   return = \"index\",   return_endpoints = TRUE,   ... )  first_above(   y,   x = NULL,   threshold,   return = \"index\",   return_endpoints = TRUE,   ... )"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/ThresholdFunctions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Find point(s) when a numeric vector crosses some threshold — ThresholdFunctions","text":"y Numeric vector y values identify threshold crossing event(s) x Optional numeric vector corresponding x values threshold Threshold y value interest return One c(\"index\", \"x\"), determining whether function return index x value associated threshold-crossing event. index, refer data point immediately crossing event. x, use linear interpolation data points immediately threshold-crossing return exact x value threshold crossing occurred return_rising logical whether crossing events y rises threshold returned return_falling logical whether crossing events y falls threshold returned return_endpoints logical whether startpoint returned startpoint threshold return_rising = TRUE, startpoint threshold return_falling = TRUE subset vector logical values indicating x y values included (TRUE) excluded (FALSE). return = \"index\", index whole  vector subset vector na.rm logical whether NA's removed analyzing. return = 'index', indices refer original y vector *including* NA values ... (first_above first_below) arguments  pass find_threshold_crosses","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/ThresholdFunctions.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Find point(s) when a numeric vector crosses some threshold — ThresholdFunctions","text":"find_threshold_crosses returns vector corresponding     threshold crossings.  first_above returns first time y values    rise threshold, shortcut  find_threshold_crosses(return_rising = TRUE, return_falling = FALSE)[1]  first_below returns first time y values    fall threshold, shortcut  find_threshold_crosses(return_rising = FALSE, return_falling = TRUE)[1] return = \"index\", returned value(s) indices    immediately following threshold crossing(s) return = \"x\", returned value(s) x value(s)     corresponding threshold crossing(s) threshold-crossings detected meet criteria,    return NA","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/ThresholdFunctions.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Find point(s) when a numeric vector crosses some threshold — ThresholdFunctions","text":"function designed compatible use within  dplyr::group_by dplyr::summarize","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/WhichMinMaxGC.html","id":null,"dir":"Reference","previous_headings":"","what":"Where is the Min() or Max() or first TRUE or FALSE? — WhichMinMaxGC","title":"Where is the Min() or Max() or first TRUE or FALSE? — WhichMinMaxGC","text":"Determines location, .e. index, (first) minimum maximum numeric (logical) vector.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/WhichMinMaxGC.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Where is the Min() or Max() or first TRUE or FALSE? — WhichMinMaxGC","text":"","code":"which_min_gc(x, empty_NA = TRUE)  which_max_gc(x, empty_NA = TRUE)"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/WhichMinMaxGC.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Where is the Min() or Max() or first TRUE or FALSE? — WhichMinMaxGC","text":"x numeric (logical, integer, double) vector R object internal coercion double works whose min max searched . empty_NA logical, indicating empty value returned NA (default) integer(0) (.min .max).","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/WhichMinMaxGC.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Where is the Min() or Max() or first TRUE or FALSE? — WhichMinMaxGC","text":"empty_NA = FALSE, identical .min  .max empty_NA = TRUE, identical .min  .max except , cases .min  .max return integer(0), which_min_gc  which_max_gc return NA","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/WhichMinMaxGC.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Where is the Min() or Max() or first TRUE or FALSE? — WhichMinMaxGC","text":"functions wrappers .min .max, additional argument empty_NA.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/auc.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate area under the curve — auc","title":"Calculate area under the curve — auc","text":"function takes vector x y values returns scalar area curve, calculated using  trapezoid rule","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/auc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate area under the curve — auc","text":"","code":"auc(x, y, xlim = NULL, blank = 0, na.rm = TRUE, neg.rm = FALSE)"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/auc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate area under the curve — auc","text":"x Numeric vector x values y Numeric vector y values xlim Vector, length 2, delimiting x range area curve calculated (NA can provided area calculated start end data) blank Value subtracted y values calculating area curve na.rm logical indicating whether missing values removed neg.rm logical indicating whether y values zero  treated zeros. FALSE, area curve negative y values calculated normally, effectively subtracting returned value.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/auc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate area under the curve — auc","text":"scalar total area curve","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/auc.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate area under the curve — auc","text":"function designed compatible use within  dplyr::group_by dplyr::summarize","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/block_tidydesign.html","id":null,"dir":"Reference","previous_headings":"","what":"Turn tidydesign into block format — block_tidydesign","title":"Turn tidydesign into block format — block_tidydesign","text":"function allows users convert designs created tidydesign  block format easy output csv inclusion lab notebooks,  etc human-readable format","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/block_tidydesign.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Turn tidydesign into block format — block_tidydesign","text":"","code":"block_tidydesign(   tidydesign,   collapse = NULL,   wellnames_sep = \"_\",   wellnames_colname = \"Well\" )"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/block_tidydesign.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Turn tidydesign into block format — block_tidydesign","text":"tidydesign tidydesign data.frame (e.g. created make_tidydesign) collapse NULL string use concatenating design elements together. NULL design column put block. string, string used paste together design elements design elements returned single block wellnames_sep string used concatenating rownames column names create well names wellnames_colname Header newly-created column containing well names","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/block_tidydesign.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Turn tidydesign into block format — block_tidydesign","text":"list blockdesign data.frames (collapse  NULL list length 1","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/calc_deriv.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate derivatives of vector of data — calc_deriv","title":"Calculate derivatives of vector of data — calc_deriv","text":"Provided vector y values, function returns either plain per-capita difference derivative sequential values","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/calc_deriv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate derivatives of vector of data — calc_deriv","text":"","code":"calc_deriv(   y,   x = NULL,   return = \"derivative\",   percapita = FALSE,   x_scale = 1,   blank = NULL,   subset_by = NULL,   window_width = NULL,   window_width_n = NULL,   trans_y = \"linear\",   na.rm = TRUE )"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/calc_deriv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate derivatives of vector of data — calc_deriv","text":"y Data calculate difference derivative x Vector x values provided simple numeric. return One c(\"difference\", \"derivative\") whether differences y returned, derivative y respect x percapita percapita = TRUE, per-capita difference derivative returned x_scale Numeric scale x derivative calculation Set x_scale ratio units  x desired units. E.g. x seconds,  desired derivative units /minute, set  x_scale = 60 (since 60 seconds 1 minute). blank y-value associated \"blank\" density 0. required percapita = TRUE. vector blank values specified, blank values assumed order unique(subset_by) subset_by optional vector long y.  y split unique values vector  derivative group calculated  independently others. provides internally-implemented approach similar dplyr::group_by dplyr::mutate window_width_n, window_width Set many data points used determine slope point. NULL, calc_deriv  calculates difference derivative point next point, appending NA end. one specified, linear regression  fit points window determine  slope. window_width_n specifies width window number data points. window_width specifies width window units x. using window_width window_width_n  time, windows conservative. Points  included window meet  window_width window_width_n trans_y One c(\"linear\", \"log\") specifying                 transformation y-values. 'log' available calculating per-capita                 derivatives using fitting approach (non-default                  values specified window_width                  window_width_n). per-capita growth expected exponential                  nearly-exponential, \"log\" recommended, since                  exponential growth linear log-transformed. However,                  log-transformations must used care, since y-values                  0 become undefined results                  sensitive incorrect values blank. na.rm logical whether NA's removed analyzing","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/calc_deriv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate derivatives of vector of data — calc_deriv","text":"vector values plain (percapita = FALSE)         per-capita (percapita = TRUE) difference          (return = \"difference\") derivative          (return = \"derivative\") y values. Vector         length y,  NA values          ends","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/calc_deriv.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate derivatives of vector of data — calc_deriv","text":"per-capita derivatives, trans_y = 'linear'          trans_y = 'log' approach value time resolution          increases. instance, assume exponential growth \\(N = e^rt\\)           per-capita growth rate \\(r\\). trans_y = 'linear', note \\(dN/dt = r e^rt = r N\\).           can calculate per-capita growth rate \\(r = dN/dt * 1/N\\). trans_y = 'log', note \\(log(N) = log(e^rt) = rt\\).          can calculate per-capita growth rate slope linear          fit \\(log(N)\\) time, \\(r = log(N)/t\\).","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/doubling_time.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate doubling time equivalent of per-capita growth rate — doubling_time","title":"Calculate doubling time equivalent of per-capita growth rate — doubling_time","text":"Provided vector per-capita growth rates, function returns  vector equivalent doubling times","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/doubling_time.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate doubling time equivalent of per-capita growth rate — doubling_time","text":"","code":"doubling_time(y, x_scale = 1)"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/doubling_time.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate doubling time equivalent of per-capita growth rate — doubling_time","text":"y Vector per-capita derivative data calculate  equivalent doubling time x_scale Numeric scale per-capita derivative values Set x_scale ratio units  y desired units. E.g. y per-second,  desired doubling time minutes, x_scale = 60  (since 60 seconds 1 minute).","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/doubling_time.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate doubling time equivalent of per-capita growth rate — doubling_time","text":"vector values doubling time equivalent         per-capita growth rate supplied y","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/example_widedata.html","id":null,"dir":"Reference","previous_headings":"","what":"Example noisy growth curve data in wide format — example_widedata","title":"Example noisy growth curve data in wide format — example_widedata","text":"dataset containing example growth 96 wells simulated bacteria  bacteria phages Wells A1...A8 F1...F8 contain 48 different simulated bacterial strains growing alone. Wells G1...G8 L1...L8 contain 48 bacterial strains identical layout, time growing presence phage","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/example_widedata.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Example noisy growth curve data in wide format — example_widedata","text":"","code":"example_widedata"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/example_widedata.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Example noisy growth curve data in wide format — example_widedata","text":"dataframe 97 rows 97 variables: time time, seconds, since growth curve began A1, A2...H11, H12 bacterial density given well","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/example_widedata.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Example noisy growth curve data in wide format — example_widedata","text":"Bacterial populations exhibit diauxic growth approach carrying capacity, also evolve resistance face  selection phage population. data includes simulated noise approximate noise generated data collection plate readers","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/example_widedata_noiseless.html","id":null,"dir":"Reference","previous_headings":"","what":"Example growth curve data in wide format — example_widedata_noiseless","title":"Example growth curve data in wide format — example_widedata_noiseless","text":"dataset containing example growth 96 wells simulated bacteria  bacteria phages Wells A1...A8 F1...F8 contain 48 different simulated bacterial strains growing alone. Wells G1...G8 L1...L8 contain 48 bacterial strains identical layout, time growing presence phage","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/example_widedata_noiseless.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Example growth curve data in wide format — example_widedata_noiseless","text":"","code":"example_widedata_noiseless"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/example_widedata_noiseless.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Example growth curve data in wide format — example_widedata_noiseless","text":"dataframe 97 rows 97 variables: time time, seconds, since growth curve began A1, A2...H11, H12 bacterial density given well","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/example_widedata_noiseless.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Example growth curve data in wide format — example_widedata_noiseless","text":"Bacterial populations exhibit diauxic growth approach carrying capacity, also evolve resistance face  selection phage population. data include simulated noise","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/extr_val.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract parts of an object — extr_val","title":"Extract parts of an object — extr_val","text":"wrapper [ handling NA's use dplyr::summarize()","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/extr_val.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract parts of an object — extr_val","text":"","code":"extr_val(x, i, allNA_NA = TRUE, na.rm = TRUE)"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/extr_val.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract parts of an object — extr_val","text":"x object extract element(s) index specifying element extract. allNA_NA logical indicating whether NA returned (.na()) == TRUE. na.rm logical indicating whether missing index values  removed.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/extr_val.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract parts of an object — extr_val","text":"all_NA = FALSE na.rm = FALSE, identical  x[]. all_NA = FALSE na.rm = TRUE, identical  x[[!.na()]]. all_NA = TRUE, identical x[] unless  (.na()) == TRUE, case returns NA","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/first_peak.html","id":null,"dir":"Reference","previous_headings":"","what":"Find the first local maxima of a numeric vector — first_peak","title":"Find the first local maxima of a numeric vector — first_peak","text":"function deprecated favor identical new  function first_maxima","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/first_peak.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find the first local maxima of a numeric vector — first_peak","text":"","code":"first_peak(   y,   x = NULL,   window_width = NULL,   window_width_n = NULL,   window_height = NULL,   return = \"index\",   return_endpoints = TRUE,   ... )"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/first_peak.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Find the first local maxima of a numeric vector — first_peak","text":"y Numeric vector y values identify local extrema x Optional numeric vector corresponding x values window_width Width window (units x) used search local extrema. narrower width sensitive narrow local maxima/minima, wider width less sensitive local maxima/minima. window_width_n maximum number data points single  extrema-search step allowed take. example, maxima-finding, function pass valley consisting window_width_n data points. smaller window_width_n sensitive  narrow local maxima/minima, larger  window_width_n less sensitive  narrow local maxima/minima. provided, defaults ~0.2*length(y) window_height maximum change y single extrema-search step allowed take.  example,  maxima-finding, function pass valley deeper window_height. smaller window_height sensitive  shallow local maxima/minima, larger  window_height less sensitive  shallow maxima/minima. return One c(\"index\", \"x\", \"y\"), determining whether function return index, x value, y value associated first maxima y values return_endpoints first last value y allowed returned? ... parameters pass find_local_extrema","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/first_peak.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Find the first local maxima of a numeric vector — first_peak","text":"return = \"index\", vector indices corresponding            local extrema data return = \"x\", vector x values corresponding           local extrema data return = \"y\", vector y values corresponding           local extrema data","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/first_peak.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Find the first local maxima of a numeric vector — first_peak","text":"function takes vector y values returns index (default) first local maxima. serves shortcut find_local_extrema(return_maxima = TRUE, return_minima = FALSE)[1] none window_width, window_width_n,  window_height provided, default value window_width_n used. function designed compatible use within  dplyr::group_by dplyr::summarize","code":""},{"path":[]},{"path":"https://mikeblazanin.github.io/gcplyr/reference/from_excel.html","id":null,"dir":"Reference","previous_headings":"","what":"A function that converts base-26 Excel-style letters to numbers — from_excel","title":"A function that converts base-26 Excel-style letters to numbers — from_excel","text":"function converts base-26 Excel-style letters numbers","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/from_excel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A function that converts base-26 Excel-style letters to numbers — from_excel","text":"","code":"from_excel(x)"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/from_excel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A function that converts base-26 Excel-style letters to numbers — from_excel","text":"x vector column names Excel-style base-26 letter format (values already base-10 returned -)","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/from_excel.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A function that converts base-26 Excel-style letters to numbers — from_excel","text":"vector numbers base-10","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/import_blockdesigns.html","id":null,"dir":"Reference","previous_headings":"","what":"Import blockdesigns — import_blockdesigns","title":"Import blockdesigns — import_blockdesigns","text":"Function import block-shaped designs files return tidy designs. function acts wrapper call read_blocks,  paste_blocks, trans_block_to_wide, trans_wide_to_tidy,  separate_tidys one go","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/import_blockdesigns.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Import blockdesigns — import_blockdesigns","text":"","code":"import_blockdesigns(files, block_names = NULL, sep = NULL, ...)"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/import_blockdesigns.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Import blockdesigns — import_blockdesigns","text":"files Vector filenames (strings),  block-shaped designs file. Inputs can .csv, .xls, .xlsx block_names Vector names design elements. resulting column names output data frame.  order files /order corresponding files . NULL, file names used column names. sep block design files already pasted, sep specifies string separating design elements NULL, import_blockdesigns assume elements already pasted together attempt find character used imported files paste later separate design elements. ... arguments pass read_blocks,  paste_blocks, trans_block_to_wide, trans_wide_to_tidy, separate_tidy. See Details information","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/import_blockdesigns.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Import blockdesigns — import_blockdesigns","text":"tidy-shaped data.frame containing design information         files","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/import_blockdesigns.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Import blockdesigns — import_blockdesigns","text":"Common arguments may want provide via ...              include: startrow, endrow, startcol, endcol,               sheet - specifying location design information               inside files read_blocks wellnames_sep - specifying character (\"\" none)              used pasting together rownames              column names. Note chosen match              well names measures. Note import_blockdesigns currently handle              metadata specified via metadata argument              read_blocks find needing control, can run               steps manually, first reading read_blocks,              pasting needed paste_blocks,               transforming tidy trans_block_to_wide              trans_wide_to_tidy, separating needed              separate_tidys.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/import_blockmeasures.html","id":null,"dir":"Reference","previous_headings":"","what":"Import blockmeasures — import_blockmeasures","title":"Import blockmeasures — import_blockmeasures","text":"Function import blockmeasures files return widemeasures function acts wrapper call read_blocks,  uninterleave, trans_block_to_wide one go","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/import_blockmeasures.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Import blockmeasures — import_blockmeasures","text":"","code":"import_blockmeasures(   files,   num_plates = 1,   plate_names = NULL,   wellnames_sep = \"\",   ... )"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/import_blockmeasures.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Import blockmeasures — import_blockmeasures","text":"files Vector filenames (strings),  block-shaped file containing measures data. File formats can .csv, .xls, .xlsx num_plates Number plates. multiple plates uninterleave used separate blockmeasures plates accordingly plate_names (optional) Names put onto plates output wellnames_sep String use separator well names  rowname column name ... arguments pass read_blocks, uninterleave, widen_blocks","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/import_blockmeasures.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Import blockmeasures — import_blockmeasures","text":"num_plates = 1, wide-shaped data.frame containing measures data. num_plates greater one, list  data.frame's, data.frame wide-shaped.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/import_blockmeasures.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Import blockmeasures — import_blockmeasures","text":"Common arguments may want provide via ...              include: startrow, endrow, startcol, endcol,               sheet - specifying location design information               inside files read_blocks metadata - specifying metadata read_blocks See help read_blocks details find needing control, can run               steps manually, first reading read_blocks,               separating plates needed uninterleave,               transforming wide trans_block_to_wide.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/lag_time.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate lag time — lag_time","title":"Calculate lag time — lag_time","text":"Lag time calculated projecting tangent line point maximum (per-capita) derivative backwards find time intersects starting y-value","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/lag_time.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate lag time — lag_time","text":"","code":"lag_time(   x = NULL,   y = NULL,   deriv = NULL,   trans_y = \"log\",   na.rm = TRUE,   slope = NULL,   x1 = NULL,   y1 = NULL,   y0 = NULL )"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/lag_time.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate lag time — lag_time","text":"x Vector x values (typically time) y Vector y values (typically density) deriv Vector derivative values (typically per-capita derivative) trans_y One c(\"linear\", \"log\") specifying                 transformation y-values. 'log' default, producing calculations                 lag time assuming transition exponential growth 'linear' available alternate uses na.rm logical indicating whether missing values removed slope Slope project x1,y1 y0 (typically per-capita growth rate). provided, calculated max(deriv) x1 x value (typically time) project slope . provided, calculated x[.max(deriv)]. y1 y value (typically density) project slope . provided, calculated y[.max(deriv)]. y0 y value (typically density) find intersection slope x1, y1 . provided, calculated min(y)","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/lag_time.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate lag time — lag_time","text":"Typically scalar lag time units x. See Details cases value vector.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/lag_time.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate lag time — lag_time","text":"typical uses, simply supply x, y, deriv (using per-capita derivative trans_y = 'log'). Advanced users may wish use alternate values slope, origination point, initial y-value. case, values can supplied slope, x1, y1, /y0, override default calculations. slope, x1,  y1, y0 provided, lag_time vectorized inputs return vector lag time values. function designed compatible use within  dplyr::group_by dplyr::summarize","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/make_design.html","id":null,"dir":"Reference","previous_headings":"","what":"Make design data.frame(s) — make_design","title":"Make design data.frame(s) — make_design","text":"function easily input experimental design elements later merging read data","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/make_design.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make design data.frame(s) — make_design","text":"","code":"make_design(   nrows = NULL,   ncols = NULL,   block_row_names = NULL,   block_col_names = NULL,   output_format = \"tidy\",   wellnames_numeric = FALSE,   wellnames_sep = \"\",   wellnames_colname = \"Well\",   colnames_first = FALSE,   lookup_tbl_start = 1,   pattern_split = \"\",   ... )"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/make_design.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make design data.frame(s) — make_design","text":"nrows, ncols Number rows columns plate data block_row_names, block_col_names Names rows, columns plate blockmeasures data output_format One c(\"blocks\", \"blocks_pasted\", \"wide\", \"tidy\") denoting format resulting data.frame easy merging tidymeasures, leave default 'tidy'. human-readability confirm design correct, choose 'blocks' 'blocks_pasted'. writing block-shaped file(s), choose 'blocks' 'blocks_pasted'. wellnames_numeric block_row_names block_col_names specified, names generated automatically according wellnames_numeric. wellnames_numeric TRUE, rows columns numbered \"R\" \"C\" prefixes, respectively. wellnames_numeric FALSE, rows lettered Z, columns numbered wellnames_sep string used concatenating rownames column names create well names,  output_format = \"wide\"  output_format = \"tidy\" wellnames_colname Header newly-created column containing well names, output_format = \"tidy\" colnames_first wellnames created  output_format = \"wide\"  output_format = \"tidy\" paste-ing rownames column names, column names come first. lookup_tbl_start Value lookup table split pattern values corresponds first value vector. Lookup table default  c(1,2,...,8,9,,B,...Y,Z,,b,...,y,z). , example, lookup_tbl_start = \"\", lookup table now c(,B,...Y,Z,,b,...,y,z) pattern_split character split pattern elements provided ... , already vector ... ... argument must named, must list             five elements: 1. vector values 2. vector rows pattern applied 3. vector columns pattern applied 4. string vector denoting pattern                 values filled rows columns specified. string, split pattern_split.                 Pattern used indices values vector. 0's refer NA. pattern recycled necessary                 fill wells rows columns specified. 5. logical whether pattern filled byrow","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/make_design.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Make design data.frame(s) — make_design","text":"Depends output_format: output_format = \"blocks\", list data.frame's         data.frame block-shaped containing         information single design element output_format = \"blocks_pasted\", single  data.frame containing paste-ed information         design elements output_format = \"wide\", wide-shaped data.frame containing design elements output_format = \"tidy\", tidy-shaped data.frame containing design elements","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/make_design.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Make design data.frame(s) — make_design","text":"Note either nrows block_row_names must provided either ncols block_col_names must provided","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/make_design.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Make design data.frame(s) — make_design","text":"","code":"make_design(nrows = 8, ncols = 12,             design_element_name = list(c(\"A\", \"B\", \"C\"),                                        2:7,                                        2:11,                                        \"112301\",                                         TRUE)) #>    Well design_element_name #> 1    A1                <NA> #> 2    A2                <NA> #> 3    A3                <NA> #> 4    A4                <NA> #> 5    A5                <NA> #> 6    A6                <NA> #> 7    A7                <NA> #> 8    A8                <NA> #> 9    A9                <NA> #> 10  A10                <NA> #> 11  A11                <NA> #> 12  A12                <NA> #> 13   B1                <NA> #> 14   B2                   A #> 15   B3                   A #> 16   B4                   B #> 17   B5                   C #> 18   B6                <NA> #> 19   B7                   A #> 20   B8                   A #> 21   B9                   A #> 22  B10                   B #> 23  B11                   C #> 24  B12                <NA> #> 25   C1                <NA> #> 26   C2                <NA> #> 27   C3                   A #> 28   C4                   A #> 29   C5                   A #> 30   C6                   B #> 31   C7                   C #> 32   C8                <NA> #> 33   C9                   A #> 34  C10                   A #> 35  C11                   A #> 36  C12                <NA> #> 37   D1                <NA> #> 38   D2                   B #> 39   D3                   C #> 40   D4                <NA> #> 41   D5                   A #> 42   D6                   A #> 43   D7                   A #> 44   D8                   B #> 45   D9                   C #> 46  D10                <NA> #> 47  D11                   A #> 48  D12                <NA> #> 49   E1                <NA> #> 50   E2                   A #> 51   E3                   A #> 52   E4                   B #> 53   E5                   C #> 54   E6                <NA> #> 55   E7                   A #> 56   E8                   A #> 57   E9                   A #> 58  E10                   B #> 59  E11                   C #> 60  E12                <NA> #> 61   F1                <NA> #> 62   F2                <NA> #> 63   F3                   A #> 64   F4                   A #> 65   F5                   A #> 66   F6                   B #> 67   F7                   C #> 68   F8                <NA> #> 69   F9                   A #> 70  F10                   A #> 71  F11                   A #> 72  F12                <NA> #> 73   G1                <NA> #> 74   G2                   B #> 75   G3                   C #> 76   G4                <NA> #> 77   G5                   A #> 78   G6                   A #> 79   G7                   A #> 80   G8                   B #> 81   G9                   C #> 82  G10                <NA> #> 83  G11                   A #> 84  G12                <NA> #> 85   H1                <NA> #> 86   H2                <NA> #> 87   H3                <NA> #> 88   H4                <NA> #> 89   H5                <NA> #> 90   H6                <NA> #> 91   H7                <NA> #> 92   H8                <NA> #> 93   H9                <NA> #> 94  H10                <NA> #> 95  H11                <NA> #> 96  H12                <NA>                            ## To be reminded what arguments are needed, use make_designpattern: make_design(nrows = 8, ncols = 12,             design_element_name = make_designpattern(                  values = c(\"A\", \"B\", \"C\"),                  rows = 2:7,                   cols = 2:11,                  pattern = \"112301\",                  byrow = TRUE))               #>    Well design_element_name #> 1    A1                <NA> #> 2    A2                <NA> #> 3    A3                <NA> #> 4    A4                <NA> #> 5    A5                <NA> #> 6    A6                <NA> #> 7    A7                <NA> #> 8    A8                <NA> #> 9    A9                <NA> #> 10  A10                <NA> #> 11  A11                <NA> #> 12  A12                <NA> #> 13   B1                <NA> #> 14   B2                   A #> 15   B3                   A #> 16   B4                   B #> 17   B5                   C #> 18   B6                <NA> #> 19   B7                   A #> 20   B8                   A #> 21   B9                   A #> 22  B10                   B #> 23  B11                   C #> 24  B12                <NA> #> 25   C1                <NA> #> 26   C2                <NA> #> 27   C3                   A #> 28   C4                   A #> 29   C5                   A #> 30   C6                   B #> 31   C7                   C #> 32   C8                <NA> #> 33   C9                   A #> 34  C10                   A #> 35  C11                   A #> 36  C12                <NA> #> 37   D1                <NA> #> 38   D2                   B #> 39   D3                   C #> 40   D4                <NA> #> 41   D5                   A #> 42   D6                   A #> 43   D7                   A #> 44   D8                   B #> 45   D9                   C #> 46  D10                <NA> #> 47  D11                   A #> 48  D12                <NA> #> 49   E1                <NA> #> 50   E2                   A #> 51   E3                   A #> 52   E4                   B #> 53   E5                   C #> 54   E6                <NA> #> 55   E7                   A #> 56   E8                   A #> 57   E9                   A #> 58  E10                   B #> 59  E11                   C #> 60  E12                <NA> #> 61   F1                <NA> #> 62   F2                <NA> #> 63   F3                   A #> 64   F4                   A #> 65   F5                   A #> 66   F6                   B #> 67   F7                   C #> 68   F8                <NA> #> 69   F9                   A #> 70  F10                   A #> 71  F11                   A #> 72  F12                <NA> #> 73   G1                <NA> #> 74   G2                   B #> 75   G3                   C #> 76   G4                <NA> #> 77   G5                   A #> 78   G6                   A #> 79   G7                   A #> 80   G8                   B #> 81   G9                   C #> 82  G10                <NA> #> 83  G11                   A #> 84  G12                <NA> #> 85   H1                <NA> #> 86   H2                <NA> #> 87   H3                <NA> #> 88   H4                <NA> #> 89   H5                <NA> #> 90   H6                <NA> #> 91   H7                <NA> #> 92   H8                <NA> #> 93   H9                <NA> #> 94  H10                <NA> #> 95  H11                <NA> #> 96  H12                <NA>"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/make_designpattern.html","id":null,"dir":"Reference","previous_headings":"","what":"Make design pattern — make_designpattern","title":"Make design pattern — make_designpattern","text":"helper function use make_design","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/make_designpattern.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make design pattern — make_designpattern","text":"","code":"make_designpattern(   values,   rows,   cols,   pattern = 1:length(values),   byrow = TRUE )  mdp(values, rows, cols, pattern = 1:length(values), byrow = TRUE)"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/make_designpattern.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make design pattern — make_designpattern","text":"values Vector values use rows Vector rows pattern applies cols Vector cols pattern applies pattern Numeric pattern , numbers refer entries values byrow logical whether pattern created row","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/make_designpattern.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Make design pattern — make_designpattern","text":"list(values, rows, cols, pattern, byrow)","code":""},{"path":[]},{"path":"https://mikeblazanin.github.io/gcplyr/reference/make_designpattern.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Make design pattern — make_designpattern","text":"","code":"make_design(nrows = 8, ncols = 12,             design_element_name = make_designpattern(                  values = c(\"A\", \"B\", \"C\"),                  rows = 2:7,                   cols = 2:11,                  pattern = \"112301\",                  byrow = TRUE)) #>    Well design_element_name #> 1    A1                <NA> #> 2    A2                <NA> #> 3    A3                <NA> #> 4    A4                <NA> #> 5    A5                <NA> #> 6    A6                <NA> #> 7    A7                <NA> #> 8    A8                <NA> #> 9    A9                <NA> #> 10  A10                <NA> #> 11  A11                <NA> #> 12  A12                <NA> #> 13   B1                <NA> #> 14   B2                   A #> 15   B3                   A #> 16   B4                   B #> 17   B5                   C #> 18   B6                <NA> #> 19   B7                   A #> 20   B8                   A #> 21   B9                   A #> 22  B10                   B #> 23  B11                   C #> 24  B12                <NA> #> 25   C1                <NA> #> 26   C2                <NA> #> 27   C3                   A #> 28   C4                   A #> 29   C5                   A #> 30   C6                   B #> 31   C7                   C #> 32   C8                <NA> #> 33   C9                   A #> 34  C10                   A #> 35  C11                   A #> 36  C12                <NA> #> 37   D1                <NA> #> 38   D2                   B #> 39   D3                   C #> 40   D4                <NA> #> 41   D5                   A #> 42   D6                   A #> 43   D7                   A #> 44   D8                   B #> 45   D9                   C #> 46  D10                <NA> #> 47  D11                   A #> 48  D12                <NA> #> 49   E1                <NA> #> 50   E2                   A #> 51   E3                   A #> 52   E4                   B #> 53   E5                   C #> 54   E6                <NA> #> 55   E7                   A #> 56   E8                   A #> 57   E9                   A #> 58  E10                   B #> 59  E11                   C #> 60  E12                <NA> #> 61   F1                <NA> #> 62   F2                <NA> #> 63   F3                   A #> 64   F4                   A #> 65   F5                   A #> 66   F6                   B #> 67   F7                   C #> 68   F8                <NA> #> 69   F9                   A #> 70  F10                   A #> 71  F11                   A #> 72  F12                <NA> #> 73   G1                <NA> #> 74   G2                   B #> 75   G3                   C #> 76   G4                <NA> #> 77   G5                   A #> 78   G6                   A #> 79   G7                   A #> 80   G8                   B #> 81   G9                   C #> 82  G10                <NA> #> 83  G11                   A #> 84  G12                <NA> #> 85   H1                <NA> #> 86   H2                <NA> #> 87   H3                <NA> #> 88   H4                <NA> #> 89   H5                <NA> #> 90   H6                <NA> #> 91   H7                <NA> #> 92   H8                <NA> #> 93   H9                <NA> #> 94  H10                <NA> #> 95  H11                <NA> #> 96  H12                <NA>"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/make_tidydesign.html","id":null,"dir":"Reference","previous_headings":"","what":"Make tidy design data.frames — make_tidydesign","title":"Make tidy design data.frames — make_tidydesign","text":"function easily input experimental design elements later merging read data","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/make_tidydesign.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make tidy design data.frames — make_tidydesign","text":"","code":"make_tidydesign(   nrows = NULL,   ncols = NULL,   block_row_names = NULL,   block_col_names = NULL,   wellnames_sep = \"\",   wellnames_colname = \"Well\",   wellnames_Excel = TRUE,   lookup_tbl_start = 1,   pattern_split = \"\",   colnames_first = FALSE,   ... )"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/make_tidydesign.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make tidy design data.frames — make_tidydesign","text":"nrows, ncols Number rows columns plate data block_row_names, block_col_names Names rows, columns plate blockmeasures data wellnames_sep string used concatenating rownames column names create well names wellnames_colname Header newly-created column containing well names wellnames_Excel block_row_names block_col_names specified, rows columns named using Excel-style base-26 lettering rows numbering columns? FALSE, rows columns numbered \"R\" \"C\" prefix. lookup_tbl_start Value lookup table split pattern values corresponds first value vector. Lookup table default  c(1,2,...,8,9,,B,...Y,Z,,b,...,y,z). , example, lookup_tbl_start = \"\", lookup table now c(,B,...Y,Z,,b,...,y,z) pattern_split character split pattern elements provided ... colnames_first wellnames created paste-ing rownames column names, column names come first ... ... argument must list five elements: 1. vector values 2. vector rows pattern applied 3. vector columns pattern applied 4. string pattern , numbers refer               indices values vector 0's refer NA pattern split using pattern_split,               defaults every character 5. logical whether pattern filled byrow","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/make_tidydesign.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Make tidy design data.frames — make_tidydesign","text":"tidy-shaped data.frame containing design elements","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/make_tidydesign.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Make tidy design data.frames — make_tidydesign","text":"Note either nrows block_row_names must provided either ncols block_col_names must provided Examples: my_example <- make_tidydesign(nrows = 8, ncols = 12,         design_element_name = list(c(\"Value1\", \"Value2\", \"Value3\"),                           rowstart:rowend, colstart:colend,                           \"111222333000\", TRUE) make easier pass arguments, use make_designpattern: my_example <- make_tidydesign(nrows = 8, ncols = 12,       design_element_name = make_designpattern(values = c(\"L\", \"G\", \"C\"),                                                 rows = 2:7, cols = 2:11,                                                 pattern = \"11223300\",                                                 byrow = TRUE))","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/merge_dfs.html","id":null,"dir":"Reference","previous_headings":"","what":"Collapse a list of dataframes, or merge two dataframes together — merge_dfs","title":"Collapse a list of dataframes, or merge two dataframes together — merge_dfs","text":"function essentially wrapper dplyr::full_join typical use function merge designs  measures data, use collapse functionality  function merge list dataframes single dataframe. Merging done column-names match x y.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/merge_dfs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Collapse a list of dataframes, or merge two dataframes together — merge_dfs","text":"","code":"merge_dfs(   x,   y = NULL,   by = NULL,   drop = FALSE,   collapse = FALSE,   names_to = NA,   ... )"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/merge_dfs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Collapse a list of dataframes, or merge two dataframes together — merge_dfs","text":"x First data.frame, list data frames, joined y Second data.frame, list data frames, joined character vector variables join , passed directly dplyr::full_join drop complete_cases resulting data.frame returned? collapse logical indicating whether x y list containing data frames merged together merged names_to Column name names(x) names(y)  entered collapse = TRUE. value NA names(x)  names(y) put column returned data.frame ... arguments pass dplyr::full_join","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/merge_dfs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Collapse a list of dataframes, or merge two dataframes together — merge_dfs","text":"Data.frame containing merged output x  y","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/moving_average.html","id":null,"dir":"Reference","previous_headings":"","what":"Moving average smoothing — moving_average","title":"Moving average smoothing — moving_average","text":"function uses moving average smooth data","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/moving_average.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Moving average smoothing — moving_average","text":"","code":"moving_average(   formula,   data,   window_width_n = NULL,   window_width = NULL,   na.rm = TRUE )"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/moving_average.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Moving average smoothing — moving_average","text":"formula Formula specifying numeric response (density)  numeric predictor (time). data Dataframe containing variables formula window_width_n Number data points wide moving average window (therefore, must odd number points) window_width Width moving average window (units x) na.rm logical whether NA's removed analyzing","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/moving_average.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Moving average smoothing — moving_average","text":"Vector smoothed data, NA's appended ends","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/moving_median.html","id":null,"dir":"Reference","previous_headings":"","what":"Moving median smoothing — moving_median","title":"Moving median smoothing — moving_median","text":"function uses moving median smooth data","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/moving_median.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Moving median smoothing — moving_median","text":"","code":"moving_median(   formula,   data,   window_width_n = NULL,   window_width = NULL,   na.rm = TRUE )"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/moving_median.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Moving median smoothing — moving_median","text":"formula Formula specifying numeric response (density)  numeric predictor (time). data Dataframe containing variables formula window_width_n Number data points wide moving median window (therefore, must odd number points) window_width Width moving median window (units x)| na.rm logical whether NA's removed analyzing","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/moving_median.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Moving median smoothing — moving_median","text":"Vector smoothed data, NA's appended ends","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/paste_blocks.html","id":null,"dir":"Reference","previous_headings":"","what":"Paste a list of blocks into a single block — paste_blocks","title":"Paste a list of blocks into a single block — paste_blocks","text":"function uses paste concatenate -location entries list data.frames together (.e. first row-first column values pasted together, second row-first column values pasted together, etc.)","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/paste_blocks.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Paste a list of blocks into a single block — paste_blocks","text":"","code":"paste_blocks(blocks, sep = \"_\", nested_metadata = NULL)"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/paste_blocks.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Paste a list of blocks into a single block — paste_blocks","text":"blocks Blocks, either single data.frame list data.frames sep String use separator output pasted values nested_metadata logical indicating existence nested metadata blockmeasures list, e.g. typically output read_blocks. NULL, attempt infer existence nested metadata","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/paste_blocks.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Paste a list of blocks into a single block — paste_blocks","text":"nested_metadata = TRUE (inferred TRUE), list         containing list containing: 1. data.frame         pasted data values blocks, 2. vector          pasted metadata values blocks nested_metadata = FALSE (inferred FALSE), list         containing data.frame's pasted values  blocks","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/read_blocks.html","id":null,"dir":"Reference","previous_headings":"","what":"Read blockmeasures — read_blocks","title":"Read blockmeasures — read_blocks","text":"function reads block measures R environment","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/read_blocks.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read blockmeasures — read_blocks","text":"","code":"read_blocks(   files,   extension = NULL,   startrow = NULL,   endrow = NULL,   startcol = NULL,   endcol = NULL,   sheet = NULL,   metadata = NULL,   block_names = NULL,   header = NA,   sider = NA,   wellnames_numeric = FALSE,   na.strings = c(\"NA\", \"\"),   ... )"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/read_blocks.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read blockmeasures — read_blocks","text":"files vector filepaths relative current working directory filepath single plate read extension (optional) extension files: \"csv\", \"xls\", \"xlsx\", \"tbl\" use read.table none provided, read_blocks infer file extension provided filenames. extension \"csv\", \"xls\", \"xlsx\" use utils::read.table startrow, endrow, startcol, endcol (optional) rows columns  measures data located files. Can vector list length files, single value applies files. Values can numeric string automatically converted numeric from_excel. provided, data presumed begin first row column file(s) end last row column file(s). sheet (optional) data .xls .xlsx files, sheet  located . Defaults first sheet specified metadata (optional) non-spectrophotometric data  associated read blockmeasures. named list  item list either: vector length 2, list containing two vectors. former case, vector provide row  column metadata located blockmeasures input files. latter case, first vector provide rows metadata located corresponding input files, second vector provide  columns metadata located corresponding input files. (case typically used  reading multiple blocks single file.) block_names (optional) vector names corresponding plate files. provided, block_names inferred filenames header TRUE, FALSE, NA, vector values, indicating whether file(s) contains column names first line. header = NA attempt infer presence column names. header = FALSE column names inferred  header = NA, column names generated automatically according wellnames_numeric sider TRUE, FALSE, NA, vector values, indicating whether file(s) contains row names first line. sider = NA attempt infer presence row names. sider = FALSE row names inferred  sider = NA, row names generated automatically according wellnames_numeric wellnames_numeric row names column names provided input dataframe specified header sider, names generated automatically according wellnames_numeric. wellnames_numeric TRUE, rows columns numbered \"R\" \"C\" prefixes, respectively. wellnames_numeric FALSE, rows lettered Z, columns numbered na.strings character vector strings interpreted NA values utils::read.csv, readxl::read_xls, readxl::read_xlsx, utils::read.table ... arguments passed utils::read.csv, readxl::read_xls, readxl::read_xlsx, utils::read.table","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/read_blocks.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Read blockmeasures — read_blocks","text":"list entry list containing block data frame         followed block_names (filenames, block_names          provided) specified metadata.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/read_blocks.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Read blockmeasures — read_blocks","text":"metadata, read_blocks can handle arbitrary number additional  pieces information extract blockcurve file metadata.  pieces information specified named list vectors  vector c(row, column) information  pulled input files. metadata returned second list element  blockcurve, e.g.: [[1]] [1] \"data\" #1 [2] \"metadata\"  [2][1] name #1 [2][2] date-time #1 [2][3] temp #1 [[2]] [1] \"data\" #2 [2] \"metadata\"  [2][1] name #2 [2][2] date-time #2 [2][3] temp #2 ... Calling uninterleave output read_blocks works block data  associated metadata uninterleave operates highest   level entries list ([[1]] [[2]] level items),   leaving meta-data associated block data trans_block_to_wide integrates metadata  wide-shaped dataframe produces","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/read_tidys.html","id":null,"dir":"Reference","previous_headings":"","what":"Read tidy-shaped files — read_tidys","title":"Read tidy-shaped files — read_tidys","text":"function imports tidy-shaped files R. Largely acts wrapper utils::read.csv, readxl::read_xls, readxl::read_xls, readxl::read_xlsx, can handle multiple files additional options taking subsets  rows/columns rather entire file adding filename  run names added column output.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/read_tidys.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read tidy-shaped files — read_tidys","text":"","code":"read_tidys(   files,   extension = NULL,   startrow = NULL,   endrow = NULL,   startcol = NULL,   endcol = NULL,   sheet = NULL,   run_names = NULL,   names_to_col = NULL,   na.strings = c(\"NA\", \"\"),   ... )"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/read_tidys.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read tidy-shaped files — read_tidys","text":"files vector filepaths (relative current working directory) one tidy-shaped data file extension (optional) extension files: \"csv\", \"xls\", \"xlsx\", \"tbl\" use read.table none provided, read_tidys infer file  extension provided filenames. extension  \"csv\", \"xls\", \"xlsx\" use utils::read.table startrow, endrow, startcol, endcol (optional) rows columns  data located files. Can vector list length files, single value applies files. Values can numeric string automatically converted numeric from_excel. provided, data presumed begin first row column file(s) end last row column file(s). sheet sheet input files data located (input files .xls .xlsx). specified defaults first run_names Names give tidy files read . default uses file names specified. names may added resulting data frame depending value names_to_col argument names_to_col run names (provided run_names inferred files) added column output? names_to_col TRUE, added . column name \"run_name\" names_to_col FALSE, added. names_to_col string, added column name string specified names_to_col. names_to_col NULL,  added multiple tidy data.frames read. case, column name \"run_name\" na.strings character vector strings interpreted NA values utils::read.csv, readxl::read_xls, readxl::read_xlsx, utils::read.table ... arguments passed utils::read.csv, readxl::read_xls, readxl::read_xlsx, utils::read.table sheet","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/read_tidys.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Read tidy-shaped files — read_tidys","text":"dataframe containing single tidy data.frame,         list tidy-shaped data.frames named filename","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/read_tidys.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Read tidy-shaped files — read_tidys","text":"startrow, endrow, startcol, endcol,  sheet extension can either single value  applies files vectors lists length files Note startrow always assumed header","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/read_wides.html","id":null,"dir":"Reference","previous_headings":"","what":"Read wides — read_wides","title":"Read wides — read_wides","text":"function imports widemeasures files R environment","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/read_wides.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read wides — read_wides","text":"","code":"read_wides(   files,   extension = NULL,   startrow = NULL,   endrow = NULL,   startcol = NULL,   endcol = NULL,   header = TRUE,   sheet = NULL,   run_names = NULL,   names_to_col = \"file\",   metadata = NULL,   na.strings = c(\"NA\", \"\"),   ... )"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/read_wides.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read wides — read_wides","text":"files vector filepaths (relative current working directory) one widemeasures set data extension (optional) extension files: \"csv\", \"xls\", \"xlsx\", \"tbl\" use read.table none provided, read_wides infer file  extension provided filenames. extension  \"csv\", \"xls\", \"xlsx\" use utils::read.table startrow, endrow, startcol, endcol (optional) rows columns  data located files. Can vector list length files, single value applies files. Values can numeric string automatically converted numeric from_excel. provided, data presumed begin first row column file(s) end last row column file(s). header logical whether header data. FALSE columns simple numbered. TRUE row startrow (startrow specified) first row input files (startrow specified) sheet sheet input files data located (input files .xls .xlsx). specified defaults first sheet run_names Names give widemeasures read . default uses file names specified names_to_col run names (provided run_names inferred files) added column widemeasures? names_to_col NULL, . names_to_col string, string column header column names stored metadata (optional) non-spectrophotometric data  associated read widemeasures. named list  item list either: vector length 2, list containing two vectors. former case, vector provide row  column metadata located blockmeasures input files. latter case, first vector provide rows metadata located corresponding input files, second vector provide  columns metadata located corresponding input files. (case typically used  reading multiple blocks single file.) na.strings character vector strings interpreted NA values utils::read.csv, readxl::read_xls, readxl::read_xlsx, utils::read.table ... arguments passed utils::read.csv, readxl::read_xls, readxl::read_xlsx, utils::read.table","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/read_wides.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Read wides — read_wides","text":"dataframe containing single widemeasures,         list widemeasures named filename","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/read_wides.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Read wides — read_wides","text":"startrow, endrow, startcol, endcol, timecol, sheet extension  can either single value applies files vectors lists length files,","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/separate_tidy.html","id":null,"dir":"Reference","previous_headings":"","what":"Separate a column into multiple columns — separate_tidy","title":"Separate a column into multiple columns — separate_tidy","text":"function primarily wrapper tidyr::separate, turns single character column multiple columns","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/separate_tidy.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Separate a column into multiple columns — separate_tidy","text":"","code":"separate_tidy(data, col, into = NULL, sep = \"_\", coerce_NA = TRUE, ...)"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/separate_tidy.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Separate a column into multiple columns — separate_tidy","text":"data data frame col Column name position character vector new column names. Use NA omit variable output. NULL, separate_gc attempt infer new column names column name col sep Separator columns passed tidyr::separate: character, sep interpreted regular expression. numeric, sep interpreted character positions            split . Positive values start 1 far-left            string; negative values start -1 far-right            string. length sep one less             coerce_NA logical dictating \"NA\" strings coerced  NA values separating. ... arguments passed tidyr::separate","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/separate_tidy.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Separate a column into multiple columns — separate_tidy","text":"data frame containing new columns place col","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/smooth_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Smooth data — smooth_data","title":"Smooth data — smooth_data","text":"function calls functions smooth growth curve data","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/smooth_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Smooth data — smooth_data","text":"","code":"smooth_data(   ...,   x = NULL,   y = NULL,   sm_method,   subset_by = NULL,   return_fitobject = FALSE )"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/smooth_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Smooth data — smooth_data","text":"... Arguments passed stats::loess, mgcv::gam, moving_average, moving_median. Typically includes tuning parameter(s), cases required. See Details information. x (optional) vector predictor values smooth along (e.g. time) y vector response values smoothed (e.g. density). NULL, formula data *must* provided via ... sm_method Argument specifying smoothing method used smooth data. Options include  \"moving-average\", \"moving-median\", \"loess\", \"gam\" subset_by optional vector long y.  y split unique values vector  derivative group calculated  independently others. provides internally-implemented approach similar dplyr::group_by dplyr::mutate return_fitobject logical indicating whether entire object returned fitting function returned. FALSE, just fitted values returned.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/smooth_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Smooth data — smooth_data","text":"return_fitobject == FALSE: vector, length y, now-smoothed y values return_fitobject == TRUE: list length unique(subset_by) element         object class returned smoothing method         (typically named list-like object) Varies method, always first element named 'fitted'         containing smoothed values response variable,          second element named 'residuals' containing residuals         fitted values input values **Note: first version released Sep 1, 2023 change **         **behavior** instead maintain class object          returned smoothing method. change, methods          return object 'fitted' first element          'residuals' second element.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/smooth_data.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Smooth data — smooth_data","text":"moving_average moving_median,             passing window_width window_width_n via             ... required. window_width sets width            moving window units x,             window_width_n sets width units number            data points. Larger values either produce             \"smoothed\" data. loess, span argument sets fraction            data points included calculation.            typically best specify, since default 0.75 often            large growth curves data. Larger values span             produce \"smoothed\" data gam, arguments gam s can            provided via .... frequently, k             argument s sets number \"knots\"            spline-fitting can use. Smaller values \"smoothed\". using sm_method = \"gam\", advanced users may also modify             parameters s(), including smoothing basis             bs. bases can thin plate (bs = \"tp\",             default), cubic regressions (bs = \"cr\"), many             options (see ?mcgv::s). recommend leaving default             thin plate regressions, whose main drawback             computationally intensive calculate. growth curves data,             unlikely relevant. alternative passing y, advanced needs             loess gam, formula data             can passed smooth_data via ... argument             (lieu y). case, formula specify response (e.g. density)             predictors. gam smoothing, formula            typically format: y ~ s(x), uses             mgcv::s smooth data. data argument             data.frame containing variables formula.            cases, subset_by can still specified vector            long nrow(data)","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/solve_linear.html","id":null,"dir":"Reference","previous_headings":"","what":"Return missing information about a line — solve_linear","title":"Return missing information about a line — solve_linear","text":"Takes set inputs sufficient information infer line returns information provided (either slope, x point line, y point line)","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/solve_linear.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Return missing information about a line — solve_linear","text":"","code":"solve_linear(   x1,   y1,   x2 = NULL,   y2 = NULL,   x3 = NULL,   y3 = NULL,   m = NULL,   named = TRUE )"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/solve_linear.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Return missing information about a line — solve_linear","text":"x1, y1 point line x2, y2 additional point line x3, y3 additional point line m slope line named logical indicating whether returned value(s) named according (m, x2, y2, x3, y3)","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/solve_linear.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Return missing information about a line — solve_linear","text":"named vector missing information line: m x2 provided, y2 returned m y2 provided, x2 returned x2 y2 provided, neither x3  y3 provided, m returned x2 y2 provided one x3  y3 provided, (y3 x3)          returned","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/solve_linear.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Return missing information about a line — solve_linear","text":"Note requirement           x1 < x2 < x3: points can order           along line. solve_linear works vectors inputs solve          multiple lines , ith element           argument corresponds ith output. Note          lines must missing information. Input vectors          recycled necessary.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/to_excel.html","id":null,"dir":"Reference","previous_headings":"","what":"A function that converts numbers into base-26 Excel-style letters — to_excel","title":"A function that converts numbers into base-26 Excel-style letters — to_excel","text":"function converts numbers base-26 Excel-style letters","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/to_excel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A function that converts numbers into base-26 Excel-style letters — to_excel","text":"","code":"to_excel(x)"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/to_excel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A function that converts numbers into base-26 Excel-style letters — to_excel","text":"x vector numbers base-10","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/to_excel.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A function that converts numbers into base-26 Excel-style letters — to_excel","text":"vector letters Excel-style base-26 format","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/trans_block_to_wide.html","id":null,"dir":"Reference","previous_headings":"","what":"Transform blocks to wides — trans_block_to_wide","title":"Transform blocks to wides — trans_block_to_wide","text":"Takes blocks returns wide format","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/trans_block_to_wide.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Transform blocks to wides — trans_block_to_wide","text":"","code":"trans_block_to_wide(   blocks,   wellnames_sep = \"\",   nested_metadata = NULL,   colnames_first = FALSE )"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/trans_block_to_wide.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Transform blocks to wides — trans_block_to_wide","text":"blocks Blocks, either single data.frame list data.frames wellnames_sep String use separator well names  rowname column name (ordered according colnames_first nested_metadata logical indicating existence nested metadata blockmeasures list, e.g. typically output read_blocks. NULL, attempt infer existence nested metadata colnames_first wellnames created paste-ing rownames column names, column names come first","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/trans_block_to_wide.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Transform blocks to wides — trans_block_to_wide","text":"single widemeasures data.frame","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/trans_wide_to_tidy.html","id":null,"dir":"Reference","previous_headings":"","what":"Pivot widemeasures longer — trans_wide_to_tidy","title":"Pivot widemeasures longer — trans_wide_to_tidy","text":"Essentially wrapper tidyr::pivot_longer works single widemeasures well list widemeasures","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/trans_wide_to_tidy.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pivot widemeasures longer — trans_wide_to_tidy","text":"","code":"trans_wide_to_tidy(   wides,   data_cols = NA,   id_cols = NA,   names_to = \"Well\",   values_to = \"Measurements\",   values_to_numeric = TRUE,   ... )"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/trans_wide_to_tidy.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pivot widemeasures longer — trans_wide_to_tidy","text":"wides single widemeasures data.frame, list widemeasures data.frame's data_cols, id_cols Specifies columns data vs ID's (tidyr::pivot_longer parlance). can single vector (applied widemeasures) list vectors, vector corresponding -index widemeasure widemeasures Entries NA list used neither data_cols id_cols specified, user must provide arguments tidyr::pivot_longer via ... least cols argument arguments provided via ... used widemeasures data.frame's names_to, values_to Specifies output column names created tidyr::pivot_longer. can provided vectors length widemeasures Note neither data_cols id_cols values_to_numeric logical indicating whether values coerced numeric. See may overridden arguments passed ... ... functions passed tidyr::pivot_longer Note including values_transform override behavior values_to_numeric","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/trans_wide_to_tidy.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pivot widemeasures longer — trans_wide_to_tidy","text":"Pivoted longer data.frame (widemeasures single data.frame)         list pivoted longer data.frame's (widemeasures         list data.frame's)","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/uninterleave.html","id":null,"dir":"Reference","previous_headings":"","what":"Uninterleave list — uninterleave","title":"Uninterleave list — uninterleave","text":"Takes list actually interleaved elements multiple sources uninterleaves separate sources instance, list blockmeasures actually corresponds two different plates can split two lists, blockmeasures corresponding single plate","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/uninterleave.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Uninterleave list — uninterleave","text":"","code":"uninterleave(interleaved_list, n)"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/uninterleave.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Uninterleave list — uninterleave","text":"interleaved_list list R objects n many output sub lists (.e. many groups interleaved list divided )","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/uninterleave.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Uninterleave list — uninterleave","text":"list lists R objects","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/write_blocks.html","id":null,"dir":"Reference","previous_headings":"","what":"Write block designs to csv — write_blocks","title":"Write block designs to csv — write_blocks","text":"function writes block-shaped lists (created read_blocks make_design) csv files, including data metadata variety output formats","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/write_blocks.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Write block designs to csv — write_blocks","text":"","code":"write_blocks(   blocks,   file,   output_format = \"multiple\",   block_name_location = NULL,   paste_sep = \"_\",   filename_sep = \"_\",   na = \"\",   ... )"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/write_blocks.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Write block designs to csv — write_blocks","text":"blocks list block-shaped data written file file NULL, character string naming file write ,              vector character strings naming files write . file name required output_format = \"single\" file name can specified output_format = \"pasted\",             file can set NULL long              block_name_location = \"filename\" (pasted              block_name metadata used file name) File names can specified output_format = \"multiple\",             file can set NULL long              block_name_location = \"filename\" (             block_name metadata used file names) output_format One \"single\", \"pasted\", \"multiple\". \"single\" write blocks single                      csv file, empty row successive                      blocks. \"pasted\" paste blocks together using                      paste_sep, write now-pasted                      block single csv file. \"multiple\" write block csv file. block_name_location Either NULL, 'filename' 'file'. NULL, block_name_location                            automatically selected based                            output_format.                            output_format = 'single'                            output_format = 'pasted',                            block_name_location defaults 'file'.                           output_format = 'multiple',                            block_name_location defaults 'filename' 'filename', block_name metadata                            used output file name(s)                           file name(s) provided, appended                           file name(s) provided. 'file', block_name metadata                           included row output file. paste_sep output_format = 'pasted', character used paste together blocks. filename_sep character used paste together  filenames block_name_location = 'filename'. na string use missing values data. ... arguments passed write.table","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/write_blocks.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Write block designs to csv — write_blocks","text":"Nothing, R objects written files","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/news/index.html","id":"gcplyr-150","dir":"Changelog","previous_headings":"","what":"gcplyr 1.5.0","title":"gcplyr 1.5.0","text":"Several fixes bugs calc_deriv returning incorrect values trans_y = ‘log’ either blank specified fitting used (.e. window_width window_width_n NULL) Bug fixes better warning messages lag_time, especially relating negative infinite y-values following log-transformation New function: solve_linear, enables easy calculation slope two points, finding additional point known line New functions: which_min_gc, which_max_gc, min_gc, max_gc, extr_val. serve versions base functions .min, .max, min, max, [] (respectively) better defaults handling edge cases (often related NA values) growth curve analyses dplyr::summarize auc function two new arguments. ‘blank’ allows setting blank value, ‘neg.rm’ gives users choice handle -zero values Various documentation improvements manual vignettes","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/news/index.html","id":"gcplyr-141","dir":"Changelog","previous_headings":"","what":"gcplyr 1.4.1","title":"gcplyr 1.4.1","text":"Bug fix calc_deriv nearly values become NA log-transformation","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/news/index.html","id":"gcplyr-140","dir":"Changelog","previous_headings":"","what":"gcplyr 1.4.0","title":"gcplyr 1.4.0","text":"planned changes smooth_data return_fitobject = TRUE: forthcoming version (first version released Sep 1, 2023), return_fitobject = TRUE return list object created underlying method directly. current behavior modifies generated object ‘fitted’ always first element ‘residuals’ always second element mdp() new function, simply shorthand alias make_designpattern() Column numbers row numbers read_* import_* functions can now specified using mix base-10 numbers base-26 Excel-style letters separate_tidy now coerces strings “NA” NA values default Bug fix make_design NA values returned “NA” (string) instead NA (missing value indicator) output_format = ‘tidy’ multiple design columns Bug fix make_design pattern just “1” Bug fix error arose calc_deriv trans_y = ‘log’ used y values 0. calc_deriv now handles resulting NA/NaN values raises warning Bug fixes first_maxima first_minima Added warning using make_design ’s likely setting custom lookup_tbl_start forgotten Improved documentation make_designpattern","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/news/index.html","id":"gcplyr-130","dir":"Changelog","previous_headings":"","what":"gcplyr 1.3.0","title":"gcplyr 1.3.0","text":"New function lag_time calculate lag time New function doubling_time convert per-capita growth rate equivalent doubling time smooth_data calc_deriv now pass warning used outside dplyr::mutate ungrouped data make_design better warning messages common mistakes Major edits vignettes Various documentation improvements","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/news/index.html","id":"gcplyr-120","dir":"Changelog","previous_headings":"","what":"gcplyr 1.2.0","title":"gcplyr 1.2.0","text":"function first_peak renamed first_maxima. first_peak continue function normally long time warning use first_maxima instead. New functions added shortcuts common use cases: first_minima first_above Bug fixes find_threshold_crossings related return_endpoints = TRUE Bug fixes find_threshold_crossings find_local_extrema input values NA Style content improvements vignettes Help pages improved","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/news/index.html","id":"gcplyr-110","dir":"Changelog","previous_headings":"","what":"gcplyr 1.1.0","title":"gcplyr 1.1.0","text":"CRAN release: 2023-02-03 default behavior write_blocks changed: users now required specify file argument either NULL, file name, vector file names. old default naming, specify file = NULL. change required CRAN compatibility. Minor changes citation Tweaked documentation CRAN compatibility","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/news/index.html","id":"gcplyr-102","dir":"Changelog","previous_headings":"","what":"gcplyr 1.0.2","title":"gcplyr 1.0.2","text":"Tweaks CITATION CRAN compatibility","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/news/index.html","id":"gcplyr-101","dir":"Changelog","previous_headings":"","what":"gcplyr 1.0.1","title":"gcplyr 1.0.1","text":"Readability improvements “Dealing noise” vignette Minor tweaks several vignettes reduce build time CRAN compatibility","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/news/index.html","id":"gcplyr-100","dir":"Changelog","previous_headings":"","what":"gcplyr 1.0.0","title":"gcplyr 1.0.0","text":"minor documentation tweaks CRAN compatibility since 0.12.3. version 1.0.0 first released CRAN denotes gcplyr stable going forward","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/news/index.html","id":"gcplyr-0123","dir":"Changelog","previous_headings":"","what":"gcplyr 0.12.3","title":"gcplyr 0.12.3","text":"Tweaks CRAN compatibility, largely minor documentation changes","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/news/index.html","id":"gcplyr-0122","dir":"Changelog","previous_headings":"","what":"gcplyr 0.12.2","title":"gcplyr 0.12.2","text":"Improved clarity vignettes, especially calculating derivatives analyzing data pages New vignette dealing noise data Small tweaks documentation","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/news/index.html","id":"gcplyr-0121","dir":"Changelog","previous_headings":"","what":"gcplyr 0.12.1","title":"gcplyr 0.12.1","text":"Minor bug fixes","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/news/index.html","id":"gcplyr-012","dir":"Changelog","previous_headings":"","what":"gcplyr 0.12","title":"gcplyr 0.12","text":"new citation. Run citation(“gcplyr”) see new version smooth_data methods moving-average moving-median now accept new smoothing parameter: window_width find_local_extrema now arguments window_width, window_width_n, window_height (naming consistency smooth_data calc_deriv arguments). Arguments width_limit, width_limit_n, height_limit deprecated. calc_deriv can now calculate derivatives using linear fit multiple data points determined arguments window_width /window_width_n. per-capita derivatives, y-values can fit -supplied divided mid-point y-value, can fit log-transformation gcplyr-workflow vignette split multiple smaller vignettes new data.frame included gcplyr: example_data_noiseless. data example_data include simulated noise present example_data. small numerical changes example_data values occurred re-generation example_data. Packages mgcv readxl now Suggests (previously Imports), errors thrown installed required gcplyr functionality find_local_extrema now much faster","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/news/index.html","id":"gcplyr-0112","dir":"Changelog","previous_headings":"","what":"gcplyr 0.11.2","title":"gcplyr 0.11.2","text":"new vignette section running statistics vignette, use dplyr::mutate smoothing derivatives sections","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/news/index.html","id":"gcplyr-0111","dir":"Changelog","previous_headings":"","what":"gcplyr 0.11.1","title":"gcplyr 0.11.1","text":"updates vignette README","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/news/index.html","id":"gcplyr-011","dir":"Changelog","previous_headings":"","what":"gcplyr 0.11","title":"gcplyr 0.11","text":"first public release gcplyr Open Beta. Documentation complete, although planned additions vignette completed included . Functions arguments largely stabilized, although small changes may occur going forward following user feedback. Internal tests mostly complete, although additional edge cases may added bugs reported.","code":""}]
