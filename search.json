[{"path":"https://mikeblazanin.github.io/gcplyr/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2023 Michael Blazanin Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/analyze.html","id":"where-are-we-so-far","dir":"Articles","previous_headings":"","what":"Where are we so far?","title":"Analyzing data","text":"Introduction: vignette(\"gcplyr\") Importing transforming data: vignette(\"import_transform\") Incorporating design information: vignette(\"incorporate_designs\") Pre-processing plotting data: vignette(\"preprocess_plot\") Processing data: vignette(\"process\") Analyzing data: vignette(\"analyze\") Dealing noise: vignette(\"noise\") Statistics, merging data, resources: vignette(\"conclusion\") far, ’ve imported transformed measures, combined design information, pre-processed, processed, plotted data. Now ’re going analyze data summarizing growth curves number metrics. haven’t already, load necessary packages.","code":"library(gcplyr) #> ##  #> ## gcplyr (Version 0.12.3, Build Date: 2023-01-30) #> ## See http://github.com/mikeblazanin/gcplyr for additional documentation #> ## Please cite software as: #> ##   Blazanin, Michael. 2023. 'gcplyr: manipulate and analyze growth #> ##   curve data.' R package version 0.12.3 #> ##  library(dplyr) #>  #> Attaching package: 'dplyr' #> The following objects are masked from 'package:stats': #>  #>     filter, lag #> The following objects are masked from 'package:base': #>  #>     intersect, setdiff, setequal, union library(ggplot2) #This code was previously explained #Here we're re-running it so it's available for us to work with example_tidydata <- trans_wide_to_tidy(example_widedata_noiseless,                                        id_cols = \"Time\") example_design <- make_design(   pattern_split = \",\", nrows = 8, ncols = 12,   \"Bacteria_strain\" = make_designpattern(     values = paste(\"Strain\", 1:48),     rows = 1:8, cols = 1:6, pattern = 1:48, byrow = TRUE),   \"Bacteria_strain\" = make_designpattern(     values = paste(\"Strain\", 1:48),     rows = 1:8, cols = 7:12, pattern = 1:48, byrow = TRUE),   \"Phage\" = make_designpattern(     values = c(\"No Phage\"), rows = 1:8, cols = 1:6, pattern = \"1\"),   \"Phage\" = make_designpattern(     values = c(\"Phage Added\"), rows = 1:8, cols = 7:12, pattern = \"1\")) ex_dat_mrg <- merge_dfs(example_tidydata, example_design) #> Joining, by = \"Well\" ex_dat_mrg$Well <-    factor(ex_dat_mrg$Well,          levels = paste(rep(LETTERS[1:8], each = 12), 1:12, sep = \"\")) ex_dat_mrg <- group_by(ex_dat_mrg, Well, Bacteria_strain, Phage) ex_dat_mrg <-   mutate(ex_dat_mrg,          deriv = calc_deriv(x = Time, y = Measurements, x_scale = 3600),          deriv_percap5 = calc_deriv(x = Time, y = Measurements,                                          percapita = TRUE, blank = 0,                                         window_width_n = 5, trans_y = \"log\",                                     x_scale = 3600)) sample_wells <- c(\"A1\", \"F1\", \"F10\", \"E11\")"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/analyze.html","id":"Analyzing","dir":"Articles","previous_headings":"","what":"Analyzing data with summarize","title":"Analyzing data","text":"Ultimately, analyzing growth curves requires summarizing entire time series data metric metrics. instance, may calculate metrics like: maximum density total area curve lag time (approximated time start maximum per-capita growth rate achieved) maximum per-capita growth rate density diauxic shift occurs time diauxic shift occurs peak per-capita growth rate diauxic shift peak density decline phage predation time bacteria drop density phage predation gcplyr contains number functions make easier carry calculations. Additionally, gcplyr functions flexible enough can use designing metric calculations. following sections highlight general-use gcplyr functions provide examples calculate common metrics . first, need familiarize one dplyr function: summarize. ? upcoming gcplyr analysis functions must used within dplyr::summarize. ’re already familiar dplyr’s summarize, feel free skip primer next section. ’re familiar yet, don’t worry! Continue next section, provide primer teach need know using summarize gcplyr functions.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/analyze.html","id":"another-brief-primer-on-dplyr-summarize","dir":"Articles","previous_headings":"","what":"Another brief primer on dplyr: summarize","title":"Analyzing data","text":"’re going focus summarize function dplyr, must used group_by function covered first primer: brief primer dplyr. summarize carries user-specified calculations group grouped data.frame independently, producing new data.frame group now just single row. growth curves, means : group_by data every well group summarize well calculations like maximum density area curve Since summarize drop columns data aren’t grouped aren’t summarized, typically want list design columns group_by, along plate name well. , make sure ’re grouping Time, Absorbance, anything else varies within well, since dplyr group timepoints within well separately. next section, provide simple example max function used group_by summarize calculate lag time maximum per-capita growth rate. want learn , dplyr extensive documentation examples online. Feel free explore desired, primer coming example sufficient use remaining gcplyr functions.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/analyze.html","id":"summarizing-with-simple-base-functions-maximum-density-and-growth-rate","dir":"Articles","previous_headings":"","what":"Summarizing with simple base functions: maximum density and growth rate","title":"Analyzing data","text":"One common steps calculating global maxima (minima) data. instance, bacterial growth, maximum density growth rate commonly measured traits. , ’ll show find using built-max function. First, need group data. , group_by simply requires data.frame grouped, names columns want group . , run summarize. Just like mutate, specify: name variable want results saved function calculates summarized results case, function return just single value group. instance, code ’ve calculated maximum Measurements column, saved column named max_dens (note need specify na.rm = TRUE tell max ignore NA values). ’ve saved output summarize new data.frame: ex_dat_mrg_sum, short example_data_merged_summarized. want additional characteristics, simply add summarize. instance, want time maximum density occurs, just add second argument. case, use .max function, returns index maximum value, get index Time maximum occurs, save column titled max_time: can quite easily plot summarized values horizontal line vertical line top original growth curves data geom_hline geom_vline functions:  Alternatively, plot summary points point:  can also use process find maximum per-capita growth rates previously calculated:","code":"#First, drop unneeded columns (optional) ex_dat_mrg <- dplyr::select(ex_dat_mrg,                             Time, Well, Measurements, Bacteria_strain, Phage,                             deriv, deriv_percap5) #Then, carry out grouping ex_dat_mrg <- group_by(ex_dat_mrg, Bacteria_strain, Phage, Well) ex_dat_mrg_sum <- summarize(ex_dat_mrg,                             max_dens = max(Measurements, na.rm = TRUE)) #> `summarise()` has grouped output by 'Bacteria_strain', 'Phage'. You can #> override using the `.groups` argument. head(ex_dat_mrg_sum) #> # A tibble: 6 × 4 #> # Groups:   Bacteria_strain, Phage [6] #>   Bacteria_strain Phage       Well  max_dens #>   <chr>           <chr>       <fct>    <dbl> #> 1 Strain 1        No Phage    A1       1.18  #> 2 Strain 1        Phage Added A7       0.499 #> 3 Strain 10       No Phage    B4       1.21  #> 4 Strain 10       Phage Added B10      0.962 #> 5 Strain 11       No Phage    B5       1.21  #> 6 Strain 11       Phage Added B11      1.03 ex_dat_mrg_sum <- summarize(ex_dat_mrg,                             max_dens = max(Measurements, na.rm = TRUE),                             max_time = Time[which.max(Measurements)]) #> `summarise()` has grouped output by 'Bacteria_strain', 'Phage'. You can #> override using the `.groups` argument. head(ex_dat_mrg_sum) #> # A tibble: 6 × 5 #> # Groups:   Bacteria_strain, Phage [6] #>   Bacteria_strain Phage       Well  max_dens max_time #>   <chr>           <chr>       <fct>    <dbl>    <dbl> #> 1 Strain 1        No Phage    A1       1.18     86400 #> 2 Strain 1        Phage Added A7       0.499    31500 #> 3 Strain 10       No Phage    B4       1.21     85500 #> 4 Strain 10       Phage Added B10      0.962    30600 #> 5 Strain 11       No Phage    B5       1.21     70200 #> 6 Strain 11       Phage Added B11      1.03     86400 ggplot(data = dplyr::filter(ex_dat_mrg, Well %in% sample_wells),        aes(x = Time, y = Measurements)) +   geom_line() +   facet_wrap(~Well) +   geom_hline(data = dplyr::filter(ex_dat_mrg_sum, Well %in% sample_wells),               aes(yintercept = max_dens), lty = 2) +   geom_vline(data = dplyr::filter(ex_dat_mrg_sum, Well %in% sample_wells),               aes(xintercept = max_time), lty = 2) ggplot(data = dplyr::filter(ex_dat_mrg, Well %in% sample_wells),        aes(x = Time, y = Measurements)) +   geom_line() +   facet_wrap(~Well) +   geom_point(data = dplyr::filter(ex_dat_mrg_sum, Well %in% sample_wells),               aes(x = max_time, y = max_dens),              size = 2, color = \"red\") ex_dat_mrg_sum <- summarize(ex_dat_mrg,                             max_percap = max(deriv_percap5, na.rm = TRUE),                             max_percap_time = Time[which.max(deriv_percap5)]) #> `summarise()` has grouped output by 'Bacteria_strain', 'Phage'. You can #> override using the `.groups` argument. ggplot(data = dplyr::filter(ex_dat_mrg, Well %in% sample_wells),        aes(x = Time, y = deriv_percap5)) +   geom_line() +   facet_wrap(~Well) +   geom_point(data = dplyr::filter(ex_dat_mrg_sum, Well %in% sample_wells),               aes(x = max_percap_time, y = max_percap),              size = 2, color = \"red\") #> Warning: Removed 4 rows containing missing values (`geom_line()`)."},{"path":"https://mikeblazanin.github.io/gcplyr/articles/analyze.html","id":"summarizing-with-simple-gcplyr-functions-area-under-the-curve","dir":"Articles","previous_headings":"","what":"Summarizing with simple gcplyr functions: area under the curve","title":"Analyzing data","text":"One common metric growth curves total area curve. gcplyr auc function easily calculate area. Just like min max, needs used inside summarize data.frame grouped. use auc, simply specify x y data whose area---curve want calculate. , calculate area---curve Measurements column save column titled auc.","code":"ex_dat_mrg_sum <-   summarize(ex_dat_mrg,             auc = auc(x = Time, y = Measurements)) #> `summarise()` has grouped output by 'Bacteria_strain', 'Phage'. You can #> override using the `.groups` argument. head(ex_dat_mrg_sum) #> # A tibble: 6 × 4 #> # Groups:   Bacteria_strain, Phage [6] #>   Bacteria_strain Phage       Well     auc #>   <chr>           <chr>       <fct>  <dbl> #> 1 Strain 1        No Phage    A1    57291. #> 2 Strain 1        Phage Added A7     3856. #> 3 Strain 10       No Phage    B4    73505. #> 4 Strain 10       Phage Added B10   22156. #> 5 Strain 11       No Phage    B5    75289. #> 6 Strain 11       Phage Added B11   27966."},{"path":"https://mikeblazanin.github.io/gcplyr/articles/analyze.html","id":"finding-local-extrema-peak-density-maximum-growth-rate-lag-time-and-diauxic-shifts","dir":"Articles","previous_headings":"","what":"Finding local extrema: peak density, maximum growth rate, lag time, and diauxic shifts","title":"Analyzing data","text":"’ve previously shown can use max min find global maxima minima data. However, local maxima minima? , peaks valleys obvious eye aren’t highest smallest values entire time series. section, ’ll show can use gcplyr functions first_peak find_local_extrema find points local maxima minima data.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/analyze.html","id":"finding-the-first-peak-peak-density-maximum-growth-rate-and-lag-time","dir":"Articles","previous_headings":"Finding local extrema: peak density, maximum growth rate, lag time, and diauxic shifts","what":"Finding the first peak: peak density, maximum growth rate, and lag time","title":"Analyzing data","text":"One particular special case ’re often interested first peak set data. instance, bacteria grown phages, density reach start declining due phage predation measure susceptibility phage. Alternatively, previous section found global maximum per-capita growth rate, maxima happened near-extinction recovery wanted find peak growth rate near-extinction?","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/analyze.html","id":"peak-density","dir":"Articles","previous_headings":"Finding local extrema: peak density, maximum growth rate, lag time, and diauxic shifts > Finding the first peak: peak density, maximum growth rate, and lag time","what":"Peak density","title":"Analyzing data","text":"Let’s start former example: finding peak density. identify first peak, can use gcplyr function first_peak. first_peak simply requires y data want identify peak . case, ’s Measurements. also need specify whether want function return index first peak, x value peak, y value peak. ’ll get x y values, saving columns first_peak_x first_peak_y, respectively. usual, first_peak needs used inside summarize command data already grouped. Let’s plot points wells confirm expect:  worked great! cases, might find first_peak sensitive enough, sensitive, data. cases, can adjust tuning parameters make first_peak less sensitive small peaks valleys. first_peak, tuning parameters window_width, window_width_n, window_height: window_width determines width window used search peaks valleys, units x window_width_n determines width window, units number data points window_height determines shortest peak shallowest valley window cross, units y","code":"ex_dat_mrg_sum <-   summarize(ex_dat_mrg,             first_peak_x = first_peak(x = Time, y = Measurements, return = \"x\"),             first_peak_y = first_peak(x = Time, y = Measurements, return = \"y\")) #> `summarise()` has grouped output by 'Bacteria_strain', 'Phage'. You can #> override using the `.groups` argument.  head(ex_dat_mrg_sum) #> # A tibble: 6 × 5 #> # Groups:   Bacteria_strain, Phage [6] #>   Bacteria_strain Phage       Well  first_peak_x first_peak_y #>   <chr>           <chr>       <fct>        <dbl>        <dbl> #> 1 Strain 1        No Phage    A1           86400        1.18  #> 2 Strain 1        Phage Added A7           31500        0.499 #> 3 Strain 10       No Phage    B4           71100        1.21  #> 4 Strain 10       Phage Added B10          30600        0.962 #> 5 Strain 11       No Phage    B5           70200        1.21  #> 6 Strain 11       Phage Added B11          18900        0.439 ggplot(data = ex_dat_mrg, aes(x = Time, y = Measurements)) +   geom_line() +   facet_wrap(~Well, nrow = 8, ncol = 12) +   geom_point(data = ex_dat_mrg_sum,               aes(x = first_peak_x, y = first_peak_y),               color = \"red\", size = 1.5)"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/analyze.html","id":"maximum-growth-rate-and-lag-time","dir":"Articles","previous_headings":"Finding local extrema: peak density, maximum growth rate, lag time, and diauxic shifts > Finding the first peak: peak density, maximum growth rate, and lag time","what":"Maximum growth rate and lag time","title":"Analyzing data","text":"Now let’s look example: using first_peak find first peak per-capita growth rate. Finding point tells us maximum growth rate , long took cells reach rate (measure lag time).  want find extrema ’s first peak? next section, ’ll learn use find_local_extrema identify kinds local extrema.","code":"ex_dat_mrg_sum <-   summarize(ex_dat_mrg,             max_growth_rate = first_peak(x = Time, y = deriv_percap5,                                           return = \"y\"),             lag_time = first_peak(x = Time, y = deriv_percap5,                                    return = \"x\")) #> `summarise()` has grouped output by 'Bacteria_strain', 'Phage'. You can #> override using the `.groups` argument.  head(ex_dat_mrg_sum) #> # A tibble: 6 × 5 #> # Groups:   Bacteria_strain, Phage [6] #>   Bacteria_strain Phage       Well  max_growth_rate lag_time #>   <chr>           <chr>       <fct>           <dbl>    <dbl> #> 1 Strain 1        No Phage    A1               1.03    15300 #> 2 Strain 1        Phage Added A7               1.03    15300 #> 3 Strain 10       No Phage    B4               1.59    12600 #> 4 Strain 10       Phage Added B10              1.59    12600 #> 5 Strain 11       No Phage    B5               1.65    12600 #> 6 Strain 11       Phage Added B11              1.65    12600  ggplot(data = dplyr::filter(ex_dat_mrg, Well %in% sample_wells),        aes(x = Time, y = deriv_percap5)) +   geom_line() +   facet_wrap(~Well, scales = \"free\") +   geom_point(data = dplyr::filter(ex_dat_mrg_sum, Well %in% sample_wells),              aes(x = lag_time, y = max_growth_rate),              color = \"red\", size = 2) #> Warning: Removed 4 rows containing missing values (`geom_line()`)."},{"path":"https://mikeblazanin.github.io/gcplyr/articles/analyze.html","id":"finding-any-kind-of-local-extrema-diauxic-shifts","dir":"Articles","previous_headings":"Finding local extrema: peak density, maximum growth rate, lag time, and diauxic shifts","what":"Finding any kind of local extrema: diauxic shifts","title":"Analyzing data","text":"’ve seen first_peak can used identify first peak data. kinds local extrema? first minimum? second peak? order identify kinds extrema, can use -general function find_local_extrema. fact, first_peak really just special case find_local_extrema. Just like first_peak, find_local_extrema requires vector y data find local extrema, can return index, x value, y value extrema finds. Unlike first_peak, find_local_extrema returns vector containing local extrema found given settings. Users can alter kinds local extrema reported using arguments return_maxima, return_minima, return_endpoints. However, find_local_extrema always return vector extrema found, users must use brackets select one want summarize save. Let’s dig example: identifying diauxic shifts. refresh memory saw derivatives article, ’s plot derivative wells time.  fact, look wells phage added, ’ll see similar pattern repeatedly.  second, slower, burst growth first wave growth common bacterial growth curves called diauxic growth. identify time bacteria switch first burst growth second? can find second minima deriv values (first minima going start growth curve). , specify find_local_extrema want return = \"x\" don’t want maxima returned:  Now ’ve found point bacteria switch, let’s identify density diauxic shift occurs. First, ’ll save index diauxic shift occurs column titled diaxuie_idx. , can get Measurements value index. (Note wouldn’t work just specify return = \"y\", y values case deriv values).  Something hard see density plot now easily quantified can visualized exactly shift occurs.","code":"ggplot(data = dplyr::filter(ex_dat_mrg, Well %in% sample_wells),        aes(x = Time, y = deriv)) +   geom_line() +   facet_wrap(~Well, scales = \"free\") #> Warning: Removed 1 row containing missing values (`geom_line()`). sample_wells <- c(\"A1\", \"A4\", \"E2\", \"F1\") ggplot(data = dplyr::filter(ex_dat_mrg, Well %in% sample_wells),        aes(x = Time, y = deriv)) +   geom_line() +   facet_wrap(~Well, scales = \"free\") #> Warning: Removed 1 row containing missing values (`geom_line()`). ex_dat_mrg_sum <-   summarize(ex_dat_mrg,     diauxie_time = find_local_extrema(x = Time, y = deriv, return = \"x\",                                    return_maxima = FALSE, return_minima = TRUE,                                    window_width_n = 39)[2]) #> `summarise()` has grouped output by 'Bacteria_strain', 'Phage'. You can #> override using the `.groups` argument.  #Plot data with vertical line at detected diauxie ggplot(data = dplyr::filter(ex_dat_mrg, Well %in% sample_wells),        aes(x = Time, y = deriv)) +   geom_line() +   facet_wrap(~Well, scales = \"free\") +   geom_vline(data = dplyr::filter(ex_dat_mrg_sum, Well %in% sample_wells),               aes(xintercept = diauxie_time), lty = 2) #> Warning: Removed 1 row containing missing values (`geom_line()`). ex_dat_mrg_sum <-   summarize(     ex_dat_mrg,     diauxie_time = find_local_extrema(x = Time, y = deriv, return = \"x\",                                    return_maxima = FALSE, return_minima = TRUE,                                    window_width_n = 39)[2],     diauxie_idx = find_local_extrema(x = Time, y = deriv, return = \"index\",                                    return_maxima = FALSE, return_minima = TRUE,                                    window_width_n = 39)[2],     diauxie_dens = Measurements[diauxie_idx]) #> `summarise()` has grouped output by 'Bacteria_strain', 'Phage'. You can #> override using the `.groups` argument.  #Plot data with a point at the moment of diauxic shift ggplot(data = dplyr::filter(ex_dat_mrg, Well %in% sample_wells),        aes(x = Time, y = Measurements)) +   geom_line() +   facet_wrap(~Well, scales = \"free\") +   geom_point(data = dplyr::filter(ex_dat_mrg_sum, Well %in% sample_wells),               aes(x = diauxie_time, y = diauxie_dens),              size = 2, color = \"red\")"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/analyze.html","id":"combining-subsets-and-local-extrema-diauxic-growth-rate","dir":"Articles","previous_headings":"Finding local extrema: peak density, maximum growth rate, lag time, and diauxic shifts","what":"Combining subsets and local extrema: diauxic growth rate","title":"Analyzing data","text":"previous section identified bacteria shifted second burst growth. Can find peak per-capita growth rate second burst? Yes, just put together things ’ve learned already. particular, ’re going combine use find_local_extrema, max, subsets find max(deriv_percap_hr) times diauxic shift:","code":"ex_dat_mrg_sum <-   summarize(     ex_dat_mrg,     diauxie_time = find_local_extrema(x = Time, y = deriv, return = \"x\",                                    return_maxima = FALSE, return_minima = TRUE,                                    window_width_n = 39)[2],     diauxie_percap = max(deriv_percap5[Time >= diauxie_time], na.rm = TRUE),     diauxie_percap_time =        Time[Time >= diauxie_time][         which.max(deriv_percap5[Time >= diauxie_time])]     ) #> `summarise()` has grouped output by 'Bacteria_strain', 'Phage'. You can #> override using the `.groups` argument.  #Plot data with a point at the moment of peak diauxic growth rate ggplot(data = dplyr::filter(ex_dat_mrg, Well %in% sample_wells),        aes(x = Time, y = deriv_percap5)) +   geom_line() +   facet_wrap(~Well, scales = \"free\") +   geom_point(data = dplyr::filter(ex_dat_mrg_sum, Well %in% sample_wells),               aes(x = diauxie_percap_time, y = diauxie_percap),              size = 2, color = \"red\") #> Warning: Removed 4 rows containing missing values (`geom_line()`)."},{"path":"https://mikeblazanin.github.io/gcplyr/articles/analyze.html","id":"finding-threshold-crossings-extinction-time-and-time-to-density","dir":"Articles","previous_headings":"","what":"Finding threshold-crossings: extinction time and time to density","title":"Analyzing data","text":"’ve previously shown can find local global extrema data, just want find data passes threshold value? section, ’ll show can use gcplyr functions first_below find_threshold_crosses find points data crosses user-defined thresholds.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/analyze.html","id":"finding-the-first-point-below-a-threshold-extinction-time","dir":"Articles","previous_headings":"Finding threshold-crossings: extinction time and time to density","what":"Finding the first point below a threshold: extinction time","title":"Analyzing data","text":"One common case threshold-crossing might interested first point data falls threshold density. instance, bacteria grown phages, amount time takes bacterial population falls threshold can proxy metric sensitive bacteria phage. Let’s take look absorbance values example wells bacteria phages:  Ok great. Now let’s suppose think absorbance 0.15 good threshold extinction experiment. use first_below calculate time first occurs across different wells? Well, primarily, first_below simply needs x y values, threshold want use, well whether want return index first point threshold, x value point (since care time happened , ’ll latter). Additionally, ’ll specify don’t care startpoint threshold: care data goes .  phage-added wells time bacteria drop threshold, plot clearly shows ’s right ’d expect .","code":"sample_wells <- c(\"A7\", \"B10\", \"F10\", \"H8\")  ggplot(data = dplyr::filter(ex_dat_mrg, Well %in% sample_wells),        aes(x = Time, y = Measurements)) +   geom_line() +   facet_wrap(~Well) ex_dat_mrg_sum <-   summarize(     ex_dat_mrg,     extin_time = first_below(x = Time, y = Measurements, threshold = 0.15,                              return = \"x\", return_endpoints = FALSE)) #> `summarise()` has grouped output by 'Bacteria_strain', 'Phage'. You can #> override using the `.groups` argument. head(ex_dat_mrg_sum) #> # A tibble: 6 × 4 #> # Groups:   Bacteria_strain, Phage [6] #>   Bacteria_strain Phage       Well  extin_time #>   <chr>           <chr>       <fct>      <dbl> #> 1 Strain 1        No Phage    A1           NA  #> 2 Strain 1        Phage Added A7        33063. #> 3 Strain 10       No Phage    B4           NA  #> 4 Strain 10       Phage Added B10       34946. #> 5 Strain 11       No Phage    B5           NA  #> 6 Strain 11       Phage Added B11       20319.  ggplot(data = dplyr::filter(ex_dat_mrg, Well %in% sample_wells),        aes(x = Time, y = Measurements)) +   geom_line() +   facet_wrap(~Well) +   geom_vline(data = dplyr::filter(ex_dat_mrg_sum, Well %in% sample_wells),              aes(xintercept = extin_time), lty = 2)"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/analyze.html","id":"finding-any-kind-of-threshold-crossing-time-to-density","dir":"Articles","previous_headings":"Finding threshold-crossings: extinction time and time to density","what":"Finding any kind of threshold-crossing: time to density","title":"Analyzing data","text":"’ve seen first_below can used identify first point data crosses threshold. kinds threshold-crossing events? first point passes threshold? first point ’s ever threshold, including start? order identify kinds extrema, can use -general function find_threshold_crosses. fact, first_below really just special case find_threshold_crosses. Just like first_below, find_threshold_crosses requires threshold vector y data find threshold crosses, can return index x value crossing events finds. However, unlike first_below, find_threshold_crosses returns vector containing threshold crossings found given settings. Users can alter kinds threshold crossings reported using arguments return_rising, return_falling, return_endpoints. However, find_threshold_crosses always return vector extrema found, users must use brackets select one want summarize save. Let’s dig example: identifying first time bacteria reach density, including start density can see, find_threshold_crosses returned times bacteria reached densities. can see bacteria (e.g. Well F10) never reached 0.5, NA value time_to_05. comparing times took strain reach absorbance 0.1, learn something soon bacteria started growing quickly grew.","code":"sample_wells <- c(\"A1\", \"F1\", \"F10\", \"E11\") ex_dat_mrg_sum <-   summarize(     ex_dat_mrg,     time_to_01 = find_threshold_crosses(x = Time, y = Measurements,                                          threshold = 0.1, return = \"x\",                                          return_endpoints = TRUE,                                          return_falling = FALSE)[1],     time_to_05 = find_threshold_crosses(x = Time, y = Measurements,                                          threshold = 0.5, return = \"x\",                                          return_endpoints = TRUE,                                          return_falling = FALSE)[1]) #> `summarise()` has grouped output by 'Bacteria_strain', 'Phage'. You can #> override using the `.groups` argument. head(ex_dat_mrg_sum) #> # A tibble: 6 × 5 #> # Groups:   Bacteria_strain, Phage [6] #>   Bacteria_strain Phage       Well  time_to_01 time_to_05 #>   <chr>           <chr>       <fct>      <dbl>      <dbl> #> 1 Strain 1        No Phage    A1        21913.     31194. #> 2 Strain 1        Phage Added A7        21913.        NA  #> 3 Strain 10       No Phage    B4        15300      20624. #> 4 Strain 10       Phage Added B10       15300      20624. #> 5 Strain 11       No Phage    B5        14543.     19490  #> 6 Strain 11       Phage Added B11       14543.     59955  ggplot(data = dplyr::filter(ex_dat_mrg, Well %in% sample_wells),        aes(x = Time, y = Measurements)) +   geom_line() +   facet_wrap(~Well) +   geom_vline(data = dplyr::filter(ex_dat_mrg_sum, Well %in% sample_wells),              aes(xintercept = time_to_01), lty = 2) +   geom_vline(data = dplyr::filter(ex_dat_mrg_sum, Well %in% sample_wells),              aes(xintercept = time_to_05), lty = 2) #> Warning: Removed 1 rows containing missing values (`geom_vline()`)."},{"path":"https://mikeblazanin.github.io/gcplyr/articles/analyze.html","id":"whats-next","dir":"Articles","previous_headings":"","what":"What’s next?","title":"Analyzing data","text":"Now ’ve analyzed data, can read approaches deal noise growth curve data, can read concluding notes best practices running statistics, merging growth curve analyses data, additional resources analyzing growth curves. Introduction: vignette(\"gcplyr\") Importing transforming data: vignette(\"import_transform\") Incorporating design information: vignette(\"incorporate_designs\") Pre-processing plotting data: vignette(\"preprocess_plot\") Processing data: vignette(\"process\") Analyzing data: vignette(\"analyze\") Dealing noise: vignette(\"noise\") Statistics, merging data, resources: vignette(\"conclusion\")","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/conclusion.html","id":"where-are-we-so-far","dir":"Articles","previous_headings":"","what":"Where are we so far?","title":"Statistics, merging other data, and other resources","text":"Introduction: vignette(\"gcplyr\") Importing transforming data: vignette(\"import_transform\") Incorporating design information: vignette(\"incorporate_designs\") Pre-processing plotting data: vignette(\"preprocess_plot\") Processing data: vignette(\"process\") Analyzing data: vignette(\"analyze\") Dealing noise: vignette(\"noise\") Statistics, merging data, resources: vignette(\"conclusion\") far, ’ve imported transformed measures, combined design information, pre-processed, processed, plotted, analyzed data. things left notes best practices running statistics, merging growth curve analyses data, additional resources analyzing growth curves. haven’t already, load necessary packages.","code":"library(gcplyr) #> ##  #> ## gcplyr (Version 0.12.3, Build Date: 2023-01-30) #> ## See http://github.com/mikeblazanin/gcplyr for additional documentation #> ## Please cite software as: #> ##   Blazanin, Michael. 2023. 'gcplyr: manipulate and analyze growth #> ##   curve data.' R package version 0.12.3 #> ##  library(dplyr) #>  #> Attaching package: 'dplyr' #> The following objects are masked from 'package:stats': #>  #>     filter, lag #> The following objects are masked from 'package:base': #>  #>     intersect, setdiff, setequal, union library(ggplot2) #This code was previously explained #Here we're re-running it so it's available for us to work with example_tidydata <- trans_wide_to_tidy(example_widedata_noiseless,                                        id_cols = \"Time\") example_design <- make_design(   pattern_split = \",\", nrows = 8, ncols = 12,   \"Bacteria_strain\" = make_designpattern(     values = paste(\"Strain\", 1:48),     rows = 1:8, cols = 1:6, pattern = 1:48, byrow = TRUE),   \"Bacteria_strain\" = make_designpattern(     values = paste(\"Strain\", 1:48),     rows = 1:8, cols = 7:12, pattern = 1:48, byrow = TRUE),   \"Phage\" = make_designpattern(     values = c(\"No Phage\"), rows = 1:8, cols = 1:6, pattern = \"1\"),   \"Phage\" = make_designpattern(     values = c(\"Phage Added\"), rows = 1:8, cols = 7:12, pattern = \"1\")) ex_dat_mrg <- merge_dfs(example_tidydata, example_design) #> Joining, by = \"Well\" ex_dat_mrg$Well <-    factor(ex_dat_mrg$Well,          levels = paste(rep(LETTERS[1:8], each = 12), 1:12, sep = \"\")) ex_dat_mrg <- group_by(ex_dat_mrg, Well, Bacteria_strain, Phage)  ex_dat_mrg <-   mutate(ex_dat_mrg,          smoothed_med3 =             smooth_data(x = Time, y = Measurements,                        sm_method = \"moving-median\", window_width_n = 3),          #Note that for the second round, we're using the           #first smoothing as the input y          smoothed =             smooth_data(x = Time, y = smoothed_med3,                        sm_method = \"moving-average\", window_width_n = 3))"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/conclusion.html","id":"statistical-analyses-of-growth-curves-data","dir":"Articles","previous_headings":"","what":"Statistical analyses of growth curves data","title":"Statistics, merging other data, and other resources","text":"point, ’ve now summarized growth curves data metrics. can best go drawing statistical conclusions data?","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/conclusion.html","id":"when-should-we-average-replicates","dir":"Articles","previous_headings":"Statistical analyses of growth curves data","what":"When should we average replicates?","title":"Statistics, merging other data, and other resources","text":"dig next, want emphasize something workflow: averaging different wells together summarization. opinion, averaging occur summarization, . ? Even wells contents (.e. technical replicates) can still differ growth due biological variation (e.g. stochastic growth dynamics). average density values beginning, may introduce bias ability visualize assess biological variation present data. Let’s look simple example demonstrate point. ’m going simulate bacterial growth using Baranyi-Roberts mathematical model growth, logistic growth period acclimation beginning: \\[\\frac{dN}{dt} = \\frac{q_{0}}{q_{0} + e^{-mt}} * r N\\left(1-\\frac{N}{k}\\right)\\] \\(N\\) population size, \\(q_{0}\\) parameter controlling initial acclimatization state population, \\(m\\) rate acclimation, \\(r\\) rate growth, \\(k\\) carrying capacity population. code , simulate growth 96 different wells bacteria. bacteria identical, except differ rate acclimate.  ’ve plotted individual well black, “average well” plotted red. can clearly see different wells varying quickly ’re acclimating. average well appears reflect data pretty well, give good measure average maximum per-capita growth rate?  can see maximum per-capita growth rate “average well” (red line) true average maximum per-capita growth rate wells (dashed line). bias “average well” might seem small, fact consistent: ran simulation many times, “average well” growth rate nearly always higher true average growth rate. Moreover, “average well” often biased many summarized statistics, just growth rate. Additionally, calculating “average well” means ability plot distribution growth rates wells; single value red line, way directly visualize biased . visualizing distribution directly, can see skewed perhaps use transformed metric (e.g. log growth rate) analyses assume normality.","code":"#Define the function that calculates density according to Baranyi-Roberts eq baranyi_gr <- function(r, k, q0, m, init_dens, times) {   #Note: these eqs are the integral of the dN/dt eq in the text above   #Acclimation function   a <- times + 1/m*log((exp(-m*times)+q0)/(1+q0))   #Density function   return(k/(1-(1-(k/init_dens))*exp(-r*a))) }  #Set up our wide-shaped data frame times <- seq(from = 0, to = 24*60, by = 15) sim_dat <- as.data.frame(matrix(NA, nrow = length(times), ncol = 98)) sim_dat[, 1] <- times colnames(sim_dat) <- c(\"time\", \"averaged\", paste(\"Well\", 1:96, sep = \"\"))  #Simulate growth for (i in 3:ncol(sim_dat)) {   sim_dat[, i] <- baranyi_gr(times = sim_dat$time,                               r = 0.02, k = 1, q0 = 0.5,                              m = rgamma(n = 1, shape = 2, scale = 0.02/2),                              init_dens = 0.001) }  #Calculate the \"average well\" sim_dat[, \"averaged\"] <- rowMeans(sim_dat[, 3:ncol(sim_dat)])  #Transform to tidy and calculate per-capita growth rate                   sim_dat_tdy <- trans_wide_to_tidy(sim_dat, id_cols = \"time\") sim_dat_tdy <- mutate(group_by(sim_dat_tdy, Well),                       percap_deriv = calc_deriv(y = Measurements, x = time,                                                 percapita = TRUE, blank = 0))  #Plot the growth in our wells ggplot(data = filter(sim_dat_tdy, Well != \"averaged\"),         aes(x = time, y = Measurements, group = Well)) +   geom_line(alpha = 0.1) +   geom_line(data = filter(sim_dat_tdy, Well == \"averaged\"), color = \"red\") +   scale_y_continuous(trans = \"log10\") #Summarize our data sim_dat_sum <- summarize(group_by(sim_dat_tdy, Well),                          max_growth_rate = max(percap_deriv, na.rm = TRUE))  #Plot the maximum per-capita growth rates of each well # Add a red line for the max growth rate of the \"average well\" # Add a dashed line for the true average growth rate of all the wells ggplot(data = filter(sim_dat_sum, Well != \"averaged\"),         aes(x = max_growth_rate)) +   geom_histogram() +   geom_vline(data = filter(sim_dat_sum, Well == \"averaged\"),               aes(xintercept = max_growth_rate), color = \"red\") +   geom_vline(xintercept =                 mean(filter(sim_dat_sum, Well != \"averaged\")$max_growth_rate),              lty = 2) #> `stat_bin()` using `bins = 30`. Pick better value with `binwidth`."},{"path":"https://mikeblazanin.github.io/gcplyr/articles/conclusion.html","id":"carrying-out-statistical-testing","dir":"Articles","previous_headings":"Statistical analyses of growth curves data","what":"Carrying out statistical testing","title":"Statistics, merging other data, and other resources","text":"aside average done, go running statistics individual wells? Typically, growth curves experiments highly nested structure. probably multiple wells contents (.e. technical replicates) plate. may also multiple plates different runs (creating possibility batch effects). order pull apart effects test differences treatments, ’ll need mixed-effects modeling. Unfortunately, ’s beyond scope vignette provide sufficient explanation mixed-effects statistics. However, can provide guidance: frequentist statistics, R package lme4 one -popular implementations mixed-effects modeling. Bayesian statistics, R packages brms rstanarm popular implementations can incorporate mixed-effects modeling. Regardless approach, : use summarized statistics (e.g. auc, max_growth_rate, lag_time, etc.) response variable use design elements (e.g. Bacteria_strain, Phage) explanatory variables incorporate random effects technical replicates incorporate random effects potential batch effects -play number excellent resources learn sort mixed-effects modeling, including think good introductory guide process Michael Clark.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/conclusion.html","id":"combining-growth-curves-data-with-other-data","dir":"Articles","previous_headings":"","what":"Combining growth curves data with other data","title":"Statistics, merging other data, and other resources","text":"approach end growth curves analyses, summarized dynamics growth curves one metrics. point, may wish pull sources data compare growth curves metrics. Just like merging multiple growth curves data frames together, can achieved merge_dfs. Let’s use ex_dat_mrg_sum earlier section, ’ve summarized growth curves using area---curve (although approach work number summarized metrics). Now imagine , separately, ’ve measured resistance bacteria antibiotics, want know ’s relationship antibiotic resistance bacteria growth. ’re just going focus bacterial growth absence phage, let’s use dplyr::filter remove phage added rows. Now, let’s generate mock antibiotic resistance data. file containing antibiotic resistance data bacterial strain names header Bacterial_strain, merge_dfs knows match two columns. ’ll put whether strain resistant antibiotic Antibiotic_resis column, TRUE resistance, FALSE sensitivity. Don’t worry exactly code works, since ’s just simulating data collected lab. Great, now merge two data frames. now let’s see ’s relationship!  ! can see antibiotic resistant strains (TRUE) smaller area---curve antibiotic sensitive strains (FALSE) (although, fair, simulate data ’d get result).","code":"ex_dat_mrg_sum <-   summarize(ex_dat_mrg, auc = auc(x = Time, y = smoothed)) #> `summarise()` has grouped output by 'Well', 'Bacteria_strain'. You can override #> using the `.groups` argument. ex_dat_mrg_sum <- dplyr::filter(ex_dat_mrg_sum, Phage == \"No Phage\") head(ex_dat_mrg_sum) #> # A tibble: 6 × 4 #> # Groups:   Well, Bacteria_strain [6] #>   Well  Bacteria_strain Phage       auc #>   <fct> <chr>           <chr>     <dbl> #> 1 A1    Strain 1        No Phage 55172. #> 2 A2    Strain 2        No Phage 67181. #> 3 A3    Strain 3        No Phage 52392  #> 4 A4    Strain 4        No Phage 70101. #> 5 A5    Strain 5        No Phage 70932. #> 6 A6    Strain 6        No Phage 44079. set.seed(123) antibiotic_dat <-    data.frame(Bacteria_strain = paste(\"Strain\", 1:48),              Antibiotic_resis =                 ex_dat_mrg_sum$auc[                  match(paste(\"Strain\", 1:48),                         ex_dat_mrg_sum$Bacteria_strain)] *                 runif(48, 0.5, 1.5) < mean(ex_dat_mrg_sum$auc))  head(antibiotic_dat) #>   Bacteria_strain Antibiotic_resis #> 1        Strain 1             TRUE #> 2        Strain 2            FALSE #> 3        Strain 3             TRUE #> 4        Strain 4            FALSE #> 5        Strain 5            FALSE #> 6        Strain 6             TRUE growth_and_antibiotics <-    merge_dfs(ex_dat_mrg_sum, antibiotic_dat) #> Joining, by = \"Bacteria_strain\" head(growth_and_antibiotics) #> # A tibble: 6 × 5 #> # Groups:   Well, Bacteria_strain [6] #>   Well  Bacteria_strain Phage       auc Antibiotic_resis #>   <fct> <chr>           <chr>     <dbl> <lgl>            #> 1 A1    Strain 1        No Phage 55172. TRUE             #> 2 A2    Strain 2        No Phage 67181. FALSE            #> 3 A3    Strain 3        No Phage 52392  TRUE             #> 4 A4    Strain 4        No Phage 70101. FALSE            #> 5 A5    Strain 5        No Phage 70932. FALSE            #> 6 A6    Strain 6        No Phage 44079. TRUE ggplot(data = growth_and_antibiotics,         aes(x = Antibiotic_resis, y = auc)) +   geom_point()"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/conclusion.html","id":"other-growth-curve-analysis-packages","dir":"Articles","previous_headings":"","what":"Other growth curve analysis packages","title":"Statistics, merging other data, and other resources","text":"number R packages besides gcplyr facilitate analysis growth curves data. , broadly speaking, two ways analyze growth curves data: directly quantify attributes growth dynamics fit growth dynamics mathematical model, extract parameters fitted model gcplyr focuses manipulation growth curves data first analysis approach (direct quantification growth curves dynamics), many R packages focus fitting growth dynamics mathematical model. Generally, fitting growth dynamics model greater power accurately quantify underlying traits. However, also takes much effort rigorous fitting data model. carefully choose model whose assumptions data meet. also evaluate fits ensure optimization algorithms arrived reasonable solutions. number R packages implement fitting-style approaches, list readers explore . point future, hope incorporate direct examples use tidy-shaped data imported manipulated gcplyr packages. growthcurver QurvE AUDIT (including growr mtpview1) growthrates drc opm grofit R-Biolog growthmodels cellGrowth grofit GCAT CarboLogR biogrowth Additionally, one R package doesn’t implement fitting-style approaches, contain useful functionality plate-reader data analysis: plater","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/conclusion.html","id":"whats-next","dir":"Articles","previous_headings":"","what":"What’s next?","title":"Statistics, merging other data, and other resources","text":"’ve finished documentation ’ve written (far). Congratulations! gcplyr powerful framework build additional analyses , since data nicely organized. Feel free reach questions, comments, concerns might . ’d love continue making gcplyr useful others scientific community . can reach mikeblazanin [] gmail [dot] com. Introduction: vignette(\"gcplyr\") Importing transforming data: vignette(\"import_transform\") Incorporating design information: vignette(\"incorporate_designs\") Pre-processing plotting data: vignette(\"preprocess_plot\") Processing data: vignette(\"process\") Analyzing data: vignette(\"analyze\") Dealing noise: vignette(\"noise\") Statistics, merging data, resources: vignette(\"conclusion\")","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gcplyr.html","id":"getting-started","dir":"Articles","previous_headings":"","what":"Getting started","title":"Introduction to using gcplyr","text":"gcplyr package implements number functions make easier import, manipulate, analyze bacterial growth data collected multiwell plate readers (“growth curves”). Without gcplyr, importing analyzing plate reader data can complicated process tailored experiment, requiring many lines code. gcplyr many steps now just single line code. document gives introduction use gcplyr’s common functions, points additional documents -depth explanations common steps growth curve analysis gcplyr. get started, need data file growth curve measures saved tabular format (.csv, .xls, .xlsx) computer. Users often want combine data information experimental design elements growth curve plate(s). instance, might include strains went wells. can save information tabular file well (see [Reading design elements files]), can just keep handy enter directly function later (see [Generating designs R]). Let’s get started loading gcplyr. ’re also going load couple packages ’ll need.","code":"library(gcplyr) #> ##  #> ## gcplyr (Version 0.12.3, Build Date: 2023-01-30) #> ## See http://github.com/mikeblazanin/gcplyr for additional documentation #> ## Please cite software as: #> ##   Blazanin, Michael. 2023. 'gcplyr: manipulate and analyze growth #> ##   curve data.' R package version 0.12.3 #> ##  library(dplyr) #>  #> Attaching package: 'dplyr' #> The following objects are masked from 'package:stats': #>  #>     filter, lag #> The following objects are masked from 'package:base': #>  #>     intersect, setdiff, setequal, union library(ggplot2)"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gcplyr.html","id":"a-quick-demo-of-gcplyr","dir":"Articles","previous_headings":"","what":"A quick demo of gcplyr","title":"Introduction to using gcplyr","text":"digging details various options gcplyr provides users, ’s simple example final gcplyr script can look like. script imports data files created plate reader, combines design files created user, calculates maximum growth rate area---curve. Don’t worry understanding details code works right now. steps explained depth later documents. , ’re just providing demonstration analyzing growth curve data gcplyr can look like.","code":"#Read in our data # (our plate reader data is saved in \"widedata.csv\") data_wide <- read_wides(files = \"widedata.csv\")  #Transform our data to be tidy-shaped data_tidy <-    trans_wide_to_tidy(wides = data_wide, id_cols = c(\"file\", \"Time\"))  #Import our designs # (saved in the files Bacteria_strain.csv and Phage.csv) designs <- import_blockdesigns(files = c(\"Bacteria_strain.csv\", \"Phage.csv\"))  #Merge our designs and data data_merged <- merge_dfs(data_tidy, designs) #> Joining, by = \"Well\"  #Plot the data ggplot(data = data_merged,        aes(x = as.numeric(Time), y = Measurements, color = Well)) +   geom_line(aes(lty = Phage)) +    guides(color = \"none\") #Voila! 8 lines of code and all your data is imported & plotted!  #Calculate the per-capita growth rate over time in each well data_merged <- mutate(   group_by(data_merged, Well),   percap_deriv = calc_deriv(y = Measurements, x = Time, percapita = TRUE,                              blank = 0, window_width_n = 5, x_scale = 3600))  #Calculate two common metrics of bacterial growth: # the maximum growth rate, saving it to a column named max_percap # the area-under-the-curve, saving it to a column named 'auc' data_sum <- summarize(   group_by(data_merged, Well, Bacteria_strain, Phage),   max_percap = max(percap_deriv, na.rm = TRUE),   auc = auc(y = Measurements, x = as.numeric(Time))) #> `summarise()` has grouped output by 'Well', 'Bacteria_strain'. You can override #> using the `.groups` argument.  #Print some of the max growth rates and auc's head(data_sum) #> # A tibble: 6 × 5 #> # Groups:   Well, Bacteria_strain [6] #>   Well  Bacteria_strain Phage       max_percap    auc #>   <chr> <chr>           <chr>            <dbl>  <dbl> #> 1 A1    Strain 1        No Phage         1.00  57291. #> 2 A10   Strain 4        Phage Added      1.43  20060. #> 3 A11   Strain 5        Phage Added      1.47  21571. #> 4 A12   Strain 6        Phage Added      0.789  1422. #> 5 A2    Strain 2        No Phage         1.31  69361. #> 6 A3    Strain 3        No Phage         0.915 54460.  #Plot the results for max growth rate and area under the curve in presence vs absence of phage ggplot(data = data_sum,        aes(x = max_percap, y = auc, color = Phage)) +   geom_point()"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gcplyr.html","id":"whats-next","dir":"Articles","previous_headings":"","what":"What’s next?","title":"Introduction to using gcplyr","text":"Now ’ve read brief introduction, probably want get little detail learning use gcplyr work. Generally, working gcplyr follow number steps, likely one lines code final script. ’ve explained steps page linked . start, ’ll learn import data R transform convenient format. Introduction: vignette(\"gcplyr\") Importing transforming data: vignette(\"import_transform\") Incorporating design information: vignette(\"incorporate_designs\") Pre-processing plotting data: vignette(\"preprocess_plot\") Processing data: vignette(\"process\") Analyzing data: vignette(\"analyze\") Dealing noise: vignette(\"noise\") Statistics, merging data, resources: vignette(\"conclusion\")","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/import_transform.html","id":"where-are-we-so-far","dir":"Articles","previous_headings":"","what":"Where are we so far?","title":"Importing and transforming data","text":"Introduction: vignette(\"gcplyr\") Importing transforming data: vignette(\"import_transform\") Incorporating design information: vignette(\"incorporate_designs\") Pre-processing plotting data: vignette(\"preprocess_plot\") Processing data: vignette(\"process\") Analyzing data: vignette(\"analyze\") Dealing noise: vignette(\"noise\") Statistics, merging data, resources: vignette(\"conclusion\") Previously, gave overview quick demonstration gcplyr can . , ’re going start going detail just can carry step analysis data. haven’t already, load necessary packages.","code":"library(gcplyr) #> ##  #> ## gcplyr (Version 0.12.3, Build Date: 2023-01-30) #> ## See http://github.com/mikeblazanin/gcplyr for additional documentation #> ## Please cite software as: #> ##   Blazanin, Michael. 2023. 'gcplyr: manipulate and analyze growth #> ##   curve data.' R package version 0.12.3 #> ##"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/import_transform.html","id":"data-layouts","dir":"Articles","previous_headings":"","what":"Data layouts","title":"Importing and transforming data","text":"previous demonstration mind, let’s dig details input data might organized gcplyr . Growth curve data design elements can organized one three different tabular layouts: block-shaped, wide-shaped, tidy-shaped, described . Tidy-shaped data best layout analyses, plate readers output block-shaped wide-shaped data, user-created design files block-shaped. Thus, gcplyr works reshaping block-shaped wide-shaped data, wide-shaped data tidy-shaped data, running analyses. , three data layouts, can tell data ? Block-shaped block-shaped data, organization data corresponds directly layout physical multi-well plate generated . instance, data point third row fourth column data.frame well third row fourth column physical plate. , timeseries growth curve data block-shaped consist many separate block-shaped data.frames, corresponding single timepoint. example, block-shaped data.frame 96-well plate (“…” indicating Columns 4 - 10, shown). example, data shown single timepoint. Wide-shaped wide-shaped data, column dataframe corresponds single well plate, row dataframe corresponds single timepoint. Typically, headers contain well names. example, wide-shaped dataframe 96-well plate (, “…” indicates 91 columns A4 - H10, shown). row dataframe corresponds single timepoint. Tidy-shaped tidy-shaped data, single column contains plate reader measurements, unique measurement row. Additional columns specify timepoint, well data comes , design elements. Note , tidy-shaped data, number rows equals number wells times number timepoints. instance, 96 well plate 100 timepoints, 9600 rows. (Yes, ’s lot rows! don’t worry, tidy-shaped data best format downstream analyses.) Tidy-shaped data common number R packages, including ggplot, ’s sometimes called “long” format. want read tidy-shaped data ’s ideal analyses, see: Wickham, Hadley. Tidy data. Journal Statistical Software, vol. 59, 2014.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/import_transform.html","id":"importing-data","dir":"Articles","previous_headings":"","what":"Importing data","title":"Importing and transforming data","text":"’ve determined format data , can begin importing using read_* import_* functions gcplyr. data block-shaped: use import_blockmeasures start next section: Importing block-shaped data data wide-shaped: use read_wides skip Importing wide-shaped data section data already tidy-shaped: use read_tidys skip Importing tidy-shaped data section.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/import_transform.html","id":"importing-block-shaped-data","dir":"Articles","previous_headings":"","what":"Importing block-shaped data","title":"Importing and transforming data","text":"import block-shaped data, use import_blockmeasures function. import_blockmeasures requires list filenames (relative file paths) return wide-shaped data.frame can save R.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/import_transform.html","id":"a-basic-example","dir":"Articles","previous_headings":"Importing block-shaped data","what":"A basic example","title":"Importing and transforming data","text":"’s simple example. First, need create series example block-shaped .csv files. Don’t worry code works. working real growth curve data, files output plate reader. need put file names R vector, ’ve stored file names temp_filenames. ’ve saved files single folder, can easily get vector names using list.files. folder contains files, can specify regular expression pattern limit just want import: ’s one files looks like (values absorbance/optical density): file corresponds reads single plate taken first timepoint. can see second row file contains metadata timepoint plate read read taken. , data starts column headers row 4 rownames column 1. want read files R, simply provide import_blockmeasures vector file names, save result R object (, imported_blockdata). Since data doesn’t start first row column file, simply need specify row/column start using startrow, startcol, endrow, endcol arguments. (import_blockmeasures assumes data starts first row column ends last row column, don’t specify data meets criteria). can see import_blockmeasures created wide-shaped R object containing data reads. also added file names block_name column, can easily track row came file. ’re looking data Excel similar spreadsheet program, ’ll notice columns aren’t nicely numbered. Instead, ’re coded letter. Rather count hand columns data starts ends , just specify column letter import_blockmeasures translate number ! (example don’t specify start column, since data starts first column, just show letter-style functionality).","code":"#This code just creates a series of block-shaped example files #Don't worry about how it works - when working with real growth #curves data, all these files would be created by the plate reader temp_filenames <-    paste(\"Plate1-\",          paste(example_widedata_noiseless$Time %/% 3600,               formatC((example_widedata_noiseless$Time %% 3600) %/% 60,                        width = 2, flag = 0),               formatC((example_widedata_noiseless$Time %% 3600) %% 60,                       width = 2, flag = 0),               sep = \"_\"), \".csv\", sep = \"\") for (i in 1:length(temp_filenames)) {   temp_filenames[i] <- strsplit(temp_filenames[i], split = \"\\\\\\\\\")[[1]][     length(strsplit(temp_filenames[i], split = \"\\\\\\\\\")[[1]])] } for (i in 1:length(temp_filenames)) {   write.table(     cbind(       matrix(c(\"\", \"\", \"\", \"\", \"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\"),               nrow = 12),       rbind(rep(\"\", 12),             matrix(c(\"Time\", example_widedata_noiseless$Time[i], rep(\"\", 10)),                     ncol = 12),             rep(\"\", 12),             matrix(1:12, ncol = 12),             matrix(               example_widedata_noiseless[i, 2:ncol(example_widedata_noiseless)],               ncol = 12))     ),      file = temp_filenames[i], quote = FALSE, row.names = FALSE, sep = \",\",     col.names = FALSE) } #Here we print all the files we're going to read list.files(pattern = \"Plate1.*csv\") #>  [1] \"Plate1-0_00_00.csv\"  \"Plate1-0_15_00.csv\"  \"Plate1-0_30_00.csv\"  #>  [4] \"Plate1-0_45_00.csv\"  \"Plate1-1_00_00.csv\"  \"Plate1-1_15_00.csv\"  #>  [7] \"Plate1-1_30_00.csv\"  \"Plate1-1_45_00.csv\"  \"Plate1-10_00_00.csv\" #> [10] \"Plate1-10_15_00.csv\" \"Plate1-10_30_00.csv\" \"Plate1-10_45_00.csv\" #> [13] \"Plate1-11_00_00.csv\" \"Plate1-11_15_00.csv\" \"Plate1-11_30_00.csv\" #> [16] \"Plate1-11_45_00.csv\" \"Plate1-12_00_00.csv\" \"Plate1-12_15_00.csv\" #> [19] \"Plate1-12_30_00.csv\" \"Plate1-12_45_00.csv\" \"Plate1-13_00_00.csv\" #> [22] \"Plate1-13_15_00.csv\" \"Plate1-13_30_00.csv\" \"Plate1-13_45_00.csv\" #> [25] \"Plate1-14_00_00.csv\" \"Plate1-14_15_00.csv\" \"Plate1-14_30_00.csv\" #> [28] \"Plate1-14_45_00.csv\" \"Plate1-15_00_00.csv\" \"Plate1-15_15_00.csv\" #> [31] \"Plate1-15_30_00.csv\" \"Plate1-15_45_00.csv\" \"Plate1-16_00_00.csv\" #> [34] \"Plate1-16_15_00.csv\" \"Plate1-16_30_00.csv\" \"Plate1-16_45_00.csv\" #> [37] \"Plate1-17_00_00.csv\" \"Plate1-17_15_00.csv\" \"Plate1-17_30_00.csv\" #> [40] \"Plate1-17_45_00.csv\" \"Plate1-18_00_00.csv\" \"Plate1-18_15_00.csv\" #> [43] \"Plate1-18_30_00.csv\" \"Plate1-18_45_00.csv\" \"Plate1-19_00_00.csv\" #> [46] \"Plate1-19_15_00.csv\" \"Plate1-19_30_00.csv\" \"Plate1-19_45_00.csv\" #> [49] \"Plate1-2_00_00.csv\"  \"Plate1-2_15_00.csv\"  \"Plate1-2_30_00.csv\"  #> [52] \"Plate1-2_45_00.csv\"  \"Plate1-20_00_00.csv\" \"Plate1-20_15_00.csv\" #> [55] \"Plate1-20_30_00.csv\" \"Plate1-20_45_00.csv\" \"Plate1-21_00_00.csv\" #> [58] \"Plate1-21_15_00.csv\" \"Plate1-21_30_00.csv\" \"Plate1-21_45_00.csv\" #> [61] \"Plate1-22_00_00.csv\" \"Plate1-22_15_00.csv\" \"Plate1-22_30_00.csv\" #> [64] \"Plate1-22_45_00.csv\" \"Plate1-23_00_00.csv\" \"Plate1-23_15_00.csv\" #> [67] \"Plate1-23_30_00.csv\" \"Plate1-23_45_00.csv\" \"Plate1-24_00_00.csv\" #> [70] \"Plate1-3_00_00.csv\"  \"Plate1-3_15_00.csv\"  \"Plate1-3_30_00.csv\"  #> [73] \"Plate1-3_45_00.csv\"  \"Plate1-4_00_00.csv\"  \"Plate1-4_15_00.csv\"  #> [76] \"Plate1-4_30_00.csv\"  \"Plate1-4_45_00.csv\"  \"Plate1-5_00_00.csv\"  #> [79] \"Plate1-5_15_00.csv\"  \"Plate1-5_30_00.csv\"  \"Plate1-5_45_00.csv\"  #> [82] \"Plate1-6_00_00.csv\"  \"Plate1-6_15_00.csv\"  \"Plate1-6_30_00.csv\"  #> [85] \"Plate1-6_45_00.csv\"  \"Plate1-7_00_00.csv\"  \"Plate1-7_15_00.csv\"  #> [88] \"Plate1-7_30_00.csv\"  \"Plate1-7_45_00.csv\"  \"Plate1-8_00_00.csv\"  #> [91] \"Plate1-8_15_00.csv\"  \"Plate1-8_30_00.csv\"  \"Plate1-8_45_00.csv\"  #> [94] \"Plate1-9_00_00.csv\"  \"Plate1-9_15_00.csv\"  \"Plate1-9_30_00.csv\"  #> [97] \"Plate1-9_45_00.csv\"  #Here we save them to the temp_filenames variable temp_filenames <- list.files(pattern = \"Plate1.*csv\") print_df(read.csv(temp_filenames[1], header = FALSE, colClasses = \"character\")) #>                                                                           #>    Time     0                                                             #>                                                                           #>       1     2     3     4     5     6     7     8     9    10    11    12 #> A 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 #> B 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 #> C 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 #> D 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 #> E 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 #> F 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 #> G 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 #> H 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 #Now let's read it with import_blockmeasures imported_blockdata <- import_blockmeasures(   files = temp_filenames, startrow = 4)  head(imported_blockdata, c(6, 8)) #>       block_name    A1    A2    A3    A4    A5    A6    A7 #> 1 Plate1-0_00_00 0.002 0.002 0.002 0.002 0.002 0.002 0.002 #> 2 Plate1-0_15_00 0.002 0.002 0.002 0.002 0.002 0.002 0.002 #> 3 Plate1-0_30_00 0.002 0.002 0.002 0.002 0.002 0.002 0.002 #> 4 Plate1-0_45_00 0.002 0.002 0.002 0.002 0.002 0.002 0.002 #> 5 Plate1-1_00_00 0.002 0.002 0.002 0.002 0.002 0.002 0.002 #> 6 Plate1-1_15_00 0.002 0.003 0.002 0.003 0.003 0.002 0.002 #We can specify rows or columns by Excel-style letters too imported_blockdata <- import_blockmeasures(   files = temp_filenames,   startrow = 4, startcol = \"A\")"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/import_transform.html","id":"specifying-metadata","dir":"Articles","previous_headings":"Importing block-shaped data","what":"Specifying metadata","title":"Importing and transforming data","text":"Sometimes, input files information want import ’s included main block data. instance, block-shaped data timepoint nearly always specified somewhere input file. import_blockmeasures can include information well via metadata argument. example, let’s return -recent example files: files, timepoint information located 2nd row 3rd column. ’s specify metadata import_blockmeasures command: can see metadata specified added column output data.frame. specifying metadata, metadata argument must list named vectors. vector two elements specifying location metadata input files: first element row, second element column. just like can specify startrow, startcol, etc. Excel-style lettering, location metadata can also specified Excel-style lettering.","code":"print_df(read.csv(temp_filenames[1], header = FALSE, colClasses = \"character\")) #>                                                                           #>    Time     0                                                             #>                                                                           #>       1     2     3     4     5     6     7     8     9    10    11    12 #> A 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 #> B 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 #> C 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 #> D 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 #> E 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 #> F 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 #> G 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 #> H 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 #Reading the blockcurves files with metadata included imported_blockdata <- import_blockmeasures(   files = temp_filenames,   startrow = 4,   metadata = list(\"time\" = c(2, 3)))  head(imported_blockdata, c(6, 8)) #>       block_name time    A1    A2    A3    A4    A5    A6 #> 1 Plate1-0_00_00    0 0.002 0.002 0.002 0.002 0.002 0.002 #> 2 Plate1-0_15_00  900 0.002 0.002 0.002 0.002 0.002 0.002 #> 3 Plate1-0_30_00 1800 0.002 0.002 0.002 0.002 0.002 0.002 #> 4 Plate1-0_45_00 2700 0.002 0.002 0.002 0.002 0.002 0.002 #> 5 Plate1-1_00_00 3600 0.002 0.002 0.002 0.002 0.002 0.002 #> 6 Plate1-1_15_00 4500 0.002 0.003 0.002 0.003 0.003 0.002 #Reading the blockcurves files with metadata included imported_blockdata <- import_blockmeasures(   files = temp_filenames,   startrow = 4,   metadata = list(\"time\" = c(2, \"C\")))"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/import_transform.html","id":"reading-multiple-blocks-from-a-single-file","dir":"Articles","previous_headings":"Importing block-shaped data","what":"Reading multiple blocks from a single file","title":"Importing and transforming data","text":"import_blockmeasures can also import multiple blocks single file, plate readers may output. case, simply specify vector rows columns define location block within file. First, let’s create example file. Don’t worry code works, normally file created plate reader. Let’s take look file looks like: can see first block metadata , block data . ’s empty row next block starts. fact, look whole file, ’ll notice blocks go column 1 (“” Excel) column 13 (“M” Excel), start rows 3, 15, 27, 39, etc, end rows 11, 23, 35, 47, etc. look file, can also see last block starts row 1155 ends row 1163. Let’s read information using import_blockmeasures (example don’t specify start column, since data starts first column, explicit): ’ve used built-R function seq generate full vector startrows endrows. take look, can see ’s read successfully: Now let’s add metadata. ’re reading single file, need specify metadata slightly differently. Instead metadata single vector c(row,column) location, ’s going list two vectors, one row numbers, one column numbers. Going back file, can see time block saved second column, rows 2, 14, 26, 38, … 1154. now take look resulting object, can see time metadata incorporated.","code":"#This code just creates an example file with multiple blocks #Don't worry about how it works - when working with real growth #curves data, this would be created by the plate reader write_blocks(read_blocks(files = temp_filenames,                          startrow = 4,                          metadata = list(\"time\" = c(2, \"C\"))),              file = \"blocks_single.csv\",              output_format = \"single\",              block_name_location = \"file\") print_df(head(read.csv(\"blocks_single.csv\", header = FALSE,                         colClasses = \"character\"),               c(20, 8))) #> block_name Plate1-0_00_00                                     #>       time              0                                     #>                         1     2     3     4     5     6     7 #>          A          0.002 0.002 0.002 0.002 0.002 0.002 0.002 #>          B          0.002 0.002 0.002 0.002 0.002 0.002 0.002 #>          C          0.002 0.002 0.002 0.002 0.002 0.002 0.002 #>          D          0.002 0.002 0.002 0.002 0.002 0.002 0.002 #>          E          0.002 0.002 0.002 0.002 0.002 0.002 0.002 #>          F          0.002 0.002 0.002 0.002 0.002 0.002 0.002 #>          G          0.002 0.002 0.002 0.002 0.002 0.002 0.002 #>          H          0.002 0.002 0.002 0.002 0.002 0.002 0.002 #>                                                               #> block_name Plate1-0_15_00                                     #>       time            900                                     #>                         1     2     3     4     5     6     7 #>          A          0.002 0.002 0.002 0.002 0.002 0.002 0.002 #>          B          0.002 0.002 0.002 0.002 0.002 0.002 0.002 #>          C          0.002 0.002 0.002 0.002 0.002 0.002 0.002 #>          D          0.002 0.002 0.002 0.002 0.002 0.002 0.002 #>          E          0.002 0.002 0.002 0.002 0.002 0.002 0.002 imported_blockdata <- import_blockmeasures(   \"blocks_single.csv\",   startrow = seq(from = 3, to = 1155, by = 12),   endrow = seq(from = 11, to = 1163, by = 12),   startcol = 1, endcol = 13) head(imported_blockdata, c(6, 8)) #>      block_name    A1    A2    A3    A4    A5    A6    A7 #> 1 blocks_single 0.002 0.002 0.002 0.002 0.002 0.002 0.002 #> 2 blocks_single 0.002 0.002 0.002 0.002 0.002 0.002 0.002 #> 3 blocks_single 0.002 0.002 0.002 0.002 0.002 0.002 0.002 #> 4 blocks_single 0.002 0.002 0.002 0.002 0.002 0.002 0.002 #> 5 blocks_single 0.002 0.002 0.002 0.002 0.002 0.002 0.002 #> 6 blocks_single 0.002 0.003 0.002 0.003 0.003 0.002 0.002 imported_blockdata <- import_blockmeasures(   \"blocks_single.csv\",   startrow = seq(from = 3, to = 1155, by = 12),   endrow = seq(from = 11, to = 1163, by = 12),   startcol = 1, endcol = 13,   metadata = list(\"time\" = list(seq(from = 2, to = 1154, by = 12), 2))) head(imported_blockdata, c(6, 8)) #>      block_name time    A1    A2    A3    A4    A5    A6 #> 1 blocks_single    0 0.002 0.002 0.002 0.002 0.002 0.002 #> 2 blocks_single  900 0.002 0.002 0.002 0.002 0.002 0.002 #> 3 blocks_single 1800 0.002 0.002 0.002 0.002 0.002 0.002 #> 4 blocks_single 2700 0.002 0.002 0.002 0.002 0.002 0.002 #> 5 blocks_single 3600 0.002 0.002 0.002 0.002 0.002 0.002 #> 6 blocks_single 4500 0.002 0.003 0.002 0.003 0.003 0.002"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/import_transform.html","id":"notes-for-more-advanced-use","dir":"Articles","previous_headings":"Importing block-shaped data","what":"Notes for more advanced use","title":"Importing and transforming data","text":"Note import_blockmeasures essentially wrapper function calls read_blocks, uninterleave, trans_block_to_wide. arguments functions can passed import_blockmeasures. find needing even control process importing block-shaped measures files, functions available users call . can run steps manually, first reading read_blocks, separating plates needed uninterleave, transforming wide trans_block_to_wide.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/import_transform.html","id":"what-to-do-next","dir":"Articles","previous_headings":"Importing block-shaped data","what":"What to do next","title":"Importing and transforming data","text":"Now ’ve imported block-shaped data, ’ll need transform later analyses. Jump directly Transforming data section.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/import_transform.html","id":"importing-wide-shaped-data","dir":"Articles","previous_headings":"","what":"Importing wide-shaped data","title":"Importing and transforming data","text":"import wide-shaped data, use read_wides function. read_wides requires filename (vector filenames, relative file paths) return data.frame (list data.frames) can save R.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/import_transform.html","id":"a-basic-example-1","dir":"Articles","previous_headings":"Importing wide-shaped data","what":"A basic example","title":"Importing and transforming data","text":"’s simple example. First, need create example wide-shaped .csv file. Don’t worry code works. working real growth curve data, files output plate reader. need know file name(s) put R code. example, file name widedata.csv. ’s start file looks like (values absorbance/optical density): file contains reads single plate taken across timepoints. can see first two rows contain metadata saved plate reader, like name experiment date experiment. , can see data starts 5th row header. first column contains timepoint information, subsequent column corresponds well plate. want read file R, simply provide read_wides file name, save result R object (, imported_widedata). Since data doesn’t start first row column file, simply need specify row/column start using startrow, startcol, endrow, endcol arguments. (read_wides assumes data starts first row column ends last row column, don’t specify data meets criteria. Also note header = TRUE default`). resulting data.frame looks like : Note read_wides automatically saves filename data imported first column output data.frame. done ensure later , data.frames multiple plates can combined without fear losing identity plate. ’re looking data Excel similar spreadsheet program, ’ll notice columns aren’t nicely numbered. Instead, ’re coded letter. Rather count hand columns data starts ends , just specify column letter read_wides translate number ! (example don’t specify start column, since data starts first column, just show letter-style functionality). Note multiple files ’d like read , can directly single read_wides command. case, read_wides return list containing data.frames:","code":"#This code just creates a wide-shaped example file where the data doesn't #start on the first row. #Don't worry about how it works - when working with real growth #curves data, this file would be created by the plate reader temp_example_widedata <- example_widedata_noiseless colnames(temp_example_widedata) <- paste(\"V\", 1:ncol(temp_example_widedata),                                          sep = \"\") modified_example_widedata <-   rbind(     as.data.frame(matrix(\"\", nrow = 4, ncol = ncol(example_widedata_noiseless))),     colnames(example_widedata_noiseless),     temp_example_widedata) modified_example_widedata[1:2, 1:2] <-    c(\"Experiment name\", \"Start date\", \"Experiment_1\", as.character(Sys.Date()))  write.table(modified_example_widedata, file = \"widedata.csv\",            row.names = FALSE, col.names = FALSE, sep = \",\") write.table(modified_example_widedata, file = \"widedata2.csv\",            row.names = FALSE, col.names = FALSE, sep = \",\") #Let's take a peek at what this file looks like print_df(head(read.csv(\"widedata.csv\", header = FALSE,                         colClasses = \"character\"),                c(10, 10))) #> Experiment name Experiment_1                                                 #>      Start date   2023-01-30                                                 #>                                                                              #>                                                                              #>            Time           A1    B1    C1    D1    E1    F1    G1    H1    A2 #>               0        0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 #>             900        0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 #>            1800        0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 #>            2700        0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 #>            3600        0.002 0.002 0.002 0.003 0.003 0.002 0.002 0.003 0.002 imported_widedata <- read_wides(files = \"widedata.csv\", startrow = 5) head(imported_widedata, c(6, 10)) #>        file Time    A1    B1    C1    D1    E1    F1    G1    H1 #> 6  widedata    0 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 #> 7  widedata  900 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 #> 8  widedata 1800 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 #> 9  widedata 2700 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 #> 10 widedata 3600 0.002 0.002 0.002 0.003 0.003 0.002 0.002 0.003 #> 11 widedata 4500 0.002 0.003 0.002 0.003 0.003 0.002 0.003 0.003 imported_widedata <- read_wides(files = \"widedata.csv\",                                 startrow = 5, startcol = \"A\") #If we had multiple wide-shaped data files to import imported_widedata <- read_wides(files = c(\"widedata.csv\", \"widedata2.csv\"))"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/import_transform.html","id":"specifying-metadata-1","dir":"Articles","previous_headings":"Importing wide-shaped data","what":"Specifying metadata","title":"Importing and transforming data","text":"Sometimes, input files information want import ’s included main block data. instance, many readers output information like experiment name date header file. read_wides can include information well via metadata argument. metadata argument list named vectors. vector length 2, first entry specifying row second entry specifying column metadata located. example, previous example files, experiment name located 2nd row, 2nd column, start date located 3rd row, 2nd column. ’s specify metadata: just like can specify startrow, startcol, etc. Excel-style lettering, location metadata can also specified Excel-style lettering.","code":"imported_widedata <- read_wides(files = \"widedata.csv\",                                 startrow = 5,                                 metadata = list(\"experiment_name\" = c(1, 2),                                                 \"start_date\" = c(2, 2))) head(imported_widedata, c(6, 8)) #>        file experiment_name start_date Time    A1    B1    C1    D1 #> 6  widedata    Experiment_1 2023-01-30    0 0.002 0.002 0.002 0.002 #> 7  widedata    Experiment_1 2023-01-30  900 0.002 0.002 0.002 0.002 #> 8  widedata    Experiment_1 2023-01-30 1800 0.002 0.002 0.002 0.002 #> 9  widedata    Experiment_1 2023-01-30 2700 0.002 0.002 0.002 0.002 #> 10 widedata    Experiment_1 2023-01-30 3600 0.002 0.002 0.002 0.003 #> 11 widedata    Experiment_1 2023-01-30 4500 0.002 0.003 0.002 0.003 imported_widedata <- read_wides(files = \"widedata.csv\",                                 startrow = 5,                                 metadata = list(\"experiment_name\" = c(1, \"B\"),                                                 \"start_date\" = c(2, \"B\")))"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/import_transform.html","id":"reading-multiple-wides-from-a-single-file","dir":"Articles","previous_headings":"Importing wide-shaped data","what":"Reading multiple wides from a single file","title":"Importing and transforming data","text":"rare case multiple wide-shaped datasets saved single file, read_wides can import well. Refer earlier section Reading multiple blocks single file, since syntax operations read_wides import_blockmeasures.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/import_transform.html","id":"what-to-do-next-1","dir":"Articles","previous_headings":"Importing wide-shaped data","what":"What to do next","title":"Importing and transforming data","text":"Now ’ve imported wide-shaped data, ’ll need transform later analyses. Continue Transforming data section.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/import_transform.html","id":"importing-tidy-shaped-data","dir":"Articles","previous_headings":"","what":"Importing tidy-shaped data","title":"Importing and transforming data","text":"import tidy-shaped data, use built-R functions like read.table. However, need options, can use gcplyr function read_tidys. Unlike built-option, read_tidys can import multiple tidy-shaped files , can add filename column resulting data.frame, can handle files tidy-shaped information doesn’t start first row column. read_tidys requires filename (vector filenames, relative file paths) return data.frame (list data.frames) can save R. ’ve read tidy-shaped data, won’t need transform , can skip ’s next? section.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/import_transform.html","id":"transforming-data","dir":"Articles","previous_headings":"","what":"Transforming data","title":"Importing and transforming data","text":"Now ’ve gotten data R environment, need transform can analyses. reiterate, necessary plate readers generate growth curve data outputs block-shaped wide-shaped files, tidy-shaped data.frames best shape analyses required gcplyr. can transform data.frames using trans_* functions gcplyr.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/import_transform.html","id":"transforming-from-wide-shaped-to-tidy-shaped","dir":"Articles","previous_headings":"Transforming data","what":"Transforming from wide-shaped to tidy-shaped","title":"Importing and transforming data","text":"data ’ve read theRenvironment wide-shaped (’ve gotten wide-shaped data transforming originally block-shaped data), ’ll transform tidy-shaped using trans_wide_to_tidy. First, need provide trans_wide_to_tidy theRobject created read_wides trans_block_to_wide. , specify one : * columns data (spectrophotometric measures) via data_cols * columns non-data (e.g. time information) via id_cols","code":"imported_blocks_now_tidy <- trans_wide_to_tidy(   wides = imported_blockdata,   id_cols = c(\"block_name\", \"time\"))  imported_wides_now_tidy <- trans_wide_to_tidy(   wides = imported_widedata,   id_cols = c(\"file\", \"experiment_name\", \"start_date\", \"Time\"))  print(head(imported_blocks_now_tidy), row.names = FALSE) #>     block_name time Well Measurements #>  blocks_single    0   A1        0.002 #>  blocks_single    0   A2        0.002 #>  blocks_single    0   A3        0.002 #>  blocks_single    0   A4        0.002 #>  blocks_single    0   A5        0.002 #>  blocks_single    0   A6        0.002"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/import_transform.html","id":"whats-next","dir":"Articles","previous_headings":"","what":"What’s next?","title":"Importing and transforming data","text":"Now ’ve imported transformed data tidy-shaped, likely want incorporate design information went well (plate). Alternatively, ’d like skip step now, can go directly pre-processing plotting data Introduction: vignette(\"gcplyr\") Importing transforming data: vignette(\"import_transform\") Incorporating design information: vignette(\"incorporate_designs\") Pre-processing plotting data: vignette(\"preprocess_plot\") Processing data: vignette(\"process\") Analyzing data: vignette(\"analyze\") Dealing noise: vignette(\"noise\") Statistics, merging data, resources: vignette(\"conclusion\")","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/incorporate_designs.html","id":"where-are-we-so-far","dir":"Articles","previous_headings":"","what":"Where are we so far?","title":"Incorporating design information","text":"Introduction: vignette(\"gcplyr\") Importing transforming data: vignette(\"import_transform\") Incorporating design information: vignette(\"incorporate_designs\") Pre-processing plotting data: vignette(\"preprocess_plot\") Processing data: vignette(\"process\") Analyzing data: vignette(\"analyze\") Dealing noise: vignette(\"noise\") Statistics, merging data, resources: vignette(\"conclusion\") far, ’ve imported transformed measures data R. Now ’re going address incorporate design information went well (plate). haven’t already, load necessary packages.","code":"library(gcplyr) #> ##  #> ## gcplyr (Version 0.12.3, Build Date: 2023-01-30) #> ## See http://github.com/mikeblazanin/gcplyr for additional documentation #> ## Please cite software as: #> ##   Blazanin, Michael. 2023. 'gcplyr: manipulate and analyze growth #> ##   curve data.' R package version 0.12.3 #> ##"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/incorporate_designs.html","id":"including-design-elements","dir":"Articles","previous_headings":"","what":"Including design elements","title":"Incorporating design information","text":"analysis growth curve data, often want incorporate information experimental design. example, bacteria present wells, wells received certain treatments. gcplyr enables incorporation design elements two ways: Design elements can imported files Design elements can generated programmatically using make_design","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/incorporate_designs.html","id":"reading-design-elements-from-files","dir":"Articles","previous_headings":"","what":"Reading design elements from files","title":"Incorporating design information","text":"Users two options read design elements files, depending shape design files created: design files block-shaped, can read import_blockdesigns design files tidy-shaped, can simply read read_tidys","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/incorporate_designs.html","id":"importing-block-shaped-design-files","dir":"Articles","previous_headings":"Reading design elements from files","what":"Importing block-shaped design files","title":"Incorporating design information","text":"import block-shaped design files, can use import_blockdesigns function, return tidy-shaped designs data frame (list data frames). import_blockdesigns requires list filenames (relative file paths) return data.frame (list data frames) tidy format can save R. ’s right, reads block-shaped designs returns tidy-shaped data frame!","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/incorporate_designs.html","id":"a-basic-example","dir":"Articles","previous_headings":"Reading design elements from files > Importing block-shaped design files","what":"A basic example","title":"Incorporating design information","text":"Let’s take look example. First, need create example file sake tutorial. Don’t worry code works, just imagine ’ve created file Excel. Now let’s take look file looks like: can see design Treatment 1 left-hand side plate (wells columns 1 6), Treatment 2 right-hand side plate (wells columns 7 12). Let’s import design using import_blockdesigns. Since block contains treatment numbers, ’ve given block_names “Treatment_numbers”. block_names provided, import_blockdesigns automatically name according file name.","code":"write.csv(   file = \"mydesign.csv\",   x = matrix(rep(c(\"Tr1\", \"Tr2\"), each = 48),              nrow = 8, ncol = 12, dimnames = list(LETTERS[1:8], 1:12))) print_df(read.csv(\"mydesign.csv\", header = FALSE, colClasses = \"character\")) #>     1   2   3   4   5   6   7   8   9  10  11  12 #> A Tr1 Tr1 Tr1 Tr1 Tr1 Tr1 Tr2 Tr2 Tr2 Tr2 Tr2 Tr2 #> B Tr1 Tr1 Tr1 Tr1 Tr1 Tr1 Tr2 Tr2 Tr2 Tr2 Tr2 Tr2 #> C Tr1 Tr1 Tr1 Tr1 Tr1 Tr1 Tr2 Tr2 Tr2 Tr2 Tr2 Tr2 #> D Tr1 Tr1 Tr1 Tr1 Tr1 Tr1 Tr2 Tr2 Tr2 Tr2 Tr2 Tr2 #> E Tr1 Tr1 Tr1 Tr1 Tr1 Tr1 Tr2 Tr2 Tr2 Tr2 Tr2 Tr2 #> F Tr1 Tr1 Tr1 Tr1 Tr1 Tr1 Tr2 Tr2 Tr2 Tr2 Tr2 Tr2 #> G Tr1 Tr1 Tr1 Tr1 Tr1 Tr1 Tr2 Tr2 Tr2 Tr2 Tr2 Tr2 #> H Tr1 Tr1 Tr1 Tr1 Tr1 Tr1 Tr2 Tr2 Tr2 Tr2 Tr2 Tr2 my_design <- import_blockdesigns(files = \"mydesign.csv\",                                   block_names = \"Treatment_numbers\") head(my_design, 20) #>    Well Treatment_numbers #> 1    A1               Tr1 #> 2    A2               Tr1 #> 3    A3               Tr1 #> 4    A4               Tr1 #> 5    A5               Tr1 #> 6    A6               Tr1 #> 7    A7               Tr2 #> 8    A8               Tr2 #> 9    A9               Tr2 #> 10  A10               Tr2 #> 11  A11               Tr2 #> 12  A12               Tr2 #> 13   B1               Tr1 #> 14   B2               Tr1 #> 15   B3               Tr1 #> 16   B4               Tr1 #> 17   B5               Tr1 #> 18   B6               Tr1 #> 19   B7               Tr2 #> 20   B8               Tr2"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/incorporate_designs.html","id":"importing-multiple-block-shaped-design-elements","dir":"Articles","previous_headings":"Reading design elements from files > Importing block-shaped design files","what":"Importing multiple block-shaped design elements","title":"Incorporating design information","text":"multiple design components? instance, several different bacterial strains several different treatments? case, simply save design component separate file, import one go import_blockdesigns. First, let’s create another example designs file. , don’t worry code works, just imagine ’ve created file Excel. Now let’s take look file looks like: can see design Strain first two rows, Strain B next two rows, . Let’s now import designs using import_blockdesigns. Since two blocks contain treatment numbers strain letters, ’ve given block_names c(\"Treatment_numbers\", \"Strain_letters\"). block_names provided, import_blockdesigns automatically name according file name.","code":"write.csv(   file = \"mydesign2.csv\",   x = matrix(rep(c(\"StrA\", \"StrB\", \"StrC\", \"StrD\"), each = 24),              nrow = 8, ncol = 12, dimnames = list(LETTERS[1:8], 1:12),              byrow = TRUE)) print_df(read.csv(\"mydesign2.csv\", header = FALSE, colClasses = \"character\")) #>      1    2    3    4    5    6    7    8    9   10   11   12 #> A StrA StrA StrA StrA StrA StrA StrA StrA StrA StrA StrA StrA #> B StrA StrA StrA StrA StrA StrA StrA StrA StrA StrA StrA StrA #> C StrB StrB StrB StrB StrB StrB StrB StrB StrB StrB StrB StrB #> D StrB StrB StrB StrB StrB StrB StrB StrB StrB StrB StrB StrB #> E StrC StrC StrC StrC StrC StrC StrC StrC StrC StrC StrC StrC #> F StrC StrC StrC StrC StrC StrC StrC StrC StrC StrC StrC StrC #> G StrD StrD StrD StrD StrD StrD StrD StrD StrD StrD StrD StrD #> H StrD StrD StrD StrD StrD StrD StrD StrD StrD StrD StrD StrD my_design <-    import_blockdesigns(files = c(\"mydesign.csv\", \"mydesign2.csv\"),                        block_names = c(\"Treatment_numbers\", \"Strain_letters\")) head(my_design, 20) #>    Well Treatment_numbers Strain_letters #> 1    A1               Tr1           StrA #> 2    A2               Tr1           StrA #> 3    A3               Tr1           StrA #> 4    A4               Tr1           StrA #> 5    A5               Tr1           StrA #> 6    A6               Tr1           StrA #> 7    A7               Tr2           StrA #> 8    A8               Tr2           StrA #> 9    A9               Tr2           StrA #> 10  A10               Tr2           StrA #> 11  A11               Tr2           StrA #> 12  A12               Tr2           StrA #> 13   B1               Tr1           StrA #> 14   B2               Tr1           StrA #> 15   B3               Tr1           StrA #> 16   B4               Tr1           StrA #> 17   B5               Tr1           StrA #> 18   B6               Tr1           StrA #> 19   B7               Tr2           StrA #> 20   B8               Tr2           StrA"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/incorporate_designs.html","id":"notes-for-more-advanced-use","dir":"Articles","previous_headings":"Reading design elements from files > Importing block-shaped design files","what":"Notes for more advanced use","title":"Incorporating design information","text":"Note import_blockdesigns essentially wrapper function calls read_blocks, paste_blocks, trans_block_to_wide, trans_wide_to_tidy, separate_tidys. arguments functions can passed import_blockdesigns. instance, design files start first row first column, can specify startrow startcol just like using read_blocks. designs located sheet first sheet, can specify sheet. Additionally, ’ve already pasted together design elements , specify string used separator via sep argument (gets passed separate_tidys). find needing even control process importing block-shaped design files, functions available users call . can run steps manually, first reading read_blocks, pasting needed paste_blocks, transforming tidy trans_block_to_wide trans_wide_to_tidy, finally separating design elements separate_tidys.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/incorporate_designs.html","id":"importing-tidy-shaped-design-files","dir":"Articles","previous_headings":"Reading design elements from files","what":"Importing tidy-shaped design files","title":"Incorporating design information","text":"Just like measures data, import tidy-shaped designs use built-inRfunctions like read.table. However, need options, can use gcplyr function read_tidys. Unlike built-option, read_tidys can import multiple tidy-shaped files , can add filename column resulting data.frame, can handle files tidy-shaped information doesn’t start first row column. read_tidys requires filename (vector filenames, relative file paths) return data.frame (list data.frames) can save R. design elements read R environment, won’t need transform . can skip learning merge data Merging spectrophotometric design data section.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/incorporate_designs.html","id":"generating-designs-in-r","dir":"Articles","previous_headings":"","what":"Generating designs in R","title":"Incorporating design information","text":"’d rather make design data.frames R, gcplyr helper function makes easy : make_design. make_design can create: block-shaped data.frames design information (e.g. outputting files) tidy-shaped data.frames design information (e.g. merging tidy-shaped plate reader data)","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/incorporate_designs.html","id":"an-example-with-a-single-design","dir":"Articles","previous_headings":"Generating designs in R","what":"An example with a single design","title":"Incorporating design information","text":"Let’s start simple example demonstrating basic use make_design (’ll move complicated designs afterwards). example, let’s imagine growth curve experiment 96 well plate (12 columns 8 rows) different bacterial strain row, first last columns first last rows left empty. Typing design like manually spreadsheet can tedious. generating design data.frame using make_design easier. make_design first needs general information, like nrows ncols plate, output_format ’d like (typically blocks tidy). , different design component, make_design needs five different pieces information: vector containing possible values vector specifying rows values applied vector specifying columns values applied string vector pattern values Boolean whether pattern filled byrow (defaults TRUE) example , can see: possible values c(\"Strain 1\", \"Strain 2\", \"Strain 3\", \"Strain 4\", \"Strain 5\", \"Strain 6\") rows values applied rows 2:7 columns values applied columns 2:11 pattern values filled \"123456\" values filled row, filled column entire list passed name (, “Bacteria”), used resulting column header. result look like? can see make_design created block-shaped data.frame containing design elements requested, attached metadata containing block_name (useful later transformation tidy-shaped, ’re generating multiple design elements).","code":"my_design_blk <- make_design(   output_format = \"blocks\",   nrows = 8, ncols = 12,    Bacteria = list(c(\"Str1\", \"Str2\", \"Str3\",                      \"Str4\", \"Str5\", \"Str6\"),                   2:7,                   2:11,                   \"123456\",                   FALSE) ) my_design_blk #> [[1]] #> [[1]]$data #>   1  2      3      4      5      6      7      8      9      10     11     12 #> A NA NA     NA     NA     NA     NA     NA     NA     NA     NA     NA     NA #> B NA \"Str1\" \"Str1\" \"Str1\" \"Str1\" \"Str1\" \"Str1\" \"Str1\" \"Str1\" \"Str1\" \"Str1\" NA #> C NA \"Str2\" \"Str2\" \"Str2\" \"Str2\" \"Str2\" \"Str2\" \"Str2\" \"Str2\" \"Str2\" \"Str2\" NA #> D NA \"Str3\" \"Str3\" \"Str3\" \"Str3\" \"Str3\" \"Str3\" \"Str3\" \"Str3\" \"Str3\" \"Str3\" NA #> E NA \"Str4\" \"Str4\" \"Str4\" \"Str4\" \"Str4\" \"Str4\" \"Str4\" \"Str4\" \"Str4\" \"Str4\" NA #> F NA \"Str5\" \"Str5\" \"Str5\" \"Str5\" \"Str5\" \"Str5\" \"Str5\" \"Str5\" \"Str5\" \"Str5\" NA #> G NA \"Str6\" \"Str6\" \"Str6\" \"Str6\" \"Str6\" \"Str6\" \"Str6\" \"Str6\" \"Str6\" \"Str6\" NA #> H NA NA     NA     NA     NA     NA     NA     NA     NA     NA     NA     NA #>  #> [[1]]$metadata #> block_name  #> \"Bacteria\""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/incorporate_designs.html","id":"a-few-notes-on-the-pattern","dir":"Articles","previous_headings":"Generating designs in R","what":"A few notes on the pattern","title":"Incorporating design information","text":"One important elements every argument passed make_design string vector specifying pattern values. Oftentimes, convenient simply use single-characters correspond values. default behavior make_design, splits pattern string individual characters, uses characters correspond indices values provided. instance, example , used numbers 1 6 correspond values \"Strain 1\", \"Strain 2\", \"Strain 3\", \"Strain 4\", \"Strain 5\", \"Strain 6\". ’s important note “0” character reserved NA values. example later. 9 values, can use letters (uppercase /lowercase). case, just specify lookup_tbl_start function knows letter ’re using 1 index. lookup_tbl_start specified, default count numbers first, uppercase letters, lowercase letters. instance, previous example, equivalently done: done: Alternatively, can use separating character like comma delineate indices. order use multicharacter indices (like numbers one digit), indices numeric. find easier input pattern vector rather string needs split, can . Just like passing string, ’re using numbers, uppercase letters, lowercase letters indices, make sure specify different lookup_tbl_start:","code":"my_design_blk <- make_design(   output_format = \"blocks\",   nrows = 8, ncols = 12, lookup_tbl_start = \"A\",   Bacteria = list(     c(\"Str1\", \"Str2\", \"Str3\", \"Str4\", \"Str5\", \"Str6\"),     2:7,     2:11,     \"ABCDEF\",     FALSE) ) my_design_blk <- make_design(   output_format = \"blocks\",   nrows = 8, ncols = 12, lookup_tbl_start = \"a\",   Bacteria = list(     c(\"Str1\", \"Str2\", \"Str3\", \"Str4\", \"Str5\", \"Str6\"),     2:7,     2:11,     \"abcdef\",     FALSE) ) my_design_blk <- make_design(   output_format = \"blocks\",   nrows = 8, ncols = 12, pattern_split = \",\",   Bacteria = list(     c(\"Str1\", \"Str2\", \"Str3\", \"Str4\", \"Str5\", \"Str6\"),     2:7,     2:11,     \"1,2,3,4,5,6\",     FALSE) ) my_design_blk <- make_design(   output_format = \"blocks\",   nrows = 8, ncols = 12,   Bacteria = list(     c(\"Str1\", \"Str2\", \"Str3\", \"Str4\", \"Str5\", \"Str6\"),     2:7,     2:11,     c(1,2,3,4,5,6),     FALSE) )"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/incorporate_designs.html","id":"continuing-with-the-example-multiple-designs","dir":"Articles","previous_headings":"Generating designs in R","what":"Continuing with the example: multiple designs","title":"Incorporating design information","text":"Now let’s return example growth curve experiment. Imagine now, addition different bacterial strain row, also different media column plate. can generate bacterial strain design media design simply adding additional argument make_design call. can see two blocks created, one bacterial strains, one media. Now, imagine experiment discover Bacterial Strain 4 Media #6 contaminated, ’d like exclude analyses marking NA design. can simply modify pattern string, placing 0 anywhere like NA filled . Now can see design easily modified place NA’s wells, can use merging designs data exclude wells analyses. However, real strength make_design limited simple alternating patterns. pattern specified can pattern, make_design replicate sufficient times cover entire set listed wells. gcplyr also includes optional helper function make_design called make_designpattern. make_designpattern just helps reminding user arguments necessary design ensuring ’re correct order. example, following produces data.frame code: far, ’ve using blocks option output_format, ’s easy see design matches ’d intended format. However, merging designs plate reader data, need tidy-shaped. Luckily, ’s need transform , simply change output_format argument option tidy.","code":"my_design_blk <- make_design(   output_format = \"blocks\",   nrows = 8, ncols = 12, lookup_tbl_start = \"a\",   Bacteria = list(c(\"Str1\", \"Str2\", \"Str3\",                      \"Str4\", \"Str5\", \"Str6\"),                   2:7,                   2:11,                   \"abcdef\",                   FALSE),   Media = list(c(\"Med1\", \"Med2\", \"Med3\",                  \"Med4\", \"Med5\", \"Med6\",                  \"Med7\", \"Med8\", \"Med9\",                  \"Med10\", \"Med11\", \"Med12\"),                2:7,                2:11,                \"abcdefghij\")   )  my_design_blk #> [[1]] #> [[1]]$data #>   1  2      3      4      5      6      7      8      9      10     11     12 #> A NA NA     NA     NA     NA     NA     NA     NA     NA     NA     NA     NA #> B NA \"Str1\" \"Str1\" \"Str1\" \"Str1\" \"Str1\" \"Str1\" \"Str1\" \"Str1\" \"Str1\" \"Str1\" NA #> C NA \"Str2\" \"Str2\" \"Str2\" \"Str2\" \"Str2\" \"Str2\" \"Str2\" \"Str2\" \"Str2\" \"Str2\" NA #> D NA \"Str3\" \"Str3\" \"Str3\" \"Str3\" \"Str3\" \"Str3\" \"Str3\" \"Str3\" \"Str3\" \"Str3\" NA #> E NA \"Str4\" \"Str4\" \"Str4\" \"Str4\" \"Str4\" \"Str4\" \"Str4\" \"Str4\" \"Str4\" \"Str4\" NA #> F NA \"Str5\" \"Str5\" \"Str5\" \"Str5\" \"Str5\" \"Str5\" \"Str5\" \"Str5\" \"Str5\" \"Str5\" NA #> G NA \"Str6\" \"Str6\" \"Str6\" \"Str6\" \"Str6\" \"Str6\" \"Str6\" \"Str6\" \"Str6\" \"Str6\" NA #> H NA NA     NA     NA     NA     NA     NA     NA     NA     NA     NA     NA #>  #> [[1]]$metadata #> block_name  #> \"Bacteria\"  #>  #>  #> [[2]] #> [[2]]$data #>   1  2      3      4      5      6      7      8      9      10     11      12 #> A NA NA     NA     NA     NA     NA     NA     NA     NA     NA     NA      NA #> B NA \"Med1\" \"Med2\" \"Med3\" \"Med4\" \"Med5\" \"Med6\" \"Med7\" \"Med8\" \"Med9\" \"Med10\" NA #> C NA \"Med1\" \"Med2\" \"Med3\" \"Med4\" \"Med5\" \"Med6\" \"Med7\" \"Med8\" \"Med9\" \"Med10\" NA #> D NA \"Med1\" \"Med2\" \"Med3\" \"Med4\" \"Med5\" \"Med6\" \"Med7\" \"Med8\" \"Med9\" \"Med10\" NA #> E NA \"Med1\" \"Med2\" \"Med3\" \"Med4\" \"Med5\" \"Med6\" \"Med7\" \"Med8\" \"Med9\" \"Med10\" NA #> F NA \"Med1\" \"Med2\" \"Med3\" \"Med4\" \"Med5\" \"Med6\" \"Med7\" \"Med8\" \"Med9\" \"Med10\" NA #> G NA \"Med1\" \"Med2\" \"Med3\" \"Med4\" \"Med5\" \"Med6\" \"Med7\" \"Med8\" \"Med9\" \"Med10\" NA #> H NA NA     NA     NA     NA     NA     NA     NA     NA     NA     NA      NA #>  #> [[2]]$metadata #> block_name  #>    \"Media\" my_design_blk <- make_design(   output_format = \"blocks\",   nrows = 8, ncols = 12, lookup_tbl_start = \"a\",   Bacteria = list(c(\"Str1\", \"Str2\", \"Str3\",                      \"Str4\", \"Str5\", \"Str6\"),                   2:7,                   2:11,                   \"abc0ef\",                   FALSE),   Media = list(c(\"Med1\", \"Med2\", \"Med3\",                  \"Med4\", \"Med5\", \"Med6\",                  \"Med7\", \"Med8\", \"Med9\",                  \"Med10\", \"Med11\", \"Med12\"),                2:7,                2:11,                \"abcde0ghij\")   )  my_design_blk #> [[1]] #> [[1]]$data #>   1  2      3      4      5      6      7      8      9      10     11     12 #> A NA NA     NA     NA     NA     NA     NA     NA     NA     NA     NA     NA #> B NA \"Str1\" \"Str1\" \"Str1\" \"Str1\" \"Str1\" \"Str1\" \"Str1\" \"Str1\" \"Str1\" \"Str1\" NA #> C NA \"Str2\" \"Str2\" \"Str2\" \"Str2\" \"Str2\" \"Str2\" \"Str2\" \"Str2\" \"Str2\" \"Str2\" NA #> D NA \"Str3\" \"Str3\" \"Str3\" \"Str3\" \"Str3\" \"Str3\" \"Str3\" \"Str3\" \"Str3\" \"Str3\" NA #> E NA NA     NA     NA     NA     NA     NA     NA     NA     NA     NA     NA #> F NA \"Str5\" \"Str5\" \"Str5\" \"Str5\" \"Str5\" \"Str5\" \"Str5\" \"Str5\" \"Str5\" \"Str5\" NA #> G NA \"Str6\" \"Str6\" \"Str6\" \"Str6\" \"Str6\" \"Str6\" \"Str6\" \"Str6\" \"Str6\" \"Str6\" NA #> H NA NA     NA     NA     NA     NA     NA     NA     NA     NA     NA     NA #>  #> [[1]]$metadata #> block_name  #> \"Bacteria\"  #>  #>  #> [[2]] #> [[2]]$data #>   1  2      3      4      5      6      7  8      9      10     11      12 #> A NA NA     NA     NA     NA     NA     NA NA     NA     NA     NA      NA #> B NA \"Med1\" \"Med2\" \"Med3\" \"Med4\" \"Med5\" NA \"Med7\" \"Med8\" \"Med9\" \"Med10\" NA #> C NA \"Med1\" \"Med2\" \"Med3\" \"Med4\" \"Med5\" NA \"Med7\" \"Med8\" \"Med9\" \"Med10\" NA #> D NA \"Med1\" \"Med2\" \"Med3\" \"Med4\" \"Med5\" NA \"Med7\" \"Med8\" \"Med9\" \"Med10\" NA #> E NA \"Med1\" \"Med2\" \"Med3\" \"Med4\" \"Med5\" NA \"Med7\" \"Med8\" \"Med9\" \"Med10\" NA #> F NA \"Med1\" \"Med2\" \"Med3\" \"Med4\" \"Med5\" NA \"Med7\" \"Med8\" \"Med9\" \"Med10\" NA #> G NA \"Med1\" \"Med2\" \"Med3\" \"Med4\" \"Med5\" NA \"Med7\" \"Med8\" \"Med9\" \"Med10\" NA #> H NA NA     NA     NA     NA     NA     NA NA     NA     NA     NA      NA #>  #> [[2]]$metadata #> block_name  #>    \"Media\" my_design_blk <- make_design(   output_format = \"blocks\",   nrows = 8, ncols = 12, lookup_tbl_start = \"a\",   Bacteria = list(c(\"Str1\", \"Str2\"),                   2:7,                   2:11,                   \"abaaabbbab\",                   FALSE),   Media = list(c(\"Med1\", \"Med2\", \"Med3\"),                2:7,                2:11,                \"aabbbc000abc\"))  my_design_blk #> [[1]] #> [[1]]$data #>   1  2      3      4      5      6      7      8      9      10     11     12 #> A NA NA     NA     NA     NA     NA     NA     NA     NA     NA     NA     NA #> B NA \"Str1\" \"Str2\" \"Str1\" \"Str1\" \"Str1\" \"Str1\" \"Str2\" \"Str1\" \"Str1\" \"Str1\" NA #> C NA \"Str2\" \"Str2\" \"Str1\" \"Str2\" \"Str2\" \"Str2\" \"Str2\" \"Str1\" \"Str2\" \"Str2\" NA #> D NA \"Str1\" \"Str1\" \"Str1\" \"Str1\" \"Str2\" \"Str1\" \"Str1\" \"Str1\" \"Str1\" \"Str2\" NA #> E NA \"Str1\" \"Str2\" \"Str2\" \"Str2\" \"Str2\" \"Str1\" \"Str2\" \"Str2\" \"Str2\" \"Str2\" NA #> F NA \"Str1\" \"Str1\" \"Str2\" \"Str1\" \"Str1\" \"Str1\" \"Str1\" \"Str2\" \"Str1\" \"Str1\" NA #> G NA \"Str2\" \"Str2\" \"Str2\" \"Str1\" \"Str2\" \"Str2\" \"Str2\" \"Str2\" \"Str1\" \"Str2\" NA #> H NA NA     NA     NA     NA     NA     NA     NA     NA     NA     NA     NA #>  #> [[1]]$metadata #> block_name  #> \"Bacteria\"  #>  #>  #> [[2]] #> [[2]]$data #>   1  2      3      4      5      6      7      8      9      10     11     12 #> A NA NA     NA     NA     NA     NA     NA     NA     NA     NA     NA     NA #> B NA \"Med1\" \"Med1\" \"Med2\" \"Med2\" \"Med2\" \"Med3\" NA     NA     NA     \"Med1\" NA #> C NA \"Med2\" \"Med3\" \"Med1\" \"Med1\" \"Med2\" \"Med2\" \"Med2\" \"Med3\" NA     NA     NA #> D NA NA     \"Med1\" \"Med2\" \"Med3\" \"Med1\" \"Med1\" \"Med2\" \"Med2\" \"Med2\" \"Med3\" NA #> E NA NA     NA     NA     \"Med1\" \"Med2\" \"Med3\" \"Med1\" \"Med1\" \"Med2\" \"Med2\" NA #> F NA \"Med2\" \"Med3\" NA     NA     NA     \"Med1\" \"Med2\" \"Med3\" \"Med1\" \"Med1\" NA #> G NA \"Med2\" \"Med2\" \"Med2\" \"Med3\" NA     NA     NA     \"Med1\" \"Med2\" \"Med3\" NA #> H NA NA     NA     NA     NA     NA     NA     NA     NA     NA     NA     NA #>  #> [[2]]$metadata #> block_name  #>    \"Media\" my_design_blk <- make_design(   output_format = \"blocks\",   nrows = 8, ncols = 12, lookup_tbl_start = \"a\",   Bacteria = make_designpattern(     values = c(\"Str1\", \"Str2\", \"Str3\",                 \"Str4\", \"Str5\", \"Str6\"),     rows = 2:7, cols = 2:11, pattern = \"abc0ef\",     byrow = FALSE),   Media = make_designpattern(     values = c(\"Med1\", \"Med2\", \"Med3\",                \"Med4\", \"Med5\", \"Med6\",                \"Med7\", \"Med8\", \"Med9\",                \"Med10\", \"Med11\", \"Med12\"),     rows = 2:7, cols = 2:11, pattern = \"abcde0ghij\"))  my_design_blk #> [[1]] #> [[1]]$data #>   1  2      3      4      5      6      7      8      9      10     11     12 #> A NA NA     NA     NA     NA     NA     NA     NA     NA     NA     NA     NA #> B NA \"Str1\" \"Str1\" \"Str1\" \"Str1\" \"Str1\" \"Str1\" \"Str1\" \"Str1\" \"Str1\" \"Str1\" NA #> C NA \"Str2\" \"Str2\" \"Str2\" \"Str2\" \"Str2\" \"Str2\" \"Str2\" \"Str2\" \"Str2\" \"Str2\" NA #> D NA \"Str3\" \"Str3\" \"Str3\" \"Str3\" \"Str3\" \"Str3\" \"Str3\" \"Str3\" \"Str3\" \"Str3\" NA #> E NA NA     NA     NA     NA     NA     NA     NA     NA     NA     NA     NA #> F NA \"Str5\" \"Str5\" \"Str5\" \"Str5\" \"Str5\" \"Str5\" \"Str5\" \"Str5\" \"Str5\" \"Str5\" NA #> G NA \"Str6\" \"Str6\" \"Str6\" \"Str6\" \"Str6\" \"Str6\" \"Str6\" \"Str6\" \"Str6\" \"Str6\" NA #> H NA NA     NA     NA     NA     NA     NA     NA     NA     NA     NA     NA #>  #> [[1]]$metadata #> block_name  #> \"Bacteria\"  #>  #>  #> [[2]] #> [[2]]$data #>   1  2      3      4      5      6      7  8      9      10     11      12 #> A NA NA     NA     NA     NA     NA     NA NA     NA     NA     NA      NA #> B NA \"Med1\" \"Med2\" \"Med3\" \"Med4\" \"Med5\" NA \"Med7\" \"Med8\" \"Med9\" \"Med10\" NA #> C NA \"Med1\" \"Med2\" \"Med3\" \"Med4\" \"Med5\" NA \"Med7\" \"Med8\" \"Med9\" \"Med10\" NA #> D NA \"Med1\" \"Med2\" \"Med3\" \"Med4\" \"Med5\" NA \"Med7\" \"Med8\" \"Med9\" \"Med10\" NA #> E NA \"Med1\" \"Med2\" \"Med3\" \"Med4\" \"Med5\" NA \"Med7\" \"Med8\" \"Med9\" \"Med10\" NA #> F NA \"Med1\" \"Med2\" \"Med3\" \"Med4\" \"Med5\" NA \"Med7\" \"Med8\" \"Med9\" \"Med10\" NA #> G NA \"Med1\" \"Med2\" \"Med3\" \"Med4\" \"Med5\" NA \"Med7\" \"Med8\" \"Med9\" \"Med10\" NA #> H NA NA     NA     NA     NA     NA     NA NA     NA     NA     NA      NA #>  #> [[2]]$metadata #> block_name  #>    \"Media\" my_design_tdy <- make_design(   output_format = \"tidy\",   nrows = 8, ncols = 12, lookup_tbl_start = \"a\",   Bacteria = make_designpattern(     values = c(\"Str1\", \"Str2\", \"Str3\",                 \"Str4\", \"Str5\", \"Str6\"),     rows = 2:7, cols = 2:11, pattern = \"abc0ef\",     byrow = FALSE),   Media = make_designpattern(     values = c(\"Med1\", \"Med2\", \"Med3\",                \"Med4\", \"Med5\", \"Med6\",                \"Med7\", \"Med8\", \"Med9\",                \"Med10\", \"Med11\", \"Med12\"),     rows = 2:7, cols = 2:11, pattern = \"abcde0ghij\"))  head(my_design_tdy, 20) #>    Well Bacteria Media #> 1    A1       NA    NA #> 2    A2       NA    NA #> 3    A3       NA    NA #> 4    A4       NA    NA #> 5    A5       NA    NA #> 6    A6       NA    NA #> 7    A7       NA    NA #> 8    A8       NA    NA #> 9    A9       NA    NA #> 10  A10       NA    NA #> 11  A11       NA    NA #> 12  A12       NA    NA #> 13   B1       NA    NA #> 14   B2     Str1  Med1 #> 15   B3     Str1  Med2 #> 16   B4     Str1  Med3 #> 17   B5     Str1  Med4 #> 18   B6     Str1  Med5 #> 19   B7     Str1    NA #> 20   B8     Str1  Med7"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/incorporate_designs.html","id":"saving-designs-to-files","dir":"Articles","previous_headings":"Generating designs in R","what":"Saving designs to files","title":"Incorporating design information","text":"Often generating designs R make_design, ’ll want save designs files. might human-readable files documenting designs available without opening R. perhaps ’s need post design files, instance Dryad part manuscript submission. ’d like save designs files, can save either tidy-shaped block-shaped. formats can easily read back R gcplyr.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/incorporate_designs.html","id":"saving-tidy-shaped-designs","dir":"Articles","previous_headings":"Generating designs in R > Saving designs to files","what":"Saving tidy-shaped designs","title":"Incorporating design information","text":"design files less human-readable, easier import merge. Additionally, tidy-shaped files often better data repositories, like Dryad. save tidy-shaped designs, simply use built-write.csv function.","code":"#See the previous section where we created my_design_tdy write.csv(x = my_design_tdy, file = \"tidy_design.csv\",           row.names = FALSE)"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/incorporate_designs.html","id":"saving-block-shaped-designs","dir":"Articles","previous_headings":"Generating designs in R > Saving designs to files","what":"Saving block-shaped designs","title":"Incorporating design information","text":"design files human-readable require slightly computational steps import merge. , use gcplyr function write_blocks. Typically, ’ll use write_blocks save files one two formats: multiple - block saved .csv file single - blocks saved single .csv file, empty row ","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/incorporate_designs.html","id":"saving-block-shaped-designs-to-multiple-files","dir":"Articles","previous_headings":"Generating designs in R > Saving designs to files > Saving block-shaped designs","what":"Saving block-shaped designs to multiple files","title":"Incorporating design information","text":"default setting write_blocks output_format = 'multiple'. creates one csv file block, naming files according block_names metadata block.","code":"#See the previous section where we created my_design_blk write_blocks(my_design_blk)  #Let's see what the files look like print_df(read.csv(\"Bacteria.csv\", header = FALSE, colClasses = \"character\")) #>   1    2    3    4    5    6    7    8    9   10   11 12 #> A                                                        #> B   Str1 Str1 Str1 Str1 Str1 Str1 Str1 Str1 Str1 Str1    #> C   Str2 Str2 Str2 Str2 Str2 Str2 Str2 Str2 Str2 Str2    #> D   Str3 Str3 Str3 Str3 Str3 Str3 Str3 Str3 Str3 Str3    #> E                                                        #> F   Str5 Str5 Str5 Str5 Str5 Str5 Str5 Str5 Str5 Str5    #> G   Str6 Str6 Str6 Str6 Str6 Str6 Str6 Str6 Str6 Str6    #> H  print_df(read.csv(\"Media.csv\", header = FALSE, colClasses = \"character\")) #>   1    2    3    4    5    6 7    8    9   10    11 12 #> A                                                      #> B   Med1 Med2 Med3 Med4 Med5   Med7 Med8 Med9 Med10    #> C   Med1 Med2 Med3 Med4 Med5   Med7 Med8 Med9 Med10    #> D   Med1 Med2 Med3 Med4 Med5   Med7 Med8 Med9 Med10    #> E   Med1 Med2 Med3 Med4 Med5   Med7 Med8 Med9 Med10    #> F   Med1 Med2 Med3 Med4 Med5   Med7 Med8 Med9 Med10    #> G   Med1 Med2 Med3 Med4 Med5   Med7 Med8 Med9 Med10    #> H"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/incorporate_designs.html","id":"saving-block-shaped-designs-to-a-single-file","dir":"Articles","previous_headings":"Generating designs in R > Saving designs to files > Saving block-shaped designs","what":"Saving block-shaped designs to a single file","title":"Incorporating design information","text":"setting write_blocks output_format = 'single'. creates single csv file contains blocks, putting metadata like block_names rows precede block. Let’s take look single output format looks like: can see design information saved single file, metadata added rows block.","code":"#See the previous section where we created my_design_blk write_blocks(my_design_blk, file = \"Design.csv\", output_format = \"single\")  #Let's see what the file looks like print_df(read.csv(\"Design.csv\", header = FALSE, colClasses = \"character\")) #> block_name Bacteria                                                       #>                   1    2    3    4    5    6    7    8    9   10    11 12 #>          A                                                                #>          B          Str1 Str1 Str1 Str1 Str1 Str1 Str1 Str1 Str1  Str1    #>          C          Str2 Str2 Str2 Str2 Str2 Str2 Str2 Str2 Str2  Str2    #>          D          Str3 Str3 Str3 Str3 Str3 Str3 Str3 Str3 Str3  Str3    #>          E                                                                #>          F          Str5 Str5 Str5 Str5 Str5 Str5 Str5 Str5 Str5  Str5    #>          G          Str6 Str6 Str6 Str6 Str6 Str6 Str6 Str6 Str6  Str6    #>          H                                                                #>                                                                           #> block_name    Media                                                       #>                   1    2    3    4    5    6    7    8    9   10    11 12 #>          A                                                                #>          B          Med1 Med2 Med3 Med4 Med5      Med7 Med8 Med9 Med10    #>          C          Med1 Med2 Med3 Med4 Med5      Med7 Med8 Med9 Med10    #>          D          Med1 Med2 Med3 Med4 Med5      Med7 Med8 Med9 Med10    #>          E          Med1 Med2 Med3 Med4 Med5      Med7 Med8 Med9 Med10    #>          F          Med1 Med2 Med3 Med4 Med5      Med7 Med8 Med9 Med10    #>          G          Med1 Med2 Med3 Med4 Med5      Med7 Med8 Med9 Med10    #>          H"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/incorporate_designs.html","id":"best-practices-for-saving-designs-to-files","dir":"Articles","previous_headings":"Generating designs in R > Saving designs to files","what":"Best practices for saving designs to files","title":"Incorporating design information","text":"’s best leave make_design write_blocks commands analysis script, every time analysis run design files kept date. Just note make_design command output_format = blocks, ’ll need make version output_format = tidy can merge_dfs plate reader data.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/incorporate_designs.html","id":"merging-spectrophotometric-and-design-data","dir":"Articles","previous_headings":"","what":"Merging spectrophotometric and design data","title":"Incorporating design information","text":"design data theRenvironment tidy-shaped, can merge using merge_dfs. , ’ll use data example_widedata_noiseless dataset included gcplyr, source previous examples import_blockmeasures read_wides. example_widedata_noiseless dataset, 48 different bacterial strains. left side plate 48 strains single well , right side plate also 48 strains single well : , right hand side plate phage also inoculated (left hand side remained bacteria-): Let’s generate design: ’s resulting data.frame looks like: Now let’s transform example_widedata_noiseless tidy-shaped. finally, merge two using merge_dfs, saving result ex_dat_mrg, short example_data_merged:","code":"example_design <- make_design(   pattern_split = \",\", nrows = 8, ncols = 12,   \"Bacteria_strain\" = make_designpattern(     values = paste(\"Strain\", 1:48),     rows = 1:8, cols = 1:6,     pattern = 1:48,     byrow = TRUE),   \"Bacteria_strain\" = make_designpattern(     values = paste(\"Strain\", 1:48),     rows = 1:8, cols = 7:12,     pattern = 1:48,     byrow = TRUE),   \"Phage\" = make_designpattern(     values = c(\"No Phage\"),     rows = 1:8, cols = 1:6,     pattern = \"1\"),   \"Phage\" = make_designpattern(     values = c(\"Phage Added\"),     rows = 1:8, cols = 7:12,     pattern = \"1\")) head(example_design, 20) #>    Well Bacteria_strain       Phage #> 1    A1        Strain 1    No Phage #> 2    A2        Strain 2    No Phage #> 3    A3        Strain 3    No Phage #> 4    A4        Strain 4    No Phage #> 5    A5        Strain 5    No Phage #> 6    A6        Strain 6    No Phage #> 7    A7        Strain 1 Phage Added #> 8    A8        Strain 2 Phage Added #> 9    A9        Strain 3 Phage Added #> 10  A10        Strain 4 Phage Added #> 11  A11        Strain 5 Phage Added #> 12  A12        Strain 6 Phage Added #> 13   B1        Strain 7    No Phage #> 14   B2        Strain 8    No Phage #> 15   B3        Strain 9    No Phage #> 16   B4       Strain 10    No Phage #> 17   B5       Strain 11    No Phage #> 18   B6       Strain 12    No Phage #> 19   B7        Strain 7 Phage Added #> 20   B8        Strain 8 Phage Added example_tidydata <- trans_wide_to_tidy(example_widedata_noiseless,                                        id_cols = \"Time\") ex_dat_mrg <- merge_dfs(example_tidydata, example_design) #> Joining, by = \"Well\"  head(ex_dat_mrg) #>   Time Well Measurements Bacteria_strain    Phage #> 1    0   A1        0.002        Strain 1 No Phage #> 2    0   B1        0.002        Strain 7 No Phage #> 3    0   C1        0.002       Strain 13 No Phage #> 4    0   D1        0.002       Strain 19 No Phage #> 5    0   E1        0.002       Strain 25 No Phage #> 6    0   F1        0.002       Strain 31 No Phage"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/incorporate_designs.html","id":"whats-next","dir":"Articles","previous_headings":"","what":"What’s next?","title":"Incorporating design information","text":"Now ’ve merged data designs, can pre-process plot data Introduction: vignette(\"gcplyr\") Importing transforming data: vignette(\"import_transform\") Incorporating design information: vignette(\"incorporate_designs\") Pre-processing plotting data: vignette(\"preprocess_plot\") Processing data: vignette(\"process\") Analyzing data: vignette(\"analyze\") Dealing noise: vignette(\"noise\") Statistics, merging data, resources: vignette(\"conclusion\")","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/noise.html","id":"where-are-we-so-far","dir":"Articles","previous_headings":"","what":"Where are we so far?","title":"Dealing with noise","text":"Introduction: vignette(\"gcplyr\") Importing transforming data: vignette(\"import_transform\") Incorporating design information: vignette(\"incorporate_designs\") Pre-processing plotting data: vignette(\"preprocess_plot\") Processing data: vignette(\"process\") Analyzing data: vignette(\"analyze\") Dealing noise: vignette(\"noise\") Statistics, merging data, resources: vignette(\"conclusion\") far, ’ve imported transformed measures, combined design information, pre-processed, processed, plotted, analyzed data. , ’re going learn potential strategies dealing noise growth curve data. haven’t already, load necessary packages.","code":"library(gcplyr) #> ##  #> ## gcplyr (Version 0.12.3, Build Date: 2023-01-30) #> ## See http://github.com/mikeblazanin/gcplyr for additional documentation #> ## Please cite software as: #> ##   Blazanin, Michael. 2023. 'gcplyr: manipulate and analyze growth #> ##   curve data.' R package version 0.12.3 #> ##  library(dplyr) #>  #> Attaching package: 'dplyr' #> The following objects are masked from 'package:stats': #>  #>     filter, lag #> The following objects are masked from 'package:base': #>  #>     intersect, setdiff, setequal, union library(ggplot2) #This code was previously explained #Here we're re-running it so it's available for us to work with example_design <- make_design(   pattern_split = \",\", nrows = 8, ncols = 12,   \"Bacteria_strain\" = make_designpattern(     values = paste(\"Strain\", 1:48),     rows = 1:8, cols = 1:6, pattern = 1:48, byrow = TRUE),   \"Bacteria_strain\" = make_designpattern(     values = paste(\"Strain\", 1:48),     rows = 1:8, cols = 7:12, pattern = 1:48, byrow = TRUE),   \"Phage\" = make_designpattern(     values = c(\"No Phage\"), rows = 1:8, cols = 1:6, pattern = \"1\"),   \"Phage\" = make_designpattern(     values = c(\"Phage Added\"), rows = 1:8, cols = 7:12, pattern = \"1\"))  sample_wells <- c(\"A1\", \"F1\", \"F10\", \"E11\")"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/noise.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Dealing with noise","text":"Oftentimes, growth curve data produced plate reader noise . model-fitting analysis growth curves implemented packages, effect noise often eliminated fitting step. However, since gcplyr model-free analyses, approach can sometimes sensitive noise, necessitating steps reduce effects noise. assessing effects noise data, one first steps simply visualize data. particular, want visualize raw data, also derivatives ’ll using analyses. especially important per-capita derivatives often sensitive noise, especially bacterial population sizes small. visualizing data, can assess whether density, derivative, per-capita derivative changing smoothly, expect. , instead, observe spikes rapid fluctuations, know noise likely throw estimates maxima minima data derivatives. Broadly speaking, three strategies can use deal noise: Using fitting derivative calculations Smooth raw data Analyze less-noisy subsets data Let’s start pulling example data. Luckily us, version example data ’ve working simulated noise added .   Great! can see noisy noiseless data compare. ’ve plotted data linear axes log-transformed y-axes. log axes useful exponential growth straight line plotted log scale, case also helps highlight higher relative noise low densities compared high densities. fact, common occurrence: low densities, random noise tends much larger effect high densities. level noise doesn’t seem like mess calculations maximum density area curve much, ’s enough reason smooth. let’s look derivatives look like.   values jumping place, including growth rate calculated infinite! Let’s see can address .","code":"#This is the data we've been working with previously noiseless_data <-    trans_wide_to_tidy(example_widedata_noiseless, id_cols = \"Time\") #This is the same data but with simulated noise added noisy_data <- trans_wide_to_tidy(example_widedata, id_cols = \"Time\") #We'll add some identifiers and then merge them together noiseless_data <- mutate(noiseless_data, noise = \"No\") noisy_data <- mutate(noisy_data, noise = \"Yes\") ex_dat_mrg <- merge_dfs(noisy_data, noiseless_data) #> Joining, by = c(\"Time\", \"Well\", \"Measurements\", \"noise\") #> Warning in merge_dfs(noisy_data, noiseless_data):  #> merged_df has more rows than x or y, this may indicate #>                mis-matched values in the shared column(s) used to merge  #>               (e.g. 'Well') ex_dat_mrg <- merge_dfs(ex_dat_mrg, example_design) #> Joining, by = \"Well\"  ex_dat_mrg$Well <-    factor(ex_dat_mrg$Well,          levels = paste(rep(LETTERS[1:8], each = 12), 1:12, sep = \"\"))  #Plot with a linear y-axis ggplot(data = dplyr::filter(ex_dat_mrg, Well %in% sample_wells),        aes(x = Time, y = Measurements, color = noise)) +   geom_point(alpha = 0.5) +   facet_wrap(~Well) #Plot with a log y-axis ggplot(data = dplyr::filter(ex_dat_mrg, Well %in% sample_wells),        aes(x = Time, y = Measurements, color = noise)) +   geom_point(alpha = 0.5) +   facet_wrap(~Well) +   scale_y_continuous(trans = \"log10\") #> Warning: Transformation introduced infinite values in continuous y-axis ex_dat_mrg <-    mutate(group_by(ex_dat_mrg, Well, Bacteria_strain, Phage, noise),          deriv = calc_deriv(x = Time, y = Measurements, x_scale = 3600),          deriv_percap = calc_deriv(x = Time, y = Measurements, x_scale = 3600,                                    percapita = TRUE, blank = 0))  #Plot derivative ggplot(data = dplyr::filter(ex_dat_mrg, Well %in% sample_wells),        aes(x = Time, y = deriv, color = noise)) +   geom_point(alpha = 0.5) +   facet_wrap(~Well, scales = \"free_y\") #> Warning: Removed 8 rows containing missing values (`geom_point()`). #Plot per-capita derivative ggplot(data = dplyr::filter(ex_dat_mrg, Well %in% sample_wells),        aes(x = Time, y = deriv_percap, color = noise)) +   geom_point(alpha = 0.5) +   facet_wrap(~Well, scales = \"free_y\") #> Warning: Removed 12 rows containing missing values (`geom_point()`)."},{"path":"https://mikeblazanin.github.io/gcplyr/articles/noise.html","id":"FittingDeriv","dir":"Articles","previous_headings":"","what":"Fitting during derivative calculation","title":"Dealing with noise","text":"One thing can actually something already Calculating Derivatives article (vignette(\"process\")): instead calculating derivative point relative next, can use moving window two points fit linear regression data. earlier situation used two points limited resolution low densities. However, solution can apply . calculating derivatives fitting many points instead just two, effect single noisy point reduced. use fitting functionality calc_deriv, need specify either window_width parameter, window_width_n parameter. window_width specifies wide window used include points fitting units x, window_width_n specifies number data points. , ’ll demonstrate use fitting regressions data points. Note using calc_deriv way, use points necessary analyses work, visualize different window widths choose smallest one sufficient analyses succeed.   Great! can see, increasing number points derivative calculation reduces amount noise. However, can also see tends bias results, making peaks less high valleys less deep. Moreover, derivatives, especially per-capita derivative, noise remains. next two sections, ’ll explore smoothing raw data analyzing just subset data can reduce effects noise analyses.","code":"ex_dat_mrg <-    mutate(group_by(ex_dat_mrg, Well, Bacteria_strain, Phage, noise),          deriv5 = calc_deriv(x = Time, y = Measurements, x_scale = 3600,                             window_width_n = 5),          deriv_percap5 = calc_deriv(x = Time, y = Measurements, x_scale = 3600,                                    percapita = TRUE, blank = 0,                                    window_width_n = 5),          deriv7 = calc_deriv(x = Time, y = Measurements, x_scale = 3600,                             window_width_n = 7),          deriv_percap7 = calc_deriv(x = Time, y = Measurements, x_scale = 3600,                                    percapita = TRUE, blank = 0,                                    window_width_n = 7),          deriv9 = calc_deriv(x = Time, y = Measurements, x_scale = 3600,                             window_width_n = 9),          deriv_percap9 = calc_deriv(x = Time, y = Measurements, x_scale = 3600,                                    percapita = TRUE, blank = 0,                                    window_width_n = 9))  #Plot derivative ggplot(data = dplyr::filter(ex_dat_mrg, Well %in% sample_wells),        aes(x = Time, y = deriv5, lty = noise)) +   geom_line(alpha = 0.5, color = \"gray20\") +   geom_line(aes(y = deriv7), color = \"gray45\") +   geom_line(aes(y = deriv9), color = \"gray65\") +   facet_wrap(~Well, scales = \"free_y\") #> Warning: Removed 8 rows containing missing values (`geom_line()`). #> Warning: Removed 12 rows containing missing values (`geom_line()`). #> Warning: Removed 16 rows containing missing values (`geom_line()`). #Plot per-capita derivative ggplot(data = dplyr::filter(ex_dat_mrg, Well %in% sample_wells),        aes(x = Time, y = deriv_percap, lty = noise)) +   geom_line(alpha = 0.5, color = \"gray20\") +   geom_line(aes(y = deriv_percap7), color = \"gray45\") +   geom_line(aes(y = deriv_percap9), color = \"gray65\") +   facet_wrap(~Well, scales = \"free_y\") #> Warning: Removed 2 rows containing missing values (`geom_line()`). #> Warning: Removed 12 rows containing missing values (`geom_line()`). #> Warning: Removed 16 rows containing missing values (`geom_line()`)."},{"path":"https://mikeblazanin.github.io/gcplyr/articles/noise.html","id":"Smoothing","dir":"Articles","previous_headings":"","what":"Smoothing raw data","title":"Dealing with noise","text":"One obvious approaches deal noise raw data use smoothing algorithm. gcplyr smooth_data function can carry smoothing. Note using smooth_data, generally carry little smoothing necessary analyses work, visualize different degrees smoothing choose least smoothed one sufficient analyses succeed. smooth_data four different smoothing algorithms choose : moving-average, moving-median, loess, gam. moving-average simple smoothing algorithm primarily acts reduce effects outliers data moving-median another simple smoothing algorithm primarily acts reduce effects outliers data loess spline-fitting approach uses polynomial-like curves, produces curves smoothly changing derivatives, can cases create curvature artifacts present original data gam also spline-fitting approach uses polynomial-like curves, produces curves smoothly changing derivatives, can cases create curvature artifacts present original data Additionally, four smoothing algorithms tuning parameter controls “smoothed” data . whichever smoothing method ’re using, plot smoothing multiple different tuning parameter values, choose value smooths data little necessary reduce noise. Make sure plot smoothing every well data, ’re choosing best setting data just one well. Smoothing data step alters values analyze. , many options smooth data, step can rife pitfalls. recommend starting simplest least “smoothed” smoothing, plotting results, increasing smoothing much needed enable downstream analyses. Additionally, sharing findings, ’s important transparent sharing raw data smoothing methods, rather treating smoothed data source. use smooth_data, pass x y values, method choice, additional arguments needed method. return vector smoothed y values.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/noise.html","id":"smoothing-with-moving-average","dir":"Articles","previous_headings":"Smoothing raw data","what":"Smoothing with moving-average","title":"Dealing with noise","text":"moving-average, two tuning parameters choose : window_width specifies wide moving window used calculate average units x. window_width_n specifies many data points wide moving window used calculate average . Specifying window_width window_width_n required, larger values “smoothed”. Think carefully whether want hold amount time number data points window constant (data collected constant intervals, difference). , ’ll show moving averages window_width_n values 3, 7, 11 data points wide (window centered data point, window_width_n must odd number data points wide). Note moving-average returns NA data points start end data window extends beyond domain data.  can see moving-average helped reduce effects early noise. However, window_width_n = 11 (lightest line), smoothing started biasing medium-density data points higher actually . Based , ’d probably want use window_width_n less 11. Unfortunately, smaller window_width_n early data still affected early noise, explore smoothing methods, try combining multiple smoothing methods.","code":"ex_dat_mrg <-   mutate(group_by(ex_dat_mrg, Well, Bacteria_strain, Phage, noise),          smoothed3 = smooth_data(x = Time, y = Measurements,               sm_method = \"moving-average\", window_width_n = 3),          smoothed7 = smooth_data(x = Time, y = Measurements,               sm_method = \"moving-average\", window_width_n = 7),          smoothed11 = smooth_data(x = Time, y = Measurements,               sm_method = \"moving-average\", window_width_n = 11))  #What does the smoothed data look like compared to the noisy original? #Lighter lines are wider window_width_n's and more \"smoothed\" ggplot(data = dplyr::filter(ex_dat_mrg, Well %in% sample_wells),        aes(x = Time, lty = noise)) +   geom_line(aes(y = Measurements)) +   geom_line(aes(y = smoothed3), color = \"gray20\") +   geom_line(aes(y = smoothed7), color = \"gray45\") +   geom_line(aes(y = smoothed11), color = \"gray65\") +   facet_wrap(~Well) +   scale_y_continuous(trans = \"log10\") #> Warning: Transformation introduced infinite values in continuous y-axis #> Transformation introduced infinite values in continuous y-axis #> Warning: Removed 4 rows containing missing values (`geom_line()`). #> Warning: Removed 12 rows containing missing values (`geom_line()`). #> Warning: Removed 20 rows containing missing values (`geom_line()`)."},{"path":"https://mikeblazanin.github.io/gcplyr/articles/noise.html","id":"smoothing-with-moving-median","dir":"Articles","previous_headings":"Smoothing raw data","what":"Smoothing with moving-median","title":"Dealing with noise","text":"moving-median, two tuning parameters: window_width specifies wide moving window used calculate average units x. window_width_n specifies many data points wide moving window used calculate average . Specifying window_width window_width_n required, larger values “smoothed”. Think carefully whether want hold amount time number data points window constant (data collected constant intervals, difference). , ’ll show moving medians windows 3, 7, 11 data points wide (window centered data point, must odd number data points wide). Note moving-median returns NA data points start end data window extends beyond domain data.  can see moving-median really excluded low-density noise, even smallest window_width_n = 3. Additionally, moving-median bias larger data hardly , except widest window_width_n. However, produced smoothed density fairly “jumpy”, something wider window_width_n fix. common moving-median, often may need try smoothing methods combining moving-median methods.","code":"ex_dat_mrg <-   mutate(group_by(ex_dat_mrg, Well, Bacteria_strain, Phage, noise),          smoothed3 =             smooth_data(x = Time, y = Measurements,                        sm_method = \"moving-median\", window_width_n = 3),          smoothed7 =             smooth_data(x = Time, y = Measurements,                        sm_method = \"moving-median\", window_width_n = 7),          smoothed11 =             smooth_data(x = Time, y = Measurements,                        sm_method = \"moving-median\", window_width_n = 11))  #What does the smoothed data look like compared to the noisy original? #Lighter lines are wider window_width_n's and more \"smoothed\" ggplot(data = dplyr::filter(ex_dat_mrg, Well %in% sample_wells),        aes(x = Time, lty = noise)) +   geom_line(aes(y = Measurements)) +   geom_line(aes(y = smoothed3), color = \"gray20\") +   geom_line(aes(y = smoothed7), color = \"gray45\") +   geom_line(aes(y = smoothed11), color = \"gray65\") +   facet_wrap(~Well) +   scale_y_continuous(trans = \"log10\") #> Warning: Transformation introduced infinite values in continuous y-axis #> Transformation introduced infinite values in continuous y-axis #> Transformation introduced infinite values in continuous y-axis #> Transformation introduced infinite values in continuous y-axis #> Warning: Removed 4 rows containing missing values (`geom_line()`). #> Warning: Removed 12 rows containing missing values (`geom_line()`). #> Warning: Removed 20 rows containing missing values (`geom_line()`)."},{"path":"https://mikeblazanin.github.io/gcplyr/articles/noise.html","id":"smoothing-with-loess","dir":"Articles","previous_headings":"Smoothing raw data","what":"Smoothing with LOESS","title":"Dealing with noise","text":"loess, tuning parameter span argument. loess works fits subset windows data centered data point. fits can linear (degree = 1) polynomial (typically degree = 2). span width window, fraction data points. instance, default span 0.75, 75% data points included window. Thus, span values typically 0 1 (although see ?loess use span values greater 1), larger values “smoothed”. , ’ll show loess smoothing spans 0.1, 0.2, 0.5 degree = 1.  can see loess smaller spans (darker lines) smoothed data somewhat still sensitive outliers. However, loess larger span (lightest line) introduced significant bias. fix , might explore smoothing methods, combining loess smoothing methods.","code":"ex_dat_mrg <-   mutate(group_by(ex_dat_mrg, Well, Bacteria_strain, Phage, noise),          smoothed1 = smooth_data(x = Time, y = Measurements,                                  sm_method = \"loess\", span = .1, degree = 1),          smoothed2 = smooth_data(x = Time, y = Measurements,                                  sm_method = \"loess\", span = .2, degree = 1),          smoothed5 = smooth_data(x = Time, y = Measurements,                                  sm_method = \"loess\", span = .5, degree = 1))  #What does the smoothed data look like compared to the noisy original? #Lighter lines are larger span's and more \"smoothed\" ggplot(data = dplyr::filter(ex_dat_mrg, Well %in% sample_wells),        aes(x = Time, lty = noise)) +   geom_line(aes(y = Measurements)) +   geom_line(aes(y = smoothed1), color = \"gray20\") +   geom_line(aes(y = smoothed2), color = \"gray45\") +   geom_line(aes(y = smoothed5), color = \"gray65\") +   facet_wrap(~Well) +   scale_y_continuous(trans = \"log10\") #> Warning: Transformation introduced infinite values in continuous y-axis #> Warning in self$trans$transform(x): NaNs produced #> Warning: Transformation introduced infinite values in continuous y-axis #> Warning in self$trans$transform(x): NaNs produced #> Warning: Transformation introduced infinite values in continuous y-axis #> Warning: Removed 18 rows containing missing values (`geom_line()`)."},{"path":"https://mikeblazanin.github.io/gcplyr/articles/noise.html","id":"smoothing-with-gam","dir":"Articles","previous_headings":"Smoothing raw data","what":"Smoothing with GAM","title":"Dealing with noise","text":"gam, primary tuning parameter k argument. gam works fits subsets data linking fits together. k determines many link points (“knots”) can use. specified, default k value smoothing time series 10, smaller values “smoothed” (note opposite trend smoothing methods). However, unlike earlier methods, k values large also problematic, tend ‘overfit’ data. k larger number data points, usually substantially smaller . Also note gam can sometimes create artifacts, especially oscillations density derivatives. check gam carrying analyses. , ’ll show gam smoothing k values 5, 10, 20.  can see gam alright working phage-added wells (A1 F1): higher k values (darkest line) smoothed data still sensitive early outliers, lower k values (lighter lines) introduced significant bias. However, gam struggling phage added (E11 F10). Across k values added many fluctuations often dips values 0 lower (plotted breaks line, since log numbers <= 0 undefined). fix , might explore smoothing methods combining gam smoothing methods.","code":"ex_dat_mrg <-   mutate(group_by(ex_dat_mrg, Well, Bacteria_strain, Phage, noise),          smoothed20 = smooth_data(x = Time, y = Measurements,                                   sm_method = \"gam\", k = 20),          smoothed10 = smooth_data(x = Time, y = Measurements,                                   sm_method = \"gam\", k = 10),          smoothed5 = smooth_data(x = Time, y = Measurements,                                  sm_method = \"gam\", k = 5))  #What does the smoothed data look like compared to the noisy original? #Lighter lines are smaller k and more \"smoothed\" ggplot(data = dplyr::filter(ex_dat_mrg, Well %in% sample_wells),        aes(x = Time, lty = noise)) +   geom_line(aes(y = Measurements)) +   geom_line(aes(y = smoothed20), color = \"gray20\") +   geom_line(aes(y = smoothed10), color = \"gray45\") +   geom_line(aes(y = smoothed5), color = \"gray65\") +   facet_wrap(~Well) +   scale_y_continuous(trans = \"log10\") #> Warning: Transformation introduced infinite values in continuous y-axis #> Warning in self$trans$transform(x): NaNs produced #> Warning: Transformation introduced infinite values in continuous y-axis #> Warning in self$trans$transform(x): NaNs produced #> Warning: Transformation introduced infinite values in continuous y-axis #> Warning in self$trans$transform(x): NaNs produced #> Warning: Transformation introduced infinite values in continuous y-axis #> Warning: Removed 2 rows containing missing values (`geom_line()`)."},{"path":"https://mikeblazanin.github.io/gcplyr/articles/noise.html","id":"combining-multiple-smoothing-methods","dir":"Articles","previous_headings":"Smoothing raw data","what":"Combining multiple smoothing methods","title":"Dealing with noise","text":"Often, combining multiple smoothing methods can provide improved results. instance, moving-median particularly good removing outliers, good producing continuously smooth data. contrast, moving-average, loess, gam work better producing continuously smooth data, aren’t good removing outliers. ’s example using strengths moving-median moving-average. (Note earlier columns created mutate available creation later columns, can done one step):  can see combination minimal moving-median moving-average smoothing produced curve noise removed minimal introduction bias. (Note first last 2 data points now NA smoothing)","code":"ex_dat_mrg <-   mutate(group_by(ex_dat_mrg, Well, Bacteria_strain, Phage, noise),          smoothed_med3 =             smooth_data(x = Time, y = Measurements,                        sm_method = \"moving-median\", window_width_n = 3),          #Note that for the second round, we're using the           #first smoothing as the input y          smoothed =             smooth_data(x = Time, y = smoothed_med3,                        sm_method = \"moving-average\", window_width_n = 3))  #What does the smoothed data look like compared to the noisy original? #The first round of smoothing with moving-median is plotted in lighter colors #The second round of smoothing with moving-average is plotted in darker colors ggplot(data = dplyr::filter(ex_dat_mrg, Well %in% sample_wells),        aes(x = Time, lty = noise)) +   geom_line(aes(y = Measurements)) +   geom_line(aes(y = smoothed_med3), color = \"gray20\") +   geom_line(aes(y = smoothed), color = \"gray65\") +   facet_wrap(~Well) +   scale_y_continuous(trans = \"log10\") #> Warning: Transformation introduced infinite values in continuous y-axis #> Transformation introduced infinite values in continuous y-axis #> Transformation introduced infinite values in continuous y-axis #> Warning: Removed 4 rows containing missing values (`geom_line()`). #> Warning: Removed 8 rows containing missing values (`geom_line()`)."},{"path":"https://mikeblazanin.github.io/gcplyr/articles/noise.html","id":"DerivsOfSmoothed","dir":"Articles","previous_headings":"","what":"Calculating derivatives of smoothed data","title":"Dealing with noise","text":"’ve smoothed data, can calculate derivatives using smoothed data. Combining smoothing raw data fitting using multiple points calculating derivatives can powerful combination reducing effects noise minimizing introduction bias.","code":"ex_dat_mrg <-    mutate(group_by(ex_dat_mrg, Well, Bacteria_strain, Phage, noise),          deriv = calc_deriv(x = Time, y = smoothed, x_scale = 3600),          deriv_percap = calc_deriv(x = Time, y = smoothed, x_scale = 3600,                                    percapita = TRUE, blank = 0),          deriv3 = calc_deriv(x = Time, y = smoothed, x_scale = 3600,                             window_width_n = 3),          deriv_percap3 = calc_deriv(x = Time, y = smoothed, x_scale = 3600,                                    percapita = TRUE, blank = 0,                                    window_width_n = 3))  #Plot derivative ggplot(data = dplyr::filter(ex_dat_mrg, Well %in% sample_wells),        aes(x = Time, y = deriv, lty = noise)) +   geom_line(alpha = 0.5, color = \"gray20\") +   geom_line(aes(y = deriv3), color = \"gray65\") +   facet_wrap(~Well, scales = \"free_y\") #> Warning: Removed 10 rows containing missing values (`geom_line()`). #> Warning: Removed 12 rows containing missing values (`geom_line()`). #Plot per-capita derivative ggplot(data = dplyr::filter(ex_dat_mrg, Well %in% sample_wells),        aes(x = Time, y = deriv_percap, lty = noise)) +   geom_line(alpha = 0.5, color = \"gray20\") +   geom_line(aes(y = deriv_percap3), color = \"gray65\") +   facet_wrap(~Well, scales = \"free_y\") #> Warning: Removed 10 rows containing missing values (`geom_line()`). #> Removed 12 rows containing missing values (`geom_line()`)."},{"path":"https://mikeblazanin.github.io/gcplyr/articles/noise.html","id":"SubsetAnalysis","dir":"Articles","previous_headings":"","what":"Summarizing on subsets of derivatives","title":"Dealing with noise","text":"one final strategy can employ dealing noisy data: since noise often relatively stronger effects densities near 0, can simply exclude data points density near 0. Let’s look smoothed per-capita growth rates:  now let’s compare density plots:  Clearly can see noise per-capita growth rate occurs bacterial population density low. Indeed, common per-capita growth rates, sensitive noise low densities. can ? can simply exclude values density really low. Let’s plot per-capita growth rate data different cutoffs minimum density bacteria:    can see, limit analyses derivatives bacterial population cutoff density, many noisy points disappear, noisy derivative curves look increasingly similar noiseless derivative curves. take final step, can use cutoffs summarize commands calculate maximum growth rate bacteria density least 0.005. now can visualize findings:  can see limiting analyses just subset data, maximum per-capita growth rate nearly identical three example wells, F1 noise altering calculated maximum somewhat. happens data, continue try alternate smoothing, derivative calculating, subset strategies try reduce effects noise findings.","code":"ggplot(data = dplyr::filter(ex_dat_mrg, Well %in% sample_wells),        aes(x = Time, y = deriv_percap3, lty = noise)) +   geom_line() +   facet_wrap(~Well, scales = \"free\") #> Warning: Removed 12 rows containing missing values (`geom_line()`). ggplot(data = dplyr::filter(ex_dat_mrg, Well %in% sample_wells),        aes(x = Time, y = smoothed)) +   geom_line() +   facet_wrap(~Well, scales = \"free\") #> Warning: Removed 8 rows containing missing values (`geom_line()`). for (my_well in sample_wells) {   #Title   title <- cowplot::ggdraw() +      cowplot::draw_label(paste(\"Well\", my_well),                          fontface = \"bold\", x = 0, hjust = 0) +     theme(plot.margin = margin(0, 0, 0, 7))      #Save x and y limits for all plots so they're all on the same axes   xdat <- dplyr::filter(ex_dat_mrg, Well == my_well)$Time   ydat <- dplyr::filter(ex_dat_mrg, Well == my_well)$deriv_percap3   xlims <- c(min(xdat[is.finite(xdat)], na.rm = TRUE),              max(xdat[is.finite(xdat)], na.rm = TRUE))   ylims <- c(min(ydat[is.finite(ydat)], na.rm = TRUE),              max(ydat[is.finite(ydat)], na.rm = TRUE))      #Plot unfiltered data   p1 <- ggplot(data = dplyr::filter(ex_dat_mrg, Well == my_well),                aes(x = Time, y = deriv_percap3, color = noise)) +     geom_point(alpha = 0.5) + facet_wrap(~Well, scales = \"free\") +     ggtitle(\"all data\") +     xlim(xlims[1], xlims[2]) + ylim(ylims[1], ylims[2])      #Plot data with filters for density   p2 <- ggplot(data = dplyr::filter(ex_dat_mrg,                                      Well == my_well, smoothed > 0.001),                aes(x = Time, y = deriv_percap3, color = noise)) +     geom_point(alpha = 0.5) + facet_wrap(~Well, scales = \"free\") +     ggtitle(\"data where Abs > 0.001\") +     xlim(xlims[1], xlims[2]) + ylim(ylims[1], ylims[2])   p3 <- ggplot(data = dplyr::filter(ex_dat_mrg,                                      Well == my_well, smoothed > 0.005),                aes(x = Time, y = deriv_percap3, color = noise)) +     geom_point(alpha = 0.5) + facet_wrap(~Well, scales = \"free\") +     ggtitle(\"data where Abs > 0.005\") +     xlim(xlims[1], xlims[2]) + ylim(ylims[1], ylims[2])   p4 <- ggplot(data = dplyr::filter(ex_dat_mrg,                                      Well == my_well, smoothed > 0.01),                aes(x = Time, y = deriv_percap3, color = noise)) +     geom_point(alpha = 0.5) + facet_wrap(~Well, scales = \"free\") +     ggtitle(\"data where Abs > 0.01\") +     xlim(xlims[1], xlims[2]) + ylim(ylims[1], ylims[2])      print(cowplot::plot_grid(title, cowplot::plot_grid(p1, p2, p3, p4, ncol = 2),                            ncol = 1, rel_heights = c(0.1, 1))) } #> Warning: Removed 12 rows containing missing values (`geom_point()`). #> Warning: Removed 4 rows containing missing values (`geom_point()`). #> Warning: Removed 2 rows containing missing values (`geom_point()`). #> Removed 2 rows containing missing values (`geom_point()`). #> Warning: Removed 12 rows containing missing values (`geom_point()`). #> Warning: Removed 4 rows containing missing values (`geom_point()`). #> Warning: Removed 2 rows containing missing values (`geom_point()`). #> Removed 2 rows containing missing values (`geom_point()`). #> Warning: Removed 14 rows containing missing values (`geom_point()`). #> Warning: Removed 3 rows containing missing values (`geom_point()`). #> Warning: Removed 12 rows containing missing values (`geom_point()`). #> Warning: Removed 4 rows containing missing values (`geom_point()`). #> Warning: Removed 3 rows containing missing values (`geom_point()`). #> Warning: Removed 2 rows containing missing values (`geom_point()`). ex_dat_mrg_sum <-   summarize(group_by(ex_dat_mrg, Well, Bacteria_strain, Phage, noise),             max_growth_rate = max(deriv_percap3[smoothed > 0.01],                                    na.rm = TRUE)) #> `summarise()` has grouped output by 'Well', 'Bacteria_strain', 'Phage'. You can #> override using the `.groups` argument. head(ex_dat_mrg_sum) #> # A tibble: 6 × 5 #> # Groups:   Well, Bacteria_strain, Phage [3] #>   Well  Bacteria_strain Phage    noise max_growth_rate #>   <fct> <chr>           <chr>    <chr>           <dbl> #> 1 A1    Strain 1        No Phage No              1.02  #> 2 A1    Strain 1        No Phage Yes             1.02  #> 3 A2    Strain 2        No Phage No              1.35  #> 4 A2    Strain 2        No Phage Yes             1.49  #> 5 A3    Strain 3        No Phage No              0.935 #> 6 A3    Strain 3        No Phage Yes             1.19 ggplot(data = dplyr::filter(ex_dat_mrg,                              Well %in% sample_wells, smoothed >= 0.01),        aes(x = Time, y = deriv_percap3, color = noise)) +   geom_point() +   facet_wrap(~Well, scales = \"free\") +   ggtitle(\"data where smoothed density > 0.01\") +   geom_hline(data = dplyr::filter(ex_dat_mrg_sum, Well %in% sample_wells),               aes(yintercept = max_growth_rate, color = noise), lty = 2) #> Warning: Removed 6 rows containing missing values (`geom_point()`)."},{"path":"https://mikeblazanin.github.io/gcplyr/articles/noise.html","id":"whats-next","dir":"Articles","previous_headings":"","what":"What’s next?","title":"Dealing with noise","text":"Now ’ve analyzed data dealt noise, ’s just concluding notes best practices running statistics, merging growth curve analyses data, additional resources analyzing growth curves. Introduction: vignette(\"gcplyr\") Importing transforming data: vignette(\"import_transform\") Incorporating design information: vignette(\"incorporate_designs\") Pre-processing plotting data: vignette(\"preprocess_plot\") Processing data: vignette(\"process\") Analyzing data: vignette(\"analyze\") Dealing noise: vignette(\"noise\") Statistics, merging data, resources: vignette(\"conclusion\")","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/preprocess_plot.html","id":"where-are-we-so-far","dir":"Articles","previous_headings":"","what":"Where are we so far?","title":"Pre-processing and plotting data","text":"Introduction: vignette(\"gcplyr\") Importing transforming data: vignette(\"import_transform\") Incorporating design information: vignette(\"incorporate_designs\") Pre-processing plotting data: vignette(\"preprocess_plot\") Processing data: vignette(\"process\") Analyzing data: vignette(\"analyze\") Dealing noise: vignette(\"noise\") Statistics, merging data, resources: vignette(\"conclusion\") far, ’ve imported transformed measures, combined design information. Now ’re going final pre-processing steps show easily plot data ggplot. haven’t already, load necessary packages.","code":"library(gcplyr) #> ##  #> ## gcplyr (Version 0.12.3, Build Date: 2023-01-30) #> ## See http://github.com/mikeblazanin/gcplyr for additional documentation #> ## Please cite software as: #> ##   Blazanin, Michael. 2023. 'gcplyr: manipulate and analyze growth #> ##   curve data.' R package version 0.12.3 #> ##  library(dplyr) #>  #> Attaching package: 'dplyr' #> The following objects are masked from 'package:stats': #>  #>     filter, lag #> The following objects are masked from 'package:base': #>  #>     intersect, setdiff, setequal, union library(ggplot2) library(lubridate) #>  #> Attaching package: 'lubridate' #> The following objects are masked from 'package:base': #>  #>     date, intersect, setdiff, union #This code was previously explained #Here we're re-running it so it's available for us to work with example_tidydata <- trans_wide_to_tidy(example_widedata_noiseless,                                        id_cols = \"Time\") example_design <- make_design(   pattern_split = \",\", nrows = 8, ncols = 12,   \"Bacteria_strain\" = make_designpattern(     values = paste(\"Strain\", 1:48),     rows = 1:8, cols = 1:6, pattern = 1:48, byrow = TRUE),   \"Bacteria_strain\" = make_designpattern(     values = paste(\"Strain\", 1:48),     rows = 1:8, cols = 7:12, pattern = 1:48, byrow = TRUE),   \"Phage\" = make_designpattern(     values = c(\"No Phage\"), rows = 1:8, cols = 1:6, pattern = \"1\"),   \"Phage\" = make_designpattern(     values = c(\"Phage Added\"), rows = 1:8, cols = 7:12, pattern = \"1\")) ex_dat_mrg <- merge_dfs(example_tidydata, example_design) #> Joining, by = \"Well\""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/preprocess_plot.html","id":"pre-processing","dir":"Articles","previous_headings":"","what":"Pre-processing","title":"Pre-processing and plotting data","text":"Now data designs merged, ’re almost ready start processing analyzing . However, first need carry necessary pre-processing steps, like excluding wells contaminated empty, converting time formats numeric.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/preprocess_plot.html","id":"pre-processing-excluding-data","dir":"Articles","previous_headings":"Pre-processing","what":"Pre-processing: excluding data","title":"Pre-processing and plotting data","text":"cases, want remove wells growth curves data carry downstream analyses. instance, may left empty, contained negative controls, contaminated. can use dplyr’s filter function remove wells meet criteria want exclude. instance, let’s imagine realized put wrong media Well B1, remove analyses. case, can simply: Now can see rows Well B1 excluded. something similar realized Bacterial strain contaminated. instance, strain 13 contaminated, exclude (Well B1) follows:","code":"example_data_and_designs_filtered <- filter(ex_dat_mrg, Well != \"B1\") head(example_data_and_designs_filtered) #>   Time Well Measurements Bacteria_strain    Phage #> 1    0   A1        0.002        Strain 1 No Phage #> 2    0   C1        0.002       Strain 13 No Phage #> 3    0   D1        0.002       Strain 19 No Phage #> 4    0   E1        0.002       Strain 25 No Phage #> 5    0   F1        0.002       Strain 31 No Phage #> 6    0   G1        0.002       Strain 37 No Phage example_data_and_designs_filtered <-    filter(ex_dat_mrg,           Well != \"B1\", Bacteria_strain != \"Strain 13\") head(example_data_and_designs_filtered) #>   Time Well Measurements Bacteria_strain    Phage #> 1    0   A1        0.002        Strain 1 No Phage #> 2    0   D1        0.002       Strain 19 No Phage #> 3    0   E1        0.002       Strain 25 No Phage #> 4    0   F1        0.002       Strain 31 No Phage #> 5    0   G1        0.002       Strain 37 No Phage #> 6    0   H1        0.002       Strain 43 No Phage"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/preprocess_plot.html","id":"pre-processing-converting-dates-times-into-numeric","dir":"Articles","previous_headings":"Pre-processing","what":"Pre-processing: converting dates & times into numeric","title":"Pre-processing and plotting data","text":"Growth curve data produced plate reader often encodes timestamp information string (e.g. “2:45:11” 2 hours, 45 minutes, 11 seconds), downstream analyses need timestamp information numeric (e.g. number seconds elapsed). Luckily, others written great packages make easy convert common date-time text formats plain numeric formats. , ’ll see use lubridate : First create data frame time saved might plate reader. usual, don’t worry block code works, since ’s just creating example file format output plate reader. Let’s take look data.frame. shows Time column might written plate reader. can see Time aren’t written easy numeric. Instead, ’re format ’s easy human understand (unfortunately usable analysis). Let’s use lubridate convert text usable format. lubridate whole family functions can parse text hour, minute, /second components. can use hms text contains hour, minute, second information, hm contains hour minute information, ms contains minute second information. Since example three, ’ll use hms. hms parsed text, ’ll use another function convert output hms pure numeric value: time_length. default, time_length returns units seconds, can change changing unit argument time_length. See ?time_length details. now can see ’ve gotten nice numeric Time values! can proceed next steps analysis.","code":"ex_dat_mrg$Time <-   paste(ex_dat_mrg$Time %/% 3600,         formatC((ex_dat_mrg$Time %% 3600) %/% 60,                  width = 2, flag = 0),         formatC((ex_dat_mrg$Time %% 3600) %% 60,                 width = 2, flag = 0),         sep = \":\") head(ex_dat_mrg) #>      Time Well Measurements Bacteria_strain    Phage #> 1 0:00:00   A1        0.002        Strain 1 No Phage #> 2 0:00:00   B1        0.002        Strain 7 No Phage #> 3 0:00:00   C1        0.002       Strain 13 No Phage #> 4 0:00:00   D1        0.002       Strain 19 No Phage #> 5 0:00:00   E1        0.002       Strain 25 No Phage #> 6 0:00:00   F1        0.002       Strain 31 No Phage #We have previously loaded lubridate, but if you haven't already then #make sure to add the line: #   library(lubridate)  ex_dat_mrg$Time <- time_length(hms(ex_dat_mrg$Time))  head(ex_dat_mrg) #>   Time Well Measurements Bacteria_strain    Phage #> 1    0   A1        0.002        Strain 1 No Phage #> 2    0   B1        0.002        Strain 7 No Phage #> 3    0   C1        0.002       Strain 13 No Phage #> 4    0   D1        0.002       Strain 19 No Phage #> 5    0   E1        0.002       Strain 25 No Phage #> 6    0   F1        0.002       Strain 31 No Phage"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/preprocess_plot.html","id":"plotting-your-data","dir":"Articles","previous_headings":"","what":"Plotting your data","title":"Pre-processing and plotting data","text":"data merged times converted numeric, can easily plot data using ggplot2 package. ’s ggplot2 specifically built assumption data tidy-shaped, ! won’t go depth use ggplot , three main commands plot : ggplot - ggplot function specify data.frame like use aesthetics plot (x y axes like) geom_line - tells ggplot like plot data, case line (another common geom time-series data geom_point) facet_wrap - tells ggplot plot Well separate facet ’ll using format plot data throughout remainder vignette  Generally speaking, plot data frequently, every way can think ! every processing analysis step, visualize input data output data understand processing analysis steps whether right choices particular data (vignette !)","code":"#We have previously loaded ggplot2, but if you haven't already then #make sure to add the line: #    library(ggplot2)  #First, we'll reorder the Well levels so they plot in the correct order ex_dat_mrg$Well <-    factor(ex_dat_mrg$Well,          levels = paste(rep(LETTERS[1:8], each = 12), 1:12, sep = \"\"))  ggplot(data = ex_dat_mrg, aes(x = Time, y = Measurements)) +   geom_line() +   facet_wrap(~Well, nrow = 8, ncol = 12)"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/preprocess_plot.html","id":"whats-next","dir":"Articles","previous_headings":"","what":"What’s next?","title":"Pre-processing and plotting data","text":"Now ’ve pre-processed visualized data, ’s time process (cases) analyze (pretty much always) ! Introduction: vignette(\"gcplyr\") Importing transforming data: vignette(\"import_transform\") Incorporating design information: vignette(\"incorporate_designs\") Pre-processing plotting data: vignette(\"preprocess_plot\") Processing data: vignette(\"process\") Analyzing data: vignette(\"analyze\") Dealing noise: vignette(\"noise\") Statistics, merging data, resources: vignette(\"conclusion\")","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/process.html","id":"where-are-we-so-far","dir":"Articles","previous_headings":"","what":"Where are we so far?","title":"Processing data","text":"Introduction: vignette(\"gcplyr\") Importing transforming data: vignette(\"import_transform\") Incorporating design information: vignette(\"incorporate_designs\") Pre-processing plotting data: vignette(\"preprocess_plot\") Processing data: vignette(\"process\") Analyzing data: vignette(\"analyze\") Dealing noise: vignette(\"noise\") Statistics, merging data, resources: vignette(\"conclusion\") far, ’ve imported transformed measures, combined design information, pre-processed plotted data. Now ’re going processing raw data: calculating derivatives. haven’t already, load necessary packages.","code":"library(gcplyr) #> ##  #> ## gcplyr (Version 0.12.3, Build Date: 2023-01-30) #> ## See http://github.com/mikeblazanin/gcplyr for additional documentation #> ## Please cite software as: #> ##   Blazanin, Michael. 2023. 'gcplyr: manipulate and analyze growth #> ##   curve data.' R package version 0.12.3 #> ##  library(dplyr) #>  #> Attaching package: 'dplyr' #> The following objects are masked from 'package:stats': #>  #>     filter, lag #> The following objects are masked from 'package:base': #>  #>     intersect, setdiff, setequal, union library(ggplot2) #This code was previously explained #Here we're re-running it so it's available for us to work with example_tidydata <- trans_wide_to_tidy(example_widedata_noiseless,                                        id_cols = \"Time\") example_design <- make_design(   pattern_split = \",\", nrows = 8, ncols = 12,   \"Bacteria_strain\" = make_designpattern(     values = paste(\"Strain\", 1:48),     rows = 1:8, cols = 1:6, pattern = 1:48, byrow = TRUE),   \"Bacteria_strain\" = make_designpattern(     values = paste(\"Strain\", 1:48),     rows = 1:8, cols = 7:12, pattern = 1:48, byrow = TRUE),   \"Phage\" = make_designpattern(     values = c(\"No Phage\"), rows = 1:8, cols = 1:6, pattern = \"1\"),   \"Phage\" = make_designpattern(     values = c(\"Phage Added\"), rows = 1:8, cols = 7:12, pattern = \"1\")) ex_dat_mrg <- merge_dfs(example_tidydata, example_design) #> Joining, by = \"Well\" ex_dat_mrg$Well <-    factor(ex_dat_mrg$Well,          levels = paste(rep(LETTERS[1:8], each = 12), 1:12, sep = \"\"))"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/process.html","id":"how-to-process-and-analyze-your-data","dir":"Articles","previous_headings":"","what":"How to process and analyze your data","title":"Processing data","text":"data design information pre-processed, dataset now organized way ’s easy export analyze. also point next steps can diversify many options. Broadly speaking, two main approaches analyzing growth curves data: directly quantify attributes growth dynamics fit growth dynamics mathematical model, extract parameters fitted model remaining functions gcplyr can facilitate analyses following first approach: directly quantifying attributes observed dynamics. ’re interested exploring model-fitting approaches, can provide enormous analytical power, check growth curve analysis packages section vignette(“conclusion”). point, since data now well-organized, advanced users may also decide want write custom analyses (lieu , alongside, gcplyr-based /fitting-based analyses). , directly quantify attributes growth curves? First, may need calculate derivatives data. density derivative values analyze identify features growth curves. gcplyr number functions facilitate steps. However, unlike import, transformation, merging steps ’ve done far, different projects may require different analyses, users analysis steps. Calculating Derivatives section article, Analyzing Data Dealing Noise vignettes, therefore, written highlight functions available provide examples common analyses may want run, rather prescribing set analysis steps everyone must . dig processing analyzing data, first need familiarize dplyr package functions group_by mutate. ? upcoming gcplyr processing functions best used within dplyr::mutate. ’re already familiar dplyr, feel free skip primer. ’re familiar yet, don’t worry! section provides primer teach need know using group_by mutate gcplyr functions.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/process.html","id":"a-brief-primer-on-dplyr","dir":"Articles","previous_headings":"How to process and analyze your data","what":"A brief primer on dplyr","title":"Processing data","text":"R package dplyr provides “grammar data manipulation” useful broad array data analysis tasks (fact, dplyr direct inspiration name package!) purposes right now, ’re going focus two particular functions: group_by mutate. mutate function dplyr allows users easily create new columns data.frame’s. us, ’re going use mutate create columns data derivatives calculate. However, want make sure derivative-calculating done unique well independently. order , ’re first going use group_by function, allows users group rows data.frame’s groups mutate treat independently. growth curves, means : group_by data every unique well group mutate create new columns data calculated derivatives Let’s walk simple example group_by, need specify data.frame grouped, want list columns needed identify unique well dataset. Typically, includes design columns along plate name well name. Make sure ’re grouping Time, Absorbance, anything else varies within well, since dplyr group timepoints within well separately. Notice hasn’t changed anything data.frame, R now knows groups . Now calculations carried unique well independently. use mutate, simply specify: name variable want results saved function calculates new column Note function return vector long number data points group. simple example, code ’ve simply added one Measurements values saved column named Measurements_plus1: want additional columns, simply add mutate. instance, also want column Measurements plus two, just add second argument: rather simple example, next sections show can use mutate calc_deriv create new columns containing derivatives. want learn , dplyr extensive documentation examples online. Feel free explore desired, primer sufficient use gcplyr processing functions, (reminder) best used within mutate.","code":"ex_dat_mrg <- group_by(ex_dat_mrg, Well, Bacteria_strain, Phage)  head(ex_dat_mrg) #> # A tibble: 6 × 5 #> # Groups:   Well, Bacteria_strain, Phage [6] #>    Time Well  Measurements Bacteria_strain Phage    #>   <dbl> <fct>        <dbl> <chr>           <chr>    #> 1     0 A1           0.002 Strain 1        No Phage #> 2     0 B1           0.002 Strain 7        No Phage #> 3     0 C1           0.002 Strain 13       No Phage #> 4     0 D1           0.002 Strain 19       No Phage #> 5     0 E1           0.002 Strain 25       No Phage #> 6     0 F1           0.002 Strain 31       No Phage ex_dat_mrg <-   mutate(ex_dat_mrg,          Measurements_plus1 = Measurements+1)  head(ex_dat_mrg) #> # A tibble: 6 × 6 #> # Groups:   Well, Bacteria_strain, Phage [6] #>    Time Well  Measurements Bacteria_strain Phage    Measurements_plus1 #>   <dbl> <fct>        <dbl> <chr>           <chr>                 <dbl> #> 1     0 A1           0.002 Strain 1        No Phage               1.00 #> 2     0 B1           0.002 Strain 7        No Phage               1.00 #> 3     0 C1           0.002 Strain 13       No Phage               1.00 #> 4     0 D1           0.002 Strain 19       No Phage               1.00 #> 5     0 E1           0.002 Strain 25       No Phage               1.00 #> 6     0 F1           0.002 Strain 31       No Phage               1.00 ex_dat_mrg <-   mutate(ex_dat_mrg,          Measurements_plus1 = Measurements+1,          Measurements_plus2 = Measurements+2)  head(ex_dat_mrg) #> # A tibble: 6 × 7 #> # Groups:   Well, Bacteria_strain, Phage [6] #>    Time Well  Measurements Bacteria_strain Phage    Measurements_plus1 Measure…¹ #>   <dbl> <fct>        <dbl> <chr>           <chr>                 <dbl>     <dbl> #> 1     0 A1           0.002 Strain 1        No Phage               1.00      2.00 #> 2     0 B1           0.002 Strain 7        No Phage               1.00      2.00 #> 3     0 C1           0.002 Strain 13       No Phage               1.00      2.00 #> 4     0 D1           0.002 Strain 19       No Phage               1.00      2.00 #> 5     0 E1           0.002 Strain 25       No Phage               1.00      2.00 #> 6     0 F1           0.002 Strain 31       No Phage               1.00      2.00 #> # … with abbreviated variable name ¹​Measurements_plus2"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/process.html","id":"CalculatingDerivatives","dir":"Articles","previous_headings":"","what":"Processing data: calculating derivatives","title":"Processing data","text":"many cases, identifying features growth curve requires looking absorbance data time, slope absorbance data time. gcplyr includes calc_deriv function can used calculate empirical derivative (slope) absorbance data time.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/process.html","id":"a-simple-derivative","dir":"Articles","previous_headings":"Processing data: calculating derivatives","what":"A simple derivative","title":"Processing data","text":"calculate simple derivative (slope original data) using calc_deriv, simply provide x y values. Note growth rate cells, rather measure quickly whole population growing time point. useful identifying events like population declines, multiple rounds growth. visualize results, let’s look wells representative overall diversity dynamics example data. (code, visualize data).  first thing might notice lines aren’t smooth might expect. ? noise derivatives actually created limited resolution plate reader. Since plate readers can commonly read resolution 0.001, means values jump least 0.001 step, even true difference smaller. aside, plots can clearly see upward slope total population steepest, also populations declined wells phages. Well E11 can even see bacteria grow later phage-driven declines. derivatives also make something apparent might obvious visually raw density data: look Well A1 can see second peak growth. ’s steep (derivative high), ’s . pattern common bacterial growth curves called diauxic growth.","code":"ex_dat_mrg <- mutate(ex_dat_mrg,                      deriv = calc_deriv(x = Time, y = Measurements)) sample_wells <- c(\"A1\", \"F1\", \"F10\", \"E11\")  #Now let's plot the derivative ggplot(data = dplyr::filter(ex_dat_mrg, Well %in% sample_wells),        aes(x = Time, y = deriv)) +   geom_line() +   facet_wrap(~Well, scales = \"free\") #> Warning: Removed 1 row containing missing values (`geom_line()`)."},{"path":"https://mikeblazanin.github.io/gcplyr/articles/process.html","id":"per-capita-derivative","dir":"Articles","previous_headings":"Processing data: calculating derivatives","what":"Per-capita derivative","title":"Processing data","text":"want calculate growth rate cells, need use calc_deriv return per-capita derivative. Just , provide x y values, now set percapita = TRUE. Note case, required specify blank value, .e. value Measurements corresponds population density 0. data already normalized, simply add blank = 0.  Hmm, ’s going ? Well, bacterial densities close 0, per-capita growth rate can noisy. Luckily, calc_deriv includes method can reduce effects noise. Instead calculating derivative point relative next, can use moving window two points fit linear regression data. can help reduce effect low densities. use fitting functionality calc_deriv, need specify either window_width parameter, window_width_n parameter. window_width specifies wide window used include points fitting units x, window_width_n specifies number data points. , ’ll demonstrate ’s use fitting regressions include five data points.  Great! reduced effects low densities greatly! fitting calculate per-capita growth rate, can alternatively fitting log-transformed y-values. exponential growth linear y-values log-transformed, typically gives us better estimate per-capita growth rate, although can fail y-values 0. Check documentation calc_deriv details.  Great! Taking look per-capita growth rates, can see bacteria lag period growth beginning starting grow haveing early peak growth rates.","code":"ex_dat_mrg <- mutate(ex_dat_mrg,                      deriv_percap = calc_deriv(x = Time, y = Measurements,                                         percapita = TRUE, blank = 0))  #Now let's plot the per-capita derivative ggplot(data = dplyr::filter(ex_dat_mrg, Well %in% sample_wells),        aes(x = Time, y = deriv_percap)) +   geom_line() +   facet_wrap(~Well, scales = \"free\") #> Warning: Removed 1 row containing missing values (`geom_line()`). ex_dat_mrg <- mutate(ex_dat_mrg,                      deriv_percap5 = calc_deriv(x = Time, y = Measurements,                                          percapita = TRUE, blank = 0,                                         window_width_n = 5))  #Now let's plot the derivative ggplot(data = dplyr::filter(ex_dat_mrg, Well %in% sample_wells),        aes(x = Time, y = deriv_percap5)) +   geom_line() +   facet_wrap(~Well, scales = \"free\") #> Warning: Removed 4 rows containing missing values (`geom_line()`). ex_dat_mrg <- mutate(ex_dat_mrg,                      deriv_percap5 = calc_deriv(x = Time, y = Measurements,                                          percapita = TRUE, blank = 0,                                         window_width_n = 5, trans_y = \"log\"))  #Now let's plot the derivative ggplot(data = dplyr::filter(ex_dat_mrg, Well %in% sample_wells),        aes(x = Time, y = deriv_percap5)) +   geom_line() +   facet_wrap(~Well, scales = \"free\") #> Warning: Removed 4 rows containing missing values (`geom_line()`)."},{"path":"https://mikeblazanin.github.io/gcplyr/articles/process.html","id":"changing-the-derivative-units","dir":"Articles","previous_headings":"Processing data: calculating derivatives","what":"Changing the derivative units","title":"Processing data","text":"convert x-axis (time) units derivative calculations different unit, use x_scale argument. Simply specify ratio x units desired units. instance, example data x number seconds since growth curve began. wanted growth rate per-hour? 3600 seconds hour, set x_scale = 3600  Now can see bacterial growth rate -understandable units: peak growth rates often around 1-2 divisions/hour.","code":"ex_dat_mrg <-    mutate(ex_dat_mrg,          deriv_percap_hr = calc_deriv(x = Time, y = Measurements,                                       percapita = TRUE, blank = 0,                                       window_width_n = 5, trans_y = \"log\",                                       x_scale = 3600))  #Now let's plot the derivative in units of Abs/hour ggplot(data = dplyr::filter(ex_dat_mrg, Well %in% sample_wells),        aes(x = Time, y = deriv_percap_hr)) +   geom_line() +   facet_wrap(~Well, scales = \"free\") #> Warning: Removed 4 rows containing missing values (`geom_line()`)."},{"path":"https://mikeblazanin.github.io/gcplyr/articles/process.html","id":"whats-next","dir":"Articles","previous_headings":"","what":"What’s next?","title":"Processing data","text":"Now ’ve processed data, ’re ready analyze ! Introduction: vignette(\"gcplyr\") Importing transforming data: vignette(\"import_transform\") Incorporating design information: vignette(\"incorporate_designs\") Pre-processing plotting data: vignette(\"preprocess_plot\") Processing data: vignette(\"process\") Analyzing data: vignette(\"analyze\") Dealing noise: vignette(\"noise\") Statistics, merging data, resources: vignette(\"conclusion\")","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Mike Blazanin. Author, maintainer.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Blazanin, Michael. 2023. 'gcplyr: manipulation analysis growth curves data.' R package version 0.12.3","code":"@Manual{,   title = {{gcplyr}: manipulation and analysis of growth curves data},   author = {Michael Blazanin},   year = {2023},   note = {version 0.12.3},   url = {https://github.com/mikeblazanin/gcplyr/}, }"},{"path":"https://mikeblazanin.github.io/gcplyr/index.html","id":"gcplyr","dir":"","previous_headings":"","what":"Manipulate and Analyze Growth Curve Data","title":"Manipulate and Analyze Growth Curve Data","text":"gcplyr facilitates manipulation analysis bacterial growth curve data. Please send questions, requests, comments, bugs mikeblazanin [] gmail [dot] com","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/index.html","id":"what-this-package-can-do","dir":"","previous_headings":"","what":"What this package can do","title":"Manipulate and Analyze Growth Curve Data","text":"Bacterial density time series data commonly generated plate readers number different formats. gcplyr can flexibly import common formats reshape downstream analyses. Information experimental design elements set growth curves might saved tabular file (e.g. Excel file), may exist non-digitally (e.g. lab notebook). gcplyr can import experimental designs files allow users input information directly gcplyr functions. , gcplyr can merge design elements density data imported files. Growth curves datasets can processed (e.g. smoothing) analyzed using variety gcplyr functions","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Manipulate and Analyze Growth Curve Data","text":"can install gcplyr GitHub running following lines R:","code":"install.packages(\"devtools\") devtools::install_github(\"mikeblazanin/gcplyr\")"},{"path":"https://mikeblazanin.github.io/gcplyr/index.html","id":"getting-started","dir":"","previous_headings":"","what":"Getting Started","title":"Manipulate and Analyze Growth Curve Data","text":"best way get started read articles series, breaks typical workflow using gcplyr start finish, starting introduction: Introduction: vignette(\"gcplyr\") Importing transforming data: vignette(\"import_transform\") Incorporating design information: vignette(\"incorporate_designs\") Pre-processing plotting data: vignette(\"preprocess_plot\") Processing data: vignette(\"process\") Analyzing data: vignette(\"analyze\") Dealing noise: vignette(\"noise\") Statistics, merging data, resources: vignette(\"conclusion\")","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/index.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Manipulate and Analyze Growth Curve Data","text":"Please cite software : Blazanin, Michael. 2022. ‘gcplyr: manipulate analyze growth curve data.’ R package version 0.12.3","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/auc.html","id":null,"dir":"Reference","previous_headings":"","what":"calculate area under the curve — auc","title":"calculate area under the curve — auc","text":"function takes vector x y values returns scalar area curve, calculated using  trapezoid rule","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/auc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"calculate area under the curve — auc","text":"","code":"auc(x, y, xlim = NULL, na.rm = TRUE)"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/auc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"calculate area under the curve — auc","text":"x Numeric vector x values y Numeric vector y values xlim Vector, length 2, delimiting x range area curve calculated (NA can provided area calculated start end data) na.rm logical indicating whether missing values removed","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/auc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"calculate area under the curve — auc","text":"scalar total area curve","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/auc.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"calculate area under the curve — auc","text":"function designed compatible use within  dplyr::group_by dplyr::summarize","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/block_tidydesign.html","id":null,"dir":"Reference","previous_headings":"","what":"Turn tidydesign into block format — block_tidydesign","title":"Turn tidydesign into block format — block_tidydesign","text":"function allows users convert designs created tidydesign  block format easy output csv inclusion lab notebooks,  etc human-readable format","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/block_tidydesign.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Turn tidydesign into block format — block_tidydesign","text":"","code":"block_tidydesign(   tidydesign,   collapse = NULL,   wellnames_sep = \"_\",   wellnames_colname = \"Well\" )"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/block_tidydesign.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Turn tidydesign into block format — block_tidydesign","text":"tidydesign tidydesign data.frame (e.g. created make_tidydesign) collapse NULL string use concatenating design elements together. NULL design column put block. string, string used paste together design elements design elements returned single block wellnames_sep string used concatenating rownames column names create well names wellnames_colname Header newly-created column containing well names","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/block_tidydesign.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Turn tidydesign into block format — block_tidydesign","text":"list blockdesign data.frames (collapse  NULL list length 1","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/calc_deriv.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate derivatives of vector of data — calc_deriv","title":"Calculate derivatives of vector of data — calc_deriv","text":"Provided vector y values, function returns either plain per-capita difference derivative sequential values","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/calc_deriv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate derivatives of vector of data — calc_deriv","text":"","code":"calc_deriv(   y,   x = NULL,   return = \"derivative\",   percapita = FALSE,   x_scale = 1,   blank = NULL,   subset_by = NULL,   window_width = NULL,   window_width_n = NULL,   trans_y = \"linear\",   na.rm = TRUE )"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/calc_deriv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate derivatives of vector of data — calc_deriv","text":"y Data calculate difference derivative x Vector x values provided simple numeric. return One c(\"difference\", \"derivative\") whether differences y returned, derivative y respect x percapita percapita = TRUE, per-capita difference derivative returned x_scale Factor scale x denominator derivative calculation Set x_scale ratio units  x desired units. E.g. x seconds,  desired derivative units /minute, set  x_scale = 60 (since 60 seconds 1 minute). blank y-value associated \"blank\" density 0. required percapita = TRUE. vector blank values specified, blank values assumed order unique(subset_by) subset_by optional vector long y.  y split unique values vector  derivative group calculated  independently others. provides internally-implemented approach similar dplyr::group_by dplyr::mutate window_width_n, window_width Set many data points used determine slope point. NULL, calc_deriv  calculates difference derivative point next point, appending NA end. one specified, linear regression  fit points window determine  slope. window_width_n specifies width window number data points. window_width specifies width window units x. using window_width window_width_n  time, windows conservative. Points  included window meet  window_width window_width_n trans_y One c(\"linear\", \"log\") specifying                 transformation y-values. 'log' available calculating per-capita                 derivatives using fitting approach (non-default                  values specified window_width                  window_width_n). per-capita growth expected exponential                  nearly-exponential, \"log\" recommended, since                  exponential growth linear log-transformed. However,                  log-transformations must used care, since y-values                  0 become undefined results                  sensitive incorrect values blank. na.rm Boolean whether NA's removed analyzing","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/calc_deriv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate derivatives of vector of data — calc_deriv","text":"vector values plain (percapita = FALSE)         per-capita (percapita = TRUE) difference          (return = \"difference\") derivative          (return = \"derivative\") y values. Vector         length y,  NA values          ends","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/calc_deriv.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate derivatives of vector of data — calc_deriv","text":"per-capita derivatives, trans_y = 'linear'          trans_y = 'log' approach value time resolution          increases. instance, assume exponential growth \\(N = e^rt\\)           per-capita growth rate \\(r\\). trans_y = 'linear', note \\(dN/dt = r e^rt = r N\\).           can calculate per-capita growth rate \\(r = dN/dt * 1/N\\). trans_y = 'log', note \\(log(N) = log(e^rt) = rt\\).          can calculate per-capita growth rate slope linear          fit \\(log(N)\\) time, \\(r = log(N)/t\\).","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/example_widedata.html","id":null,"dir":"Reference","previous_headings":"","what":"Example noisy growth curve data in wide format — example_widedata","title":"Example noisy growth curve data in wide format — example_widedata","text":"dataset containing example growth 96 wells simulated bacteria  bacteria phages Wells A1...A8 F1...F8 contain 48 different simulated bacterial strains growing alone. Wells G1...G8 L1...L8 contain 48 bacterial strains identical layout, time growing presence phage","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/example_widedata.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Example noisy growth curve data in wide format — example_widedata","text":"","code":"example_widedata"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/example_widedata.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Example noisy growth curve data in wide format — example_widedata","text":"dataframe 97 rows 97 variables: time time, seconds, since growth curve began A1, A2...H11, H12 bacterial density given well","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/example_widedata.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Example noisy growth curve data in wide format — example_widedata","text":"Bacterial populations exhibit diauxic growth approach carrying capacity, also evolve resistance face  selection phage population. data includes simulated noise approximate noise generated data collection plate readers","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/example_widedata_noiseless.html","id":null,"dir":"Reference","previous_headings":"","what":"Example growth curve data in wide format — example_widedata_noiseless","title":"Example growth curve data in wide format — example_widedata_noiseless","text":"dataset containing example growth 96 wells simulated bacteria  bacteria phages Wells A1...A8 F1...F8 contain 48 different simulated bacterial strains growing alone. Wells G1...G8 L1...L8 contain 48 bacterial strains identical layout, time growing presence phage","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/example_widedata_noiseless.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Example growth curve data in wide format — example_widedata_noiseless","text":"","code":"example_widedata_noiseless"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/example_widedata_noiseless.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Example growth curve data in wide format — example_widedata_noiseless","text":"dataframe 97 rows 97 variables: time time, seconds, since growth curve began A1, A2...H11, H12 bacterial density given well","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/example_widedata_noiseless.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Example growth curve data in wide format — example_widedata_noiseless","text":"Bacterial populations exhibit diauxic growth approach carrying capacity, also evolve resistance face  selection phage population. data include simulated noise","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/find_local_extrema.html","id":null,"dir":"Reference","previous_headings":"","what":"Find local extrema of numeric vector — find_local_extrema","title":"Find local extrema of numeric vector — find_local_extrema","text":"function takes vector y values returns vector indices local value extrema (default, includes local minima local maxima). One window_width,  window_width_n, window_height must provided","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/find_local_extrema.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find local extrema of numeric vector — find_local_extrema","text":"","code":"find_local_extrema(   y,   x = NULL,   window_width = NULL,   window_width_n = NULL,   window_height = NULL,   return = \"index\",   return_maxima = TRUE,   return_minima = TRUE,   return_endpoints = TRUE,   subset = NULL,   na.rm = TRUE,   width_limit = NULL,   width_limit_n = NULL,   height_limit = NULL )"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/find_local_extrema.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Find local extrema of numeric vector — find_local_extrema","text":"y Numeric vector y values identify local extrema x Optional numeric vector corresponding x values window_width Width window (units x) used search local extrema. narrower width sensitive narrow local maxima/minima, wider width less sensitive local maxima/minima. window_width_n maximum number data points single  extrema-search step allowed take. example, maxima-finding, function pass valley consisting window_width_n data points. smaller window_width_n sensitive  narrow local maxima/minima, larger  window_width_n less sensitive  narrow local maxima/minima. window_height maximum change y single extrema-search step allowed take.  example,  maxima-finding, function pass valley deeper window_height. smaller window_height sensitive  shallow local maxima/minima, larger  window_height less sensitive  shallow maxima/minima. return One c(\"index\", \"x\", \"y\"), determining whether function return index, x value, y value associated identified extremas return_maxima, return_minima Boolean classes local extrema return return_endpoints first last values y included returned  vector extrema? subset vector Boolean values indicating x y values included (TRUE) excluded (FALSE). return = \"index\", index whole  vector subset vector na.rm Boolean whether NA's removed analyzing width_limit Deprecated, use window_width instead width_limit_n Deprecated, use window_width_n instead height_limit Deprecated, use window_height instead","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/find_local_extrema.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Find local extrema of numeric vector — find_local_extrema","text":"return = \"index\", vector indices corresponding            local extrema data return = \"x\", vector x values corresponding           local extrema data return = \"y\", vector y values corresponding           local extrema data","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/find_local_extrema.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Find local extrema of numeric vector — find_local_extrema","text":"multiple window_width, window_width_n,  window_height provided, steps limited conservatively  (single step must meet criteria) function designed compatible use within  dplyr::group_by dplyr::summarize case exact ties y values within window_width,  window_width_n, window_height (applicable)  , first local extrema returned.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/find_threshold_crosses.html","id":null,"dir":"Reference","previous_headings":"","what":"Find all points when a numeric vector crosses some threshold — find_threshold_crosses","title":"Find all points when a numeric vector crosses some threshold — find_threshold_crosses","text":"function takes vector y values  returns index x value every point y values cross threshold y value.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/find_threshold_crosses.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find all points when a numeric vector crosses some threshold — find_threshold_crosses","text":"","code":"find_threshold_crosses(   y,   x = NULL,   threshold,   return = \"index\",   return_rising = TRUE,   return_falling = TRUE,   return_endpoints = TRUE,   subset = NULL,   na.rm = TRUE )"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/find_threshold_crosses.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Find all points when a numeric vector crosses some threshold — find_threshold_crosses","text":"y Numeric vector y values identify threshold crossing events x Optional numeric vector corresponding x values threshold Threshold y value interest return One c(\"index\", \"x\"), determining whether function return index x value associated threshold-crossing event. index, refer data point immediately crossing event. x, use linear interpolation data points immediately threshold-crossing return exact x value threshold crossing occurred return_rising Boolean whether crossing events y rises threshold returned return_falling Boolean whether crossing events y falls threshold returned return_endpoints Boolean whether startpoint returned startpoint threshold return_rising = TRUE, startpoint threshold return_falling = TRUE subset vector Boolean values indicating x y values included (TRUE) excluded (FALSE). return = \"index\", index whole  vector subset vector na.rm Boolean whether NA's removed analyzing. return = 'index', indices refer original y vector *including* NA values","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/find_threshold_crosses.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Find all points when a numeric vector crosses some threshold — find_threshold_crosses","text":"vector indices (return = \"index\") x values         (return = \"x\") y crossed threshold","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/first_below.html","id":null,"dir":"Reference","previous_headings":"","what":"Find the first point when a numeric vector falls below some threshold — first_below","title":"Find the first point when a numeric vector falls below some threshold — first_below","text":"function takes vector y values  returns index (default) first point falls threshold y value. function essentially wrapper  find_threshold_crosses(return_rising = FALSE, return_falling = TRUE)[1]","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/first_below.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find the first point when a numeric vector falls below some threshold — first_below","text":"","code":"first_below(   y,   x = NULL,   threshold,   return = \"index\",   return_endpoints = TRUE,   subset = NULL,   na.rm = TRUE,   ... )"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/first_below.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Find the first point when a numeric vector falls below some threshold — first_below","text":"y Numeric vector y values identify first point x Optional numeric vector corresponding x values threshold Threshold y value interest return One c(\"index\", \"x\"), determining whether function return index x value associated  first-point. index, refer first data point threshold. x, use linear interpolation data points immediately threshold-crossing return exact x value y first came threshold return_endpoints Boolean whether startpoint returned startpoint threshold subset vector Boolean values indicating x y values included (TRUE) excluded (FALSE). return = \"index\", index whole  vector subset vector na.rm Boolean whether NA's removed analyzing. return = 'index', indices refer original y vector *including* NA values ... arguments pass find_threshold_crosses","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/first_below.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Find the first point when a numeric vector falls below some threshold — first_below","text":"vector indices (return = \"index\") x values         (return = \"x\") y crossed threshold","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/first_below.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Find the first point when a numeric vector falls below some threshold — first_below","text":"function designed compatible use within  dplyr::group_by dplyr::summarize","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/first_peak.html","id":null,"dir":"Reference","previous_headings":"","what":"Find the first local peak of a numeric vector — first_peak","title":"Find the first local peak of a numeric vector — first_peak","text":"function takes vector y values returns index (default) first local maxima. serves wrapper function find_local_extrema","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/first_peak.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find the first local peak of a numeric vector — first_peak","text":"","code":"first_peak(   y,   x = NULL,   window_width = NULL,   window_width_n = NULL,   window_height = NULL,   return = \"index\",   return_endpoints = TRUE,   ... )"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/first_peak.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Find the first local peak of a numeric vector — first_peak","text":"y Numeric vector y values identify local extrema x Optional numeric vector corresponding x values window_width Width window (units x) used search local extrema. narrower width sensitive narrow local maxima/minima, wider width less sensitive local maxima/minima. window_width_n maximum number data points single  extrema-search step allowed take. example, maxima-finding, function pass valley consisting window_width_n data points. smaller window_width_n sensitive  narrow local maxima/minima, larger  window_width_n less sensitive  narrow local maxima/minima. provided, defaults ~0.2*length(y) window_height maximum change y single extrema-search step allowed take.  example,  maxima-finding, function pass valley deeper window_height. smaller window_height sensitive  shallow local maxima/minima, larger  window_height less sensitive  shallow maxima/minima. return One c(\"index\", \"x\", \"y\"), determining whether function return index, x value, y value associated first peak y values return_endpoints first last value y allowed returned? ... parameters pass find_local_extrema","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/first_peak.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Find the first local peak of a numeric vector — first_peak","text":"return = \"index\", vector indices corresponding            local extrema data return = \"x\", vector x values corresponding           local extrema data return = \"y\", vector y values corresponding           local extrema data","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/first_peak.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Find the first local peak of a numeric vector — first_peak","text":"none window_width, window_width_n,  window_height provided, default value window_width_n used. function designed compatible use within  dplyr::group_by dplyr::summarize","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/from_excel.html","id":null,"dir":"Reference","previous_headings":"","what":"A function that converts base-26 Excel-style letters to numbers — from_excel","title":"A function that converts base-26 Excel-style letters to numbers — from_excel","text":"function converts base-26 Excel-style letters numbers","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/from_excel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A function that converts base-26 Excel-style letters to numbers — from_excel","text":"","code":"from_excel(x)"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/from_excel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A function that converts base-26 Excel-style letters to numbers — from_excel","text":"x vector numbers Excel-style base-26 letter format","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/from_excel.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A function that converts base-26 Excel-style letters to numbers — from_excel","text":"vector numbers base-10","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/import_blockdesigns.html","id":null,"dir":"Reference","previous_headings":"","what":"Import blockdesigns — import_blockdesigns","title":"Import blockdesigns — import_blockdesigns","text":"Function import block-shaped designs files return tidy designs. function acts wrapper call read_blocks,  paste_blocks, trans_block_to_wide, trans_wide_to_tidy,  separate_tidys one go","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/import_blockdesigns.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Import blockdesigns — import_blockdesigns","text":"","code":"import_blockdesigns(files, block_names = NULL, sep = NULL, ...)"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/import_blockdesigns.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Import blockdesigns — import_blockdesigns","text":"files Vector filenames (strings),  block-shaped designs file. Inputs can .csv, .xls, .xlsx block_names Vector names design elements. resulting column names output data frame.  order files /order corresponding files . NULL, file names used column names. sep block design files already pasted, sep specifies string separating design elements NULL, import_blockdesigns assume elements already pasted together attempt find character used imported files paste later separate design elements. ... arguments pass read_blocks,  paste_blocks, trans_block_to_wide, trans_wide_to_tidy, separate_tidy. See Details information","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/import_blockdesigns.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Import blockdesigns — import_blockdesigns","text":"tidy-shaped data.frame containing design information         files","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/import_blockdesigns.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Import blockdesigns — import_blockdesigns","text":"Common arguments may want provide include: startrow, endrow, startcol, endcol,               sheet - specifying location design information               inside files read_blocks wellnames_sep - specifying character (\"\" none)              used pasting together rownames              column names. Note chosen match              wellnames measures. Note import_blockdesigns currently handle              metadata specified via metadata argument              read_blocks","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/import_blockmeasures.html","id":null,"dir":"Reference","previous_headings":"","what":"Import blockmeasures — import_blockmeasures","title":"Import blockmeasures — import_blockmeasures","text":"Function import blockmeasures files return widemeasures function acts wrapper call read_blocks, uninterleave,  trans_block_to_wide one go","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/import_blockmeasures.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Import blockmeasures — import_blockmeasures","text":"","code":"import_blockmeasures(   files,   num_plates = 1,   plate_names = NULL,   wellnames_sep = \"\",   ... )"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/import_blockmeasures.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Import blockmeasures — import_blockmeasures","text":"files Vector filenames (strings),  block-shaped file containing measures data. File formats can .csv, .xls, .xlsx num_plates Number plates. multiple plates uninterleave used separate blockmeasures plates accordingly plate_names (optional) Names put onto plates output wellnames_sep String use separator well names  rowname column name ... arguments pass read_blocks, uninterleave, widen_blocks","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/import_blockmeasures.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Import blockmeasures — import_blockmeasures","text":"num_plates = 1, wide-shaped data.frame containing measures data. num_plates greater one, list  data.frame's, data.frame wide-shaped.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/import_blockmeasures.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Import blockmeasures — import_blockmeasures","text":"Common arguments may want provide include: startrow, endrow, startcol, endcol,               sheet - specifying location design information               inside files read_blocks metadata - specifying metadata read_blocks See help read_blocks details","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/make_design.html","id":null,"dir":"Reference","previous_headings":"","what":"Make design data.frame(s) — make_design","title":"Make design data.frame(s) — make_design","text":"function easily input experimental design elements later merging read data","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/make_design.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make design data.frame(s) — make_design","text":"","code":"make_design(   nrows = NULL,   ncols = NULL,   block_row_names = NULL,   block_col_names = NULL,   output_format = \"tidy\",   wellnames_numeric = FALSE,   wellnames_sep = \"\",   wellnames_colname = \"Well\",   colnames_first = FALSE,   lookup_tbl_start = 1,   pattern_split = \"\",   ... )"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/make_design.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make design data.frame(s) — make_design","text":"nrows, ncols Number rows columns plate data block_row_names, block_col_names Names rows, columns plate blockmeasures data output_format One c(\"blocks\", \"blocks_pasted\", \"wide\", \"tidy\") denoting format resulting data.frame easy merging tidymeasures, leave default 'tidy'. human-readability confirm design correct, choose 'blocks' 'blocks_pasted'. writing block-shaped file(s), choose 'blocks' 'blocks_pasted'. wellnames_numeric block_row_names block_col_names specified, names generated automatically according wellnames_numeric. wellnames_numeric TRUE, rows columns numbered \"R\" \"C\" prefixes, respectively. wellnames_numeric FALSE, rows lettered Z, columns numbered wellnames_sep string used concatenating rownames column names create well names,  output_format = \"wide\"  output_format = \"tidy\" wellnames_colname Header newly-created column containing well names, output_format = \"tidy\" colnames_first wellnames created  output_format = \"wide\"  output_format = \"tidy\" paste-ing rownames column names, column names come first. lookup_tbl_start Value lookup table split pattern values corresponds first value vector. Lookup table default  c(1,2,...,8,9,,B,...Y,Z,,b,...,y,z). , example, lookup_tbl_start = \"\", lookup table now c(,B,...Y,Z,,b,...,y,z) pattern_split character split pattern elements provided ... , already vector ... ... argument must list five elements: 1. vector values 2. vector rows pattern applied 3. vector columns pattern applied 4. string vector denoting pattern                 values filled rows columns specified. string, split pattern_split.                 Pattern used indices values vector. 0's refer NA 5. Boolean whether pattern filled byrow","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/make_design.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Make design data.frame(s) — make_design","text":"Depends output_format: output_format = \"blocks\", list data.frame's         data.frame block-shaped containing         information single design element output_format = \"blocks_pasted\", single  data.frame containing paste-ed information         design elements output_format = \"wide\", wide-shaped data.frame containing design elements output_format = \"tidy\", tidy-shaped data.frame containing design elements","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/make_design.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Make design data.frame(s) — make_design","text":"Note either nrows block_row_names must provided either ncols block_col_names must provided","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/make_design.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Make design data.frame(s) — make_design","text":"","code":"make_design(nrows = 8, ncols = 12,             design_element_name = list(c(\"A\", \"B\", \"C\"),                                        2:7,                                        2:11,                                        \"112301\",                                         TRUE)) #>    Well design_element_name #> 1    A1                <NA> #> 2    A2                <NA> #> 3    A3                <NA> #> 4    A4                <NA> #> 5    A5                <NA> #> 6    A6                <NA> #> 7    A7                <NA> #> 8    A8                <NA> #> 9    A9                <NA> #> 10  A10                <NA> #> 11  A11                <NA> #> 12  A12                <NA> #> 13   B1                <NA> #> 14   B2                   A #> 15   B3                   A #> 16   B4                   B #> 17   B5                   C #> 18   B6                <NA> #> 19   B7                   A #> 20   B8                   A #> 21   B9                   A #> 22  B10                   B #> 23  B11                   C #> 24  B12                <NA> #> 25   C1                <NA> #> 26   C2                <NA> #> 27   C3                   A #> 28   C4                   A #> 29   C5                   A #> 30   C6                   B #> 31   C7                   C #> 32   C8                <NA> #> 33   C9                   A #> 34  C10                   A #> 35  C11                   A #> 36  C12                <NA> #> 37   D1                <NA> #> 38   D2                   B #> 39   D3                   C #> 40   D4                <NA> #> 41   D5                   A #> 42   D6                   A #> 43   D7                   A #> 44   D8                   B #> 45   D9                   C #> 46  D10                <NA> #> 47  D11                   A #> 48  D12                <NA> #> 49   E1                <NA> #> 50   E2                   A #> 51   E3                   A #> 52   E4                   B #> 53   E5                   C #> 54   E6                <NA> #> 55   E7                   A #> 56   E8                   A #> 57   E9                   A #> 58  E10                   B #> 59  E11                   C #> 60  E12                <NA> #> 61   F1                <NA> #> 62   F2                <NA> #> 63   F3                   A #> 64   F4                   A #> 65   F5                   A #> 66   F6                   B #> 67   F7                   C #> 68   F8                <NA> #> 69   F9                   A #> 70  F10                   A #> 71  F11                   A #> 72  F12                <NA> #> 73   G1                <NA> #> 74   G2                   B #> 75   G3                   C #> 76   G4                <NA> #> 77   G5                   A #> 78   G6                   A #> 79   G7                   A #> 80   G8                   B #> 81   G9                   C #> 82  G10                <NA> #> 83  G11                   A #> 84  G12                <NA> #> 85   H1                <NA> #> 86   H2                <NA> #> 87   H3                <NA> #> 88   H4                <NA> #> 89   H5                <NA> #> 90   H6                <NA> #> 91   H7                <NA> #> 92   H8                <NA> #> 93   H9                <NA> #> 94  H10                <NA> #> 95  H11                <NA> #> 96  H12                <NA>                            ## To be reminded what arguments are needed, use make_designpattern: make_design(nrows = 8, ncols = 12,             design_element_name = make_designpattern(                  values = c(\"A\", \"B\", \"C\"),                  rows = 2:7,                   cols = 2:11,                  pattern = \"112301\",                  byrow = TRUE))               #>    Well design_element_name #> 1    A1                <NA> #> 2    A2                <NA> #> 3    A3                <NA> #> 4    A4                <NA> #> 5    A5                <NA> #> 6    A6                <NA> #> 7    A7                <NA> #> 8    A8                <NA> #> 9    A9                <NA> #> 10  A10                <NA> #> 11  A11                <NA> #> 12  A12                <NA> #> 13   B1                <NA> #> 14   B2                   A #> 15   B3                   A #> 16   B4                   B #> 17   B5                   C #> 18   B6                <NA> #> 19   B7                   A #> 20   B8                   A #> 21   B9                   A #> 22  B10                   B #> 23  B11                   C #> 24  B12                <NA> #> 25   C1                <NA> #> 26   C2                <NA> #> 27   C3                   A #> 28   C4                   A #> 29   C5                   A #> 30   C6                   B #> 31   C7                   C #> 32   C8                <NA> #> 33   C9                   A #> 34  C10                   A #> 35  C11                   A #> 36  C12                <NA> #> 37   D1                <NA> #> 38   D2                   B #> 39   D3                   C #> 40   D4                <NA> #> 41   D5                   A #> 42   D6                   A #> 43   D7                   A #> 44   D8                   B #> 45   D9                   C #> 46  D10                <NA> #> 47  D11                   A #> 48  D12                <NA> #> 49   E1                <NA> #> 50   E2                   A #> 51   E3                   A #> 52   E4                   B #> 53   E5                   C #> 54   E6                <NA> #> 55   E7                   A #> 56   E8                   A #> 57   E9                   A #> 58  E10                   B #> 59  E11                   C #> 60  E12                <NA> #> 61   F1                <NA> #> 62   F2                <NA> #> 63   F3                   A #> 64   F4                   A #> 65   F5                   A #> 66   F6                   B #> 67   F7                   C #> 68   F8                <NA> #> 69   F9                   A #> 70  F10                   A #> 71  F11                   A #> 72  F12                <NA> #> 73   G1                <NA> #> 74   G2                   B #> 75   G3                   C #> 76   G4                <NA> #> 77   G5                   A #> 78   G6                   A #> 79   G7                   A #> 80   G8                   B #> 81   G9                   C #> 82  G10                <NA> #> 83  G11                   A #> 84  G12                <NA> #> 85   H1                <NA> #> 86   H2                <NA> #> 87   H3                <NA> #> 88   H4                <NA> #> 89   H5                <NA> #> 90   H6                <NA> #> 91   H7                <NA> #> 92   H8                <NA> #> 93   H9                <NA> #> 94  H10                <NA> #> 95  H11                <NA> #> 96  H12                <NA>"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/make_designpattern.html","id":null,"dir":"Reference","previous_headings":"","what":"Make design pattern — make_designpattern","title":"Make design pattern — make_designpattern","text":"helper function use make_tidydesign","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/make_designpattern.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make design pattern — make_designpattern","text":"","code":"make_designpattern(values, rows, cols, pattern, byrow = TRUE)"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/make_designpattern.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make design pattern — make_designpattern","text":"values Vector values use rows Vector rows pattern applies cols Vector cols pattern applies pattern Numeric pattern , numbers refer entries values byrow Boolean whether pattern created row","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/make_designpattern.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Make design pattern — make_designpattern","text":"list(values, rows, cols, pattern, byrow)","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/make_designpattern.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Make design pattern — make_designpattern","text":"Example: my_example <- make_tidydesign(nrows = 8, ncols = 12,       design_element_name = make_designpattern(values = c(\"L\", \"G\", \"C\"),                                                 rows = 2:7, cols = 2:11,                                                 pattern = \"11223300\",                                                 byrow = TRUE))","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/make_tidydesign.html","id":null,"dir":"Reference","previous_headings":"","what":"Make tidy design data.frames — make_tidydesign","title":"Make tidy design data.frames — make_tidydesign","text":"function easily input experimental design elements later merging read data","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/make_tidydesign.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make tidy design data.frames — make_tidydesign","text":"","code":"make_tidydesign(   nrows = NULL,   ncols = NULL,   block_row_names = NULL,   block_col_names = NULL,   wellnames_sep = \"\",   wellnames_colname = \"Well\",   wellnames_Excel = TRUE,   lookup_tbl_start = 1,   pattern_split = \"\",   colnames_first = FALSE,   ... )"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/make_tidydesign.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make tidy design data.frames — make_tidydesign","text":"nrows, ncols Number rows columns plate data block_row_names, block_col_names Names rows, columns plate blockmeasures data wellnames_sep string used concatenating rownames column names create well names wellnames_colname Header newly-created column containing well names wellnames_Excel block_row_names block_col_names specified, rows columns named using Excel-style base-26 lettering rows numbering columns? FALSE, rows columns numbered \"R\" \"C\" prefix. lookup_tbl_start Value lookup table split pattern values corresponds first value vector. Lookup table default  c(1,2,...,8,9,,B,...Y,Z,,b,...,y,z). , example, lookup_tbl_start = \"\", lookup table now c(,B,...Y,Z,,b,...,y,z) pattern_split character split pattern elements provided ... colnames_first wellnames created paste-ing rownames column names, column names come first ... ... argument must list five elements: 1. vector values 2. vector rows pattern applied 3. vector columns pattern applied 4. string pattern , numbers refer               indices values vector 0's refer NA pattern split using pattern_split,               defaults every character 5. Boolean whether pattern filled byrow","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/make_tidydesign.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Make tidy design data.frames — make_tidydesign","text":"Note either nrows block_row_names must provided either ncols block_col_names must provided Examples: my_example <- make_tidydesign(nrows = 8, ncols = 12,         design_element_name = list(c(\"Value1\", \"Value2\", \"Value3\"),                           rowstart:rowend, colstart:colend,                           \"111222333000\", TRUE) make easier pass arguments, use make_designpattern: my_example <- make_tidydesign(nrows = 8, ncols = 12,       design_element_name = make_designpattern(values = c(\"L\", \"G\", \"C\"),                                                 rows = 2:7, cols = 2:11,                                                 pattern = \"11223300\",                                                 byrow = TRUE))","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/merge_dfs.html","id":null,"dir":"Reference","previous_headings":"","what":"Collapse a list of dataframes, or merge two dataframes together — merge_dfs","title":"Collapse a list of dataframes, or merge two dataframes together — merge_dfs","text":"function essentially wrapper dplyr::full_join typical use function merge designs  measures data, use collapse functionality  function merge list dataframes single dataframe. Merging done column-names match x y.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/merge_dfs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Collapse a list of dataframes, or merge two dataframes together — merge_dfs","text":"","code":"merge_dfs(   x,   y = NULL,   by = NULL,   drop = FALSE,   collapse = FALSE,   names_to = NA,   ... )"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/merge_dfs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Collapse a list of dataframes, or merge two dataframes together — merge_dfs","text":"x First data.frame, list data frames, joined y Second data.frame, list data frames, joined character vector variables join , passed directly dplyr::full_join drop complete_cases resulting data.frame returned? collapse Boolean indicating whether x y list containing data frames merged together merged names_to Column name names(x) names(y)  entered collapse = TRUE. value NA names(x)  names(y) put column returned data.frame ... arguments pass dplyr::full_join","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/merge_dfs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Collapse a list of dataframes, or merge two dataframes together — merge_dfs","text":"Data.frame containing merged output x  y","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/moving_average.html","id":null,"dir":"Reference","previous_headings":"","what":"Moving average smoothing — moving_average","title":"Moving average smoothing — moving_average","text":"function uses moving average smooth data","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/moving_average.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Moving average smoothing — moving_average","text":"","code":"moving_average(   formula,   data,   window_width_n = NULL,   window_width = NULL,   na.rm = TRUE )"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/moving_average.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Moving average smoothing — moving_average","text":"formula Formula specifying numeric response (density)  numeric predictor (time). data Dataframe containing variables formula window_width_n Number data points wide moving average window (therefore, must odd number points) window_width Width moving average window (units x) na.rm Boolean whether NA's removed analyzing","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/moving_average.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Moving average smoothing — moving_average","text":"Vector smoothed data, NA's appended ends","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/moving_median.html","id":null,"dir":"Reference","previous_headings":"","what":"Moving median smoothing — moving_median","title":"Moving median smoothing — moving_median","text":"function uses moving median smooth data","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/moving_median.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Moving median smoothing — moving_median","text":"","code":"moving_median(   formula,   data,   window_width_n = NULL,   window_width = NULL,   na.rm = TRUE )"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/moving_median.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Moving median smoothing — moving_median","text":"formula Formula specifying numeric response (density)  numeric predictor (time). data Dataframe containing variables formula window_width_n Number data points wide moving median window (therefore, must odd number points) window_width Width moving median window (units x)| na.rm Boolean whether NA's removed analyzing","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/moving_median.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Moving median smoothing — moving_median","text":"Vector smoothed data, NA's appended ends","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/paste_blocks.html","id":null,"dir":"Reference","previous_headings":"","what":"Paste a list of blocks into a single block — paste_blocks","title":"Paste a list of blocks into a single block — paste_blocks","text":"function uses paste concatenate -location entries list data.frames together (.e. first row-first column values pasted together, second row-first column values pasted together, etc.)","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/paste_blocks.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Paste a list of blocks into a single block — paste_blocks","text":"","code":"paste_blocks(blocks, sep = \"_\", nested_metadata = NULL)"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/paste_blocks.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Paste a list of blocks into a single block — paste_blocks","text":"blocks Blocks, either single data.frame list data.frames sep String use separator output pasted values nested_metadata Boolean indicating existence nested metadata blockmeasures list, e.g. typically output read_blocks. NULL, attempt infer existence nested metadata","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/paste_blocks.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Paste a list of blocks into a single block — paste_blocks","text":"nested_metadata = TRUE (inferred TRUE), list         containing list containing: 1. data.frame         pasted data values blocks, 2. vector          pasted metadata values blocks nested_metadata = FALSE (inferred FALSE), list         containing data.frame's pasted values  blocks","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/read_blocks.html","id":null,"dir":"Reference","previous_headings":"","what":"Read blockmeasures — read_blocks","title":"Read blockmeasures — read_blocks","text":"function reads block measures R environment","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/read_blocks.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read blockmeasures — read_blocks","text":"","code":"read_blocks(   files,   extension = NULL,   startrow = NULL,   endrow = NULL,   startcol = NULL,   endcol = NULL,   sheet = NULL,   metadata = NULL,   block_names = NULL,   header = NA,   sider = NA,   wellnames_numeric = FALSE,   na.strings = c(\"NA\", \"\"),   ... )"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/read_blocks.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read blockmeasures — read_blocks","text":"files vector filepaths relative current working directory filepath single plate read extension (optional) extension files: \"csv\", \"xls\", \"xlsx\", \"tbl\" use read.table none provided, read_blocks infer file extension provided filenames. extension \"csv\", \"xls\", \"xlsx\" use utils::read.table startrow, endrow, startcol, endcol (optional) rows columns  measures data files, can vector list length files, single value applies files. provided data presumed begin first row column files. sheet (optional) data .xls .xlsx files, sheet  located . Defaults first sheet specified metadata (optional) non-spectrophotometric data  associated read blockmeasures. named list  item list either: vector length 2, list containing two vectors. former case, vector provide row  column metadata located blockmeasures input files. latter case, first vector provide rows metadata located corresponding input files, second vector provide  columns metadata located corresponding input files. (case typically used  reading multiple blocks single file.) block_names (optional) vector names corresponding plate files. provided, block_names inferred filenames header TRUE, FALSE, NA, vector values, indicating whether file(s) contains column names first line. header = NA attempt infer presence column names. header = FALSE column names inferred  header = NA, column names generated automatically according wellnames_numeric sider TRUE, FALSE, NA, vector values, indicating whether file(s) contains row names first line. sider = NA attempt infer presence row names. sider = FALSE row names inferred  sider = NA, row names generated automatically according wellnames_numeric wellnames_numeric row names column names provided input dataframe specified header sider, names generated automatically according wellnames_numeric. wellnames_numeric TRUE, rows columns numbered \"R\" \"C\" prefixes, respectively. wellnames_numeric FALSE, rows lettered Z, columns numbered na.strings character vector strings interpreted NA values utils::read.csv, readxl::read_xls, readxl::read_xlsx, utils::read.table ... arguments passed utils::read.csv, readxl::read_xls, readxl::read_xlsx, utils::read.table","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/read_blocks.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Read blockmeasures — read_blocks","text":"list entry list containing block data frame         followed block_names (filenames, block_names          provided) specified metadata.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/read_blocks.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Read blockmeasures — read_blocks","text":"metadata, read_blocks can handle arbitrary number additional  pieces information extract blockcurve file metadata.  pieces information specified named list vectors  vector c(row, column) information  pulled input files. metadata returned second list element  blockcurve, e.g.: [[1]] [1] \"data\" #1 [2] \"metadata\"  [2][1] name #1 [2][2] date-time #1 [2][3] temp #1 [[2]] [1] \"data\" #2 [2] \"metadata\"  [2][1] name #2 [2][2] date-time #2 [2][3] temp #2 ... Calling uninterleave output read_blocks works block data  associated metadata uninterleave operates highest   level entries list ([[1]] [[2]] level items),   leaving meta-data associated block data trans_block_to_wide integrates metadata  wide-shaped dataframe produces","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/read_tidys.html","id":null,"dir":"Reference","previous_headings":"","what":"Read tidy-shaped files — read_tidys","title":"Read tidy-shaped files — read_tidys","text":"function imports tidy-shaped files R. Largely acts wrapper utils::read.csv, readxl::read_xls, readxl::read_xls, readxl::read_xlsx, can handle multiple files additional options taking subsets  rows/columns rather entire file adding filename  run names added column output.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/read_tidys.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read tidy-shaped files — read_tidys","text":"","code":"read_tidys(   files,   extension = NULL,   startrow = NULL,   endrow = NULL,   startcol = NULL,   endcol = NULL,   sheet = NULL,   run_names = NULL,   names_to_col = NULL,   na.strings = c(\"NA\", \"\"),   ... )"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/read_tidys.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read tidy-shaped files — read_tidys","text":"files vector filepaths (relative current working directory) one tidy-shaped data file extension (optional) extension files: \"csv\", \"xls\", \"xlsx\", \"tbl\" use read.table none provided, read_tidys infer file  extension provided filenames. extension  \"csv\", \"xls\", \"xlsx\" use utils::read.table startrow, endrow, startcol, endcol (optional) rows columns data located. none provided assumes entire file data. Can specified numeric using base-26 Excel letter notation sheet sheet input files data located (input files .xls .xlsx). specified defaults first run_names Names give tidy files read . default uses file names specified. names may added resulting data frame depending value names_to_col argument names_to_col run names (provided run_names inferred files) added column output? names_to_col TRUE, added . column name \"run_name\" names_to_col FALSE, added. names_to_col string, added column name string specified names_to_col. names_to_col NULL,  added multiple tidy data.frames read. case, column name \"run_name\" na.strings character vector strings interpreted NA values utils::read.csv, readxl::read_xls, readxl::read_xlsx, utils::read.table ... arguments passed utils::read.csv, readxl::read_xls, readxl::read_xlsx, utils::read.table sheet","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/read_tidys.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Read tidy-shaped files — read_tidys","text":"dataframe containing single tidy data.frame,         list tidy-shaped data.frames named filename","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/read_tidys.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Read tidy-shaped files — read_tidys","text":"startrow, endrow, startcol, endcol,  sheet extension can either single value  applies files vectors lists length files Note startrow always assumed header","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/read_wides.html","id":null,"dir":"Reference","previous_headings":"","what":"Read wides — read_wides","title":"Read wides — read_wides","text":"function imports widemeasures files R environment","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/read_wides.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read wides — read_wides","text":"","code":"read_wides(   files,   extension = NULL,   startrow = NULL,   endrow = NULL,   startcol = NULL,   endcol = NULL,   header = TRUE,   sheet = NULL,   run_names = NULL,   names_to_col = \"file\",   metadata = NULL,   na.strings = c(\"NA\", \"\"),   ... )"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/read_wides.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read wides — read_wides","text":"files vector filepaths (relative current working directory) one widemeasures set data extension (optional) extension files: \"csv\", \"xls\", \"xlsx\", \"tbl\" use read.table none provided, read_wides infer file  extension provided filenames. extension  \"csv\", \"xls\", \"xlsx\" use utils::read.table startrow, endrow, startcol, endcol (optional) rows columns data located. none provided assumes entire file data. Can specified numeric using base-26 Excel letter notation header Boolean whether header data. FALSE columns simple numbered. TRUE row startrow (startrow specified) first row input files (startrow specified) sheet sheet input files data located (input files .xls .xlsx). specified defaults first sheet run_names Names give widemeasures read . default uses file names specified names_to_col run names (provided run_names inferred files) added column widemeasures? names_to_col NULL, . names_to_col string, string column header column names stored metadata (optional) non-spectrophotometric data  associated read widemeasures. named list  item list either: vector length 2, list containing two vectors. former case, vector provide row  column metadata located blockmeasures input files. latter case, first vector provide rows metadata located corresponding input files, second vector provide  columns metadata located corresponding input files. (case typically used  reading multiple blocks single file.) na.strings character vector strings interpreted NA values utils::read.csv, readxl::read_xls, readxl::read_xlsx, utils::read.table ... arguments passed utils::read.csv, readxl::read_xls, readxl::read_xlsx, utils::read.table","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/read_wides.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Read wides — read_wides","text":"dataframe containing single widemeasures,         list widemeasures named filename","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/read_wides.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Read wides — read_wides","text":"startrow, endrow, startcol, endcol, timecol, sheet extension  can either single value applies files vectors lists length files,","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/separate_tidy.html","id":null,"dir":"Reference","previous_headings":"","what":"Separate a column into multiple columns — separate_tidy","title":"Separate a column into multiple columns — separate_tidy","text":"function primarily wrapper tidyr::separate, turns single character column multiple columns","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/separate_tidy.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Separate a column into multiple columns — separate_tidy","text":"","code":"separate_tidy(data, col, into = NULL, sep = \"_\", ...)"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/separate_tidy.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Separate a column into multiple columns — separate_tidy","text":"data data frame col Column name position character vector new column names. Use NA omit variable output. NULL, separate_gc attempt infer new column names column name col sep Separator columns passed tidyr::separate: character, sep interpreted regular expression. numeric, sep interpreted character positions            split . Positive values start 1 far-left            string; negative values start -1 far-right            string. length sep one less             ... arguments passed tidyr::separate","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/separate_tidy.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Separate a column into multiple columns — separate_tidy","text":"data frame containing new columns place col","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/smooth_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Smooth data — smooth_data","title":"Smooth data — smooth_data","text":"function calls functions smooth growth curve data","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/smooth_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Smooth data — smooth_data","text":"","code":"smooth_data(   ...,   x = NULL,   y = NULL,   sm_method,   subset_by = NULL,   return_fitobject = FALSE )"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/smooth_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Smooth data — smooth_data","text":"... Arguments passed stats::loess, mgcv::gam, moving_average, moving_median. Typically includes tuning parameter(s), cases required. See Details information. x (optional) vector predictor values smooth along (e.g. time) y vector response values smoothed (e.g. density). NULL, formula data *must* provided via ... sm_method Argument specifying smoothing method used smooth data. Options include  \"moving-average\", \"moving-median\", \"loess\", \"gam\" subset_by optional vector long y.  y split unique values vector  derivative group calculated  independently others. provides internally-implemented approach similar dplyr::group_by dplyr::mutate return_fitobject Boolean indicating whether entire object returned fitting function returned. FALSE, just fitted values returned.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/smooth_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Smooth data — smooth_data","text":"return_fitobject == FALSE: vector, length y, now-smoothed y values return_fitobject == TRUE: list length unique(subset_by) element         object class returned smoothing method         (typically named list-like object) Varies method, always first element named 'fitted'         containing smoothed values response variable,          second element named 'residuals' containing residuals         fitted values input values","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/smooth_data.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Smooth data — smooth_data","text":"moving_average moving_median,             passing window_width window_width_n via             ... required. window_width sets width            moving window units x,             window_width_n sets width units number            data points. Larger values either produce             \"smoothed\" data. loess, span argument sets fraction            data points included calculation.            typically best specify, since default 0.75 often            large growth curves data. Larger values span             produce \"smoothed\" data gam, arguments gam s can            provided via .... frequently, k             argument s sets number \"knots\"            spline-fitting can use. Smaller values \"smoothed\". using sm_method = \"gam\", advanced users may also modify             parameters s(), including smoothing basis             bs. bases can thin plate (bs = \"tp\",             default), cubic regressions (bs = \"cr\"), many             options (see ?mcgv::s). recommend leaving default             thin plate regressions, whose main drawback             computationally intensive calculate. growth curves data,             unlikely relevant. alternative passing y, advanced needs             loess gam, formula data             can passed smooth_data via ... argument             (lieu y). case, formula specify response (e.g. density)             predictors. gam smoothing, formula            typically format: y ~ s(x), uses             mgcv::s smooth data. data argument             data.frame containing variables formula.            cases, subset_by can still specified vector            long nrow(data)","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/to_excel.html","id":null,"dir":"Reference","previous_headings":"","what":"A function that converts numbers into base-26 Excel-style letters — to_excel","title":"A function that converts numbers into base-26 Excel-style letters — to_excel","text":"function converts numbers base-26 Excel-style letters","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/to_excel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A function that converts numbers into base-26 Excel-style letters — to_excel","text":"","code":"to_excel(x)"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/to_excel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A function that converts numbers into base-26 Excel-style letters — to_excel","text":"x vector numbers base-10","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/to_excel.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A function that converts numbers into base-26 Excel-style letters — to_excel","text":"vector letters Excel-style base-26 format","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/trans_block_to_wide.html","id":null,"dir":"Reference","previous_headings":"","what":"Transform blocks to wides — trans_block_to_wide","title":"Transform blocks to wides — trans_block_to_wide","text":"Takes blocks returns wide format","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/trans_block_to_wide.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Transform blocks to wides — trans_block_to_wide","text":"","code":"trans_block_to_wide(   blocks,   wellnames_sep = \"\",   nested_metadata = NULL,   colnames_first = FALSE )"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/trans_block_to_wide.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Transform blocks to wides — trans_block_to_wide","text":"blocks Blocks, either single data.frame list data.frames wellnames_sep String use separator well names  rowname column name (ordered according colnames_first nested_metadata Boolean indicating existence nested metadata blockmeasures list, e.g. typically output read_blocks. NULL, attempt infer existence nested metadata colnames_first wellnames created paste-ing rownames column names, column names come first","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/trans_block_to_wide.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Transform blocks to wides — trans_block_to_wide","text":"single widemeasures data.frame","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/trans_wide_to_tidy.html","id":null,"dir":"Reference","previous_headings":"","what":"Pivot widemeasures longer — trans_wide_to_tidy","title":"Pivot widemeasures longer — trans_wide_to_tidy","text":"Essentially wrapper tidyr::pivot_longer works single widemeasures well list widemeasures","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/trans_wide_to_tidy.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pivot widemeasures longer — trans_wide_to_tidy","text":"","code":"trans_wide_to_tidy(   wides,   data_cols = NA,   id_cols = NA,   names_to = \"Well\",   values_to = \"Measurements\",   values_to_numeric = TRUE,   ... )"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/trans_wide_to_tidy.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pivot widemeasures longer — trans_wide_to_tidy","text":"wides single widemeasures data.frame, list widemeasures data.frame's data_cols, id_cols Specifies columns data vs ID's (tidyr::pivot_longer parlance). can single vector (applied widemeasures) list vectors, vector corresponding -index widemeasure widemeasures Entries NA list used neither data_cols id_cols specified, user must provide arguments tidyr::pivot_longer via ... least cols argument arguments provided via ... used widemeasures data.frame's names_to, values_to Specifies output column names created tidyr::pivot_longer. can provided vectors length widemeasures Note neither data_cols id_cols values_to_numeric Boolean indicating whether values coerced numeric. See may overridden arguments passed ... ... functions passed tidyr::pivot_longer Note including values_transform override behavior values_to_numeric","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/trans_wide_to_tidy.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pivot widemeasures longer — trans_wide_to_tidy","text":"Pivoted longer data.frame (widemeasures single data.frame)         list pivoted longer data.frame's (widemeasures         list data.frame's)","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/uninterleave.html","id":null,"dir":"Reference","previous_headings":"","what":"Uninterleave list — uninterleave","title":"Uninterleave list — uninterleave","text":"Takes list actually interleaved elements multiple sources uninterleaves separate sources instance, list blockmeasures actually corresponds two different plates can split two lists, blockmeasures corresponding single plate","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/uninterleave.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Uninterleave list — uninterleave","text":"","code":"uninterleave(interleaved_list, n)"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/uninterleave.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Uninterleave list — uninterleave","text":"interleaved_list list R objects n many output sub lists (.e. many groups interleaved list divided )","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/uninterleave.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Uninterleave list — uninterleave","text":"list lists R objects","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/write_blocks.html","id":null,"dir":"Reference","previous_headings":"","what":"Write block designs to csv — write_blocks","title":"Write block designs to csv — write_blocks","text":"function writes block-shaped lists (created read_blocks make_design) csv files, including data metadata variety output formats","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/write_blocks.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Write block designs to csv — write_blocks","text":"","code":"write_blocks(   blocks,   file = NULL,   output_format = \"multiple\",   block_name_location = NULL,   paste_sep = \"_\",   filename_sep = \"_\",   na = \"\",   ... )"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/write_blocks.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Write block designs to csv — write_blocks","text":"blocks list block-shaped data written file file filename filenames. Required : output_format = \"single\" Optional :             block_name_location = \"filename\" output_format = \"pasted\" output_format = \"multiple\" output_format One \"single\", \"pasted\", \"multiple\". \"single\" write blocks single                      csv file, empty row successive                      blocks \"pasted\" paste blocks together using                      paste_sep, write now-pasted                      block single csv file \"multiple\" write block csv file block_name_location Either NULL, 'filename' 'file'. NULL, automatically selected based                           output_format.                            output_format = 'single'                            output_format = 'pasted',                            block_name_location defaults file.                           output_format = 'multiple',                            block_name_location defaults                            filename 'filename', block_name metadata                            used output file name(s)                           file name(s) provided, appended                           file name(s) provided. 'file', block_name metadata                           included row output file. paste_sep output_format = 'pasted', character used paste together blocks. filename_sep character used paste together  filenames block_name_location = 'filename'. na string use missing values data. ... arguments passed write.table","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/write_blocks.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Write block designs to csv — write_blocks","text":"Nothing, R objects written files","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/news/index.html","id":"gcplyr-0123","dir":"Changelog","previous_headings":"","what":"gcplyr 0.12.3","title":"gcplyr 0.12.3","text":"Tweaks CRAN compatibility, largely minor documentation changes","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/news/index.html","id":"gcplyr-0122","dir":"Changelog","previous_headings":"","what":"gcplyr 0.12.2","title":"gcplyr 0.12.2","text":"Improved clarity vignettes, especially calculating derivatives analyzing data pages New vignette dealing noise data Small tweaks documentation","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/news/index.html","id":"gcplyr-0121","dir":"Changelog","previous_headings":"","what":"gcplyr 0.12.1","title":"gcplyr 0.12.1","text":"Minor bug fixes","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/news/index.html","id":"gcplyr-012","dir":"Changelog","previous_headings":"","what":"gcplyr 0.12","title":"gcplyr 0.12","text":"new citation. Run citation(“gcplyr”) see new version smooth_data methods moving-average moving-median now accept new smoothing parameter: window_width find_local_extrema now arguments window_width, window_width_n, window_height (naming consistency smooth_data calc_deriv arguments). Arguments width_limit, width_limit_n, height_limit deprecated. calc_deriv can now calculate derivatives using linear fit multiple data points determined arguments window_width /window_width_n. per-capita derivatives, y-values can fit -supplied divided mid-point y-value, can fit log-transformation gcplyr-workflow vignette split multiple smaller vignettes new data.frame included gcplyr: example_data_noiseless. data example_data include simulated noise present example_data. small numerical changes example_data values occurred re-generation example_data. Packages mgcv readxl now Suggests (previously Imports), errors thrown installed required gcplyr functionality find_local_extrema now much faster","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/news/index.html","id":"gcplyr-0112","dir":"Changelog","previous_headings":"","what":"gcplyr 0.11.2","title":"gcplyr 0.11.2","text":"new vignette section running statistics vignette, use dplyr::mutate smoothing derivatives sections","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/news/index.html","id":"gcplyr-0111","dir":"Changelog","previous_headings":"","what":"gcplyr 0.11.1","title":"gcplyr 0.11.1","text":"updates vignette README","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/news/index.html","id":"gcplyr-011","dir":"Changelog","previous_headings":"","what":"gcplyr 0.11","title":"gcplyr 0.11","text":"first public release gcplyr Open Beta. Documentation complete, although planned additions vignette completed included . Functions arguments largely stabilized, although small changes may occur going forward following user feedback. Internal tests mostly complete, although additional edge cases may added bugs reported.","code":""}]
