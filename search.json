[{"path":"https://mikeblazanin.github.io/gcplyr/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2023 Michael Blazanin Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc01_gcplyr.html","id":"getting-started","dir":"Articles","previous_headings":"","what":"Getting started","title":"Introduction to using gcplyr","text":"gcplyr package implements number functions make easier import, manipulate, analyze microbial growth data collected multiwell plate readers (“growth curves”). Without gcplyr, importing analyzing plate reader data can complicated process tailored experiment, requiring many lines code. gcplyr many steps now just single line code. document gives introduction use gcplyr step growth curve analysis. get started, need growth curve data file saved computer (.csv, .xls, .xlsx, format can read read.table). Users often want combine data information experimental design plate(s). can save information tabular file well, can just keep handy enter directly R (see vignette(\"gc03_incorporate_designs\")). Let’s get started loading gcplyr. ’re also going load couple packages ’ll need.","code":"library(gcplyr) #> ##  #> ## gcplyr (Version 1.12.0, Build Date: 2025-07-28) #> ## See http://github.com/mikeblazanin/gcplyr for additional documentation #> ## Please cite software as: #> ##   Blazanin, Michael. gcplyr: an R package for microbial growth #> ##   curve data analysis. BMC Bioinformatics 25, 232 (2024). #> ##   https://doi.org/10.1186/s12859-024-05817-3 #> ##  library(dplyr) #>  #> Attaching package: 'dplyr' #> The following objects are masked from 'package:stats': #>  #>     filter, lag #> The following objects are masked from 'package:base': #>  #>     intersect, setdiff, setequal, union library(ggplot2)"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc01_gcplyr.html","id":"a-quick-demo-of-gcplyr","dir":"Articles","previous_headings":"","what":"A quick demo of gcplyr","title":"Introduction to using gcplyr","text":"digging details, ’s simple demonstration final gcplyr script can look like. script: imports data files created plate reader combines design files created user calculates lag time, maximum growth rate, maximum density, area---curve Don’t worry understanding details code works right now. steps explained depth later articles.","code":"#For the purposes of this demo, we have to create our example data and # design files. Normally, the data file would be created by a plate reader, and # the design file would be created by you, the user  #Generate our example data file, widedata.csv make_example(vignette = 1, example = 1) #> Files have been written #> [1] \"./widedata.csv\"  #Generate our example design files, Bacteria_strain.csv and Phage.csv make_example(vignette = 1, example = 2) #> Files have been written #> [1] \"./Bacteria_strain.csv\" \"./Phage.csv\"  # Read in our data  data_wide <- read_wides(files = \"widedata.csv\")  # Transform our data to be tidy-shaped data_tidy <-    trans_wide_to_tidy(wides = data_wide, id_cols = c(\"file\", \"Time\"))  # Convert our time into hours data_tidy$Time <- as.numeric(data_tidy$Time)/3600  # Import our designs designs <- import_blockdesigns(files = c(\"Bacteria_strain.csv\", \"Phage.csv\")) #> Inferred 'into' column names as: Bacteria_strain, Phage  # Merge our designs and data data_merged <- merge_dfs(data_tidy, designs) #> Joining with `by = join_by(Well)`  #Set up the Well column so they plot in the correct order data_merged$Well <-    factor(data_merged$Well,          levels = paste0(rep(LETTERS[1:8], each = 12), 1:12))  #Plot the data ggplot(data = data_merged, aes(x = Time, y = Measurements)) +   geom_line() +   facet_wrap(~Well, nrow = 8, ncol = 12) # Voila! 8 lines of code and all your data is imported & plotted!  # Calculate the per-capita growth rate over time in each well data_merged <- mutate(   group_by(data_merged, Well),   percap_deriv = calc_deriv(y = Measurements, x = Time, percapita = TRUE,                              blank = 0, window_width_n = 5))  # Calculate four common metrics of bacterial growth: #  the lag time, saving it to a column named lag_time #  the maximum growth rate, saving it to a column named max_percap #  the maximum density, saving it to a column named max_dens #  the area-under-the-curve, saving it to a column named 'auc' data_sum <- summarize(   group_by(data_merged, Well, Bacteria_strain, Phage),   lag_time = lag_time(x = Time, y = Measurements, deriv = percap_deriv,                       blank = 0),   max_percap = max(percap_deriv, na.rm = TRUE),   max_dens = max(Measurements),   auc = auc(y = Measurements, x = as.numeric(Time))) #> `summarise()` has grouped output by 'Well', 'Bacteria_strain'. You can override #> using the `.groups` argument.  # Print some of the values head(data_sum) #> # A tibble: 6 × 7 #> # Groups:   Well, Bacteria_strain [6] #>   Well  Bacteria_strain Phage    lag_time max_percap max_dens   auc #>   <fct> <chr>           <chr>       <dbl>      <dbl>    <dbl> <dbl> #> 1 A1    Strain 1        No Phage     2.11      1.00      1.18  15.9 #> 2 A2    Strain 2        No Phage     1.74      1.31      1.21  19.3 #> 3 A3    Strain 3        No Phage     2.14      0.915     1.15  15.1 #> 4 A4    Strain 4        No Phage     1.68      1.43      1.21  20.1 #> 5 A5    Strain 5        No Phage     1.67      1.47      1.21  20.3 #> 6 A6    Strain 6        No Phage     2.41      0.789     1.05  12.8  #Set up the Well column so they plot in the correct order data_sum$Well <- factor(data_sum$Well,                          levels = paste0(rep(LETTERS[1:8], each = 12), 1:12))  #Plot lag time ggplot(data = data_sum) +   geom_text(aes(label = round(lag_time, 2), x = 1, y = 1)) +   facet_wrap(~ Well, ncol = 12) +   labs(title = \"Lag time by well\") +   theme(axis.title = element_blank(),          axis.text = element_blank(),         axis.ticks = element_blank()) #Plot growth rate ggplot(data = data_sum) +   geom_text(aes(label = round(max_percap, 2), x = 1, y = 1)) +   facet_wrap(~ Well, ncol = 12) +   labs(title = \"Maximum growth rate by well\") +   theme(axis.title = element_blank(),          axis.text = element_blank(),         axis.ticks = element_blank()) #Plot Maximum density ggplot(data = data_sum) +   geom_text(aes(label = round(max_dens, 2), x = 1, y = 1)) +   facet_wrap(~ Well, ncol = 12) +   labs(title = \"Maximum density by well\") +   theme(axis.title = element_blank(),          axis.text = element_blank(),         axis.ticks = element_blank()) #Plot AUC ggplot(data = data_sum) +   geom_text(aes(label = round(auc, 2), x = 1, y = 1)) +   facet_wrap(~ Well, ncol = 12) +   labs(title = \"Area under the curve by well\") +   theme(axis.title = element_blank(),          axis.text = element_blank(),         axis.ticks = element_blank())"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc01_gcplyr.html","id":"whats-next","dir":"Articles","previous_headings":"","what":"What’s next?","title":"Introduction to using gcplyr","text":"example , ’ve shown step gcplyr workflow one lines code. following pages, ’ve explained steps depth. start, ’ll learn import data R transform convenient format. Introduction: vignette(\"gc01_gcplyr\") Importing reshaping data: vignette(\"gc02_import_reshape\") Incorporating experimental designs: vignette(\"gc03_incorporate_designs\") Pre-processing plotting data: vignette(\"gc04_preprocess_plot\") Processing data: vignette(\"gc05_process\") Analyzing data: vignette(\"gc06_analyze\") Dealing noise: vignette(\"gc07_noise\") Best practices tips: vignette(\"gc08_conclusion\") Working multiple plates: vignette(\"gc09_multiple_plates\") Using make_design generate experimental designs: vignette(\"gc10_using_make_design\")","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc02_import_reshape.html","id":"where-are-we-so-far","dir":"Articles","previous_headings":"","what":"Where are we so far?","title":"Importing and reshaping data","text":"Introduction: vignette(\"gc01_gcplyr\") Importing reshaping data: vignette(\"gc02_import_reshape\") Incorporating experimental designs: vignette(\"gc03_incorporate_designs\") Pre-processing plotting data: vignette(\"gc04_preprocess_plot\") Processing data: vignette(\"gc05_process\") Analyzing data: vignette(\"gc06_analyze\") Dealing noise: vignette(\"gc07_noise\") Best practices tips: vignette(\"gc08_conclusion\") Working multiple plates: vignette(\"gc09_multiple_plates\") Using make_design generate experimental designs: vignette(\"gc10_using_make_design\") Previously, gave quick demonstration gcplyr can . , ’re going detail import data R transform better layout. haven’t already, load necessary packages.","code":"library(gcplyr) #> ##  #> ## gcplyr (Version 1.12.0, Build Date: 2025-07-28) #> ## See http://github.com/mikeblazanin/gcplyr for additional documentation #> ## Please cite software as: #> ##   Blazanin, Michael. gcplyr: an R package for microbial growth #> ##   curve data analysis. BMC Bioinformatics 25, 232 (2024). #> ##   https://doi.org/10.1186/s12859-024-05817-3 #> ##"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc02_import_reshape.html","id":"data-formats-and-layouts","dir":"Articles","previous_headings":"","what":"Data formats and layouts","title":"Importing and reshaping data","text":"gcplyr built easily read -common tabular file formats. explicitly includes formats like csv, xls, xlsx, fact gcplyr functions reading importing can work file format R’s built-read.table function can handle. ’re working something besides csv, xls, xlsx, simply specify arguments need read.table relevant gcplyr function handle rest. Aside file formats, growth curve data designs can organized one three different layouts: block-shaped, wide-shaped, tidy-shaped, described . Tidy-shaped data best layout analyses, plate readers output block-shaped wide-shaped data, user-created design files block-shaped. Thus, gcplyr works reshaping block-shaped wide-shaped data tidy-shaped data, running analyses. , can tell layout data ? Block-shaped block-shaped data, organization data corresponds directly layout physical multi-well plate generated . instance, data point third row fourth column data.frame well third row fourth column physical plate. timeseries growth curve data block-shaped consist many separate block-shaped data.frames, corresponding single timepoint. example, block-shaped data.frame 96-well plate (“…” indicating Columns 4 - 10, shown). example, data shown single timepoint. Wide-shaped wide-shaped data, column dataframe corresponds single well plate, row dataframe corresponds single timepoint. Typically, headers contain well names. example, wide-shaped dataframe 96-well plate (, “…” indicates 91 columns A4 - H10, shown). row dataframe corresponds single timepoint. Tidy-shaped tidy-shaped data, single column contains plate reader measurements, unique measurement row. Additional columns specify timepoint, well data comes , design elements. Note , tidy-shaped data, number rows equals number wells times number timepoints. Yes, ’s lot rows! tidy-shaped data best format analyses, common number R packages, including ggplot, ’s sometimes called “long” format.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc02_import_reshape.html","id":"importing-data","dir":"Articles","previous_headings":"","what":"Importing data","title":"Importing and reshaping data","text":"’ve determined format data , can begin importing using read_* import_* functions gcplyr. data block-shaped: use import_blockmeasures start next section: Importing block-shaped data data wide-shaped: use read_wides skip Importing wide-shaped data section data already tidy-shaped: use read_tidys skip Importing tidy-shaped data section.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc02_import_reshape.html","id":"importing-block-shaped-data","dir":"Articles","previous_headings":"","what":"Importing block-shaped data","title":"Importing and reshaping data","text":"import block-shaped data, use import_blockmeasures function. import_blockmeasures requires list filenames (relative file paths) return wide-shaped data.frame can save R.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc02_import_reshape.html","id":"a-basic-example","dir":"Articles","previous_headings":"Importing block-shaped data","what":"A basic example","title":"Importing and reshaping data","text":"’s simple example. First, need create series example block-shaped .csv files. working real growth curve data, files output plate reader, ’ll generate make_example. case, make_example creates files returns vector names files, ’ll store temp_filenames. ’ve saved files single folder, can easily get vector names using list.files. folder contains files, can specify regular expression pattern limit just want import: ’s one files looks like (values absorbance/optical density): file corresponds reads single plate taken first timepoint. can see second row file contains metadata timepoint plate read read taken. , data starts column headers row 4 rownames column 1. want read files R, simply provide import_blockmeasures vector file names, save result R object (, imported_blockdata). import_blockmeasures assumes data starts first row column, ends last row column, unless specify otherwise. can see import_blockmeasures created wide-shaped R object containing data reads. also added file names block_name column, can easily track row came file. ’re looking data Excel similar spreadsheet program, ’ll notice columns coded letter. import_blockmeasures allows specify column letter .","code":"temp_filenames <- make_example(vignette = 2, example = 1) #> Files have been written # Here we print all the files we're going to read list.files(pattern = \"Plate1.*csv\") #>  [1] \"Plate1-0_00_00.csv\"  \"Plate1-0_15_00.csv\"  \"Plate1-0_30_00.csv\"  #>  [4] \"Plate1-0_45_00.csv\"  \"Plate1-1_00_00.csv\"  \"Plate1-1_15_00.csv\"  #>  [7] \"Plate1-1_30_00.csv\"  \"Plate1-1_45_00.csv\"  \"Plate1-10_00_00.csv\" #> [10] \"Plate1-10_15_00.csv\" \"Plate1-10_30_00.csv\" \"Plate1-10_45_00.csv\" #> [13] \"Plate1-11_00_00.csv\" \"Plate1-11_15_00.csv\" \"Plate1-11_30_00.csv\" #> [16] \"Plate1-11_45_00.csv\" \"Plate1-12_00_00.csv\" \"Plate1-12_15_00.csv\" #> [19] \"Plate1-12_30_00.csv\" \"Plate1-12_45_00.csv\" \"Plate1-13_00_00.csv\" #> [22] \"Plate1-13_15_00.csv\" \"Plate1-13_30_00.csv\" \"Plate1-13_45_00.csv\" #> [25] \"Plate1-14_00_00.csv\" \"Plate1-14_15_00.csv\" \"Plate1-14_30_00.csv\" #> [28] \"Plate1-14_45_00.csv\" \"Plate1-15_00_00.csv\" \"Plate1-15_15_00.csv\" #> [31] \"Plate1-15_30_00.csv\" \"Plate1-15_45_00.csv\" \"Plate1-16_00_00.csv\" #> [34] \"Plate1-16_15_00.csv\" \"Plate1-16_30_00.csv\" \"Plate1-16_45_00.csv\" #> [37] \"Plate1-17_00_00.csv\" \"Plate1-17_15_00.csv\" \"Plate1-17_30_00.csv\" #> [40] \"Plate1-17_45_00.csv\" \"Plate1-18_00_00.csv\" \"Plate1-18_15_00.csv\" #> [43] \"Plate1-18_30_00.csv\" \"Plate1-18_45_00.csv\" \"Plate1-19_00_00.csv\" #> [46] \"Plate1-19_15_00.csv\" \"Plate1-19_30_00.csv\" \"Plate1-19_45_00.csv\" #> [49] \"Plate1-2_00_00.csv\"  \"Plate1-2_15_00.csv\"  \"Plate1-2_30_00.csv\"  #> [52] \"Plate1-2_45_00.csv\"  \"Plate1-20_00_00.csv\" \"Plate1-20_15_00.csv\" #> [55] \"Plate1-20_30_00.csv\" \"Plate1-20_45_00.csv\" \"Plate1-21_00_00.csv\" #> [58] \"Plate1-21_15_00.csv\" \"Plate1-21_30_00.csv\" \"Plate1-21_45_00.csv\" #> [61] \"Plate1-22_00_00.csv\" \"Plate1-22_15_00.csv\" \"Plate1-22_30_00.csv\" #> [64] \"Plate1-22_45_00.csv\" \"Plate1-23_00_00.csv\" \"Plate1-23_15_00.csv\" #> [67] \"Plate1-23_30_00.csv\" \"Plate1-23_45_00.csv\" \"Plate1-24_00_00.csv\" #> [70] \"Plate1-3_00_00.csv\"  \"Plate1-3_15_00.csv\"  \"Plate1-3_30_00.csv\"  #> [73] \"Plate1-3_45_00.csv\"  \"Plate1-4_00_00.csv\"  \"Plate1-4_15_00.csv\"  #> [76] \"Plate1-4_30_00.csv\"  \"Plate1-4_45_00.csv\"  \"Plate1-5_00_00.csv\"  #> [79] \"Plate1-5_15_00.csv\"  \"Plate1-5_30_00.csv\"  \"Plate1-5_45_00.csv\"  #> [82] \"Plate1-6_00_00.csv\"  \"Plate1-6_15_00.csv\"  \"Plate1-6_30_00.csv\"  #> [85] \"Plate1-6_45_00.csv\"  \"Plate1-7_00_00.csv\"  \"Plate1-7_15_00.csv\"  #> [88] \"Plate1-7_30_00.csv\"  \"Plate1-7_45_00.csv\"  \"Plate1-8_00_00.csv\"  #> [91] \"Plate1-8_15_00.csv\"  \"Plate1-8_30_00.csv\"  \"Plate1-8_45_00.csv\"  #> [94] \"Plate1-9_00_00.csv\"  \"Plate1-9_15_00.csv\"  \"Plate1-9_30_00.csv\"  #> [97] \"Plate1-9_45_00.csv\"  # Here we save them to the temp_filenames variable temp_filenames <- list.files(pattern = \"Plate1.*csv\") print_df(read.csv(temp_filenames[1], header = FALSE, colClasses = \"character\")) #>                                                                           #>    Time     0                                                             #>                                                                           #>       1     2     3     4     5     6     7     8     9    10    11    12 #> A 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 #> B 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 #> C 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 #> D 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 #> E 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 #> F 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 #> G 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 #> H 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 # Now let's read it with import_blockmeasures imported_blockdata <- import_blockmeasures(   files = temp_filenames, startrow = 4)  head(imported_blockdata, c(6, 8)) #>       block_name    A1    A2    A3    A4    A5    A6    A7 #> 1 Plate1-0_00_00 0.002 0.002 0.002 0.002 0.002 0.002 0.002 #> 2 Plate1-0_15_00 0.002 0.002 0.002 0.002 0.002 0.002 0.002 #> 3 Plate1-0_30_00 0.002 0.002 0.002 0.002 0.002 0.002 0.002 #> 4 Plate1-0_45_00 0.002 0.002 0.002 0.002 0.002 0.002 0.002 #> 5 Plate1-1_00_00 0.002 0.002 0.002 0.002 0.002 0.002 0.002 #> 6 Plate1-1_15_00 0.002 0.003 0.002 0.003 0.003 0.002 0.002 # We can specify rows or columns by Excel-style letters too imported_blockdata <- import_blockmeasures(   files = temp_filenames,   startrow = 4, startcol = \"A\")"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc02_import_reshape.html","id":"specifying-metadata","dir":"Articles","previous_headings":"Importing block-shaped data","what":"Specifying metadata","title":"Importing and reshaping data","text":"Sometimes, input files information want import ’s included main block data. instance, block-shaped data timepoint nearly always specified somewhere input file. import_blockmeasures can include information well via metadata argument. example, let’s return -recent example files: files, timepoint information located 2nd row 3rd column. ’s specify metadata import_blockmeasures command: can see metadata specified added column output data.frame. specifying metadata, metadata argument must list named vectors. vector two elements specifying location metadata input files: first element row, second element column. can also specify location metadata Excel-style lettering.","code":"print_df(read.csv(temp_filenames[1], header = FALSE, colClasses = \"character\")) #>                                                                           #>    Time     0                                                             #>                                                                           #>       1     2     3     4     5     6     7     8     9    10    11    12 #> A 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 #> B 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 #> C 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 #> D 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 #> E 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 #> F 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 #> G 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 #> H 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 # Reading the blockcurves files with metadata included imported_blockdata <- import_blockmeasures(   files = temp_filenames,   startrow = 4,   metadata = list(\"time\" = c(2, 3)))  head(imported_blockdata, c(6, 8)) #>       block_name time    A1    A2    A3    A4    A5    A6 #> 1 Plate1-0_00_00    0 0.002 0.002 0.002 0.002 0.002 0.002 #> 2 Plate1-0_15_00  900 0.002 0.002 0.002 0.002 0.002 0.002 #> 3 Plate1-0_30_00 1800 0.002 0.002 0.002 0.002 0.002 0.002 #> 4 Plate1-0_45_00 2700 0.002 0.002 0.002 0.002 0.002 0.002 #> 5 Plate1-1_00_00 3600 0.002 0.002 0.002 0.002 0.002 0.002 #> 6 Plate1-1_15_00 4500 0.002 0.003 0.002 0.003 0.003 0.002 # Reading the blockcurves files with metadata included imported_blockdata <- import_blockmeasures(   files = temp_filenames,   startrow = 4,   metadata = list(\"time\" = c(2, \"C\")))"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc02_import_reshape.html","id":"reading-multiple-blocks-from-a-single-file","dir":"Articles","previous_headings":"Importing block-shaped data","what":"Reading multiple blocks from a single file","title":"Importing and reshaping data","text":"import_blockmeasures can also import multiple blocks single file, plate readers may output. case, simply specify vector rows columns define location block within file. First, let’s create example file (normally file created plate reader). Let’s take look file looks like: can see first block metadata , block data . ’s empty row next block starts. fact, look whole file, ’ll notice blocks go column 1 (“” Excel) column 13 (“M” Excel), start rows 3, 15, 27, 39, etc, end rows 11, 23, 35, 47, etc. look file, can also see last block starts row 1155 ends row 1163. Let’s read information using import_blockmeasures: ’ve used built-R function seq generate full vector startrows endrows. take look, can see ’s read successfully: Now let’s add metadata. ’re reading single file, need specify metadata slightly differently. Instead metadata single vector c(row,column) location, ’s going list two vectors, one row numbers, one column numbers. Going back file, can see time block saved second column, rows 2, 14, 26, 38, … 1154. now take look resulting object, can see time metadata incorporated.","code":"make_example(vignette = 2, example = 2) #> Files have been written #> [1] \"./blocks_single.csv\" print_df(head(read.csv(\"blocks_single.csv\", header = FALSE,                         colClasses = \"character\"),               c(20, 8))) #> block_name Plate1-0_00_00                                     #>       time              0                                     #>                         1     2     3     4     5     6     7 #>          A          0.002 0.002 0.002 0.002 0.002 0.002 0.002 #>          B          0.002 0.002 0.002 0.002 0.002 0.002 0.002 #>          C          0.002 0.002 0.002 0.002 0.002 0.002 0.002 #>          D          0.002 0.002 0.002 0.002 0.002 0.002 0.002 #>          E          0.002 0.002 0.002 0.002 0.002 0.002 0.002 #>          F          0.002 0.002 0.002 0.002 0.002 0.002 0.002 #>          G          0.002 0.002 0.002 0.002 0.002 0.002 0.002 #>          H          0.002 0.002 0.002 0.002 0.002 0.002 0.002 #>                                                               #> block_name Plate1-0_15_00                                     #>       time            900                                     #>                         1     2     3     4     5     6     7 #>          A          0.002 0.002 0.002 0.002 0.002 0.002 0.002 #>          B          0.002 0.002 0.002 0.002 0.002 0.002 0.002 #>          C          0.002 0.002 0.002 0.002 0.002 0.002 0.002 #>          D          0.002 0.002 0.002 0.002 0.002 0.002 0.002 #>          E          0.002 0.002 0.002 0.002 0.002 0.002 0.002 imported_blockdata <- import_blockmeasures(   \"blocks_single.csv\",   startrow = seq(from = 3, to = 1155, by = 12),   endrow = seq(from = 11, to = 1163, by = 12),   startcol = 1, endcol = 13) head(imported_blockdata, c(6, 8)) #>      block_name    A1    A2    A3    A4    A5    A6    A7 #> 1 blocks_single 0.002 0.002 0.002 0.002 0.002 0.002 0.002 #> 2 blocks_single 0.002 0.002 0.002 0.002 0.002 0.002 0.002 #> 3 blocks_single 0.002 0.002 0.002 0.002 0.002 0.002 0.002 #> 4 blocks_single 0.002 0.002 0.002 0.002 0.002 0.002 0.002 #> 5 blocks_single 0.002 0.002 0.002 0.002 0.002 0.002 0.002 #> 6 blocks_single 0.002 0.003 0.002 0.003 0.003 0.002 0.002 imported_blockdata <- import_blockmeasures(   \"blocks_single.csv\",   startrow = seq(from = 3, to = 1155, by = 12),   endrow = seq(from = 11, to = 1163, by = 12),   startcol = 1, endcol = 13,   metadata = list(\"time\" = list(seq(from = 2, to = 1154, by = 12), 2))) head(imported_blockdata, c(6, 8)) #>      block_name time    A1    A2    A3    A4    A5    A6 #> 1 blocks_single    0 0.002 0.002 0.002 0.002 0.002 0.002 #> 2 blocks_single  900 0.002 0.002 0.002 0.002 0.002 0.002 #> 3 blocks_single 1800 0.002 0.002 0.002 0.002 0.002 0.002 #> 4 blocks_single 2700 0.002 0.002 0.002 0.002 0.002 0.002 #> 5 blocks_single 3600 0.002 0.002 0.002 0.002 0.002 0.002 #> 6 blocks_single 4500 0.002 0.003 0.002 0.003 0.003 0.002"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc02_import_reshape.html","id":"what-to-do-next","dir":"Articles","previous_headings":"Importing block-shaped data","what":"What to do next","title":"Importing and reshaping data","text":"Now ’ve imported block-shaped data, ’ll need transform later analyses. Jump directly Transforming data section.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc02_import_reshape.html","id":"importing-wide-shaped-data","dir":"Articles","previous_headings":"","what":"Importing wide-shaped data","title":"Importing and reshaping data","text":"import wide-shaped data, use read_wides function. read_wides requires filename (vector filenames, relative file paths) return data.frame (list data.frames) can save R.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc02_import_reshape.html","id":"a-basic-example-1","dir":"Articles","previous_headings":"Importing wide-shaped data","what":"A basic example","title":"Importing and reshaping data","text":"’s simple example. First, need create example wide-shaped .csv file. Don’t worry code works. working real growth curve data, files output plate reader. need know file name(s) put R code. example, file name widedata.csv. ’s start file looks like (values absorbance/optical density): file contains reads single plate taken across timepoints. can see first two rows contain metadata saved plate reader, like name experiment date experiment. , can see data starts 5th row header. first column contains timepoint information, subsequent column corresponds well plate. want read file R, simply provide read_wides file name, save result R object (, imported_widedata). read_wides assumes data starts first row column, ends last row column, unless specify otherwise. resulting data.frame looks like : Note read_wides automatically saves filename data imported first column output data.frame. done ensure later , data.frames multiple plates can combined without fear losing identity plate. ’re looking data Excel similar spreadsheet program, ’ll notice columns coded letter. read_wides allows specify column letter .","code":"make_example(vignette = 2, example = 3) #> Files have been written #> [1] \"./widedata.csv\" # Let's take a peek at what this file looks like print_df(head(read.csv(\"widedata.csv\", header = FALSE,                         colClasses = \"character\"),                c(10, 10))) #> Experiment name Experiment_1                                                 #>      Start date   2025-07-28                                                 #>                                                                              #>                                                                              #>            Time           A1    B1    C1    D1    E1    F1    G1    H1    A2 #>               0        0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 #>             900        0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 #>            1800        0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 #>            2700        0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 #>            3600        0.002 0.002 0.002 0.003 0.003 0.002 0.002 0.003 0.002 imported_widedata <- read_wides(files = \"widedata.csv\", startrow = 5) head(imported_widedata, c(6, 10)) #>        file Time    A1    B1    C1    D1    E1    F1    G1    H1 #> 6  widedata    0 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 #> 7  widedata  900 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 #> 8  widedata 1800 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 #> 9  widedata 2700 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 #> 10 widedata 3600 0.002 0.002 0.002 0.003 0.003 0.002 0.002 0.003 #> 11 widedata 4500 0.002 0.003 0.002 0.003 0.003 0.002 0.003 0.003 imported_widedata <- read_wides(files = \"widedata.csv\",                                 startrow = 5, startcol = \"A\")"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc02_import_reshape.html","id":"specifying-metadata-1","dir":"Articles","previous_headings":"Importing wide-shaped data","what":"Specifying metadata","title":"Importing and reshaping data","text":"Sometimes, input files information want import ’s included main block data. read_wides can include information well via metadata argument. metadata argument list named vectors. vector length 2, first entry specifying row second entry specifying column metadata located. example, previous example files, experiment name located 2nd row, 2nd column, start date located 3rd row, 2nd column. ’s specify metadata: can also specify location metadata Excel-style lettering.","code":"imported_widedata <- read_wides(files = \"widedata.csv\",                                 startrow = 5,                                 metadata = list(\"experiment_name\" = c(1, 2),                                                 \"start_date\" = c(2, 2))) head(imported_widedata, c(6, 8)) #>        file experiment_name start_date Time    A1    B1    C1    D1 #> 6  widedata    Experiment_1 2025-07-28    0 0.002 0.002 0.002 0.002 #> 7  widedata    Experiment_1 2025-07-28  900 0.002 0.002 0.002 0.002 #> 8  widedata    Experiment_1 2025-07-28 1800 0.002 0.002 0.002 0.002 #> 9  widedata    Experiment_1 2025-07-28 2700 0.002 0.002 0.002 0.002 #> 10 widedata    Experiment_1 2025-07-28 3600 0.002 0.002 0.002 0.003 #> 11 widedata    Experiment_1 2025-07-28 4500 0.002 0.003 0.002 0.003 imported_widedata <- read_wides(files = \"widedata.csv\",                                 startrow = 5,                                 metadata = list(\"experiment_name\" = c(1, \"B\"),                                                 \"start_date\" = c(2, \"B\")))"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc02_import_reshape.html","id":"what-to-do-next-1","dir":"Articles","previous_headings":"Importing wide-shaped data","what":"What to do next","title":"Importing and reshaping data","text":"Now ’ve imported wide-shaped data, ’ll need transform later analyses. Continue Transforming data section.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc02_import_reshape.html","id":"importing-tidy-shaped-data","dir":"Articles","previous_headings":"","what":"Importing tidy-shaped data","title":"Importing and reshaping data","text":"import tidy-shaped data, use built-R functions like read.table. However, need options, can use gcplyr function read_tidys. Unlike built-option, read_tidys can import multiple tidy-shaped files , can add filename column resulting data.frame, can handle files tidy-shaped information doesn’t start first row column. read_tidys requires filename (vector filenames, relative file paths) return data.frame (list data.frames) can save R. ’ve read tidy-shaped data, won’t need transform , can skip ’s next? section.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc02_import_reshape.html","id":"transforming-data","dir":"Articles","previous_headings":"","what":"Transforming data","title":"Importing and reshaping data","text":"Now ’ve gotten data R, need transform can analyses. reiterate, necessary plate readers generate growth curve data outputs block-shaped wide-shaped files, tidy-shaped data.frames best shape analyses required gcplyr. can transform data.frames using trans_* functions gcplyr.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc02_import_reshape.html","id":"transforming-from-wide-shaped-to-tidy-shaped","dir":"Articles","previous_headings":"Transforming data","what":"Transforming from wide-shaped to tidy-shaped","title":"Importing and reshaping data","text":"data ’ve read R environment wide-shaped (’ve gotten wide-shaped data transforming originally block-shaped data), ’ll transform tidy-shaped using trans_wide_to_tidy. First, need provide trans_wide_to_tidy R object created import_blockmeasures read_wides. , specify one : columns data (spectrophotometric measures) via data_cols columns non-data (e.g. time information) via id_cols","code":"imported_blocks_now_tidy <- trans_wide_to_tidy(   wides = imported_blockdata,   id_cols = c(\"block_name\", \"time\"))  imported_wides_now_tidy <- trans_wide_to_tidy(   wides = imported_widedata,   id_cols = c(\"file\", \"experiment_name\", \"start_date\", \"Time\"))  print(head(imported_blocks_now_tidy), row.names = FALSE) #>     block_name time Well Measurements #>  blocks_single    0   A1        0.002 #>  blocks_single    0   A2        0.002 #>  blocks_single    0   A3        0.002 #>  blocks_single    0   A4        0.002 #>  blocks_single    0   A5        0.002 #>  blocks_single    0   A6        0.002"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc02_import_reshape.html","id":"whats-next","dir":"Articles","previous_headings":"","what":"What’s next?","title":"Importing and reshaping data","text":"Now ’ve imported transformed data tidy-shaped, likely want incorporate design information went well (plate). Alternatively, ’d like skip step now, can go directly pre-processing plotting data Introduction: vignette(\"gc01_gcplyr\") Importing reshaping data: vignette(\"gc02_import_reshape\") Incorporating experimental designs: vignette(\"gc03_incorporate_designs\") Pre-processing plotting data: vignette(\"gc04_preprocess_plot\") Processing data: vignette(\"gc05_process\") Analyzing data: vignette(\"gc06_analyze\") Dealing noise: vignette(\"gc07_noise\") Best practices tips: vignette(\"gc08_conclusion\") Working multiple plates: vignette(\"gc09_multiple_plates\") Using make_design generate experimental designs: vignette(\"gc10_using_make_design\")","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc03_incorporate_designs.html","id":"where-are-we-so-far","dir":"Articles","previous_headings":"","what":"Where are we so far?","title":"Incorporating experimental designs","text":"Introduction: vignette(\"gc01_gcplyr\") Importing reshaping data: vignette(\"gc02_import_reshape\") Incorporating experimental designs: vignette(\"gc03_incorporate_designs\") Pre-processing plotting data: vignette(\"gc04_preprocess_plot\") Processing data: vignette(\"gc05_process\") Analyzing data: vignette(\"gc06_analyze\") Dealing noise: vignette(\"gc07_noise\") Best practices tips: vignette(\"gc08_conclusion\") Working multiple plates: vignette(\"gc09_multiple_plates\") Using make_design generate experimental designs: vignette(\"gc10_using_make_design\") far, ’ve imported transformed measures data R. Now ’re going address incorporate experimental design. haven’t already, load necessary packages.","code":"library(gcplyr) #> ##  #> ## gcplyr (Version 1.12.0, Build Date: 2025-07-28) #> ## See http://github.com/mikeblazanin/gcplyr for additional documentation #> ## Please cite software as: #> ##   Blazanin, Michael. gcplyr: an R package for microbial growth #> ##   curve data analysis. BMC Bioinformatics 25, 232 (2024). #> ##   https://doi.org/10.1186/s12859-024-05817-3 #> ##"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc03_incorporate_designs.html","id":"including-design-elements","dir":"Articles","previous_headings":"","what":"Including design elements","title":"Incorporating experimental designs","text":"often want combine data information experimental design. gcplyr enables incorporation design elements two ways: Designs can imported files Designs can generated R using make_design ’re interested generating designs R, see vignette(\"gc10_using_make_design\") reading design elements files, gcplyr can read block-shaped tidy-shaped design files: design files block-shaped, can read import_blockdesigns design files tidy-shaped, can simply read read_tidys","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc03_incorporate_designs.html","id":"importing-block-shaped-design-files","dir":"Articles","previous_headings":"","what":"Importing block-shaped design files","title":"Incorporating experimental designs","text":"import block-shaped design files, use import_blockdesigns, return tidy-shaped designs data frame (list data frames). import_blockdesigns requires list filenames (relative file paths) return data.frame (list data frames) tidy format can save R.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc03_incorporate_designs.html","id":"a-basic-example","dir":"Articles","previous_headings":"Importing block-shaped design files","what":"A basic example","title":"Incorporating experimental designs","text":"Let’s look example. First, need create example file sake tutorial (normally ’d create file Excel) Now let’s take look file looks like: can see design Treatment 1 left-hand side plate (wells columns 1 6), Treatment 2 right-hand side plate (wells columns 7 12). Let’s import design using import_blockdesigns, saving column name Treatment_numbers.","code":"make_example(vignette = 3, example = 1, dir = \".\") #> Files have been written #> [1] \"./mydesign.csv\" print_df(read.csv(\"mydesign.csv\", header = FALSE, colClasses = \"character\")) #>     1   2   3   4   5   6   7   8   9  10  11  12 #> A Tr1 Tr1 Tr1 Tr1 Tr1 Tr1 Tr2 Tr2 Tr2 Tr2 Tr2 Tr2 #> B Tr1 Tr1 Tr1 Tr1 Tr1 Tr1 Tr2 Tr2 Tr2 Tr2 Tr2 Tr2 #> C Tr1 Tr1 Tr1 Tr1 Tr1 Tr1 Tr2 Tr2 Tr2 Tr2 Tr2 Tr2 #> D Tr1 Tr1 Tr1 Tr1 Tr1 Tr1 Tr2 Tr2 Tr2 Tr2 Tr2 Tr2 #> E Tr1 Tr1 Tr1 Tr1 Tr1 Tr1 Tr2 Tr2 Tr2 Tr2 Tr2 Tr2 #> F Tr1 Tr1 Tr1 Tr1 Tr1 Tr1 Tr2 Tr2 Tr2 Tr2 Tr2 Tr2 #> G Tr1 Tr1 Tr1 Tr1 Tr1 Tr1 Tr2 Tr2 Tr2 Tr2 Tr2 Tr2 #> H Tr1 Tr1 Tr1 Tr1 Tr1 Tr1 Tr2 Tr2 Tr2 Tr2 Tr2 Tr2 my_design <- import_blockdesigns(files = \"mydesign.csv\",                                   block_names = \"Treatment_numbers\") head(my_design, 20) #>    Well Treatment_numbers #> 1    A1               Tr1 #> 2    A2               Tr1 #> 3    A3               Tr1 #> 4    A4               Tr1 #> 5    A5               Tr1 #> 6    A6               Tr1 #> 7    A7               Tr2 #> 8    A8               Tr2 #> 9    A9               Tr2 #> 10  A10               Tr2 #> 11  A11               Tr2 #> 12  A12               Tr2 #> 13   B1               Tr1 #> 14   B2               Tr1 #> 15   B3               Tr1 #> 16   B4               Tr1 #> 17   B5               Tr1 #> 18   B6               Tr1 #> 19   B7               Tr2 #> 20   B8               Tr2"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc03_incorporate_designs.html","id":"importing-multiple-block-shaped-design-elements","dir":"Articles","previous_headings":"Importing block-shaped design files","what":"Importing multiple block-shaped design elements","title":"Incorporating experimental designs","text":"multiple designs? instance, several strains several treatments? case, two options: Save design component separate file, separate blocks within file Save design components pasted together single file Regardless option use, can import one go import_blockdesigns.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc03_incorporate_designs.html","id":"importing-multiple-block-shaped-designs-in-separate-files","dir":"Articles","previous_headings":"Importing block-shaped design files > Importing multiple block-shaped design elements","what":"Importing multiple block-shaped designs in separate files","title":"Incorporating experimental designs","text":"First, let’s create example designs files. , just imagine ’ve created files Excel. Now let’s take look files looks like: , Treatment 1 left-hand side, Treatment 2 right-hand side. addition, now also Strain first two rows, Strain B next two rows, . Let’s now import designs using import_blockdesigns, saving columns named Treatment_numbers Strain_letters.","code":"make_example(vignette = 3, example = 1, dir = \".\") #> Files have been written #> [1] \"./mydesign.csv\" make_example(vignette = 3, example = 2, dir = \".\") #> Files have been written #> [1] \"./mydesign2.csv\" print_df(read.csv(\"mydesign.csv\", header = FALSE, colClasses = \"character\")) #>     1   2   3   4   5   6   7   8   9  10  11  12 #> A Tr1 Tr1 Tr1 Tr1 Tr1 Tr1 Tr2 Tr2 Tr2 Tr2 Tr2 Tr2 #> B Tr1 Tr1 Tr1 Tr1 Tr1 Tr1 Tr2 Tr2 Tr2 Tr2 Tr2 Tr2 #> C Tr1 Tr1 Tr1 Tr1 Tr1 Tr1 Tr2 Tr2 Tr2 Tr2 Tr2 Tr2 #> D Tr1 Tr1 Tr1 Tr1 Tr1 Tr1 Tr2 Tr2 Tr2 Tr2 Tr2 Tr2 #> E Tr1 Tr1 Tr1 Tr1 Tr1 Tr1 Tr2 Tr2 Tr2 Tr2 Tr2 Tr2 #> F Tr1 Tr1 Tr1 Tr1 Tr1 Tr1 Tr2 Tr2 Tr2 Tr2 Tr2 Tr2 #> G Tr1 Tr1 Tr1 Tr1 Tr1 Tr1 Tr2 Tr2 Tr2 Tr2 Tr2 Tr2 #> H Tr1 Tr1 Tr1 Tr1 Tr1 Tr1 Tr2 Tr2 Tr2 Tr2 Tr2 Tr2 print_df(read.csv(\"mydesign2.csv\", header = FALSE, colClasses = \"character\")) #>      1    2    3    4    5    6    7    8    9   10   11   12 #> A StrA StrA StrA StrA StrA StrA StrA StrA StrA StrA StrA StrA #> B StrA StrA StrA StrA StrA StrA StrA StrA StrA StrA StrA StrA #> C StrB StrB StrB StrB StrB StrB StrB StrB StrB StrB StrB StrB #> D StrB StrB StrB StrB StrB StrB StrB StrB StrB StrB StrB StrB #> E StrC StrC StrC StrC StrC StrC StrC StrC StrC StrC StrC StrC #> F StrC StrC StrC StrC StrC StrC StrC StrC StrC StrC StrC StrC #> G StrD StrD StrD StrD StrD StrD StrD StrD StrD StrD StrD StrD #> H StrD StrD StrD StrD StrD StrD StrD StrD StrD StrD StrD StrD my_design <-    import_blockdesigns(files = c(\"mydesign.csv\", \"mydesign2.csv\"),                        block_names = c(\"Treatment_numbers\", \"Strain_letters\")) #> Inferred 'into' column names as: Treatment_numbers, Strain_letters head(my_design, 20) #>    Well Treatment_numbers Strain_letters #> 1    A1               Tr1           StrA #> 2    A2               Tr1           StrA #> 3    A3               Tr1           StrA #> 4    A4               Tr1           StrA #> 5    A5               Tr1           StrA #> 6    A6               Tr1           StrA #> 7    A7               Tr2           StrA #> 8    A8               Tr2           StrA #> 9    A9               Tr2           StrA #> 10  A10               Tr2           StrA #> 11  A11               Tr2           StrA #> 12  A12               Tr2           StrA #> 13   B1               Tr1           StrA #> 14   B2               Tr1           StrA #> 15   B3               Tr1           StrA #> 16   B4               Tr1           StrA #> 17   B5               Tr1           StrA #> 18   B6               Tr1           StrA #> 19   B7               Tr2           StrA #> 20   B8               Tr2           StrA"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc03_incorporate_designs.html","id":"importing-multiple-separated-block-shaped-designs-in-one-file","dir":"Articles","previous_headings":"Importing block-shaped design files > Importing multiple block-shaped design elements","what":"Importing multiple separated block-shaped designs in one file","title":"Incorporating experimental designs","text":"blocks separated saved file, simply specify location block within file:","code":"make_example(vignette = 3, example = 3, dir = \".\") #> Files have been written #> [1] \"./mydesign_sep.csv\"  #Print what the file looks like print_df(read.csv(\"mydesign_sep.csv\", header = FALSE, colClasses = \"character\")) #>      1    2    3    4    5    6    7    8    9   10   11   12 #> A  Tr1  Tr1  Tr1  Tr1  Tr1  Tr1  Tr2  Tr2  Tr2  Tr2  Tr2  Tr2 #> B  Tr1  Tr1  Tr1  Tr1  Tr1  Tr1  Tr2  Tr2  Tr2  Tr2  Tr2  Tr2 #> C  Tr1  Tr1  Tr1  Tr1  Tr1  Tr1  Tr2  Tr2  Tr2  Tr2  Tr2  Tr2 #> D  Tr1  Tr1  Tr1  Tr1  Tr1  Tr1  Tr2  Tr2  Tr2  Tr2  Tr2  Tr2 #> E  Tr1  Tr1  Tr1  Tr1  Tr1  Tr1  Tr2  Tr2  Tr2  Tr2  Tr2  Tr2 #> F  Tr1  Tr1  Tr1  Tr1  Tr1  Tr1  Tr2  Tr2  Tr2  Tr2  Tr2  Tr2 #> G  Tr1  Tr1  Tr1  Tr1  Tr1  Tr1  Tr2  Tr2  Tr2  Tr2  Tr2  Tr2 #> H  Tr1  Tr1  Tr1  Tr1  Tr1  Tr1  Tr2  Tr2  Tr2  Tr2  Tr2  Tr2 #>                                                               #>      1    2    3    4    5    6    7    8    9   10   11   12 #> A StrA StrA StrA StrA StrA StrA StrA StrA StrA StrA StrA StrA #> B StrA StrA StrA StrA StrA StrA StrA StrA StrA StrA StrA StrA #> C StrB StrB StrB StrB StrB StrB StrB StrB StrB StrB StrB StrB #> D StrB StrB StrB StrB StrB StrB StrB StrB StrB StrB StrB StrB #> E StrC StrC StrC StrC StrC StrC StrC StrC StrC StrC StrC StrC #> F StrC StrC StrC StrC StrC StrC StrC StrC StrC StrC StrC StrC #> G StrD StrD StrD StrD StrD StrD StrD StrD StrD StrD StrD StrD #> H StrD StrD StrD StrD StrD StrD StrD StrD StrD StrD StrD StrD  #Read in the designs my_design <-    import_blockdesigns(files = c(\"mydesign_sep.csv\"),                        block_names = c(\"Treatment_numbers\", \"Strain_letters\"),                       startrow = c(1, 11), endrow = c(9, 19)) #> Inferred 'into' column names as: Treatment_numbers, Strain_letters head(my_design, 20) #>    Well Treatment_numbers Strain_letters #> 1    A1               Tr1           StrA #> 2    A2               Tr1           StrA #> 3    A3               Tr1           StrA #> 4    A4               Tr1           StrA #> 5    A5               Tr1           StrA #> 6    A6               Tr1           StrA #> 7    A7               Tr2           StrA #> 8    A8               Tr2           StrA #> 9    A9               Tr2           StrA #> 10  A10               Tr2           StrA #> 11  A11               Tr2           StrA #> 12  A12               Tr2           StrA #> 13   B1               Tr1           StrA #> 14   B2               Tr1           StrA #> 15   B3               Tr1           StrA #> 16   B4               Tr1           StrA #> 17   B5               Tr1           StrA #> 18   B6               Tr1           StrA #> 19   B7               Tr2           StrA #> 20   B8               Tr2           StrA"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc03_incorporate_designs.html","id":"importing-multiple-pasted-block-shaped-designs","dir":"Articles","previous_headings":"Importing block-shaped design files > Importing multiple block-shaped design elements","what":"Importing multiple pasted block-shaped designs","title":"Incorporating experimental designs","text":"Alternative saving designs separated, often may easiest save design information single block, separating distinct components design character. demonstrate , first let’s create example designs file. , just imagine ’ve created file Excel. Now let’s take look file looks like: , Treatment 1 left-hand side, Treatment 2 right-hand side, Strain first two rows, Strain B next two rows, . However, information now pasted together, “_” separating string (can use string separator). import design import_blockdesigns, simply need specify sep string, well output column names. Since designs pasted together, column names result splitting designs apart. easiest way specify split column names use argument passed separate_tidy [specified, import_blockdesigns attempt split block_names (either specified inferred) sep generate output column names].","code":"make_example(vignette = 3, example = 4, dir = \".\") #> Files have been written #> [1] \"./mydesign_pasted.csv\" print_df(read.csv(\"mydesign_pasted.csv\", header = FALSE, colClasses = \"character\")[, 1:10]) #>          1        2        3        4        5        6        7        8        9 #> A Tr1_StrA Tr1_StrA Tr1_StrA Tr1_StrA Tr1_StrA Tr1_StrA Tr2_StrA Tr2_StrA Tr2_StrA #> B Tr1_StrA Tr1_StrA Tr1_StrA Tr1_StrA Tr1_StrA Tr1_StrA Tr2_StrA Tr2_StrA Tr2_StrA #> C Tr1_StrB Tr1_StrB Tr1_StrB Tr1_StrB Tr1_StrB Tr1_StrB Tr2_StrB Tr2_StrB Tr2_StrB #> D Tr1_StrB Tr1_StrB Tr1_StrB Tr1_StrB Tr1_StrB Tr1_StrB Tr2_StrB Tr2_StrB Tr2_StrB #> E Tr1_StrC Tr1_StrC Tr1_StrC Tr1_StrC Tr1_StrC Tr1_StrC Tr2_StrC Tr2_StrC Tr2_StrC #> F Tr1_StrC Tr1_StrC Tr1_StrC Tr1_StrC Tr1_StrC Tr1_StrC Tr2_StrC Tr2_StrC Tr2_StrC #> G Tr1_StrD Tr1_StrD Tr1_StrD Tr1_StrD Tr1_StrD Tr1_StrD Tr2_StrD Tr2_StrD Tr2_StrD #> H Tr1_StrD Tr1_StrD Tr1_StrD Tr1_StrD Tr1_StrD Tr1_StrD Tr2_StrD Tr2_StrD Tr2_StrD my_design <-    import_blockdesigns(files = \"mydesign_pasted.csv\",                        into = c(\"Treatment_numbers\", \"Strain_letters\"),                       sep = \"_\") head(my_design, 20) #>    Well Treatment_numbers Strain_letters #> 1    A1               Tr1           StrA #> 2    A2               Tr1           StrA #> 3    A3               Tr1           StrA #> 4    A4               Tr1           StrA #> 5    A5               Tr1           StrA #> 6    A6               Tr1           StrA #> 7    A7               Tr2           StrA #> 8    A8               Tr2           StrA #> 9    A9               Tr2           StrA #> 10  A10               Tr2           StrA #> 11  A11               Tr2           StrA #> 12  A12               Tr2           StrA #> 13   B1               Tr1           StrA #> 14   B2               Tr1           StrA #> 15   B3               Tr1           StrA #> 16   B4               Tr1           StrA #> 17   B5               Tr1           StrA #> 18   B6               Tr1           StrA #> 19   B7               Tr2           StrA #> 20   B8               Tr2           StrA"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc03_incorporate_designs.html","id":"importing-tidy-shaped-design-files","dir":"Articles","previous_headings":"","what":"Importing tidy-shaped design files","title":"Incorporating experimental designs","text":"can import tidy-shaped designs read_tidys. read_tidys requires filename (vector filenames, relative file paths) return data.frame (list data.frames) can save R. design elements read R environment, ready merge.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc03_incorporate_designs.html","id":"merging-growth-curve-data-with-designs","dir":"Articles","previous_headings":"","what":"Merging growth curve data with designs","title":"Incorporating experimental designs","text":"design data R tidy-shaped, can merge using merge_dfs. demonstrate , ’ll use data example_widedata_noiseless dataset included gcplyr, source previous examples import_blockmeasures read_wides. example_widedata_noiseless dataset, 48 different bacterial strains. left side plate 48 strains single well , right side plate also 48 strains single well : , right hand side plate phage also inoculated (left hand side remained bacteria-): Let’s transform example_widedata_noiseless tidy-shaped. gcplyr also includes design data easy use: Now data designs tidy-shaped, merge two using merge_dfs, saving result ex_dat_mrg, short example_data_merged. merge_dfs merges using columns name two data.frames.","code":"example_tidydata <- trans_wide_to_tidy(example_widedata_noiseless,                                        id_cols = \"Time\") example_design <- example_design_tidy head(example_design_tidy) #>   Well Bacteria_strain    Phage #> 1   A1        Strain 1 No Phage #> 2   A2        Strain 2 No Phage #> 3   A3        Strain 3 No Phage #> 4   A4        Strain 4 No Phage #> 5   A5        Strain 5 No Phage #> 6   A6        Strain 6 No Phage ex_dat_mrg <- merge_dfs(example_tidydata, example_design) #> Joining with `by = join_by(Well)`  head(ex_dat_mrg) #>   Time Well Measurements Bacteria_strain    Phage #> 1    0   A1        0.002        Strain 1 No Phage #> 2    0   B1        0.002        Strain 7 No Phage #> 3    0   C1        0.002       Strain 13 No Phage #> 4    0   D1        0.002       Strain 19 No Phage #> 5    0   E1        0.002       Strain 25 No Phage #> 6    0   F1        0.002       Strain 31 No Phage"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc03_incorporate_designs.html","id":"whats-next","dir":"Articles","previous_headings":"","what":"What’s next?","title":"Incorporating experimental designs","text":"Now ’ve merged data designs, can pre-process plot data Introduction: vignette(\"gc01_gcplyr\") Importing reshaping data: vignette(\"gc02_import_reshape\") Incorporating experimental designs: vignette(\"gc03_incorporate_designs\") Pre-processing plotting data: vignette(\"gc04_preprocess_plot\") Processing data: vignette(\"gc05_process\") Analyzing data: vignette(\"gc06_analyze\") Dealing noise: vignette(\"gc07_noise\") Best practices tips: vignette(\"gc08_conclusion\") Working multiple plates: vignette(\"gc09_multiple_plates\") Using make_design generate experimental designs: vignette(\"gc10_using_make_design\")","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc04_preprocess_plot.html","id":"where-are-we-so-far","dir":"Articles","previous_headings":"","what":"Where are we so far?","title":"Pre-processing and plotting data","text":"Introduction: vignette(\"gc01_gcplyr\") Importing reshaping data: vignette(\"gc02_import_reshape\") Incorporating experimental designs: vignette(\"gc03_incorporate_designs\") Pre-processing plotting data: vignette(\"gc04_preprocess_plot\") Processing data: vignette(\"gc05_process\") Analyzing data: vignette(\"gc06_analyze\") Dealing noise: vignette(\"gc07_noise\") Best practices tips: vignette(\"gc08_conclusion\") Working multiple plates: vignette(\"gc09_multiple_plates\") Using make_design generate experimental designs: vignette(\"gc10_using_make_design\") far, ’ve imported transformed measures, combined design information. Now ’re going final pre-processing steps show easily plot data ggplot. haven’t already, load necessary packages.","code":"library(gcplyr) #> ##  #> ## gcplyr (Version 1.12.0, Build Date: 2025-07-28) #> ## See http://github.com/mikeblazanin/gcplyr for additional documentation #> ## Please cite software as: #> ##   Blazanin, Michael. gcplyr: an R package for microbial growth #> ##   curve data analysis. BMC Bioinformatics 25, 232 (2024). #> ##   https://doi.org/10.1186/s12859-024-05817-3 #> ##  library(dplyr) #>  #> Attaching package: 'dplyr' #> The following objects are masked from 'package:stats': #>  #>     filter, lag #> The following objects are masked from 'package:base': #>  #>     intersect, setdiff, setequal, union library(ggplot2) library(lubridate) #>  #> Attaching package: 'lubridate' #> The following objects are masked from 'package:base': #>  #>     date, intersect, setdiff, union # This code was previously explained # Here we're re-running it so it's available for us to work with example_tidydata <- trans_wide_to_tidy(example_widedata_noiseless,                                        id_cols = \"Time\") ex_dat_mrg <- merge_dfs(example_tidydata, example_design_tidy) #> Joining with `by = join_by(Well)`"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc04_preprocess_plot.html","id":"pre-processing","dir":"Articles","previous_headings":"","what":"Pre-processing","title":"Pre-processing and plotting data","text":"Now data designs merged, ’re almost ready start processing analyzing . However, first need carry necessary pre-processing steps, like excluding wells contaminated empty, converting time formats numeric, subtracting blanks.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc04_preprocess_plot.html","id":"pre-processing-excluding-data","dir":"Articles","previous_headings":"Pre-processing","what":"Pre-processing: excluding data","title":"Pre-processing and plotting data","text":"cases, want remove wells growth curves data carry downstream analyses. instance, may left empty, contained negative controls, contaminated. can use dplyr’s filter function remove wells meet criteria want exclude. instance, let’s imagine realized put wrong media Well B1, strain 13 contaminated. exclude analyses, can simply:","code":"example_data_and_designs_filtered <-    dplyr::filter(ex_dat_mrg,           Well != \"B1\", Bacteria_strain != \"Strain 13\") head(example_data_and_designs_filtered) #>   Time Well Measurements Bacteria_strain    Phage #> 1    0   A1        0.002        Strain 1 No Phage #> 2    0   D1        0.002       Strain 19 No Phage #> 3    0   E1        0.002       Strain 25 No Phage #> 4    0   F1        0.002       Strain 31 No Phage #> 5    0   G1        0.002       Strain 37 No Phage #> 6    0   H1        0.002       Strain 43 No Phage"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc04_preprocess_plot.html","id":"pre-processing-converting-dates-times-into-numeric","dir":"Articles","previous_headings":"Pre-processing","what":"Pre-processing: converting dates & times into numeric","title":"Pre-processing and plotting data","text":"Growth curve data produced plate reader encodes timestamp information variety ways. timestamp data already nicely-formatted number (e.g. number seconds since growth curve began), just need make ’s stored R numeric type: Time column currently stored character. problem later ’re analyzing plotting data, let’s convert numeric: Alternatively, timestamp information produced plate reader often encoded string (e.g. “2:45:11” 2 hours, 45 minutes, 11 seconds). downstream analyses, need convert timestamp information numeric (e.g. number seconds elapsed). Luckily, others written great packages make easy convert common date-time text formats plain numeric formats. , ’ll see use lubridate : First create data frame time saved might plate reader. can see Time aren’t written easy numeric. Instead, ’re format ’s easy human understand (unfortunately usable analysis). Let’s use lubridate convert text usable format. lubridate whole family functions can parse text hour, minute, /second components. can use hms text contains hour, minute, second information, hm contains hour minute information, ms contains minute second information. hms parsed text, ’ll use time_length convert output hms pure numeric value. default, time_length returns units seconds, can change changing unit argument time_length. now can see ’ve gotten nice numeric Time values!","code":"ex_dat_mrg <- make_example(vignette = 4, example = 1) head(ex_dat_mrg$Time) #> [1] \"0\" \"0\" \"0\" \"0\" \"0\" \"0\" class(ex_dat_mrg$Time) #> [1] \"character\" ex_dat_mrg$Time <- as.numeric(ex_dat_mrg$Time) head(ex_dat_mrg$Time) #> [1] 0 0 0 0 0 0 ex_dat_mrg <- make_example(vignette = 4, example = 2)  head(ex_dat_mrg) #>      Time Well Measurements Bacteria_strain    Phage #> 1 0:00:00   A1        0.002        Strain 1 No Phage #> 2 0:00:00   B1        0.002        Strain 7 No Phage #> 3 0:00:00   C1        0.002       Strain 13 No Phage #> 4 0:00:00   D1        0.002       Strain 19 No Phage #> 5 0:00:00   E1        0.002       Strain 25 No Phage #> 6 0:00:00   F1        0.002       Strain 31 No Phage # We have previously loaded lubridate, but if you haven't already then # make sure to add the line: #    library(lubridate)  ex_dat_mrg$Time <- time_length(hms(ex_dat_mrg$Time), unit = \"hour\")  head(ex_dat_mrg) #>   Time Well Measurements Bacteria_strain    Phage #> 1    0   A1        0.002        Strain 1 No Phage #> 2    0   B1        0.002        Strain 7 No Phage #> 3    0   C1        0.002       Strain 13 No Phage #> 4    0   D1        0.002       Strain 19 No Phage #> 5    0   E1        0.002       Strain 25 No Phage #> 6    0   F1        0.002       Strain 31 No Phage"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc04_preprocess_plot.html","id":"pre-processing-subtracting-blanks","dir":"Articles","previous_headings":"Pre-processing","what":"Pre-processing: subtracting blanks","title":"Pre-processing and plotting data","text":"Many growth curves collected measuring absorbance optical density culture. However, data absorbance value 0 equal cell density 0, since components media often absorb light. ’s best practice least one ‘blank’ well plate containing media cells, can subtract difference data values working scaled correctly. data including blank well. first thing always plot blank wells data ensure look correct:  ’ve confirmed blank wells weren’t contaminated, one simple way subtract blanks calculate average value blank well(s) across timepoints subtract Measurements: Note different blanks different wells (e.g. multiple medias), ’ll calculate different blank values [vignette(\"gc06_analyze\") primer summarize function used , ’d like learn ]:","code":"ex_dat_mrg <- make_example(vignette = 4, example = 3) ggplot(data = ex_dat_mrg,        aes(x = Time, y = Measurements, color = Well_type)) +   geom_point() +   ylim(0, NA) mean_blank <- mean(dplyr::filter(ex_dat_mrg, Well_type == \"Blank\")$Measurements) mean_blank #> [1] 0.2000928 ex_dat_mrg$Meas_norm <- ex_dat_mrg$Measurements - mean_blank ex_dat_mrg <- make_example(vignette = 4, example = 4) ggplot(data = ex_dat_mrg,        aes(x = Time, y = Measurements, color = Well_type)) +   geom_point() +   facet_grid(~Media)  +   ylim(0, NA) blank_data <- dplyr::filter(ex_dat_mrg, Well_type == \"Blank\") blank_data <- group_by(blank_data, Media) ex_dat_sum <- summarize(blank_data,                         mean_blank = mean(Measurements)) head(ex_dat_sum) #> # A tibble: 4 × 2 #>   Media   mean_blank #>   <chr>        <dbl> #> 1 Media_1     0.200  #> 2 Media_2     0.250  #> 3 Media_3     0.0997 #> 4 Media_4     0.150 ex_dat_mrg <- merge_dfs(ex_dat_mrg, ex_dat_sum) #> Joining with `by = join_by(Media)` ex_dat_mrg$Meas_norm <- ex_dat_mrg$Measurements - ex_dat_mrg$mean_blank"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc04_preprocess_plot.html","id":"plotting-your-data","dir":"Articles","previous_headings":"","what":"Plotting your data","title":"Pre-processing and plotting data","text":"data merged times converted numeric, can easily plot data using ggplot2 package. ’s ggplot2 specifically built assumption data tidy-shaped, ! won’t go depth use ggplot , three main commands plot : ggplot - ggplot function specify data.frame like use aesthetics plot (x y axes like) geom_line - tells ggplot like plot data, case line (another common geom time-series data geom_point) facet_wrap - tells ggplot plot Well separate facet ’ll using format plot data throughout remainder vignette  Generally speaking, plot data frequently, every way can think ! every processing analysis step, visualize input data output data understand processing analysis steps whether right choices particular data (vignette !)","code":"# We have previously loaded ggplot2, but if you haven't already then # make sure to add the line: #     library(ggplot2)  # First, we'll reorder the Well levels so they plot in the correct order ex_dat_mrg$Well <-    factor(ex_dat_mrg$Well,          levels = paste0(rep(LETTERS[1:8], each = 12), 1:12))  ggplot(data = ex_dat_mrg, aes(x = Time, y = Measurements)) +   geom_line() +   facet_wrap(~Well, nrow = 8, ncol = 12)"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc04_preprocess_plot.html","id":"whats-next","dir":"Articles","previous_headings":"","what":"What’s next?","title":"Pre-processing and plotting data","text":"Now ’ve pre-processed visualized data, ’s time process (cases) analyze (pretty much always) ! Introduction: vignette(\"gc01_gcplyr\") Importing reshaping data: vignette(\"gc02_import_reshape\") Incorporating experimental designs: vignette(\"gc03_incorporate_designs\") Pre-processing plotting data: vignette(\"gc04_preprocess_plot\") Processing data: vignette(\"gc05_process\") Analyzing data: vignette(\"gc06_analyze\") Dealing noise: vignette(\"gc07_noise\") Best practices tips: vignette(\"gc08_conclusion\") Working multiple plates: vignette(\"gc09_multiple_plates\") Using make_design generate experimental designs: vignette(\"gc10_using_make_design\")","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc05_process.html","id":"where-are-we-so-far","dir":"Articles","previous_headings":"","what":"Where are we so far?","title":"Processing data","text":"Introduction: vignette(\"gc01_gcplyr\") Importing reshaping data: vignette(\"gc02_import_reshape\") Incorporating experimental designs: vignette(\"gc03_incorporate_designs\") Pre-processing plotting data: vignette(\"gc04_preprocess_plot\") Processing data: vignette(\"gc05_process\") Analyzing data: vignette(\"gc06_analyze\") Dealing noise: vignette(\"gc07_noise\") Best practices tips: vignette(\"gc08_conclusion\") Working multiple plates: vignette(\"gc09_multiple_plates\") Using make_design generate experimental designs: vignette(\"gc10_using_make_design\") far, ’ve imported transformed measures, combined design information, pre-processed plotted data. Now ’re going processing raw data: calculating derivatives. haven’t already, load necessary packages.","code":"library(gcplyr) #> ##  #> ## gcplyr (Version 1.12.0, Build Date: 2025-07-28) #> ## See http://github.com/mikeblazanin/gcplyr for additional documentation #> ## Please cite software as: #> ##   Blazanin, Michael. gcplyr: an R package for microbial growth #> ##   curve data analysis. BMC Bioinformatics 25, 232 (2024). #> ##   https://doi.org/10.1186/s12859-024-05817-3 #> ##  library(dplyr) #>  #> Attaching package: 'dplyr' #> The following objects are masked from 'package:stats': #>  #>     filter, lag #> The following objects are masked from 'package:base': #>  #>     intersect, setdiff, setequal, union library(ggplot2) # This code was previously explained # Here we're re-running it so it's available for us to work with example_tidydata <- trans_wide_to_tidy(example_widedata_noiseless,                                        id_cols = \"Time\") ex_dat_mrg <- merge_dfs(example_tidydata, example_design_tidy) #> Joining with `by = join_by(Well)` ex_dat_mrg$Well <-    factor(ex_dat_mrg$Well,          levels = paste(rep(LETTERS[1:8], each = 12), 1:12, sep = \"\")) #Convert time to hours ex_dat_mrg$Time <- ex_dat_mrg$Time/3600"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc05_process.html","id":"how-to-process-and-analyze-your-data","dir":"Articles","previous_headings":"","what":"How to process and analyze your data","title":"Processing data","text":"data design information pre-processed, dataset now organized way ’s easy export analyze. Broadly speaking, two main approaches analyzing growth curves data: directly quantify attributes growth dynamics (gcplyr ) fit growth dynamics mathematical model, extract parameters fitted model (packages , see vignette(\"08_conclusion\")) point, since data now well-organized, advanced users may also decide want write custom analyses (lieu , alongside, gcplyr-based /fitting-based analyses). , directly quantify attributes growth curves? Generally, find features density data derivatives. Different projects may desire different analyses, article Analyzing Data Dealing Noise articles written highlight common analyses, rather prescribing everyone . list common metrics require derivatives calculated. intend calculate metrics, just want calculate plot derivatives, continue reading. Otherwise, feel free skip right Analyzing Data article. Metrics requiring derivatives: lag time time reach growth rate maximum per-capita growth rate (.e. minimum doubling time) inflection point density time diauxic shift occurs maximum per-capita growth rate diauxie dig calculating derivatives, first need familiarize dplyr package functions group_by mutate. ? upcoming gcplyr processing functions best used within dplyr::mutate. ’re already familiar dplyr, feel free skip straight Calculating Derivatives. ’re familiar yet, primer teach need know use gcplyr.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc05_process.html","id":"a-brief-primer-on-dplyr","dir":"Articles","previous_headings":"How to process and analyze your data","what":"A brief primer on dplyr","title":"Processing data","text":"R package dplyr provides “grammar data manipulation” useful broad array data analysis tasks (fact, dplyr direct inspiration name gcplyr!) purposes, ’re going focus two functions: group_by mutate. mutate function dplyr allows users easily create new columns data.frame’s. us, ’re going use mutate create columns derivatives calculate. However, want make sure derivative-calculating done unique well independently. order , ’re first going use group_by function, allows users group rows data.frame’s groups mutate treat independently. growth curves, means : group_by data every unique well group mutate create new columns calculated derivatives group_by, need specify data.frame grouped, want list columns needed identify unique well dataset. Typically, includes design columns along plate name well name. Make sure ’re grouping Time, Absorbance, anything else varies within well, since dplyr group timepoints within well separately. use mutate, simply specify: name variable want results saved function calculates new column want additional columns, simply add mutate. ’ll see throughout rest article, ’ll using group_by mutate calculate derivatives. want learn , dplyr extensive documentation examples online, primer coming examples sufficient calculate derivatives gcplyr.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc05_process.html","id":"CalculatingDerivatives","dir":"Articles","previous_headings":"","what":"Processing data: calculating derivatives","title":"Processing data","text":"two derivatives primarily interested calculating: plain derivative - slope original density data per-capita derivative - growth rate cells gcplyr includes calc_deriv calculate .","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc05_process.html","id":"a-simple-derivative","dir":"Articles","previous_headings":"Processing data: calculating derivatives","what":"A simple derivative","title":"Processing data","text":"calculate simple derivative (slope original data) using calc_deriv, simply provide x y values. Note growth rate cells, rather measure quickly whole population growing time point. visualize results, let’s look wells representative overall diversity dynamics example data. (code, visualize data).  might notice lines aren’t super smooth. ? plate reader data limited resolution, nearest 0.001, causing derivative “jump” reading increases.","code":"ex_dat_mrg <- mutate(group_by(ex_dat_mrg, Well, Bacteria_strain, Phage),                      deriv = calc_deriv(x = Time, y = Measurements)) sample_wells <- c(\"A1\", \"F1\", \"F10\", \"E11\")  # Now let's plot the derivative ggplot(data = dplyr::filter(ex_dat_mrg, Well %in% sample_wells),        aes(x = Time, y = deriv)) +   geom_line() +   facet_wrap(~Well, scales = \"free\") #> Warning: Removed 1 row containing missing values or values outside the scale range #> (`geom_line()`)."},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc05_process.html","id":"per-capita-derivative","dir":"Articles","previous_headings":"Processing data: calculating derivatives","what":"Per-capita derivative","title":"Processing data","text":"calculate per-capita derivative, simply modify use calc_deriv argument percapita = TRUE. Note case, required specify blank value, .e. value Measurements corresponds population density 0. data already normalized, simply add blank = 0.  derivatives jumpy. ? limited resolution plate reader amplified effect per-capita derivative densities close 0. Luckily, calc_deriv can calculate derives fitting linear regression multiple points, reducing jumpiness derivative. use fitting functionality calc_deriv, specify either window_width window_width_n parameter. window_width specifies wide window used include points fitting units x, window_width_n specifies number data points. recommend trying window_width_n three five data points, since works cases. best practice, recommend fitting log-transformed y values, since exponentially growing density values linear log-transformed. can achieve simply setting trans_y = 'log'. log-transformation, note calc_deriv return NA data points reading equal blank value.  Great! jumpiness reduced immensely.","code":"ex_dat_mrg <- mutate(group_by(ex_dat_mrg, Well, Bacteria_strain, Phage),                      deriv_percap = calc_deriv(x = Time, y = Measurements,                                         percapita = TRUE, blank = 0))  # Now let's plot the per-capita derivative ggplot(data = dplyr::filter(ex_dat_mrg, Well %in% sample_wells),        aes(x = Time, y = deriv_percap)) +   geom_line() +   facet_wrap(~Well, scales = \"free\") #> Warning: Removed 1 row containing missing values or values outside the scale range #> (`geom_line()`). ex_dat_mrg <- mutate(group_by(ex_dat_mrg, Well, Bacteria_strain, Phage),                      deriv_percap5 = calc_deriv(x = Time, y = Measurements,                                          percapita = TRUE, blank = 0,                                         window_width_n = 5, trans_y = \"log\"))  # Now let's plot the derivative ggplot(data = dplyr::filter(ex_dat_mrg, Well %in% sample_wells),        aes(x = Time, y = deriv_percap5)) +   geom_line() +   facet_wrap(~Well, scales = \"free\") #> Warning: Removed 4 rows containing missing values or values outside the scale range #> (`geom_line()`)."},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc05_process.html","id":"converting-per-capita-growth-rates-into-doubling-times","dir":"Articles","previous_headings":"Processing data: calculating derivatives","what":"Converting per-capita growth rates into doubling times","title":"Processing data","text":"’d rather express per-capita growth rates doubling time, simply use doubling_time function convert per-capita growth rates equivalent doubling times.","code":"ex_dat_mrg <- mutate(group_by(ex_dat_mrg, Well, Bacteria_strain, Phage),                      deriv_percap5 = calc_deriv(x = Time, y = Measurements,                                          percapita = TRUE, blank = 0,                                         window_width_n = 5, trans_y = \"log\"),                      doub_time = doubling_time(y = deriv_percap5)) head(ex_dat_mrg) #> # A tibble: 6 × 9 #> # Groups:   Well, Bacteria_strain, Phage [4] #>    Time Well  Measurements Bacteria_strain Phage       deriv deriv_percap #>   <dbl> <fct>        <dbl> <chr>           <chr>       <dbl>        <dbl> #> 1  0    A1           0.002 Strain 1        No Phage        0            0 #> 2  0    F1           0.002 Strain 31       No Phage        0            0 #> 3  0    F10          0.002 Strain 34       Phage Added     0            0 #> 4  0    E11          0.002 Strain 29       Phage Added     0            0 #> 5  0.25 A1           0.002 Strain 1        No Phage        0            0 #> 6  0.25 F1           0.002 Strain 31       No Phage        0            0 #> # ℹ 2 more variables: deriv_percap5 <dbl>, doub_time <dbl>"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc05_process.html","id":"whats-next","dir":"Articles","previous_headings":"","what":"What’s next?","title":"Processing data","text":"Now ’ve processed data, ’re ready analyze ! Introduction: vignette(\"gc01_gcplyr\") Importing reshaping data: vignette(\"gc02_import_reshape\") Incorporating experimental designs: vignette(\"gc03_incorporate_designs\") Pre-processing plotting data: vignette(\"gc04_preprocess_plot\") Processing data: vignette(\"gc05_process\") Analyzing data: vignette(\"gc06_analyze\") Dealing noise: vignette(\"gc07_noise\") Best practices tips: vignette(\"gc08_conclusion\") Working multiple plates: vignette(\"gc09_multiple_plates\") Using make_design generate experimental designs: vignette(\"gc10_using_make_design\")","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc06_analyze.html","id":"where-are-we-so-far","dir":"Articles","previous_headings":"","what":"Where are we so far?","title":"Analyzing data","text":"Introduction: vignette(\"gc01_gcplyr\") Importing reshaping data: vignette(\"gc02_import_reshape\") Incorporating experimental designs: vignette(\"gc03_incorporate_designs\") Pre-processing plotting data: vignette(\"gc04_preprocess_plot\") Processing data: vignette(\"gc05_process\") Analyzing data: vignette(\"gc06_analyze\") Dealing noise: vignette(\"gc07_noise\") Best practices tips: vignette(\"gc08_conclusion\") Working multiple plates: vignette(\"gc09_multiple_plates\") Using make_design generate experimental designs: vignette(\"gc10_using_make_design\") far, ’ve imported transformed measures, combined design information, pre-processed, processed, plotted data. Now ’re going analyze data summarizing growth curves number metrics. haven’t already, load necessary packages.","code":"library(gcplyr) #> ##  #> ## gcplyr (Version 1.12.0, Build Date: 2025-07-28) #> ## See http://github.com/mikeblazanin/gcplyr for additional documentation #> ## Please cite software as: #> ##   Blazanin, Michael. gcplyr: an R package for microbial growth #> ##   curve data analysis. BMC Bioinformatics 25, 232 (2024). #> ##   https://doi.org/10.1186/s12859-024-05817-3 #> ##  library(dplyr) #>  #> Attaching package: 'dplyr' #> The following objects are masked from 'package:stats': #>  #>     filter, lag #> The following objects are masked from 'package:base': #>  #>     intersect, setdiff, setequal, union library(ggplot2) # This code was previously explained # Here we're re-running it so it's available for us to work with example_tidydata <- trans_wide_to_tidy(example_widedata_noiseless,                                        id_cols = \"Time\") ex_dat_mrg <- merge_dfs(example_tidydata, example_design_tidy) #> Joining with `by = join_by(Well)` ex_dat_mrg$Well <-    factor(ex_dat_mrg$Well,          levels = paste(rep(LETTERS[1:8], each = 12), 1:12, sep = \"\")) ex_dat_mrg$Time <- ex_dat_mrg$Time/3600 #Convert time to hours ex_dat_mrg <-   mutate(group_by(ex_dat_mrg, Well, Bacteria_strain, Phage),          deriv = calc_deriv(x = Time, y = Measurements),          deriv_percap5 = calc_deriv(x = Time, y = Measurements,                                          percapita = TRUE, blank = 0,                                         window_width_n = 5, trans_y = \"log\"),          doub_time = doubling_time(y = deriv_percap5)) sample_wells <- c(\"A1\", \"F1\", \"F10\", \"E11\") # Drop unneeded columns (optional, but makes things cleaner) ex_dat_mrg <- dplyr::select(ex_dat_mrg,                             Time, Well, Measurements, Bacteria_strain, Phage,                             deriv, deriv_percap5)"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc06_analyze.html","id":"analyzing-data-with-summarize","dir":"Articles","previous_headings":"","what":"Analyzing data with summarize","title":"Analyzing data","text":"Ultimately, analyzing growth curves requires summarizing entire time series data metric metrics. gcplyr makes easy calculate number metrics interest, ’ve grouped categories:","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc06_analyze.html","id":"most-common-metrics","dir":"Articles","previous_headings":"Analyzing data with summarize","what":"Most common metrics","title":"Analyzing data","text":"lag time maximum cellular growth rate (.e. minimum doubling time) maximum density (e.g. carrying capacity) area curve","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc06_analyze.html","id":"growth","dir":"Articles","previous_headings":"Analyzing data with summarize","what":"Growth","title":"Analyzing data","text":"initial density lag time time reach density time reach growth rate maximum per-capita growth rate (.e. minimum doubling time)","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc06_analyze.html","id":"saturation","dir":"Articles","previous_headings":"Analyzing data with summarize","what":"Saturation","title":"Analyzing data","text":"mid-point time inflection point maximum density (e.g. carrying capacity)","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc06_analyze.html","id":"total-growth","dir":"Articles","previous_headings":"Analyzing data with summarize","what":"Total growth","title":"Analyzing data","text":"area curve centroid area curve","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc06_analyze.html","id":"diauxic-growth","dir":"Articles","previous_headings":"Analyzing data with summarize","what":"Diauxic growth","title":"Analyzing data","text":"density time diauxic shift occurs maximum per-capita growth rate diauxie","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc06_analyze.html","id":"growth-with-antagonists-e-g--phages","dir":"Articles","previous_headings":"Analyzing data with summarize","what":"Growth with antagonists (e.g. phages)","title":"Analyzing data","text":"peak bacterial density decline (e.g. phage predation) extinction time (e.g. phage predation) area curve centroid area curve following sections show can use gcplyr functions calculate metrics. first, need familiarize one dplyr function: summarize. ? upcoming gcplyr analysis functions must used within dplyr::summarize. ’re already familiar dplyr’s summarize, feel free skip primer next section. ’re familiar yet, don’t worry! Continue next section, provide primer teach need know using summarize gcplyr functions.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc06_analyze.html","id":"another-brief-primer-on-dplyr-summarize","dir":"Articles","previous_headings":"","what":"Another brief primer on dplyr: summarize","title":"Analyzing data","text":"’re going focus summarize function dplyr, must used group_by function covered first primer: brief primer dplyr. summarize carries user-specified calculations group grouped data.frame independently, producing new data.frame group now just single row. growth curves, means : group_by data every well group summarize well one several metrics , use group_by simply pass data.frame grouped, names columns want group . Since summarize drop columns data aren’t grouped aren’t summarized, typically want list design columns group_by, along plate name well. , make sure ’re grouping Time, Measurements, anything else varies within well, since dplyr group timepoints within well separately. , run summarize. summarize works much like mutate , specify: name variable want results saved function calculates summarized results Just like mutate, want additional summary metrics, simply add summarize. However, unlike mutate, summarize functions return just single value group. ’ll see throughout rest article, ’ll using group_by summarize calculate metrics interest. want learn , dplyr extensive documentation examples online, primer coming example sufficient analyze data gcplyr.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc06_analyze.html","id":"plotting-summarized-metrics","dir":"Articles","previous_headings":"","what":"Plotting summarized metrics","title":"Analyzing data","text":"’ve calculated summarized metrics, plot original data make sure everything matches expect. can plot summarized values right top original data: density rate metrics can plotted horizontal line geom_hline time metrics can plotted vertical line geom_vline pairs metrics correspond density/rate time can plotted point geom_point ’ll see examples plots throughout article.","code":""},{"path":[]},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc06_analyze.html","id":"lag","dir":"Articles","previous_headings":"The most common metrics","what":"Lag time","title":"Analyzing data","text":"Bacteria often period time reach maximum growth rate. like quantify lag time, can use lag_time function. lag_time needs x y values, well (per-capita) derivative blank value (value Measurements corresponds population density 0; data already normalized, simply add blank = 0). find maximum derivative, project tangent line slope back crosses starting density. , calculate lag time. can see visualization tangent-line calculation , also calculate max_percap, max_percap_time, max_percap_dens, min_dens, don’t .  Notice wells minimum density value isn’t initial density? can fix overriding default minimum density calculation first_minima via y0 argument lag_time.","code":"ex_dat_mrg_sum <-    summarize(group_by(ex_dat_mrg, Bacteria_strain, Phage, Well),             lag_time = lag_time(y = Measurements, x = Time,                                  deriv = deriv_percap5, blank = 0),             max_percap = max_gc(deriv_percap5),             max_percap_time = Time[which_max_gc(deriv_percap5)],             max_percap_dens = Measurements[which_max_gc(deriv_percap5)],             min_dens = min_gc(Measurements)) #> `summarise()` has grouped output by 'Bacteria_strain', 'Phage'. You can #> override using the `.groups` argument. head(ex_dat_mrg_sum) #> # A tibble: 6 × 8 #> # Groups:   Bacteria_strain, Phage [6] #>   Bacteria_strain Phage       Well  lag_time max_percap max_percap_time #>   <chr>           <chr>       <fct>    <dbl>      <dbl>           <dbl> #> 1 Strain 1        No Phage    A1        2.18       1.03            4.25 #> 2 Strain 1        Phage Added A7        1.51       1.03            4.25 #> 3 Strain 10       No Phage    B4        1.78       1.59            3.5  #> 4 Strain 10       Phage Added B10       1.34       1.59            3.5  #> 5 Strain 11       No Phage    B5        1.67       1.65            3.5  #> 6 Strain 11       Phage Added B11       1.24       1.65            3.5  #> # ℹ 2 more variables: max_percap_dens <dbl>, min_dens <dbl>  ggplot(data = dplyr::filter(ex_dat_mrg, Well %in% sample_wells),        aes(x = Time, y = log(Measurements))) +   geom_point() +   facet_wrap(~Well) +   geom_abline(data = dplyr::filter(ex_dat_mrg_sum, Well %in% sample_wells),               color = \"red\",               aes(slope = max_percap,                   intercept = log(max_percap_dens) - max_percap*max_percap_time)) +   geom_vline(data = dplyr::filter(ex_dat_mrg_sum, Well %in% sample_wells),              aes(xintercept = lag_time), lty = 2) +   geom_hline(data = dplyr::filter(ex_dat_mrg_sum, Well %in% sample_wells),              aes(yintercept = log(min_dens))) ex_dat_mrg_sum <-    summarize(group_by(ex_dat_mrg, Bacteria_strain, Phage, Well),             min_dens = first_minima(Measurements, return = \"y\"),             lag_time = lag_time(y = Measurements, x = Time,                                  deriv = deriv_percap5, blank = 0,                                  y0 = min_dens),             max_percap = max_gc(deriv_percap5),             max_percap_time = Time[which_max_gc(deriv_percap5)],             max_percap_dens = Measurements[which_max_gc(deriv_percap5)]) #> `summarise()` has grouped output by 'Bacteria_strain', 'Phage'. You can #> override using the `.groups` argument. head(ex_dat_mrg_sum) #> # A tibble: 6 × 8 #> # Groups:   Bacteria_strain, Phage [6] #>   Bacteria_strain Phage       Well  min_dens lag_time max_percap max_percap_time #>   <chr>           <chr>       <fct>    <dbl>    <dbl>      <dbl>           <dbl> #> 1 Strain 1        No Phage    A1       0.002     2.18       1.03            4.25 #> 2 Strain 1        Phage Added A7       0.002     2.18       1.03            4.25 #> 3 Strain 10       No Phage    B4       0.002     1.78       1.59            3.5  #> 4 Strain 10       Phage Added B10      0.002     1.78       1.59            3.5  #> 5 Strain 11       No Phage    B5       0.002     1.67       1.65            3.5  #> 6 Strain 11       Phage Added B11      0.002     1.67       1.65            3.5  #> # ℹ 1 more variable: max_percap_dens <dbl>  ggplot(data = dplyr::filter(ex_dat_mrg, Well %in% sample_wells),        aes(x = Time, y = log(Measurements))) +   geom_point() +   facet_wrap(~Well) +   geom_abline(data = dplyr::filter(ex_dat_mrg_sum, Well %in% sample_wells),               color = \"red\",               aes(slope = max_percap,                   intercept = log(max_percap_dens) - max_percap*max_percap_time)) +   geom_vline(data = dplyr::filter(ex_dat_mrg_sum, Well %in% sample_wells),              aes(xintercept = lag_time), lty = 2) +   geom_hline(data = dplyr::filter(ex_dat_mrg_sum, Well %in% sample_wells),              aes(yintercept = log(min_dens)))"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc06_analyze.html","id":"max_percap","dir":"Articles","previous_headings":"The most common metrics","what":"Maximum growth rate and minimum doubling time","title":"Analyzing data","text":"want calculate bacterial maximum growth rate (.e. minimum doubling time), often sufficient use max_gc per-capita derivatives calculated vignette(\"gc05_process\"). (max_gc works just like R’s built-max, better default settings growth curve analyses summarize). can also save time maximum occurs using which_max_gc function. which_max_gc returns index maximum value, can get Time value index save column titled max_percap_time. (which_max_gc extr_val work just like R’s built-.max [, better default settings growth curve analyses summarize) like equivalent minimum doubling time, can simply calculate maximum growth rate convert equivalent minimum doubling time using doubling_time function. important note gcplyr calculates maximum realized growth rate growth curve. distinct intrinsic growth rate (maximum possible growth rate), although two quite similar started growth curves sufficiently low densities (see: Ghenu et al., 2024. Challenges pitfalls inferring microbial growth rates lab cultures. Frontiers Ecology Evolution.)","code":"ex_dat_mrg_sum <-    summarize(group_by(ex_dat_mrg, Bacteria_strain, Phage, Well),             max_percap = max_gc(deriv_percap5, na.rm = TRUE),             max_percap_time = extr_val(Time, which_max_gc(deriv_percap5)),             doub_time = doubling_time(y = max_percap)) #> `summarise()` has grouped output by 'Bacteria_strain', 'Phage'. You can #> override using the `.groups` argument. head(ex_dat_mrg_sum) #> # A tibble: 6 × 6 #> # Groups:   Bacteria_strain, Phage [6] #>   Bacteria_strain Phage       Well  max_percap max_percap_time doub_time #>   <chr>           <chr>       <fct>      <dbl>           <dbl>     <dbl> #> 1 Strain 1        No Phage    A1          1.03            4.25     0.670 #> 2 Strain 1        Phage Added A7          1.03            4.25     0.670 #> 3 Strain 10       No Phage    B4          1.59            3.5      0.436 #> 4 Strain 10       Phage Added B10         1.59            3.5      0.436 #> 5 Strain 11       No Phage    B5          1.65            3.5      0.421 #> 6 Strain 11       Phage Added B11         1.65            3.5      0.421  ggplot(data = dplyr::filter(ex_dat_mrg, Well %in% sample_wells),        aes(x = Time, y = deriv_percap5)) +   geom_line() +   facet_wrap(~Well) +   geom_point(data = dplyr::filter(ex_dat_mrg_sum, Well %in% sample_wells),               aes(x = max_percap_time, y = max_percap),              size = 2, color = \"red\") +   coord_cartesian(ylim = c(-1, NA)) #> Warning: Removed 4 rows containing missing values or values outside the scale range #> (`geom_line()`)."},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc06_analyze.html","id":"maxdens","dir":"Articles","previous_headings":"The most common metrics","what":"Maximum density","title":"Analyzing data","text":"maximum bacterial density can measure bacterial growth yield/efficiency. bacteria plateau density, maximum density can also measure bacterial carrying capacity. want quantify maximum bacterial density, can use max_gc get global maxima Measurements (max_gc, which_max_gc, extr_val work just like R’s built-max, .max, [, better default settings growth curve analyses summarize). See Peak bacterial density identifying local maxima Measurements (e.g. wanted first peak Well E11 shown ).","code":"ex_dat_mrg_sum <-    summarize(group_by(ex_dat_mrg, Bacteria_strain, Phage, Well),             max_dens = max_gc(Measurements, na.rm = TRUE),             max_time = extr_val(Time, which_max_gc(Measurements))) #> `summarise()` has grouped output by 'Bacteria_strain', 'Phage'. You can #> override using the `.groups` argument. head(ex_dat_mrg_sum) #> # A tibble: 6 × 5 #> # Groups:   Bacteria_strain, Phage [6] #>   Bacteria_strain Phage       Well  max_dens max_time #>   <chr>           <chr>       <fct>    <dbl>    <dbl> #> 1 Strain 1        No Phage    A1       1.18     24    #> 2 Strain 1        Phage Added A7       0.499     8.75 #> 3 Strain 10       No Phage    B4       1.21     23.8  #> 4 Strain 10       Phage Added B10      0.962     8.5  #> 5 Strain 11       No Phage    B5       1.21     19.5  #> 6 Strain 11       Phage Added B11      1.03     24  ggplot(data = dplyr::filter(ex_dat_mrg, Well %in% sample_wells),        aes(x = Time, y = Measurements)) +   geom_line() +   facet_wrap(~Well) +   geom_point(data = dplyr::filter(ex_dat_mrg_sum, Well %in% sample_wells),               aes(x = max_time, y = max_dens),              size = 2, color = \"red\")"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc06_analyze.html","id":"auc","dir":"Articles","previous_headings":"The most common metrics","what":"Area under the curve","title":"Analyzing data","text":"area curve common metric total bacterial growth, instance presence antagonists like antibiotics phages. want calculate area curve, can use gcplyr function auc. Simply specify Time x Measurements y data whose area---curve want calculate.","code":"ex_dat_mrg_sum <-   summarize(group_by(ex_dat_mrg, Bacteria_strain, Phage, Well),             auc = auc(x = Time, y = Measurements)) #> `summarise()` has grouped output by 'Bacteria_strain', 'Phage'. You can #> override using the `.groups` argument. head(ex_dat_mrg_sum) #> # A tibble: 6 × 4 #> # Groups:   Bacteria_strain, Phage [6] #>   Bacteria_strain Phage       Well    auc #>   <chr>           <chr>       <fct> <dbl> #> 1 Strain 1        No Phage    A1    15.9  #> 2 Strain 1        Phage Added A7     1.07 #> 3 Strain 10       No Phage    B4    20.4  #> 4 Strain 10       Phage Added B10    6.15 #> 5 Strain 11       No Phage    B5    20.9  #> 6 Strain 11       Phage Added B11    7.77"},{"path":[]},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc06_analyze.html","id":"init_dens","dir":"Articles","previous_headings":"Growth metrics","what":"Initial density","title":"Analyzing data","text":"want identify initial density bacteria, often sufficient use min_gc (works just like R’s built-min, better default settings growth curve analyses summarize). can also save time minimum occurs using which_min_gc function. which_min_gc returns index minimum value, can get Time value index save column titled min_time. (which_min_gc extr_val work just like R’s built-.min [, better default settings growth curve analyses summarize)  cases (e.g. growing phages), bacteria may later drop lower density started growth curve. case, want first local minima Measurements data, rather global minima: Note can tune sensitivity first_minima different heights widths peaks valleys using window_width, window_width_n, window_height arguments. check first_minima working data plotting , although default sensitivity works much time.","code":"ex_dat_mrg_sum <-    summarize(group_by(ex_dat_mrg, Bacteria_strain, Phage, Well),             min_dens = min_gc(Measurements, na.rm = TRUE),             min_time = extr_val(Time, which_min_gc(Measurements))) #> `summarise()` has grouped output by 'Bacteria_strain', 'Phage'. You can #> override using the `.groups` argument. head(ex_dat_mrg_sum) #> # A tibble: 6 × 5 #> # Groups:   Bacteria_strain, Phage [6] #>   Bacteria_strain Phage       Well  min_dens min_time #>   <chr>           <chr>       <fct>    <dbl>    <dbl> #> 1 Strain 1        No Phage    A1       0.002     0    #> 2 Strain 1        Phage Added A7       0.001     9.75 #> 3 Strain 10       No Phage    B4       0.002     0    #> 4 Strain 10       Phage Added B10      0.001    11    #> 5 Strain 11       No Phage    B5       0.002     0    #> 6 Strain 11       Phage Added B11      0.001     6  ggplot(data = dplyr::filter(ex_dat_mrg, Well %in% sample_wells),        aes(x = Time, y = Measurements)) +   geom_line() +   facet_wrap(~Well) +   geom_point(data = dplyr::filter(ex_dat_mrg_sum, Well %in% sample_wells),               aes(x = min_time, y = min_dens),              size = 2, color = \"red\") ex_dat_mrg_sum <-    summarize(group_by(ex_dat_mrg, Bacteria_strain, Phage, Well),             min_dens = first_minima(y = Measurements, x = Time, return = \"y\"),             min_time = first_minima(y = Measurements, x = Time, return = \"x\")) #> `summarise()` has grouped output by 'Bacteria_strain', 'Phage'. You can #> override using the `.groups` argument. head(ex_dat_mrg_sum) #> # A tibble: 6 × 5 #> # Groups:   Bacteria_strain, Phage [6] #>   Bacteria_strain Phage       Well  min_dens min_time #>   <chr>           <chr>       <fct>    <dbl>    <dbl> #> 1 Strain 1        No Phage    A1       0.002        0 #> 2 Strain 1        Phage Added A7       0.002        0 #> 3 Strain 10       No Phage    B4       0.002        0 #> 4 Strain 10       Phage Added B10      0.002        0 #> 5 Strain 11       No Phage    B5       0.002        0 #> 6 Strain 11       Phage Added B11      0.002        0"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc06_analyze.html","id":"lag-time","dir":"Articles","previous_headings":"Growth metrics","what":"Lag time","title":"Analyzing data","text":"See lag time section Common Metrics section","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc06_analyze.html","id":"dens_thresh","dir":"Articles","previous_headings":"Growth metrics","what":"Time to reach threshold density","title":"Analyzing data","text":"want quantify long takes bacteria reach threshold density, can use first_above function. example, ’ll use Measurements value 0.1 threshold.","code":"ex_dat_mrg_sum <-    summarize(group_by(ex_dat_mrg, Bacteria_strain, Phage, Well),             above_01 = first_above(y = Measurements, x = Time,                                     threshold = 0.1, return = \"x\")) #> `summarise()` has grouped output by 'Bacteria_strain', 'Phage'. You can #> override using the `.groups` argument. head(ex_dat_mrg_sum) #> # A tibble: 6 × 4 #> # Groups:   Bacteria_strain, Phage [6] #>   Bacteria_strain Phage       Well  above_01 #>   <chr>           <chr>       <fct>    <dbl> #> 1 Strain 1        No Phage    A1        6.09 #> 2 Strain 1        Phage Added A7        6.09 #> 3 Strain 10       No Phage    B4        4.25 #> 4 Strain 10       Phage Added B10       4.25 #> 5 Strain 11       No Phage    B5        4.04 #> 6 Strain 11       Phage Added B11       4.04  ggplot(data = dplyr::filter(ex_dat_mrg, Well %in% sample_wells),        aes(x = Time, y = Measurements)) +   geom_line() +   facet_wrap(~Well) +   geom_vline(data = dplyr::filter(ex_dat_mrg_sum, Well %in% sample_wells),               aes(xintercept = above_01), lty = 2, color = \"red\")"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc06_analyze.html","id":"percap_thresh","dir":"Articles","previous_headings":"Growth metrics","what":"Time to reach threshold growth rate","title":"Analyzing data","text":"want quantify long takes bacteria reach threshold per-capita growth rate, can use first_above function. example, ’ll use per-capita derivative 1 threshold.","code":"ex_dat_mrg_sum <-    summarize(group_by(ex_dat_mrg, Bacteria_strain, Phage, Well),             percap_above_1 = first_above(y = deriv_percap5, x = Time,                                     threshold = 1, return = \"x\")) #> `summarise()` has grouped output by 'Bacteria_strain', 'Phage'. You can #> override using the `.groups` argument. head(ex_dat_mrg_sum) #> # A tibble: 6 × 4 #> # Groups:   Bacteria_strain, Phage [6] #>   Bacteria_strain Phage       Well  percap_above_1 #>   <chr>           <chr>       <fct>          <dbl> #> 1 Strain 1        No Phage    A1              3.95 #> 2 Strain 1        Phage Added A7              3.95 #> 3 Strain 10       No Phage    B4              2.28 #> 4 Strain 10       Phage Added B10             2.28 #> 5 Strain 11       No Phage    B5              2.11 #> 6 Strain 11       Phage Added B11             2.11  ggplot(data = dplyr::filter(ex_dat_mrg, Well %in% sample_wells),        aes(x = Time, y = deriv_percap5)) +   geom_line() +   facet_wrap(~Well) +   geom_vline(data = dplyr::filter(ex_dat_mrg_sum, Well %in% sample_wells),              aes(xintercept = percap_above_1), lty = 2, color = \"red\") +   coord_cartesian(ylim = c(-1, NA)) #> Warning: Removed 4 rows containing missing values or values outside the scale range #> (`geom_line()`). #> Warning: Removed 2 rows containing missing values or values outside the scale range #> (`geom_vline()`)."},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc06_analyze.html","id":"maximum-growth-rate-and-minimum-doubling-time","dir":"Articles","previous_headings":"Growth metrics","what":"Maximum growth rate and minimum doubling time","title":"Analyzing data","text":"See maximum growth rate section Common Metrics section","code":""},{"path":[]},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc06_analyze.html","id":"midpoint","dir":"Articles","previous_headings":"Saturation metrics","what":"Mid-point time or inflection point","title":"Analyzing data","text":"want find mid-point inflection point bacterial growth, two different approaches: Mid-point: find point density first reaches half maximum density. Inflection point: find point derivative maximum. growth curve analysis approaches using fitting symmetric function (e.g. R packages fit logistic function data), two points equivalent. However, since gcplyr model-free analyses, assume symmetry, points may similar different. mid-point, use first_above function, threshold equal maximum bacterial density divided 2. inflection point, find time deriv maximum using which_max_gc (which_max_gc extr_val work just like R’s built-.max [, better default settings growth curve analyses summarize).","code":"ex_dat_mrg_sum <-    summarize(group_by(ex_dat_mrg, Bacteria_strain, Phage, Well),             mid_point = first_above(y = Measurements, x = Time, return = \"x\",                                     threshold = max_gc(Measurements)/2),             infl_point = extr_val(Time, which_max_gc(deriv))) #> `summarise()` has grouped output by 'Bacteria_strain', 'Phage'. You can #> override using the `.groups` argument. head(ex_dat_mrg_sum) #> # A tibble: 6 × 5 #> # Groups:   Bacteria_strain, Phage [6] #>   Bacteria_strain Phage       Well  mid_point infl_point #>   <chr>           <chr>       <fct>     <dbl>      <dbl> #> 1 Strain 1        No Phage    A1         9.15       8.25 #> 2 Strain 1        Phage Added A7         7.29       8.25 #> 3 Strain 10       No Phage    B4         6.06       5.5  #> 4 Strain 10       Phage Added B10        5.67       5.5  #> 5 Strain 11       No Phage    B5         5.71       5    #> 6 Strain 11       Phage Added B11       16.7        5  ggplot(data = dplyr::filter(ex_dat_mrg, Well %in% sample_wells),        aes(x = Time, y = Measurements)) +   geom_line() +   facet_wrap(~Well) +   geom_vline(data = dplyr::filter(ex_dat_mrg_sum, Well %in% sample_wells),              aes(xintercept = mid_point), lty = 2, color = \"red\") +   geom_vline(data = dplyr::filter(ex_dat_mrg_sum, Well %in% sample_wells),              aes(xintercept = infl_point), lty = 2, color = \"blue\")"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc06_analyze.html","id":"maximum-density","dir":"Articles","previous_headings":"Saturation metrics","what":"Maximum density","title":"Analyzing data","text":"See maximum density section Common Metrics section","code":""},{"path":[]},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc06_analyze.html","id":"area-under-the-curve","dir":"Articles","previous_headings":"Total growth metrics","what":"Area under the curve","title":"Analyzing data","text":"See area curve section Common Metrics section","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc06_analyze.html","id":"centroid","dir":"Articles","previous_headings":"Total growth metrics","what":"Centroid of area under the curve","title":"Analyzing data","text":"centroid, center mass, area curve can function metric total microbial growth. area curve solid object, centroid point object balance perfectly. centroid x coordinate y coordinate. calculate centroid coordinates, can use gcplyr function centroid_x centroid_y. Simply specify Time x Measurements y data whose centroid want calculate.","code":"ex_dat_mrg_sum <-   summarize(group_by(ex_dat_mrg, Bacteria_strain, Phage, Well),             centr_x = centroid_x(x = Time, y = Measurements),             centr_y = centroid_y(x = Time, y = Measurements)) #> `summarise()` has grouped output by 'Bacteria_strain', 'Phage'. You can #> override using the `.groups` argument. head(ex_dat_mrg_sum) #> # A tibble: 6 × 5 #> # Groups:   Bacteria_strain, Phage [6] #>   Bacteria_strain Phage       Well  centr_x centr_y #>   <chr>           <chr>       <fct>   <dbl>   <dbl> #> 1 Strain 1        No Phage    A1      16.5    0.485 #> 2 Strain 1        Phage Added A7       8.07   0.150 #> 3 Strain 10       No Phage    B4      15.2    0.546 #> 4 Strain 10       Phage Added B10     13.5    0.347 #> 5 Strain 11       No Phage    B5      15.1    0.552 #> 6 Strain 11       Phage Added B11     19.2    0.414  ggplot(data = dplyr::filter(ex_dat_mrg, Well %in% sample_wells),        aes(x = Time, y = Measurements)) +   geom_line() +   facet_wrap(~Well) +   geom_point(data = dplyr::filter(ex_dat_mrg_sum, Well %in% sample_wells),               aes(x = centr_x, y = centr_y))"},{"path":[]},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc06_analyze.html","id":"diauxie","dir":"Articles","previous_headings":"Diauxic growth metrics","what":"Diauxic shifts","title":"Analyzing data","text":"Bacteria frequently exhibit second, slower, burst growth first period rapid growth. common growth curves called diauxic growth. plot data example data wells phage added, ’ll see pattern repeatedly:  can identify time bacteria switch first period rapid growth second period finding minima derivative values. Specifically, want identify second minima (first minima occur beginning growth curve, bacteria just starting grow). Let’s look derivative values see .  can use gcplyr function find_local_extrema find minima. Specify deriv y data Time x data, want find_local_extrema return x values associated local minima. return vector x values, ’re going save just second one. time, ’re also going save density diauxic shift occurs. First, ’ll use find_local_extrema , time save index diauxic shift occurs column titled diauxie_idx. , can get Measurements value index. (Note wouldn’t work just specify return = \"y\", y values case deriv values). (extr_val works just like R’s built-[, better default settings growth curve analyses summarize).  needed, can tune sensitivity find_local_extrema different heights widths peaks valleys using window_width, window_width_n, window_height arguments.","code":"nophage_wells <- c(\"A1\", \"A4\", \"E2\", \"F1\") ggplot(data = dplyr::filter(ex_dat_mrg, Well %in% nophage_wells),        aes(x = Time, y = Measurements)) +   geom_line() +   facet_wrap(~Well, scales = \"free\") ggplot(data = dplyr::filter(ex_dat_mrg, Well %in% nophage_wells),        aes(x = Time, y = deriv)) +   geom_line() +   facet_wrap(~Well, scales = \"free\") #> Warning: Removed 1 row containing missing values or values outside the scale range #> (`geom_line()`). ex_dat_mrg_sum <-   summarize(group_by(ex_dat_mrg, Bacteria_strain, Phage, Well),     diauxie_time = find_local_extrema(x = Time, y = deriv, return = \"x\",                                    return_maxima = FALSE, return_minima = TRUE,                                    window_width_n = 39)[2],     diauxie_idx = find_local_extrema(x = Time, y = deriv, return = \"index\",                                    return_maxima = FALSE, return_minima = TRUE,                                    window_width_n = 39)[2],     diauxie_dens = extr_val(Measurements, diauxie_idx)) #> `summarise()` has grouped output by 'Bacteria_strain', 'Phage'. You can #> override using the `.groups` argument. head(ex_dat_mrg_sum) #> # A tibble: 6 × 6 #> # Groups:   Bacteria_strain, Phage [6] #>   Bacteria_strain Phage       Well  diauxie_time diauxie_idx diauxie_dens #>   <chr>           <chr>       <fct>        <dbl>       <int>        <dbl> #> 1 Strain 1        No Phage    A1           16             65        1.01  #> 2 Strain 1        Phage Added A7            9             37        0.379 #> 3 Strain 10       No Phage    B4            9.75          40        0.999 #> 4 Strain 10       Phage Added B10           9.25          38        0.682 #> 5 Strain 11       No Phage    B5            9.5           39        1.01  #> 6 Strain 11       Phage Added B11           5.5           23        0.346  # Plot data with a point at the moment of diauxic shift ggplot(data = dplyr::filter(ex_dat_mrg, Well %in% nophage_wells),        aes(x = Time, y = Measurements)) +   geom_line() +   facet_wrap(~Well, scales = \"free\") +   geom_point(data = dplyr::filter(ex_dat_mrg_sum, Well %in% nophage_wells),               aes(x = diauxie_time, y = diauxie_dens),              size = 2, color = \"red\")"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc06_analyze.html","id":"diauxic_percap","dir":"Articles","previous_headings":"Diauxic growth metrics","what":"Growth rate during diauxie","title":"Analyzing data","text":"previous section identified bacteria shifted second period rapid growth (‘diauxic growth’). want find peak per-capita growth rate second burst, ’ll use max subset data diauxic shift identified find_local_extrema Just previous section, ’ll use find_local_extrema save time diauxic shift occurs. , ’ll find maximum per-capita derivative shift occurs. Finally, ’ll find time post-diauxie maximum growth rate occurs. Note ’re using max_gc which_max_gc, work just like R’s built-max .max, better default settings growth curve analyses summarize.","code":"ex_dat_mrg_sum <-   summarize(     group_by(ex_dat_mrg, Bacteria_strain, Phage, Well),     diauxie_time =        find_local_extrema(x = Time, y = deriv, return = \"x\",                          return_maxima = FALSE, return_minima = TRUE,                          window_width_n = 39)[2],     diauxie_percap = max_gc(deriv_percap5[Time >= diauxie_time]),     diauxie_percap_time =        extr_val(Time[Time >= diauxie_time],                which_max_gc(deriv_percap5[Time >= diauxie_time]))   ) #> `summarise()` has grouped output by 'Bacteria_strain', 'Phage'. You can #> override using the `.groups` argument. head(ex_dat_mrg_sum) #> # A tibble: 6 × 6 #> # Groups:   Bacteria_strain, Phage [6] #>   Bacteria_strain Phage    Well  diauxie_time diauxie_percap diauxie_percap_time #>   <chr>           <chr>    <fct>        <dbl>          <dbl>               <dbl> #> 1 Strain 1        No Phage A1           16            0.0257                20   #> 2 Strain 1        Phage A… A7            9            0.832                 19.8 #> 3 Strain 10       No Phage B4            9.75         0.0398                13.2 #> 4 Strain 10       Phage A… B10           9.25         1.24                  17.8 #> 5 Strain 11       No Phage B5            9.5          0.0438                12.2 #> 6 Strain 11       Phage A… B11           5.5          1.43                  12.8  # Plot data with a point at the moment of peak diauxic growth rate ggplot(data = dplyr::filter(ex_dat_mrg, Well %in% nophage_wells),        aes(x = Time, y = deriv_percap5)) +   geom_line() +   facet_wrap(~Well, scales = \"free\") +   geom_point(data = dplyr::filter(ex_dat_mrg_sum, Well %in% nophage_wells),               aes(x = diauxie_percap_time, y = diauxie_percap),              size = 2, color = \"red\") #> Warning: Removed 4 rows containing missing values or values outside the scale range #> (`geom_line()`)."},{"path":[]},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc06_analyze.html","id":"peak_dens","dir":"Articles","previous_headings":"Metrics of growth with antagonists","what":"Peak bacterial density","title":"Analyzing data","text":"previously found global maximum bacterial density using simple max_gc which_max_gc functions. first local maxima can also interest. especially true bacteria grown phages, first peak density can act proxy measure susceptibility phage. ’re interested finding first local maxima bacterial density, can use gcplyr function first_maxima. first_maxima simply requires y data want identify peak . Specify Measurements y data Time x data, want first_peak return x y values associated peak. ’ll save columns first_maxima_x first_maxima_y, respectively.  Note can tune sensitivity first_maxima different heights widths peaks valleys using window_width, window_width_n, window_height arguments, although defaults work much time.","code":"ex_dat_mrg_sum <-   summarize(group_by(ex_dat_mrg, Bacteria_strain, Phage, Well),             first_maxima_x = first_maxima(x = Time, y = Measurements,                                            return = \"x\"),             first_maxima_y = first_maxima(x = Time, y = Measurements,                                            return = \"y\")) #> `summarise()` has grouped output by 'Bacteria_strain', 'Phage'. You can #> override using the `.groups` argument. head(ex_dat_mrg_sum) #> # A tibble: 6 × 5 #> # Groups:   Bacteria_strain, Phage [6] #>   Bacteria_strain Phage       Well  first_maxima_x first_maxima_y #>   <chr>           <chr>       <fct>          <dbl>          <dbl> #> 1 Strain 1        No Phage    A1             24             1.18  #> 2 Strain 1        Phage Added A7              8.75          0.499 #> 3 Strain 10       No Phage    B4             19.8           1.21  #> 4 Strain 10       Phage Added B10             8.5           0.962 #> 5 Strain 11       No Phage    B5             19.5           1.21  #> 6 Strain 11       Phage Added B11             5.25          0.439  ggplot(data = dplyr::filter(ex_dat_mrg, Well %in% sample_wells),         aes(x = Time, y = Measurements)) +   geom_line() +   facet_wrap(~Well) +   geom_point(data = dplyr::filter(ex_dat_mrg_sum, Well %in% sample_wells),               aes(x = first_maxima_x, y = first_maxima_y),               color = \"red\", size = 1.5)"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc06_analyze.html","id":"extin_time","dir":"Articles","previous_headings":"Metrics of growth with antagonists","what":"Extinction time","title":"Analyzing data","text":"time bacterial density falls threshold can also interest. especially true bacteria grown phages, ‘extinction time’ can act proxy measure susceptibility phage. ’re interested finding extinction time, can use gcplyr function first_below. example, ’ll use Measurements value 0.15 threshold.","code":"ex_dat_mrg_sum <-   summarize(     group_by(ex_dat_mrg, Bacteria_strain, Phage, Well),     extin_time = first_below(x = Time, y = Measurements, threshold = 0.15,                              return = \"x\", return_endpoints = FALSE)) #> `summarise()` has grouped output by 'Bacteria_strain', 'Phage'. You can #> override using the `.groups` argument. head(ex_dat_mrg_sum) #> # A tibble: 6 × 4 #> # Groups:   Bacteria_strain, Phage [6] #>   Bacteria_strain Phage       Well  extin_time #>   <chr>           <chr>       <fct>      <dbl> #> 1 Strain 1        No Phage    A1         NA    #> 2 Strain 1        Phage Added A7          9.18 #> 3 Strain 10       No Phage    B4         NA    #> 4 Strain 10       Phage Added B10         9.71 #> 5 Strain 11       No Phage    B5         NA    #> 6 Strain 11       Phage Added B11         5.64  phage_wells <- c(\"A7\", \"B10\", \"F10\", \"H8\") ggplot(data = dplyr::filter(ex_dat_mrg, Well %in% phage_wells),        aes(x = Time, y = Measurements)) +   geom_line() +   facet_wrap(~Well) +   geom_vline(data = dplyr::filter(ex_dat_mrg_sum, Well %in% phage_wells),              aes(xintercept = extin_time), lty = 2)"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc06_analyze.html","id":"area-under-the-curve-1","dir":"Articles","previous_headings":"Metrics of growth with antagonists","what":"Area under the curve","title":"Analyzing data","text":"See area curve section Common Metrics section","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc06_analyze.html","id":"centroid-of-area-under-the-curve","dir":"Articles","previous_headings":"Metrics of growth with antagonists","what":"Centroid of area under the curve","title":"Analyzing data","text":"See centroid section Total Growth Metrics section","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc06_analyze.html","id":"whats-next","dir":"Articles","previous_headings":"","what":"What’s next?","title":"Analyzing data","text":"Now ’ve analyzed data, can read approaches deal noise growth curve data, can read concluding notes best practices running statistics, merging growth curve analyses data, additional resources analyzing growth curves. Introduction: vignette(\"gc01_gcplyr\") Importing reshaping data: vignette(\"gc02_import_reshape\") Incorporating experimental designs: vignette(\"gc03_incorporate_designs\") Pre-processing plotting data: vignette(\"gc04_preprocess_plot\") Processing data: vignette(\"gc05_process\") Analyzing data: vignette(\"gc06_analyze\") Dealing noise: vignette(\"gc07_noise\") Best practices tips: vignette(\"gc08_conclusion\") Working multiple plates: vignette(\"gc09_multiple_plates\") Using make_design generate experimental designs: vignette(\"gc10_using_make_design\")","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc07_noise.html","id":"where-are-we-so-far","dir":"Articles","previous_headings":"","what":"Where are we so far?","title":"Dealing with noise","text":"Introduction: vignette(\"gc01_gcplyr\") Importing reshaping data: vignette(\"gc02_import_reshape\") Incorporating experimental designs: vignette(\"gc03_incorporate_designs\") Pre-processing plotting data: vignette(\"gc04_preprocess_plot\") Processing data: vignette(\"gc05_process\") Analyzing data: vignette(\"gc06_analyze\") Dealing noise: vignette(\"gc07_noise\") Best practices tips: vignette(\"gc08_conclusion\") Working multiple plates: vignette(\"gc09_multiple_plates\") Using make_design generate experimental designs: vignette(\"gc10_using_make_design\") far, ’ve imported transformed measures, combined design information, pre-processed, processed, plotted, analyzed data. , ’re going learn potential strategies dealing noise growth curve data. haven’t already, load necessary packages.","code":"library(gcplyr) #> ##  #> ## gcplyr (Version 1.12.0, Build Date: 2025-07-28) #> ## See http://github.com/mikeblazanin/gcplyr for additional documentation #> ## Please cite software as: #> ##   Blazanin, Michael. gcplyr: an R package for microbial growth #> ##   curve data analysis. BMC Bioinformatics 25, 232 (2024). #> ##   https://doi.org/10.1186/s12859-024-05817-3 #> ##  library(dplyr) #>  #> Attaching package: 'dplyr' #> The following objects are masked from 'package:stats': #>  #>     filter, lag #> The following objects are masked from 'package:base': #>  #>     intersect, setdiff, setequal, union library(ggplot2) library(tidyr)"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc07_noise.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Dealing with noise","text":"Oftentimes, growth curve data produced plate reader noise . Since gcplyr model-free analyses, approach can sometimes sensitive noise, necessitating steps reduce effects noise. assessing effects noise data, one first steps simply visualize data, including raw data derivatives ’ll analyzing. especially important per-capita derivatives can sensitive noise, especially density low. visualizing data, can assess whether noise see likely throw analyses. Broadly speaking, three strategies can use deal noise. Excluding low-density data points Using fitting derivative calculations Smoothing raw data approach progressively involved, recommend trying order. Typically, noise problematic derivatives, three approaches help . However, ’re dealing substantial noise raw density data, approach #3 help. Let’s start pulling example data. example data example data ’ve working , along version data simulated noise added .  Great! can see noisy (points) noiseless (red line) data compare. ’ve plotted data log-transformed y-axes, useful exponential growth straight line plotted log scale. log axes also reveal another common pattern: random noise tends much larger effect low densities. level noise doesn’t seem like mess calculations maximum density area curve much, ’s enough reason smooth. let’s look derivatives look like.   values jumping place! Let’s see can address .","code":"ex_dat_mrg <- make_example(vignette = 7, example = 1)  # Plot with a log y-axis ggplot(data = dplyr::filter(ex_dat_mrg, noise == \"Yes\"),        aes(x = Time, y = Measurements)) +   geom_point() +   geom_line(data = dplyr::filter(ex_dat_mrg, noise == \"No\"),             lty = 2, color = \"red\") +   facet_wrap(~Well) +   scale_y_continuous(trans = \"log10\") #> Warning in scale_y_continuous(trans = \"log10\"): log-10 #> transformation introduced infinite values. ex_dat_mrg <-    mutate(group_by(ex_dat_mrg, Well, Bacteria_strain, Phage, noise),          deriv_2 = calc_deriv(x = Time, y = Measurements),          derivpercap_2 = calc_deriv(x = Time, y = Measurements,                                    percapita = TRUE, blank = 0))  # Plot derivative ggplot(data = dplyr::filter(ex_dat_mrg, noise == \"Yes\"),        aes(x = Time, y = deriv_2)) +   geom_point() +   geom_line(data = dplyr::filter(ex_dat_mrg, noise == \"No\"),             lty = 2, color = \"red\") +   facet_wrap(~Well, scales = \"free_y\") #> Warning: Removed 4 rows containing missing values or values outside the scale range #> (`geom_point()`). #> Warning: Removed 1 row containing missing values or values outside the scale range #> (`geom_line()`). # Plot per-capita derivative ggplot(data = dplyr::filter(ex_dat_mrg, noise == \"Yes\"),        aes(x = Time, y = derivpercap_2)) +   geom_point() +   geom_line(data = dplyr::filter(ex_dat_mrg, noise == \"No\"),             lty = 2, color = \"red\") +   facet_wrap(~Well, scales = \"free_y\") #> Warning: Removed 8 rows containing missing values or values outside the scale range #> (`geom_point()`). #> Removed 1 row containing missing values or values outside the scale range #> (`geom_line()`)."},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc07_noise.html","id":"SubsetAnalysis","dir":"Articles","previous_headings":"","what":"Summarizing on subsets of derivatives","title":"Dealing with noise","text":"One strategy can employ dealing noisy data excluding data points density near 0. compare per-capita growth rates density plots, ’ll see noise occurs density close 0:   Per-capita growth rates often noisy density close 0, can make sense simply exclude data points.   limit analysis data points density close 0, much noise per-capita derivative disappears. take final step, can use cutoffs summarize commands calculate maximum growth rate bacteria density least 0.01.","code":"#Plot density ggplot(data = dplyr::filter(ex_dat_mrg, noise == \"Yes\"),        aes(x = Time, y = Measurements)) +   geom_point() +   facet_wrap(~Well, scales = \"free_y\") +   scale_y_log10() #> Warning in scale_y_log10(): log-10 transformation introduced #> infinite values. # Plot per-capita derivative ggplot(data = dplyr::filter(ex_dat_mrg, noise == \"Yes\"),        aes(x = Time, y = derivpercap_2)) +   geom_point() +   facet_wrap(~Well, scales = \"free_y\") #> Warning: Removed 8 rows containing missing values or values outside the scale range #> (`geom_point()`). #Plot density ggplot(data = dplyr::filter(ex_dat_mrg, noise == \"Yes\", Measurements > 0.01),        aes(x = Time, y = Measurements)) +   geom_point() +   facet_wrap(~Well, scales = \"free_y\") +   geom_hline(yintercept = 0.01, lty = 2) +   scale_y_log10() # Plot per-capita derivative ggplot(data = dplyr::filter(ex_dat_mrg, noise == \"Yes\", Measurements > 0.01),        aes(x = Time, y = derivpercap_2)) +   geom_point() +   facet_wrap(~Well, scales = \"free_y\") #> Warning: Removed 3 rows containing missing values or values outside the scale range #> (`geom_point()`). ex_dat_mrg_sum <-   summarize(group_by(ex_dat_mrg, Well, Bacteria_strain, Phage, noise),             max_growth_rate = max(derivpercap_2[Measurements > 0.01],                                    na.rm = TRUE)) #> `summarise()` has grouped output by 'Well', 'Bacteria_strain', 'Phage'. You can #> override using the `.groups` argument. head(ex_dat_mrg_sum) #> # A tibble: 6 × 5 #> # Groups:   Well, Bacteria_strain, Phage [3] #>   Well  Bacteria_strain Phage       noise max_growth_rate #>   <fct> <chr>           <chr>       <chr>           <dbl> #> 1 A1    Strain 1        No Phage    No               1.23 #> 2 A1    Strain 1        No Phage    Yes              2    #> 3 E11   Strain 29       Phage Added No               2.11 #> 4 E11   Strain 29       Phage Added Yes             12.3  #> 5 F1    Strain 31       No Phage    No               0.8  #> 6 F1    Strain 31       No Phage    Yes              1.75"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc07_noise.html","id":"FittingDeriv","dir":"Articles","previous_headings":"","what":"Fitting during derivative calculation","title":"Dealing with noise","text":"next approach try calculate derivatives fitting line multiple points. (might recall previously used Calculating Derivatives article vignette(\"gc05_process\").) use fitting functionality calc_deriv, specify width moving window using window_width, window_width_n, window_width_frac, window_width_n_frac. Wider windows smoothed. Fitting using moving window subject trade amount variance (noise) remains amount bias added data. small window allow higher variance add little bias, wide window allow less variance add bias. Thus, recommend using small window possible, like window_width_n = 3 window_width_n = 5. best way figure values use data try different window widths plot results, choose smallest one sufficient analyses succeed.   can see, increasing width window reduces effects noise, getting us closer noiseless data (red line). However, also starts making peaks shorter valleys shallower. Finding right width balances two effects key choosing right window_width.","code":"ex_dat_mrg <-    mutate(group_by(ex_dat_mrg, Well, Bacteria_strain, Phage, noise),          deriv_5 = calc_deriv(x = Time, y = Measurements,                             window_width_n = 5),          derivpercap_5 = calc_deriv(x = Time, y = Measurements,                                    percapita = TRUE, blank = 0,                                    window_width_n = 5),          deriv_9 = calc_deriv(x = Time, y = Measurements,                             window_width_n = 9),          derivpercap_9 = calc_deriv(x = Time, y = Measurements,                                    percapita = TRUE, blank = 0,                                    window_width_n = 9)) #Reshape our data for plotting purposes ex_dat_mrg_wide <-    pivot_longer(ex_dat_mrg, cols = starts_with(\"deriv\"),                names_to = c(\"deriv\", \"window_width_n\"), names_sep = \"_\") ex_dat_mrg_wide <-    pivot_wider(ex_dat_mrg_wide, names_from = deriv, values_from = value)                                 #Plot derivative ggplot(data = dplyr::filter(ex_dat_mrg_wide, noise == \"Yes\"),        aes(x = Time, y = deriv)) +   geom_line(aes(color = window_width_n), linewidth = 0.6) +   facet_wrap(~Well, scales = \"free_y\") +   geom_line(data = dplyr::filter(ex_dat_mrg_wide,                                   noise == \"No\", window_width_n == 2),             lty = 2, color = \"red\") +   scale_color_grey(start = 0.8, end = 0) +   theme_bw() #> Warning: Removed 13 rows containing missing values or values outside the scale range #> (`geom_line()`). #> Warning: Removed 1 row containing missing values or values outside the scale range #> (`geom_line()`). #Plot per-capita derivative ggplot(data = dplyr::filter(ex_dat_mrg_wide, noise == \"Yes\"),        aes(x = Time, y = derivpercap)) +   geom_line(aes(color = window_width_n), linewidth = 0.6, alpha = 0.75) +   facet_wrap(~Well, scales = \"free_y\") +   geom_line(data = dplyr::filter(ex_dat_mrg_wide,                                  noise == \"No\", window_width_n == 5),             lty = 2, color = \"red\") +   scale_color_grey(start = 0.8, end = 0) +   ylim(NA, 5) +   theme_bw() #> Warning: Removed 14 rows containing missing values or values outside the scale range #> (`geom_line()`). #> Warning: Removed 4 rows containing missing values or values outside the scale range #> (`geom_line()`)."},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc07_noise.html","id":"Smoothing","dir":"Articles","previous_headings":"","what":"Smoothing raw data","title":"Dealing with noise","text":"final approach dealing noise smooth raw density data. gcplyr smooth_data function can carry smoothing. smooth_data five different smoothing algorithms choose : moving-average, moving-median, loess, gam, smooth.spline. moving-average moving-median simple smoothing algorithms primarily act reduce effects outliers data loess, gam, smooth.spline spline-fitting approaches use polynomial-like curves, produces curves smoothly changing derivatives, can cases create curvature artifacts present original data Generally, recommend sticking first two algorithms, alone combination, since others tend add artifacts derivatives growth curve data. Regardless smoothing algorithm use, need set tuning parameter controls “smoothed” data . choice subject trade amount variance (noise) remains amount bias added data. Choosing value smooths data less allow higher variance add little bias data, choosing value smooths data allow less variance add bias data. , generally recommend choosing value smooths data little necessary analyses work. details, see Choosing tuning parameter values section. Additionally, sharing findings, ’s important transparent sharing raw data smoothing methods, rather presenting smoothed data source. use smooth_data, pass x y values, method choice, additional arguments needed method. return vector smoothed y values.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc07_noise.html","id":"smoothing-with-moving-median","dir":"Articles","previous_headings":"Smoothing raw data","what":"Smoothing with moving-median","title":"Dealing with noise","text":"moving-median, specify width moving window using window_width, window_width_n, window_width_frac, window_width_n_frac. Wider windows smoothed. , ’ll show moving medians windows 5 9 data points wide (movemed_1 just raw, unsmoothed data).  can see moving-median done great job excluding noise without biasing data far true values (red line). However, produced smoothed density fairly “jumpy”, something common moving-median. address , often need combine moving-median smoothing methods.","code":"ex_dat_mrg <-   mutate(group_by(ex_dat_mrg, Well, Bacteria_strain, Phage, noise),          movmed_1 = Measurements,          movmed_5 =             smooth_data(x = Time, y = Measurements,                        sm_method = \"moving-median\", window_width_n = 5),          movmed_9 =             smooth_data(x = Time, y = Measurements,                        sm_method = \"moving-median\", window_width_n = 9))  #Reshape our data for plotting purposes ex_dat_mrg_wide <-    pivot_longer(ex_dat_mrg, cols = starts_with(\"movmed\"),                names_prefix = \"movmed_\", names_to = \"window_width_n\")  #Plot data ggplot(data = dplyr::filter(ex_dat_mrg_wide, noise == \"Yes\"),        aes(x = Time, y = value)) +   geom_line(aes(color = window_width_n), linewidth = 0.6, alpha = 0.75) +   facet_wrap(~Well, scales = \"free_y\") +   geom_line(data = dplyr::filter(ex_dat_mrg_wide,                                  noise == \"No\", window_width_n == 1),             lty = 2, color = \"red\") +   scale_color_grey(start = 0.8, end = 0) +   scale_y_log10() +   ggtitle(\"moving-median\") +   theme_bw() #> Warning in scale_y_log10(): log-10 transformation introduced #> infinite values. #> Warning: Removed 12 rows containing missing values or values outside the scale range #> (`geom_line()`)."},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc07_noise.html","id":"smoothing-with-moving-average","dir":"Articles","previous_headings":"Smoothing raw data","what":"Smoothing with moving-average","title":"Dealing with noise","text":"moving-average, specify width moving window using window_width, window_width_n, window_width_frac, window_width_n_frac. Wider windows smoothed. , ’ll show moving averages window_width_n values 5 9 data points wide (movavg_1 just raw, unsmoothed data).  can see moving-average helped reduce effects early noise. However, window width gets larger, starts biasing data strongly [e.g. underrepresenting maximum density peaks relative true value (red line)].","code":"ex_dat_mrg <-   mutate(group_by(ex_dat_mrg, Well, Bacteria_strain, Phage, noise),          movavg_1 = Measurements,          movavg_5 = smooth_data(x = Time, y = Measurements,               sm_method = \"moving-average\", window_width_n = 5),          movavg_9 = smooth_data(x = Time, y = Measurements,               sm_method = \"moving-average\", window_width_n = 9))  #Reshape our data for plotting purposes ex_dat_mrg_wide <-    pivot_longer(ex_dat_mrg, cols = starts_with(\"movavg\"),                names_prefix = \"movavg_\", names_to = \"window_width_n\")  #Plot data ggplot(data = dplyr::filter(ex_dat_mrg_wide, noise == \"Yes\"),        aes(x = Time, y = value)) +   geom_line(aes(color = window_width_n), linewidth = 0.6, alpha = 0.75) +   facet_wrap(~Well, scales = \"free_y\") +   geom_line(data = dplyr::filter(ex_dat_mrg_wide,                                  noise == \"No\", window_width_n == 1),             lty = 2, color = \"red\") +   scale_color_grey(start = 0.8, end = 0) +   scale_y_log10() +   ggtitle(\"moving-average\") +   theme_bw() #> Warning in scale_y_log10(): log-10 transformation introduced #> infinite values. #> Warning: Removed 12 rows containing missing values or values outside the scale range #> (`geom_line()`)."},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc07_noise.html","id":"combining-multiple-smoothing-methods","dir":"Articles","previous_headings":"Smoothing raw data","what":"Combining multiple smoothing methods","title":"Dealing with noise","text":"Often, combining multiple smoothing methods can provide improved results. instance, moving-median particularly good removing outliers, good producing smoothly changing data. contrast, moving-average works well producing smoothly changing data, isn’t good removing outliers. Often, can get best using moving-median first, followed moving-average:  can see combination minimal moving-median moving-average smoothing produced curve noise removed minimal introduction bias relative true values (red line).","code":"ex_dat_mrg <-   mutate(group_by(ex_dat_mrg, Well, Bacteria_strain, Phage, noise),          smoothed_no = Measurements,          sm_med3 =             smooth_data(x = Time, y = Measurements,                        sm_method = \"moving-median\", window_width_n = 3),          #Note that for the second round, we're using the           #first smoothing as the input y          smoothed_yes =             smooth_data(x = Time, y = sm_med3,                        sm_method = \"moving-average\", window_width_n = 3))  #Reshape our data for plotting purposes ex_dat_mrg_wide <-    pivot_longer(ex_dat_mrg, cols = starts_with(\"smoothed\"),                names_to = \"smoothed\", names_prefix = \"smoothed_\")  #Plot data ggplot(data = dplyr::filter(ex_dat_mrg_wide, noise == \"Yes\"),        aes(x = Time, y = value, color = smoothed)) +   geom_line(linewidth = 0.6, alpha = 0.75) +   scale_color_grey(start = 0.8, end = 0) +   facet_wrap(~Well, scales = \"free_y\") +   geom_line(data = dplyr::filter(ex_dat_mrg_wide,                                  noise == \"No\", smoothed == \"no\"),             lty = 2, color = \"red\") +   scale_y_log10() +   ggtitle(\"median then average smoothing\") +   theme_bw() #> Warning in scale_y_log10(): log-10 transformation introduced #> infinite values. #> Warning: Removed 4 rows containing missing values or values outside the scale range #> (`geom_line()`)."},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc07_noise.html","id":"smoothing-with-other-methods","dir":"Articles","previous_headings":"Smoothing raw data","what":"Smoothing with other methods","title":"Dealing with noise","text":"typically recommend using smoothing algorithms, since tendency add artifacts derivatives growth curve data. However, may work analyses, considering using make sure plot smoothed output check introduced artifacts. loess, tuning parameter span argument. loess works fits subset windows data centered data point. span width window, fraction data points. span values typically 0 1, larger values “smoothed”. fits can linear (degree = 1) polynomial (typically degree = 2). gam, primary tuning parameter k argument. gam works fits subsets data linking fits together. k determines many link points (“knots”) can use. specified, default k value smoothing time series 10, smaller values “smoothed”. However, unlike earlier methods, k values large also problematic, tend ‘overfit’ data. smooth.spline, primary tuning parameters df spar. df number degrees freedom, must 1 number unique x values. spar smoothing parameter, typically 0 1.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc07_noise.html","id":"ChoosingTuningParams","dir":"Articles","previous_headings":"Smoothing raw data","what":"Choosing tuning parameter values","title":"Dealing with noise","text":"Given smoothing reduces variance data adds bias, can know right value tuning ‘smoothness’ parameter data? One way can choose trying smoothing different tuning parameter values, plotting results, choosing one smooths data little necessary analyses work. approach especially useful ’re trying deal noise strongly affecting derivatives. alternative way use cross-validation attempt estimate best smoothing parameter value. Cross-validation works randomly splitting data blocks roughly equal size, leaving one block smoothing data, seeing close smoothed values left-data, reporting average error across blocks. can repeat whole process different values smoothing parameter, testing smoothing parameter value gives us lowest error. Note, however, approach doesn’t quantify well smoothing improved derivatives. cross-validation smoothing parameters, use train_smooth_data. train_smooth_data works similar smooth_data, except instead returning smoothed data values, returns average accuracy metrics. , use train_smooth_data within dplyr function reframe, works like summarize except allows multiple rows returned. default, train_smooth_data test evenly spaced grid three values smoothing parameter. Usually, ’s enough values, ’ll want set number values test tuneLength (values take longer calculate). can see train_smooth_data given us number accuracy metrics. first one ‘RMSE’, stands “root mean squared error” often good default value use (lower values better) decide best parameter value .  Based plot, window_width_n 1 lowest average error values tested. However, often ’ll want test different values defaults train_smooth_data. , specify exactly values want test tuneGrid argument:  can see example data cross-validation suggests little smoothing necessary. makes sense, since example data noise problematic derivatives, cross-validation doesn’t consider derivatives. data, suggest combining cross-validation manual observation different smoothings decide best smoothing parameter value use.","code":"ex_dat_mrg_fortraining <- make_example(vignette = 7, example = 2)  training_results <-    reframe(group_by(ex_dat_mrg_fortraining, Bacteria_strain, Phage, Well),           train_smooth_data(x = Time, y = Measurements,                     sm_method = \"moving-average\",                    tuneLength = 5)) #> Loading required package: lattice head(training_results) #> # A tibble: 6 × 10 #>   Bacteria_strain Phage    Well  window_width_n    RMSE Rsquared     MAE  RMSESD #>   <chr>           <chr>    <fct>          <dbl>   <dbl>    <dbl>   <dbl>   <dbl> #> 1 Strain 1        No Phage A1                 1 0.0104     0.999 0.00495 0.0138  #> 2 Strain 1        No Phage A1                 3 0.00863    1.000 0.00484 0.00815 #> 3 Strain 1        No Phage A1                 7 0.0106     1.000 0.00707 0.00749 #> 4 Strain 1        No Phage A1                 9 0.0124     0.999 0.00860 0.00647 #> 5 Strain 1        No Phage A1                13 0.0179     0.999 0.0128  0.00626 #> 6 Strain 1        Phage A… A7                 1 0.0242     0.886 0.0123  0.0351  #> # ℹ 2 more variables: RsquaredSD <dbl>, MAESD <dbl> ggplot(data = training_results,        aes(x = window_width_n, y = RMSE)) +   geom_point() training_results <-    reframe(group_by(ex_dat_mrg_fortraining, Bacteria_strain, Phage, Well),           train_smooth_data(x = Time, y = Measurements,                     sm_method = \"moving-average\",                    tuneGrid = list(                      \"window_width_n\" = c(1, 3, 5, 9, 13))))  ggplot(data = training_results,        aes(x = window_width_n, y = RMSE)) +   geom_point()"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc07_noise.html","id":"DerivsOfSmoothed","dir":"Articles","previous_headings":"","what":"Calculating derivatives of smoothed data","title":"Dealing with noise","text":"’ve smoothed data, can calculate derivatives using smoothed data. Combining smoothing raw data fitting using multiple points calculating derivatives can powerful combination reducing effects noise minimizing introduction bias.   can see calculating derivatives smoothed raw data can powerfully useful combination.","code":"# Note here that we're calculating derivatives of the smoothed column generated #  in the previous section by combining moving median and moving average smoothing ex_dat_mrg <-    mutate(group_by(ex_dat_mrg, Well, Bacteria_strain, Phage, noise),          smderiv_0 = calc_deriv(x = Time, y = Measurements),          smderivpercap_0 = calc_deriv(x = Time, y = Measurements,                                        percapita = TRUE, blank = 0),          smderiv_3 = calc_deriv(x = Time, y = smoothed_yes, window_width_n = 3),          smderivpercap_3 = calc_deriv(x = Time, y = smoothed_yes, percapita = TRUE,                                      blank = 0, window_width_n = 3))  #Reshape our data for plotting purposes ex_dat_mrg_wide <-    pivot_longer(ex_dat_mrg, cols = starts_with(\"smderiv\"),                names_to = c(\"deriv\", \"window_width_n\"), names_sep = \"_\") ex_dat_mrg_wide <-    pivot_wider(ex_dat_mrg_wide, names_from = deriv, values_from = value)  #Plot derivative ggplot(data = dplyr::filter(ex_dat_mrg_wide, noise == \"Yes\"),        aes(x = Time, y = smderiv, color = window_width_n)) +   geom_line(linewidth = 0.6, alpha = 0.75) +   scale_color_grey(start = 0.8, end = 0) +   facet_wrap(~Well, scales = \"free_y\") +   geom_line(data = dplyr::filter(ex_dat_mrg_wide,                                  noise == \"No\", window_width_n == 0),             lty = 2, color = \"red\") +   theme_bw() #> Warning: Removed 7 rows containing missing values or values outside the scale range #> (`geom_line()`). #> Warning: Removed 1 row containing missing values or values outside the scale range #> (`geom_line()`). #Plot per-capita derivative ggplot(data = dplyr::filter(ex_dat_mrg_wide, noise == \"Yes\"),        aes(x = Time, y = smderivpercap, color = window_width_n)) +   geom_line(linewidth = 0.6, alpha = 0.75) +   scale_color_grey(start = 0.8, end = 0) +   facet_wrap(~Well, scales = \"free_y\") +   geom_line(data = dplyr::filter(ex_dat_mrg_wide,                                  noise == \"No\", window_width_n == 3),             lty = 2, color = \"red\") +   ylim(NA, 5) +   theme_bw() #> Warning: Removed 8 rows containing missing values or values outside the scale range #> (`geom_line()`). #> Warning: Removed 6 rows containing missing values or values outside the scale range #> (`geom_line()`)."},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc07_noise.html","id":"whats-next","dir":"Articles","previous_headings":"","what":"What’s next?","title":"Dealing with noise","text":"Now ’ve analyzed data dealt noise, ’s just concluding notes best practices running statistics, merging growth curve analyses data, additional resources analyzing growth curves. Introduction: vignette(\"gc01_gcplyr\") Importing reshaping data: vignette(\"gc02_import_reshape\") Incorporating experimental designs: vignette(\"gc03_incorporate_designs\") Pre-processing plotting data: vignette(\"gc04_preprocess_plot\") Processing data: vignette(\"gc05_process\") Analyzing data: vignette(\"gc06_analyze\") Dealing noise: vignette(\"gc07_noise\") Best practices tips: vignette(\"gc08_conclusion\") Working multiple plates: vignette(\"gc09_multiple_plates\") Using make_design generate experimental designs: vignette(\"gc10_using_make_design\")","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc08_conclusion.html","id":"where-are-we-so-far","dir":"Articles","previous_headings":"","what":"Where are we so far?","title":"Best practices and other tips","text":"Introduction: vignette(\"gc01_gcplyr\") Importing reshaping data: vignette(\"gc02_import_reshape\") Incorporating experimental designs: vignette(\"gc03_incorporate_designs\") Pre-processing plotting data: vignette(\"gc04_preprocess_plot\") Processing data: vignette(\"gc05_process\") Analyzing data: vignette(\"gc06_analyze\") Dealing noise: vignette(\"gc07_noise\") Best practices tips: vignette(\"gc08_conclusion\") Working multiple plates: vignette(\"gc09_multiple_plates\") Using make_design generate experimental designs: vignette(\"gc10_using_make_design\") far, ’ve imported transformed measures, combined design information, pre-processed, processed, plotted, analyzed data. things left notes best practices running statistics, merging growth curve analyses data, additional resources analyzing growth curves. haven’t already, load necessary packages.","code":"library(gcplyr) #> ##  #> ## gcplyr (Version 1.12.0, Build Date: 2025-07-28) #> ## See http://github.com/mikeblazanin/gcplyr for additional documentation #> ## Please cite software as: #> ##   Blazanin, Michael. gcplyr: an R package for microbial growth #> ##   curve data analysis. BMC Bioinformatics 25, 232 (2024). #> ##   https://doi.org/10.1186/s12859-024-05817-3 #> ##  library(dplyr) #>  #> Attaching package: 'dplyr' #> The following objects are masked from 'package:stats': #>  #>     filter, lag #> The following objects are masked from 'package:base': #>  #>     intersect, setdiff, setequal, union library(ggplot2)"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc08_conclusion.html","id":"statistical-analyses-of-growth-curves-data","dir":"Articles","previous_headings":"","what":"Statistical analyses of growth curves data","title":"Best practices and other tips","text":"point, ’ve now summarized growth curves data metrics. can best go drawing statistical conclusions data?","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc08_conclusion.html","id":"when-should-we-average-replicates","dir":"Articles","previous_headings":"Statistical analyses of growth curves data","what":"When should we average replicates?","title":"Best practices and other tips","text":"want emphasize something workflow: averaging different wells together summarization. opinion, averaging occur summarization, . ? Even wells contents (.e. technical replicates) can still differ growth due biological variation (e.g. stochastic growth dynamics). average density values beginning, may introduce bias, ability visualize assess biological variation present data. Let’s look simple example demonstrate point. ’m going simulate bacterial growth using logistic growth, starts finite ‘lag period’ bacteria don’t grow . dN/dt={0t<lagrN(1−Nk)t≥lag\\begin{equation} dN/dt =  \\begin{cases}   0 & t < lag \\\\   r N\\left(1-\\frac{N}{k}\\right) & t \\ge lag  \\end{cases} \\end{equation} NN population size, rr rate growth, kk carrying capacity population, laglag lag time. code , ’ve simulated growth 96 different wells bacteria. bacteria grow exactly rate, except differ lag time (long wait starting grow). Now, let’s calculate growth rate well plot growth:  ’ve plotted individual well black, “average well” plotted red. can clearly see different wells varying long lag time , growth rate start. contrast, average well quite different shape. affect maximum growth rate?  can see maximum growth rate “average well” far maximum growth rate well. Moreover, bias can show summary metrics well. ‘average curve’ rarely good representative average curves, recommend averaging wells together summarizing.","code":"sim_dat_tdy <- make_example(vignette = 8, example = 1) sim_dat_tdy <- mutate(group_by(sim_dat_tdy, Well),                       percap_deriv = calc_deriv(y = Measurements, x = time,                                                 percapita = TRUE, blank = 0))  # Plot the growth in our wells ggplot(data = filter(sim_dat_tdy, Well != \"averaged\"),         aes(x = time, y = Measurements, group = Well)) +   geom_line(alpha = 0.1) +   geom_line(data = filter(sim_dat_tdy, Well == \"averaged\"), color = \"red\") +   scale_y_continuous(trans = \"log10\") # Summarize our data sim_dat_sum <- summarize(group_by(sim_dat_tdy, Well),                          max_growth_rate = max(percap_deriv, na.rm = TRUE))  # Plot the maximum per-capita growth rates of each well #  as well as the 'average' well ggplot(data = sim_dat_sum,         aes(x = Well == \"averaged\", y = max_growth_rate)) +   geom_point(alpha = 0.5, position = position_jitter(width = 0.1)) +   ylim(0.01, 0.03)"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc08_conclusion.html","id":"carrying-out-statistical-testing","dir":"Articles","previous_headings":"Statistical analyses of growth curves data","what":"Carrying out statistical testing","title":"Best practices and other tips","text":"go running statistics analyzed growth curve data? Typically, growth curves experiments highly nested structure. probably multiple wells contents (.e. technical replicates) plate. may also multiple plates different runs (creating possibility batch effects). order pull apart effects test differences treatments, ’ll likely need mixed-effects modeling. Unfortunately, ’s beyond scope vignette provide sufficient explanation mixed-effects statistics. However, can provide guidance: frequentist statistics, R package lme4 one -popular implementations mixed-effects modeling. Bayesian statistics, R packages brms rstanarm popular implementations can incorporate mixed-effects modeling. Regardless approach, : use summarized statistics (e.g. auc, max_growth_rate, lag_time, etc.) response variable use design elements (e.g. Bacteria_strain, Phage) explanatory variables (.e. fixed effects) incorporate random effects technical replicates incorporate random effects potential batch effects -play number excellent resources learn sort mixed-effects modeling, including think good introductory guide process Michael Clark.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc08_conclusion.html","id":"combining-growth-curves-data-with-other-data","dir":"Articles","previous_headings":"","what":"Combining growth curves data with other data","title":"Best practices and other tips","text":"approach end growth curves analyses, summarized dynamics growth curves one metrics. point, may wish pull sources data compare growth curves metrics. Just like merging multiple growth curves data frames together, can achieved merge_dfs. ’ll focus area---curve metric, just bacteria grown absence phages. Imagine , separately, ’ve measured resistance example bacteria antibiotics, want know ’s relationship antibiotic resistance bacteria growth. Normally data collected lab, make_example mock antibiotic resistance data can use, strain’s resistance saved Antibiotic_resis column, TRUE resistance, FALSE sensitivity. Importantly, antibiotic data must also matching headers growth curve data merge_dfs knows merge , Bacteria_strain. Great, now merge two data frames see ’s relationship.  ! can see antibiotic resistant strains (TRUE) smaller area---curve antibiotic sensitive strains (FALSE) (although, fair, simulate data ’d get result).","code":"# This code was previously explained # Here we're re-running it so it's available for us to work with example_tidydata <- trans_wide_to_tidy(example_widedata_noiseless,                                        id_cols = \"Time\") ex_dat_mrg <- merge_dfs(example_tidydata, example_design_tidy) #> Joining with `by = join_by(Well)` ex_dat_mrg_sum <-   summarize(group_by(dplyr::filter(ex_dat_mrg, Phage == \"No Phage\"),                      Well, Bacteria_strain, Phage),             auc = auc(x = Time, y = Measurements)) #> `summarise()` has grouped output by 'Well', 'Bacteria_strain'. You can override #> using the `.groups` argument. antibiotic_dat <- make_example(vignette = 8, example = 2)  head(antibiotic_dat) #>   Bacteria_strain Antibiotic_resis #> 1        Strain 1             TRUE #> 2        Strain 2            FALSE #> 3        Strain 3             TRUE #> 4        Strain 4            FALSE #> 5        Strain 5            FALSE #> 6        Strain 6             TRUE growth_and_antibiotics <-    merge_dfs(ex_dat_mrg_sum, antibiotic_dat) #> Joining with `by = join_by(Bacteria_strain)` head(growth_and_antibiotics) #> # A tibble: 6 × 5 #> # Groups:   Well, Bacteria_strain [6] #>   Well  Bacteria_strain Phage       auc Antibiotic_resis #>   <chr> <chr>           <chr>     <dbl> <lgl>            #> 1 A1    Strain 1        No Phage 57291. TRUE             #> 2 A2    Strain 2        No Phage 69361. FALSE            #> 3 A3    Strain 3        No Phage 54460. TRUE             #> 4 A4    Strain 4        No Phage 72280. FALSE            #> 5 A5    Strain 5        No Phage 73112. FALSE            #> 6 A6    Strain 6        No Phage 45970. TRUE  ggplot(data = growth_and_antibiotics,         aes(x = Antibiotic_resis, y = auc)) +   geom_point()"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc08_conclusion.html","id":"other-growth-curve-analysis-packages","dir":"Articles","previous_headings":"","what":"Other growth curve analysis packages","title":"Best practices and other tips","text":"number software tools besides gcplyr facilitate analysis growth curves data data wrangling plate reader data. ’ll provide brief notes gcplyr compares tools, detailed comparison please see: Blazanin, M. “gcplyr: R package microbial growth curve data analysis.” BMC Bioinformatics 25, 232 (2024). https://doi.org/10.1186/s12859-024-05817-3 , broadly speaking, two ways analyze growth curves data: directly quantify attributes growth dynamics fit growth dynamics mathematical model, extract parameters fitted model gcplyr R packages focus first analysis approach (direct quantification growth curves dynamics), many R packages focus fitting growth dynamics mathematical model. Generally, fitting growth dynamics model greater power accurately quantify underlying traits. However, also takes much effort rigorous fitting data model. carefully choose model whose assumptions data meet. also evaluate fits ensure optimization algorithms arrived reasonable solutions. software tools growth curve data analysis, explore. ’ve italicized several tools might particularly compatible gcplyr can import tidy-shaped data gcplyr generates. growthcurver growthrates biogrowth opm QurvE AUDIT bletl AMiGA fitderiv phenom B-GREAT PMAnalyzer GrowthRates GCAT PRECOG IPMP 2013 GATHODE Microrisk Lab CarboLogR YODA BGFit Additionally, software doesn’t analyze growth curve data, contain useful functionality plate-reader data wrangling: plater Parsley","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc08_conclusion.html","id":"whats-next","dir":"Articles","previous_headings":"","what":"What’s next?","title":"Best practices and other tips","text":"’ve finished core documentation. Congratulations! gcplyr powerful framework build additional analyses , since data nicely organized. Feel free reach questions, comments, concerns might . ’d love continue making gcplyr useful others scientific community . can reach mikeblazanin [] gmail [dot] com. ’d like read work multiple plates data , check final vignette: vignette(\"gc09_multiple_plates\") Introduction: vignette(\"gc01_gcplyr\") Importing reshaping data: vignette(\"gc02_import_reshape\") Incorporating experimental designs: vignette(\"gc03_incorporate_designs\") Pre-processing plotting data: vignette(\"gc04_preprocess_plot\") Processing data: vignette(\"gc05_process\") Analyzing data: vignette(\"gc06_analyze\") Dealing noise: vignette(\"gc07_noise\") Best practices tips: vignette(\"gc08_conclusion\") Working multiple plates: vignette(\"gc09_multiple_plates\") Using make_design generate experimental designs: vignette(\"gc10_using_make_design\")","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc09_multiple_plates.html","id":"where-are-we-so-far","dir":"Articles","previous_headings":"","what":"Where are we so far?","title":"Working with multiple plates","text":"Introduction: vignette(\"gc01_gcplyr\") Importing reshaping data: vignette(\"gc02_import_reshape\") Incorporating experimental designs: vignette(\"gc03_incorporate_designs\") Pre-processing plotting data: vignette(\"gc04_preprocess_plot\") Processing data: vignette(\"gc05_process\") Analyzing data: vignette(\"gc06_analyze\") Dealing noise: vignette(\"gc07_noise\") Best practices tips: vignette(\"gc08_conclusion\") Working multiple plates: vignette(\"gc09_multiple_plates\") Using make_design generate experimental designs: vignette(\"gc10_using_make_design\") far, ’ve covered everything can gcplyr single plate. vignette, ’ll briefly covering gcplyr can also easily handle multiple plates data time. ’ll assuming ’ve already read analogous sections working single plate time, haven’t, now good time go back ! haven’t already, load necessary packages.","code":"library(gcplyr) #> ##  #> ## gcplyr (Version 1.12.0, Build Date: 2025-07-28) #> ## See http://github.com/mikeblazanin/gcplyr for additional documentation #> ## Please cite software as: #> ##   Blazanin, Michael. gcplyr: an R package for microbial growth #> ##   curve data analysis. BMC Bioinformatics 25, 232 (2024). #> ##   https://doi.org/10.1186/s12859-024-05817-3 #> ##  library(dplyr) #>  #> Attaching package: 'dplyr' #> The following objects are masked from 'package:stats': #>  #>     filter, lag #> The following objects are masked from 'package:base': #>  #>     intersect, setdiff, setequal, union library(ggplot2)"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc09_multiple_plates.html","id":"a-brief-primer-on-lists-in-r","dir":"Articles","previous_headings":"","what":"A brief primer on lists in R","title":"Working with multiple plates","text":"lists powerful data format R, can contain set R objects. However, can also make little difficult navigate simpler formats like vectors data.frames. Let’s make simple example explore lists can navigated. ’ve created list 3 elements: first element vector one entry, “” second element vector three entries third element matrix numbers 1 9 want extract contents elements, simply use double brackets [[ want modify contents elements, can also use double brackets working multiple plates, ’ll often dealing lists data.frames, rather single data.frames ’ve working . multiple plates, want carry operation one plate data.frames, simply use double brackets select specifically. want carry operation data.frames, gcplyr functions like trans_wide_to_tidy merge_dfs able handle list automatically.","code":"mylist <- list(\"A\", c(5, 6, 7), matrix(1:9, nrow = 3)) mylist #> [[1]] #> [1] \"A\" #>  #> [[2]] #> [1] 5 6 7 #>  #> [[3]] #>      [,1] [,2] [,3] #> [1,]    1    4    7 #> [2,]    2    5    8 #> [3,]    3    6    9 mylist[[1]] #> [1] \"A\" mylist[[2]] #> [1] 5 6 7 mylist[[3]] #>      [,1] [,2] [,3] #> [1,]    1    4    7 #> [2,]    2    5    8 #> [3,]    3    6    9 mylist[[3]] <- mylist[[3]] + 7 mylist[[3]] #>      [,1] [,2] [,3] #> [1,]    8   11   14 #> [2,]    9   12   15 #> [3,]   10   13   16"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc09_multiple_plates.html","id":"importing-data-for-multiple-plates","dir":"Articles","previous_headings":"","what":"Importing data for multiple plates","title":"Working with multiple plates","text":"data block-shaped: use import_blockmeasures start next section: Reading files multiple block-shaped plates data wide-shaped: use read_wides skip Reading files multiple wide-shaped plates section","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc09_multiple_plates.html","id":"reading-files-for-multiple-block-shaped-plates","dir":"Articles","previous_headings":"","what":"Reading files for multiple block-shaped plates","title":"Working with multiple plates","text":"’re reading files multiple block-shaped plates, approach depends files arranged: plate’s worth block-shaped files easily separable (e.g. saved different folders) files separate plates interleaved alternating (common multiple plates read plate-reader robot single run)","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc09_multiple_plates.html","id":"separated-block-shaped-plate-files","dir":"Articles","previous_headings":"Reading files for multiple block-shaped plates","what":"Separated block-shaped plate files","title":"Working with multiple plates","text":"first case, read plate files individual plate following typical process import_blockmeasures. Let’s generate example files see works. working real growth curve data, files output plate reader. can see, names files either “Plate1” “Plate2” . can use simply import separately. like later work unit, can save list.","code":"filenames_sep <- make_example(vignette = 9, example = 1, dir = \"./example_data\") #> Files have been written head(filenames_sep) #> [1] \"./example_data/Plate1-0_00_00.csv\" \"./example_data/Plate1-0_15_00.csv\" #> [3] \"./example_data/Plate1-0_30_00.csv\" \"./example_data/Plate1-0_45_00.csv\" #> [5] \"./example_data/Plate1-1_00_00.csv\" \"./example_data/Plate1-1_15_00.csv\" plates <- list(   plate1 = import_blockmeasures(     list.files(path = \"./example_data/\", pattern = \"Plate1\", full.names = TRUE),     startrow = 4,     metadata = list(Time = c(2, \"C\"))),   plate2 = import_blockmeasures(     list.files(path = \"./example_data/\", pattern = \"Plate2\", full.names = TRUE),     startrow = 4,     metadata = list(Time = c(2, \"C\"))))"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc09_multiple_plates.html","id":"interleaved-block-shaped-plate-files","dir":"Articles","previous_headings":"Reading files for multiple block-shaped plates","what":"Interleaved block-shaped plate files","title":"Working with multiple plates","text":"second case, files different plates interleaved together. can read separate import_blockmeasures. Let’s generate example files see works. working real growth curve data, files output plate reader. scenario, two plates: first plate read every 15 minutes, second plate read 1 second time first plate read. read separate , set num_plates argument number plates. output list, first element list wide-shaped data.frame plate #1, second element wide-shaped data.frame plate #2.","code":"filenames_mixed <- make_example(vignette = 9, example = 2, dir = \"./example_data\") #> Files have been written head(filenames_mixed) #> [1] \"./example_data/00_00_00.csv\" \"./example_data/00_00_01.csv\" #> [3] \"./example_data/00_15_00.csv\" \"./example_data/00_15_01.csv\" #> [5] \"./example_data/00_30_00.csv\" \"./example_data/00_30_01.csv\" plates <- import_blockmeasures(     filenames_mixed,     startrow = 4,     metadata = list(Time = c(2, \"C\")),     num_plates = 2)"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc09_multiple_plates.html","id":"reading-files-for-multiple-wide-shaped-plates","dir":"Articles","previous_headings":"","what":"Reading files for multiple wide-shaped plates","title":"Working with multiple plates","text":"can also read multiple wide-shaped datasets. Whether ’re single file, multiple files, simply input corresponding information read_wides return list containing wide-shaped data.frame","code":"make_example(vignette = 9, example = 3) #> Files have been written #> [1] \"./widedata.csv\"  \"./widedata2.csv\"  plates <- read_wides(files = c(\"widedata.csv\", \"widedata2.csv\"),            startrow = 5,            metadata = list(Experiment = c(1, \"B\"),                            Start_date = c(2, \"B\")))"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc09_multiple_plates.html","id":"transforming-multiple-plates-to-tidy-shaped","dir":"Articles","previous_headings":"","what":"Transforming multiple plates to tidy-shaped","title":"Working with multiple plates","text":"data list wide-shaped data.frames, ’s easy transform tidy-shaped. Assuming plates columns, can simply put list trans_wide_to_tidy. output list, element list tidy-shaped data.frame corresponding one plates. don’t designs merge, can collapse list single data.frame merge_dfs:","code":"tidy_plates <-    trans_wide_to_tidy(plates,                      id_cols = c(\"file\", \"Experiment\", \"Start_date\", \"Time\")) tidy_plates_collapsed <- merge_dfs(tidy_plates, collapse = TRUE) #> Joining with `by = join_by(file, Experiment, Start_date, Time, Well, #> Measurements)`  print_df(head(tidy_plates_collapsed), col.names = TRUE) #> file Experiment Start_date Time Well Measurements #> widedata Experiment_1 2025-07-28 0 A1 0.002 #> widedata Experiment_1 2025-07-28 0 B1 0.002 #> widedata Experiment_1 2025-07-28 0 C1 0.002 #> widedata Experiment_1 2025-07-28 0 D1 0.002 #> widedata Experiment_1 2025-07-28 0 E1 0.002 #> widedata Experiment_1 2025-07-28 0 F1 0.002"},{"path":[]},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc09_multiple_plates.html","id":"plates-with-different-designs","dir":"Articles","previous_headings":"Merging designs with multiple plates","what":"Plates with different designs","title":"Working with multiple plates","text":"different designs plates, ’ll merge plate separately using brackets: afterwards, can collapse data together:","code":"example_design1 <- make_design(   pattern_split = \",\", nrows = 8, ncols = 12,   \"Bacteria_strain\" = make_designpattern(     values = paste(\"Strain\", 1:48),     rows = 1:8, cols = 1:6, pattern = 1:48, byrow = TRUE),   \"Bacteria_strain\" = make_designpattern(     values = paste(\"Strain\", 1:48),     rows = 1:8, cols = 7:12, pattern = 1:48, byrow = TRUE)) #> Inferred 'into' column names as: Bacteria_strain example_design2 <- make_design(   pattern_split = \",\", nrows = 8, ncols = 12,   \"Bacteria_strain\" = make_designpattern(     values = paste(\"Strain\", 49:96),     rows = 1:8, cols = 1:6, pattern = 1:48, byrow = TRUE),   \"Bacteria_strain\" = make_designpattern(     values = paste(\"Strain\", 49:96),     rows = 1:8, cols = 7:12, pattern = 1:48, byrow = TRUE)) #> Inferred 'into' column names as: Bacteria_strain  tidy_plates[[1]] <- merge_dfs(tidy_plates[[1]], example_design1) #> Joining with `by = join_by(Well)` tidy_plates[[2]] <- merge_dfs(tidy_plates[[2]], example_design2) #> Joining with `by = join_by(Well)` data_and_designs <- merge_dfs(tidy_plates, collapse = TRUE) #> Joining with `by = join_by(file, Experiment, Start_date, Time, Well, #> Measurements, Bacteria_strain)` print_df(head(data_and_designs)) #> widedata Experiment_1 2025-07-28 0 A1 0.002  Strain 1 #> widedata Experiment_1 2025-07-28 0 B1 0.002  Strain 7 #> widedata Experiment_1 2025-07-28 0 C1 0.002 Strain 13 #> widedata Experiment_1 2025-07-28 0 D1 0.002 Strain 19 #> widedata Experiment_1 2025-07-28 0 E1 0.002 Strain 25 #> widedata Experiment_1 2025-07-28 0 F1 0.002 Strain 31"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc09_multiple_plates.html","id":"plates-with-a-shared-design","dir":"Articles","previous_headings":"Merging designs with multiple plates","what":"Plates with a shared design","title":"Working with multiple plates","text":", instead, plates design, can merge design collapsing list data merge step. Don’t worry losing track plates, file column automatically generated differentiate separate plates read .","code":"example_design <- make_design(   pattern_split = \",\", nrows = 8, ncols = 12,   \"Bacteria_strain\" = make_designpattern(     values = paste(\"Strain\", 1:48),     rows = 1:8, cols = 1:6, pattern = 1:48, byrow = TRUE),   \"Bacteria_strain\" = make_designpattern(     values = paste(\"Strain\", 1:48),     rows = 1:8, cols = 7:12, pattern = 1:48, byrow = TRUE)) #> Inferred 'into' column names as: Bacteria_strain  data_and_designs <- merge_dfs(tidy_plates, example_design, collapse = TRUE) #> Joining with `by = join_by(file, Experiment, Start_date, Time, Well, #> Measurements, Bacteria_strain)` #> Joining with `by = join_by(Well, Bacteria_strain)` print_df(head(data_and_designs)) #> widedata Experiment_1 2025-07-28 0 A1 0.002  Strain 1 #> widedata Experiment_1 2025-07-28 0 B1 0.002  Strain 7 #> widedata Experiment_1 2025-07-28 0 C1 0.002 Strain 13 #> widedata Experiment_1 2025-07-28 0 D1 0.002 Strain 19 #> widedata Experiment_1 2025-07-28 0 E1 0.002 Strain 25 #> widedata Experiment_1 2025-07-28 0 F1 0.002 Strain 31"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc10_using_make_design.html","id":"where-are-we-so-far","dir":"Articles","previous_headings":"","what":"Where are we so far?","title":"Using make_design to generate experimental designs","text":"Introduction: vignette(\"gc01_gcplyr\") Importing reshaping data: vignette(\"gc02_import_reshape\") Incorporating experimental designs:** vignette(\"gc03_incorporate_designs\") Pre-processing plotting data: vignette(\"gc04_preprocess_plot\") Processing data: vignette(\"gc05_process\") Analyzing data: vignette(\"gc06_analyze\") Dealing noise: vignette(\"gc07_noise\") Best practices tips: vignette(\"gc08_conclusion\") Working multiple plates: vignette(\"gc09_multiple_plates\") Using make_design generate experimental designs: vignette(\"gc10_using_make_design\") vignette(\"gc03_incorporate_designs\"), focused importing designs files, since ’s common way creating designs. , ’re going show designs can alternatively generated within R using gcplyr function make_design. haven’t already, load necessary packages.","code":"library(gcplyr) #> ##  #> ## gcplyr (Version 1.12.0, Build Date: 2025-07-28) #> ## See http://github.com/mikeblazanin/gcplyr for additional documentation #> ## Please cite software as: #> ##   Blazanin, Michael. gcplyr: an R package for microbial growth #> ##   curve data analysis. BMC Bioinformatics 25, 232 (2024). #> ##   https://doi.org/10.1186/s12859-024-05817-3 #> ##"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc10_using_make_design.html","id":"including-design-elements","dir":"Articles","previous_headings":"","what":"Including design elements","title":"Using make_design to generate experimental designs","text":"reminder, gcplyr enables incorporation design elements two ways: Designs can imported files Designs can generated R using make_design generating designs R, make_design can create: block-shaped data.frames design information (saving files) tidy-shaped data.frames design information (saving files merging tidy-shaped data)","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc10_using_make_design.html","id":"an-example-with-a-single-design","dir":"Articles","previous_headings":"Including design elements","what":"An example with a single design","title":"Using make_design to generate experimental designs","text":"Let’s start simple design. Imagine 96 well plate (12 columns 8 rows) different bacterial strain row, leaving first last rows columns empty. Typing design like manually spreadsheet can tedious. generating make_design easier. make_design first needs general information, like nrows ncols plate, output_format ’d like (typically blocks tidy). , different design component, make_design needs five different pieces information: vector containing possible values vector specifying rows values applied vector specifying columns values applied string vector pattern values Boolean whether pattern filled byrow (defaults TRUE) example , can see: possible values c(\"Strain 1\", \"Strain 2\", \"Strain 3\", \"Strain 4\", \"Strain 5\", \"Strain 6\") rows values applied 2:7 columns values applied 2:11 pattern values filled \"123456\" values filled row (filled column) produces data.frame Bacteria block_name metadata. save design file transform tidy-shaped, block_name metadata come handy.","code":"my_design_blk <- make_design(   output_format = \"blocks\",   nrows = 8, ncols = 12,    Bacteria = list(c(\"Str1\", \"Str2\", \"Str3\", \"Str4\", \"Str5\", \"Str6\"),                   2:7,                   2:11,                   \"123456\",                   FALSE) ) my_design_blk #> [[1]] #> [[1]]$data #>   1  2      3      4      5      6      7      8      9      10     11     12 #> A NA NA     NA     NA     NA     NA     NA     NA     NA     NA     NA     NA #> B NA \"Str1\" \"Str1\" \"Str1\" \"Str1\" \"Str1\" \"Str1\" \"Str1\" \"Str1\" \"Str1\" \"Str1\" NA #> C NA \"Str2\" \"Str2\" \"Str2\" \"Str2\" \"Str2\" \"Str2\" \"Str2\" \"Str2\" \"Str2\" \"Str2\" NA #> D NA \"Str3\" \"Str3\" \"Str3\" \"Str3\" \"Str3\" \"Str3\" \"Str3\" \"Str3\" \"Str3\" \"Str3\" NA #> E NA \"Str4\" \"Str4\" \"Str4\" \"Str4\" \"Str4\" \"Str4\" \"Str4\" \"Str4\" \"Str4\" \"Str4\" NA #> F NA \"Str5\" \"Str5\" \"Str5\" \"Str5\" \"Str5\" \"Str5\" \"Str5\" \"Str5\" \"Str5\" \"Str5\" NA #> G NA \"Str6\" \"Str6\" \"Str6\" \"Str6\" \"Str6\" \"Str6\" \"Str6\" \"Str6\" \"Str6\" \"Str6\" NA #> H NA NA     NA     NA     NA     NA     NA     NA     NA     NA     NA     NA #>  #> [[1]]$metadata #> block_name  #> \"Bacteria\""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc10_using_make_design.html","id":"a-few-notes-on-the-pattern","dir":"Articles","previous_headings":"Including design elements","what":"A few notes on the pattern","title":"Using make_design to generate experimental designs","text":"pattern make_design flexible make easy input designs. “0” character reserved NA values, can put pattern anywhere ’d like value NA previous examples, used numbers 1 6 correspond values. 9 values, can use letters . default, order numbers first, uppercase letters, lowercase letters (“” 10th index). However, ’d like use letters, can simply specify different lookup_tbl_start make_design knows letter ’re using 1 index. can also specify pattern vector rather string.","code":"my_design_blk <- make_design(   output_format = \"blocks\",   nrows = 8, ncols = 12,    Bacteria = list(c(\"Str1\", \"Str2\", \"Str3\",                      \"Str4\", \"Str5\", \"Str6\"),                   2:7,                   2:11,                   \"123056\",                   FALSE) ) my_design_blk #> [[1]] #> [[1]]$data #>   1  2      3      4      5      6      7      8      9      10     11     12 #> A NA NA     NA     NA     NA     NA     NA     NA     NA     NA     NA     NA #> B NA \"Str1\" \"Str1\" \"Str1\" \"Str1\" \"Str1\" \"Str1\" \"Str1\" \"Str1\" \"Str1\" \"Str1\" NA #> C NA \"Str2\" \"Str2\" \"Str2\" \"Str2\" \"Str2\" \"Str2\" \"Str2\" \"Str2\" \"Str2\" \"Str2\" NA #> D NA \"Str3\" \"Str3\" \"Str3\" \"Str3\" \"Str3\" \"Str3\" \"Str3\" \"Str3\" \"Str3\" \"Str3\" NA #> E NA NA     NA     NA     NA     NA     NA     NA     NA     NA     NA     NA #> F NA \"Str5\" \"Str5\" \"Str5\" \"Str5\" \"Str5\" \"Str5\" \"Str5\" \"Str5\" \"Str5\" \"Str5\" NA #> G NA \"Str6\" \"Str6\" \"Str6\" \"Str6\" \"Str6\" \"Str6\" \"Str6\" \"Str6\" \"Str6\" \"Str6\" NA #> H NA NA     NA     NA     NA     NA     NA     NA     NA     NA     NA     NA #>  #> [[1]]$metadata #> block_name  #> \"Bacteria\" my_design_blk <- make_design(   output_format = \"blocks\",   nrows = 8, ncols = 12, lookup_tbl_start = \"A\",   Bacteria = list(     c(\"Str1\", \"Str2\", \"Str3\", \"Str4\", \"Str5\", \"Str6\"),     2:7,     2:11,     \"ABCDEF\",     FALSE) ) my_design_blk <- make_design(   output_format = \"blocks\",   nrows = 8, ncols = 12,   Bacteria = list(     c(\"Str1\", \"Str2\", \"Str3\", \"Str4\", \"Str5\", \"Str6\"),     2:7,     2:11,     c(1,2,3,4,5,6),     FALSE) )"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc10_using_make_design.html","id":"continuing-with-the-example-multiple-designs","dir":"Articles","previous_headings":"Including design elements","what":"Continuing with the example: multiple designs","title":"Using make_design to generate experimental designs","text":"Now let’s return example growth curve experiment. addition different bacterial strain row, now also different media column plate. can generate designs make_design: However, real strength make_design limited simple alternating patterns. make_design can use irregular patterns , replicating needed fill wells. also optional helper function called make_designpattern, mdp short. make_designpattern just reminds us arguments necessary design. example: merging designs plate reader data, need tidy-shaped, just need change output_format tidy.","code":"my_design_blk <- make_design(   output_format = \"blocks\",   nrows = 8, ncols = 12, lookup_tbl_start = \"a\",   Bacteria = list(c(\"Str1\", \"Str2\", \"Str3\",                      \"Str4\", \"Str5\", \"Str6\"),                   2:7,                   2:11,                   \"abcdef\",                   FALSE),   Media = list(c(\"Med1\", \"Med2\", \"Med3\",                  \"Med4\", \"Med5\", \"Med6\",                  \"Med7\", \"Med8\", \"Med9\",                  \"Med10\", \"Med11\", \"Med12\"),                2:7,                2:11,                \"abcdefghij\")   )  my_design_blk #> [[1]] #> [[1]]$data #>   1  2      3      4      5      6      7      8      9      10     11     12 #> A NA NA     NA     NA     NA     NA     NA     NA     NA     NA     NA     NA #> B NA \"Str1\" \"Str1\" \"Str1\" \"Str1\" \"Str1\" \"Str1\" \"Str1\" \"Str1\" \"Str1\" \"Str1\" NA #> C NA \"Str2\" \"Str2\" \"Str2\" \"Str2\" \"Str2\" \"Str2\" \"Str2\" \"Str2\" \"Str2\" \"Str2\" NA #> D NA \"Str3\" \"Str3\" \"Str3\" \"Str3\" \"Str3\" \"Str3\" \"Str3\" \"Str3\" \"Str3\" \"Str3\" NA #> E NA \"Str4\" \"Str4\" \"Str4\" \"Str4\" \"Str4\" \"Str4\" \"Str4\" \"Str4\" \"Str4\" \"Str4\" NA #> F NA \"Str5\" \"Str5\" \"Str5\" \"Str5\" \"Str5\" \"Str5\" \"Str5\" \"Str5\" \"Str5\" \"Str5\" NA #> G NA \"Str6\" \"Str6\" \"Str6\" \"Str6\" \"Str6\" \"Str6\" \"Str6\" \"Str6\" \"Str6\" \"Str6\" NA #> H NA NA     NA     NA     NA     NA     NA     NA     NA     NA     NA     NA #>  #> [[1]]$metadata #> block_name  #> \"Bacteria\"  #>  #>  #> [[2]] #> [[2]]$data #>   1  2      3      4      5      6      7      8      9      10     11      12 #> A NA NA     NA     NA     NA     NA     NA     NA     NA     NA     NA      NA #> B NA \"Med1\" \"Med2\" \"Med3\" \"Med4\" \"Med5\" \"Med6\" \"Med7\" \"Med8\" \"Med9\" \"Med10\" NA #> C NA \"Med1\" \"Med2\" \"Med3\" \"Med4\" \"Med5\" \"Med6\" \"Med7\" \"Med8\" \"Med9\" \"Med10\" NA #> D NA \"Med1\" \"Med2\" \"Med3\" \"Med4\" \"Med5\" \"Med6\" \"Med7\" \"Med8\" \"Med9\" \"Med10\" NA #> E NA \"Med1\" \"Med2\" \"Med3\" \"Med4\" \"Med5\" \"Med6\" \"Med7\" \"Med8\" \"Med9\" \"Med10\" NA #> F NA \"Med1\" \"Med2\" \"Med3\" \"Med4\" \"Med5\" \"Med6\" \"Med7\" \"Med8\" \"Med9\" \"Med10\" NA #> G NA \"Med1\" \"Med2\" \"Med3\" \"Med4\" \"Med5\" \"Med6\" \"Med7\" \"Med8\" \"Med9\" \"Med10\" NA #> H NA NA     NA     NA     NA     NA     NA     NA     NA     NA     NA      NA #>  #> [[2]]$metadata #> block_name  #>    \"Media\" my_design_blk <- make_design(   output_format = \"blocks\",   nrows = 8, ncols = 12, lookup_tbl_start = \"a\",   Bacteria = list(c(\"Str1\", \"Str2\"),                   2:7,                   2:11,                   \"abaaabbbab\",                   FALSE),   Media = list(c(\"Med1\", \"Med2\", \"Med3\"),                2:7,                2:11,                \"aabbbc000abc\"))  my_design_blk #> [[1]] #> [[1]]$data #>   1  2      3      4      5      6      7      8      9      10     11     12 #> A NA NA     NA     NA     NA     NA     NA     NA     NA     NA     NA     NA #> B NA \"Str1\" \"Str2\" \"Str1\" \"Str1\" \"Str1\" \"Str1\" \"Str2\" \"Str1\" \"Str1\" \"Str1\" NA #> C NA \"Str2\" \"Str2\" \"Str1\" \"Str2\" \"Str2\" \"Str2\" \"Str2\" \"Str1\" \"Str2\" \"Str2\" NA #> D NA \"Str1\" \"Str1\" \"Str1\" \"Str1\" \"Str2\" \"Str1\" \"Str1\" \"Str1\" \"Str1\" \"Str2\" NA #> E NA \"Str1\" \"Str2\" \"Str2\" \"Str2\" \"Str2\" \"Str1\" \"Str2\" \"Str2\" \"Str2\" \"Str2\" NA #> F NA \"Str1\" \"Str1\" \"Str2\" \"Str1\" \"Str1\" \"Str1\" \"Str1\" \"Str2\" \"Str1\" \"Str1\" NA #> G NA \"Str2\" \"Str2\" \"Str2\" \"Str1\" \"Str2\" \"Str2\" \"Str2\" \"Str2\" \"Str1\" \"Str2\" NA #> H NA NA     NA     NA     NA     NA     NA     NA     NA     NA     NA     NA #>  #> [[1]]$metadata #> block_name  #> \"Bacteria\"  #>  #>  #> [[2]] #> [[2]]$data #>   1  2      3      4      5      6      7      8      9      10     11     12 #> A NA NA     NA     NA     NA     NA     NA     NA     NA     NA     NA     NA #> B NA \"Med1\" \"Med1\" \"Med2\" \"Med2\" \"Med2\" \"Med3\" NA     NA     NA     \"Med1\" NA #> C NA \"Med2\" \"Med3\" \"Med1\" \"Med1\" \"Med2\" \"Med2\" \"Med2\" \"Med3\" NA     NA     NA #> D NA NA     \"Med1\" \"Med2\" \"Med3\" \"Med1\" \"Med1\" \"Med2\" \"Med2\" \"Med2\" \"Med3\" NA #> E NA NA     NA     NA     \"Med1\" \"Med2\" \"Med3\" \"Med1\" \"Med1\" \"Med2\" \"Med2\" NA #> F NA \"Med2\" \"Med3\" NA     NA     NA     \"Med1\" \"Med2\" \"Med3\" \"Med1\" \"Med1\" NA #> G NA \"Med2\" \"Med2\" \"Med2\" \"Med3\" NA     NA     NA     \"Med1\" \"Med2\" \"Med3\" NA #> H NA NA     NA     NA     NA     NA     NA     NA     NA     NA     NA     NA #>  #> [[2]]$metadata #> block_name  #>    \"Media\" my_design_blk <- make_design(   output_format = \"blocks\",   nrows = 8, ncols = 12, lookup_tbl_start = \"a\",   Bacteria = mdp(     values = c(\"Str1\", \"Str2\", \"Str3\",                 \"Str4\", \"Str5\", \"Str6\"),     rows = 2:7, cols = 2:11, pattern = \"abc0ef\",     byrow = FALSE),   Media = mdp(     values = c(\"Med1\", \"Med2\", \"Med3\",                \"Med4\", \"Med5\", \"Med6\",                \"Med7\", \"Med8\", \"Med9\",                \"Med10\", \"Med11\", \"Med12\"),     rows = 2:7, cols = 2:11, pattern = \"abcde0ghij\"))  my_design_blk #> [[1]] #> [[1]]$data #>   1  2      3      4      5      6      7      8      9      10     11     12 #> A NA NA     NA     NA     NA     NA     NA     NA     NA     NA     NA     NA #> B NA \"Str1\" \"Str1\" \"Str1\" \"Str1\" \"Str1\" \"Str1\" \"Str1\" \"Str1\" \"Str1\" \"Str1\" NA #> C NA \"Str2\" \"Str2\" \"Str2\" \"Str2\" \"Str2\" \"Str2\" \"Str2\" \"Str2\" \"Str2\" \"Str2\" NA #> D NA \"Str3\" \"Str3\" \"Str3\" \"Str3\" \"Str3\" \"Str3\" \"Str3\" \"Str3\" \"Str3\" \"Str3\" NA #> E NA NA     NA     NA     NA     NA     NA     NA     NA     NA     NA     NA #> F NA \"Str5\" \"Str5\" \"Str5\" \"Str5\" \"Str5\" \"Str5\" \"Str5\" \"Str5\" \"Str5\" \"Str5\" NA #> G NA \"Str6\" \"Str6\" \"Str6\" \"Str6\" \"Str6\" \"Str6\" \"Str6\" \"Str6\" \"Str6\" \"Str6\" NA #> H NA NA     NA     NA     NA     NA     NA     NA     NA     NA     NA     NA #>  #> [[1]]$metadata #> block_name  #> \"Bacteria\"  #>  #>  #> [[2]] #> [[2]]$data #>   1  2      3      4      5      6      7  8      9      10     11      12 #> A NA NA     NA     NA     NA     NA     NA NA     NA     NA     NA      NA #> B NA \"Med1\" \"Med2\" \"Med3\" \"Med4\" \"Med5\" NA \"Med7\" \"Med8\" \"Med9\" \"Med10\" NA #> C NA \"Med1\" \"Med2\" \"Med3\" \"Med4\" \"Med5\" NA \"Med7\" \"Med8\" \"Med9\" \"Med10\" NA #> D NA \"Med1\" \"Med2\" \"Med3\" \"Med4\" \"Med5\" NA \"Med7\" \"Med8\" \"Med9\" \"Med10\" NA #> E NA \"Med1\" \"Med2\" \"Med3\" \"Med4\" \"Med5\" NA \"Med7\" \"Med8\" \"Med9\" \"Med10\" NA #> F NA \"Med1\" \"Med2\" \"Med3\" \"Med4\" \"Med5\" NA \"Med7\" \"Med8\" \"Med9\" \"Med10\" NA #> G NA \"Med1\" \"Med2\" \"Med3\" \"Med4\" \"Med5\" NA \"Med7\" \"Med8\" \"Med9\" \"Med10\" NA #> H NA NA     NA     NA     NA     NA     NA NA     NA     NA     NA      NA #>  #> [[2]]$metadata #> block_name  #>    \"Media\" my_design_tdy <- make_design(   output_format = \"tidy\",   nrows = 8, ncols = 12, lookup_tbl_start = \"a\",   Bacteria = mdp(     values = c(\"Str1\", \"Str2\", \"Str3\",                 \"Str4\", \"Str5\", \"Str6\"),     rows = 2:7, cols = 2:11, pattern = \"abc0ef\",     byrow = FALSE),   Media = mdp(     values = c(\"Med1\", \"Med2\", \"Med3\",                \"Med4\", \"Med5\", \"Med6\",                \"Med7\", \"Med8\", \"Med9\",                \"Med10\", \"Med11\", \"Med12\"),     rows = 2:7, cols = 2:11, pattern = \"abcde0ghij\")) #> Inferred 'into' column names as: Bacteria, Media  head(my_design_tdy, 20) #>    Well Bacteria Media #> 1    A1     <NA>  <NA> #> 2    A2     <NA>  <NA> #> 3    A3     <NA>  <NA> #> 4    A4     <NA>  <NA> #> 5    A5     <NA>  <NA> #> 6    A6     <NA>  <NA> #> 7    A7     <NA>  <NA> #> 8    A8     <NA>  <NA> #> 9    A9     <NA>  <NA> #> 10  A10     <NA>  <NA> #> 11  A11     <NA>  <NA> #> 12  A12     <NA>  <NA> #> 13   B1     <NA>  <NA> #> 14   B2     Str1  Med1 #> 15   B3     Str1  Med2 #> 16   B4     Str1  Med3 #> 17   B5     Str1  Med4 #> 18   B6     Str1  Med5 #> 19   B7     Str1  <NA> #> 20   B8     Str1  Med7"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc10_using_make_design.html","id":"saving-designs-to-files","dir":"Articles","previous_headings":"Including design elements","what":"Saving designs to files","title":"Using make_design to generate experimental designs","text":"’d like save designs ’ve created make_design files, just need decide ’d like tidy-shaped block-shaped. formats can easily read back R gcplyr.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc10_using_make_design.html","id":"saving-tidy-shaped-designs","dir":"Articles","previous_headings":"Including design elements > Saving designs to files","what":"Saving tidy-shaped designs","title":"Using make_design to generate experimental designs","text":"design files less human-readable, easier import merge. Additionally, tidy-shaped files often better data repositories, like Dryad. save tidy-shaped designs, simply use built-write.csv function.","code":"#See the previous section where we created my_design_tdy write.csv(x = my_design_tdy, file = \"tidy_design.csv\",           row.names = FALSE)"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc10_using_make_design.html","id":"saving-block-shaped-designs","dir":"Articles","previous_headings":"Including design elements > Saving designs to files","what":"Saving block-shaped designs","title":"Using make_design to generate experimental designs","text":"design files human-readable slightly computationally involved import merge. , use gcplyr function write_blocks. Typically, ’ll use write_blocks save files one two formats: multiple - block saved .csv file single - blocks saved single .csv file, empty row ","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc10_using_make_design.html","id":"saving-block-shaped-designs-to-multiple-files","dir":"Articles","previous_headings":"Including design elements > Saving designs to files > Saving block-shaped designs","what":"Saving block-shaped designs to multiple files","title":"Using make_design to generate experimental designs","text":"default setting write_blocks output_format = 'multiple'. creates one csv file block. set file = NULL, default name files according block_names metadata.","code":"# See the previous section where we created my_design_blk write_blocks(my_design_blk, file = NULL)  # Let's see what the files look like print_df(read.csv(\"Bacteria.csv\", header = FALSE, colClasses = \"character\")) #>   1    2    3    4    5    6    7    8    9   10   11 12 #> A                                                        #> B   Str1 Str1 Str1 Str1 Str1 Str1 Str1 Str1 Str1 Str1    #> C   Str2 Str2 Str2 Str2 Str2 Str2 Str2 Str2 Str2 Str2    #> D   Str3 Str3 Str3 Str3 Str3 Str3 Str3 Str3 Str3 Str3    #> E                                                        #> F   Str5 Str5 Str5 Str5 Str5 Str5 Str5 Str5 Str5 Str5    #> G   Str6 Str6 Str6 Str6 Str6 Str6 Str6 Str6 Str6 Str6    #> H  print_df(read.csv(\"Media.csv\", header = FALSE, colClasses = \"character\")) #>   1    2    3    4    5    6 7    8    9   10    11 12 #> A                                                      #> B   Med1 Med2 Med3 Med4 Med5   Med7 Med8 Med9 Med10    #> C   Med1 Med2 Med3 Med4 Med5   Med7 Med8 Med9 Med10    #> D   Med1 Med2 Med3 Med4 Med5   Med7 Med8 Med9 Med10    #> E   Med1 Med2 Med3 Med4 Med5   Med7 Med8 Med9 Med10    #> F   Med1 Med2 Med3 Med4 Med5   Med7 Med8 Med9 Med10    #> G   Med1 Med2 Med3 Med4 Med5   Med7 Med8 Med9 Med10    #> H"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc10_using_make_design.html","id":"saving-block-shaped-designs-to-a-single-file","dir":"Articles","previous_headings":"Including design elements > Saving designs to files > Saving block-shaped designs","what":"Saving block-shaped designs to a single file","title":"Using make_design to generate experimental designs","text":"setting write_blocks output_format = 'single'. creates single csv file contains blocks, putting metadata like block_names rows precede block. Let’s take look single output format looks like: can see design information saved single file, metadata added rows block.","code":"# See the previous section where we created my_design_blk write_blocks(my_design_blk, file = \"Design.csv\", output_format = \"single\")  # Let's see what the file looks like print_df(read.csv(\"Design.csv\", header = FALSE, colClasses = \"character\")) #> block_name Bacteria                                                       #>                   1    2    3    4    5    6    7    8    9   10    11 12 #>          A                                                                #>          B          Str1 Str1 Str1 Str1 Str1 Str1 Str1 Str1 Str1  Str1    #>          C          Str2 Str2 Str2 Str2 Str2 Str2 Str2 Str2 Str2  Str2    #>          D          Str3 Str3 Str3 Str3 Str3 Str3 Str3 Str3 Str3  Str3    #>          E                                                                #>          F          Str5 Str5 Str5 Str5 Str5 Str5 Str5 Str5 Str5  Str5    #>          G          Str6 Str6 Str6 Str6 Str6 Str6 Str6 Str6 Str6  Str6    #>          H                                                                #>                                                                           #> block_name    Media                                                       #>                   1    2    3    4    5    6    7    8    9   10    11 12 #>          A                                                                #>          B          Med1 Med2 Med3 Med4 Med5      Med7 Med8 Med9 Med10    #>          C          Med1 Med2 Med3 Med4 Med5      Med7 Med8 Med9 Med10    #>          D          Med1 Med2 Med3 Med4 Med5      Med7 Med8 Med9 Med10    #>          E          Med1 Med2 Med3 Med4 Med5      Med7 Med8 Med9 Med10    #>          F          Med1 Med2 Med3 Med4 Med5      Med7 Med8 Med9 Med10    #>          G          Med1 Med2 Med3 Med4 Med5      Med7 Med8 Med9 Med10    #>          H"},{"path":"https://mikeblazanin.github.io/gcplyr/articles/gc10_using_make_design.html","id":"merging-growth-curve-data-with-designs","dir":"Articles","previous_headings":"","what":"Merging growth curve data with designs","title":"Using make_design to generate experimental designs","text":"design data R tidy-shaped, can merge just way described vignette(\"gc03_incorporate_designs\")","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Mike Blazanin. Author, maintainer.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Blazanin, M. gcplyr: R package microbial growth curve data analysis. BMC Bioinformatics 25, 232 (2024). https://doi.org/10.1186/s12859-024-05817-3","code":"@Article{,   title = {gcplyr: an R package for microbial growth curve data analysis},   author = {Michael Blazanin},   year = {2024},   doi = {10.1186/s12859-024-05817-3},   journal = {BMC Bioinformatics},   volume = {25},   number = {232},   note = {version 1.12.0}, }"},{"path":[]},{"path":"https://mikeblazanin.github.io/gcplyr/index.html","id":"what-this-package-can-do","dir":"","previous_headings":"","what":"What this package can do","title":"Wrangle and Analyze Growth Curve Data","text":"gcplyr created make easier import, wrangle, model-free analyses microbial growth curve data, commonly output plate readers. gcplyr can flexibly import common data formats output plate readers reshape ‘tidy’ formats analyses. gcplyr can import experimental designs files directly R, merge design information density data. merged tidy-shaped data easy work plot using functions gcplyr popular packages dplyr ggplot2. gcplyr can calculate plain per-capita derivatives density data. gcplyr several methods deal noise density derivatives data. gcplyr can extract parameters like growth rate/doubling time, maximum density (carrying capacity), lag time, area curve, diauxic shifts, extinction, without fitting equation growth data. Please send questions, requests, comments, bugs mikeblazanin [] gmail [dot] com","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Wrangle and Analyze Growth Curve Data","text":"can install version -recently released CRAN running following line R: can install recently-released version GitHub running following lines R:","code":"install.packages(\"gcplyr\") install.packages(\"devtools\") devtools::install_github(\"mikeblazanin/gcplyr\")"},{"path":"https://mikeblazanin.github.io/gcplyr/index.html","id":"getting-started","dir":"","previous_headings":"","what":"Getting Started","title":"Wrangle and Analyze Growth Curve Data","text":"best way get started read articles series, breaks typical workflow using gcplyr start finish, starting introduction: Introduction: vignette(\"gc01_gcplyr\") Importing transforming data: vignette(\"gc02_import_reshape\") Incorporating experimental designs: vignette(\"gc03_incorporate_designs\") Pre-processing plotting data: vignette(\"gc04_preprocess_plot\") Processing data: vignette(\"gc05_process\") Analyzing data: vignette(\"gc06_analyze\") Dealing noise: vignette(\"gc07_noise\") Best practices tips: vignette(\"gc08_conclusion\") Working multiple plates: vignette(\"gc09_multiple_plates\") Using make_design generate experimental designs: vignette(\"gc10_using_make_design\")","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/index.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Wrangle and Analyze Growth Curve Data","text":"Please cite software : Blazanin, M. gcplyr: R package microbial growth curve data analysis. BMC Bioinformatics 25, 232 (2024). https://doi.org/10.1186/s12859-024-05817-3","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/CentroidFunctions.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate centroid — CentroidFunctions","title":"Calculate centroid — CentroidFunctions","text":"function takes vector x y values returns x /y position centroid mass area curve","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/CentroidFunctions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate centroid — CentroidFunctions","text":"","code":"centroid(   x,   y,   return,   xlim = NULL,   blank = 0,   subset = NULL,   na.rm = TRUE,   neg.rm = FALSE,   warn_xlim_out_of_range = TRUE,   warn_negative_y = TRUE )  centroid_x(x, y, return = \"x\", ...)  centroid_y(x, y, return = \"y\", ...)  centroid_both(x, y, return = \"both\", ...)"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/CentroidFunctions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate centroid — CentroidFunctions","text":"x Numeric vector x values y Numeric vector y values return One c(\"x\", \"y\", \"\"), determining whether function return x value centroid, y value centroid, vector containing x y xlim Vector, length 2, delimiting x range centroid calculated (NA can provided area calculated start end data) blank Value subtracted y values calculating centroid subset vector logical values indicating x y values included (TRUE) excluded (FALSE). na.rm logical indicating whether missing values removed neg.rm logical indicating whether y values zero treated zeros. FALSE, centroid negative y values calculated normally, effectively pulling centroid towards x axis. warn_xlim_out_of_range logical whether warning issued xlim lower lowest x value higher highest x value. warn_negative_y logical whether warning issued neg.rm == FALSE y values 0. ... arguments pass centroid","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/CentroidFunctions.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate centroid — CentroidFunctions","text":"scalar x value (return = 'x')         y value (return = 'y') centroid data","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/CentroidFunctions.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate centroid — CentroidFunctions","text":"function uses st_centroid calculate centroid mass","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/ExtremaFunctions.html","id":null,"dir":"Reference","previous_headings":"","what":"Find local extrema of a numeric vector — ExtremaFunctions","title":"Find local extrema of a numeric vector — ExtremaFunctions","text":"functions take vector y values identify local extrema.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/ExtremaFunctions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find local extrema of a numeric vector — ExtremaFunctions","text":"","code":"find_local_extrema(   y,   x = NULL,   window_width = NULL,   window_width_n = NULL,   window_height = NULL,   window_width_frac = NULL,   window_width_n_frac = NULL,   return = \"index\",   return_maxima = TRUE,   return_minima = TRUE,   return_endpoints = TRUE,   subset = NULL,   na.rm = TRUE,   width_limit = NULL,   width_limit_n = NULL,   height_limit = NULL )  first_maxima(   y,   x = NULL,   window_width = NULL,   window_width_n = NULL,   window_height = NULL,   window_width_frac = NULL,   window_width_n_frac = 0.2,   return = \"index\",   return_endpoints = TRUE,   ... )  first_minima(   y,   x = NULL,   window_width = NULL,   window_width_n = NULL,   window_height = NULL,   window_width_frac = NULL,   window_width_n_frac = 0.2,   return = \"index\",   return_endpoints = TRUE,   ... )"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/ExtremaFunctions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Find local extrema of a numeric vector — ExtremaFunctions","text":"y Numeric vector y values identify local extrema x Optional numeric vector corresponding x values window_width, window_width_n, window_height, window_width_frac, window_width_n_frac Arguments set width/height window used search local extrema. window_width units x. window_width_n units number data points. window_height maximum change y single extrema-search step allowed take. window_width_n_frac fraction total number data points. example, function pass peak valley window_width_n data points wide, peak/valley taller deeper window_height. narrower width sensitive narrow local maxima/minima, wider width less sensitive local maxima/minima. smaller height sensitive shallow local maxima/minima, larger height less sensitive shallow maxima/minima. return One c(\"index\", \"x\", \"y\"), determining whether function return index, x value, y value associated identified extremas return_maxima, return_minima logical classes local extrema return return_endpoints first last values y included returned vector extrema? subset vector logical values indicating x y values included (TRUE) excluded (FALSE). return = \"index\", index whole vector subset vector na.rm logical whether NA's removed analyzing width_limit Deprecated, use window_width instead width_limit_n Deprecated, use window_width_n instead height_limit Deprecated, use window_height instead ... (first_maxima first_minima), parameters pass find_local_extrema","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/ExtremaFunctions.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Find local extrema of a numeric vector — ExtremaFunctions","text":"find_local_extrema returns vector corresponding    found local extrema. first_maxima returns first maxima, shortcut    find_local_extrema(return_maxima = TRUE, return_minima = FALSE)[1] first_minima returns first minima, shortcut    find_local_extrema(return_maxima = FALSE, return_maxima = FALSE)[1] return = \"index\", returned value(s) indices    corresponding local extrema data return = \"x\", returned value(s) x value(s)    corresponding local extrema data return = \"y\", returned value(s) y value(s)    corresponding local extrema data","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/ExtremaFunctions.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Find local extrema of a numeric vector — ExtremaFunctions","text":"find_local_extrema, one window_width, window_width_n, window_height, window_width_n_frac must provided. first_minima first_maxima, set window_width_n_frac = NULL override default width behavior. multiple window_width, window_width_n, window_height, window_width_n_frac provided, steps limited conservatively (single step must meet criteria). case exact ties y values within window, first local extrema returned.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/MinMaxGC.html","id":null,"dir":"Reference","previous_headings":"","what":"Maxima and Minima — MinMaxGC","title":"Maxima and Minima — MinMaxGC","text":"Returns maxima minima input values.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/MinMaxGC.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Maxima and Minima — MinMaxGC","text":"","code":"max_gc(..., na.rm = TRUE, allmissing_NA = TRUE)  min_gc(..., na.rm = TRUE, allmissing_NA = TRUE)"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/MinMaxGC.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Maxima and Minima — MinMaxGC","text":"... numeric character arguments na.rm logical indicating whether missing values removed. allmissing_NA logical indicating whether NA returned non-missing arguments passed min max (often na.rm = TRUE values NA)","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/MinMaxGC.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Maxima and Minima — MinMaxGC","text":"allmissing_NA = FALSE, identical min    max. allmissing_NA = TRUE, identical min    max except , cases min    max return infinite value raise warning    non-missing arguments, min_gc    max_gc return NA","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/MinMaxGC.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Maxima and Minima — MinMaxGC","text":"functions wrappers min max, additional argument allmissing_NA.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/MovingWindowFunctions.html","id":null,"dir":"Reference","previous_headings":"","what":"Moving window smoothing — MovingWindowFunctions","title":"Moving window smoothing — MovingWindowFunctions","text":"functions use moving window smooth data","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/MovingWindowFunctions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Moving window smoothing — MovingWindowFunctions","text":"","code":"moving_average(   formula = NULL,   data = NULL,   x = NULL,   y = NULL,   window_width_n = NULL,   window_width = NULL,   window_width_n_frac = NULL,   window_width_frac = NULL,   na.rm = TRUE,   warn_nonnumeric_sort = TRUE )  moving_median(   formula = NULL,   data = NULL,   x = NULL,   y = NULL,   window_width_n = NULL,   window_width = NULL,   window_width_n_frac = NULL,   window_width_frac = NULL,   na.rm = TRUE,   warn_nonnumeric_sort = TRUE )"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/MovingWindowFunctions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Moving window smoothing — MovingWindowFunctions","text":"formula Formula specifying numeric response (density) numeric predictor (time). data Dataframe containing variables formula x vector predictor values smooth along (e.g. time) y vector response values smoothed (e.g. density). window_width_n Number data points wide moving window (therefore, must odd number points) window_width Width moving window (units x) window_width_n_frac Width window (fraction total number data points). window_width_frac Width window (fraction range x) na.rm logical whether NA's removed analyzing warn_nonnumeric_sort logical whether warning issued predictor variable data sorted non-numeric.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/MovingWindowFunctions.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Moving window smoothing — MovingWindowFunctions","text":"Vector smoothed data, NA's appended ends","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/MovingWindowFunctions.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Moving window smoothing — MovingWindowFunctions","text":"Either x y formula data          must provided. Values NULL NA ignored          window_width_n, window_width,          window_width_n_frac, window_width_frac","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/ThresholdFunctions.html","id":null,"dir":"Reference","previous_headings":"","what":"Find point(s) when a numeric vector crosses some threshold — ThresholdFunctions","title":"Find point(s) when a numeric vector crosses some threshold — ThresholdFunctions","text":"functions take vector y values identify points y values cross threshold y value.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/ThresholdFunctions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find point(s) when a numeric vector crosses some threshold — ThresholdFunctions","text":"","code":"find_threshold_crosses(   y,   x = NULL,   threshold,   return = \"index\",   return_rising = TRUE,   return_falling = TRUE,   return_endpoints = TRUE,   subset = NULL,   na.rm = TRUE )  first_below(   y,   x = NULL,   threshold,   return = \"index\",   return_endpoints = TRUE,   ... )  first_above(   y,   x = NULL,   threshold,   return = \"index\",   return_endpoints = TRUE,   ... )"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/ThresholdFunctions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Find point(s) when a numeric vector crosses some threshold — ThresholdFunctions","text":"y Numeric vector y values identify threshold crossing event(s) x Optional numeric vector corresponding x values threshold Threshold y value interest return One c(\"index\", \"x\"), determining whether function return index x value associated threshold-crossing event. index, refer data point immediately crossing event. x, use linear interpolation data points immediately threshold-crossing return exact x value threshold crossing occurred return_rising logical whether crossing events y rises threshold returned return_falling logical whether crossing events y falls threshold returned return_endpoints logical whether startpoint returned startpoint threshold return_rising = TRUE, startpoint threshold return_falling = TRUE subset vector logical values indicating x y values included (TRUE) excluded (FALSE). return = \"index\", index whole vector subset vector na.rm logical whether NA's removed analyzing. return = 'index', indices refer original y vector *including* NA values ... (first_above first_below) arguments pass find_threshold_crosses","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/ThresholdFunctions.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Find point(s) when a numeric vector crosses some threshold — ThresholdFunctions","text":"find_threshold_crosses returns vector corresponding    threshold crossings. first_above returns first time y values    rise threshold, shortcut    find_threshold_crosses(return_rising = TRUE, return_falling = FALSE)[1] first_below returns first time y values    fall threshold, shortcut    find_threshold_crosses(return_rising = FALSE, return_falling = TRUE)[1] return = \"index\", returned value(s) indices    immediately following threshold crossing(s) return = \"x\", returned value(s) x value(s)    corresponding threshold crossing(s) threshold-crossings detected meet criteria,    return NA","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/WhichMinMaxGC.html","id":null,"dir":"Reference","previous_headings":"","what":"Where is the Min() or Max() or first TRUE or FALSE? — WhichMinMaxGC","title":"Where is the Min() or Max() or first TRUE or FALSE? — WhichMinMaxGC","text":"Determines location, .e. index, (first) minimum maximum numeric (logical) vector.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/WhichMinMaxGC.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Where is the Min() or Max() or first TRUE or FALSE? — WhichMinMaxGC","text":"","code":"which_min_gc(x, empty_NA = TRUE)  which_max_gc(x, empty_NA = TRUE)"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/WhichMinMaxGC.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Where is the Min() or Max() or first TRUE or FALSE? — WhichMinMaxGC","text":"x numeric (logical, integer, double) vector R object internal coercion double works whose min max searched . empty_NA logical, indicating empty value returned NA (default) integer(0) (.min .max).","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/WhichMinMaxGC.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Where is the Min() or Max() or first TRUE or FALSE? — WhichMinMaxGC","text":"empty_NA = FALSE, identical .min    .max empty_NA = TRUE, identical .min    .max except , cases .min    .max return integer(0), which_min_gc    which_max_gc return NA","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/WhichMinMaxGC.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Where is the Min() or Max() or first TRUE or FALSE? — WhichMinMaxGC","text":"functions wrappers .min .max, additional argument empty_NA.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/auc.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate area under the curve — auc","title":"Calculate area under the curve — auc","text":"function takes vector x y values returns scalar area curve, calculated using trapezoid rule","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/auc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate area under the curve — auc","text":"","code":"auc(   x,   y,   xlim = NULL,   blank = 0,   subset = NULL,   na.rm = TRUE,   neg.rm = FALSE,   warn_xlim_out_of_range = TRUE,   warn_negative_y = TRUE )"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/auc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate area under the curve — auc","text":"x Numeric vector x values y Numeric vector y values xlim Vector, length 2, delimiting x range area curve calculated (NA can provided area calculated start end data) blank Value subtracted y values calculating area curve subset vector logical values indicating x y values included (TRUE) excluded (FALSE). na.rm logical indicating whether missing values removed neg.rm logical indicating whether y values zero treated zeros. FALSE, area curve negative y values calculated normally, effectively subtracting returned value. warn_xlim_out_of_range logical whether warning issued xlim lower lowest x value higher highest x value. warn_negative_y logical whether warning issued neg.rm == FALSE y values 0.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/auc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate area under the curve — auc","text":"scalar total area curve","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/block_tidydesign.html","id":null,"dir":"Reference","previous_headings":"","what":"Turn tidydesign into block format — block_tidydesign","title":"Turn tidydesign into block format — block_tidydesign","text":"function allows users convert designs created tidydesign  block format easy output csv inclusion lab notebooks,  etc human-readable format","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/block_tidydesign.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Turn tidydesign into block format — block_tidydesign","text":"","code":"block_tidydesign(   tidydesign,   collapse = NULL,   wellnames_sep = \"_\",   wellnames_colname = \"Well\" )"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/block_tidydesign.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Turn tidydesign into block format — block_tidydesign","text":"tidydesign tidydesign data.frame (e.g. created make_tidydesign) collapse NULL string use concatenating design elements together. NULL design column put block. string, string used paste together design elements design elements returned single block wellnames_sep string used concatenating rownames column names create well names wellnames_colname Header newly-created column containing well names","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/block_tidydesign.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Turn tidydesign into block format — block_tidydesign","text":"list blockdesign data.frames (collapse         NULL list length 1","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/calc_deriv.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate derivatives of vector of data — calc_deriv","title":"Calculate derivatives of vector of data — calc_deriv","text":"Provided vector y values, function returns either plain per-capita difference derivative sequential values","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/calc_deriv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate derivatives of vector of data — calc_deriv","text":"","code":"calc_deriv(   y,   x = NULL,   return = \"derivative\",   percapita = FALSE,   x_scale = 1,   blank = NULL,   subset_by = NULL,   window_width = NULL,   window_width_n = NULL,   window_width_frac = NULL,   window_width_n_frac = NULL,   trans_y = \"linear\",   na.rm = TRUE,   warn_ungrouped = TRUE,   warn_logtransform_warnings = TRUE,   warn_logtransform_infinite = TRUE,   warn_window_toosmall = TRUE )"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/calc_deriv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate derivatives of vector of data — calc_deriv","text":"y Data calculate difference derivative x Vector x values provided simple numeric. return One c(\"difference\", \"derivative\") whether differences y returned, derivative y respect x percapita percapita = TRUE, per-capita difference derivative returned x_scale Numeric scale x derivative calculation Set x_scale ratio units x desired units. E.g. x seconds, desired derivative units /minute, set x_scale = 60 (since 60 seconds 1 minute). blank y-value associated \"blank\" density 0. required percapita = TRUE. vector blank values specified, blank values assumed order unique(subset_by) subset_by optional vector long y. y split unique values vector derivative group calculated independently others. provides internally-implemented approach similar group_by mutate window_width, window_width_n, window_width_frac, window_width_n_frac Set many data points used determine slope point. NULL, calc_deriv calculates difference derivative point next point, appending NA end. one multiple specified, linear regression fit points window determine slope. window_width_n specifies width window number data points. window_width specifies width window units x. window_width_n_frac specifies width window fraction total number data points. using multiple window specifications time, windows conservative. Points included window meet window_width, window_width_n, window_width_n_frac. value window_width_n = 3 window_width_n = 5 often good default. trans_y One c(\"linear\", \"log\") specifying                 transformation y-values. 'log' available calculating per-capita                 derivatives using fitting approach (non-default                 values specified window_width                 window_width_n). per-capita growth expected exponential                 nearly-exponential, \"log\" recommended, since                 exponential growth linear log-transformed. However,                 log-transformations must used care, since y-values                 0 become undefined results                 sensitive incorrect values blank. na.rm logical whether NA's removed analyzing warn_ungrouped logical whether warning issued calc_deriv called ungrouped data subset_by = NULL. warn_logtransform_warnings logical whether warning issued log(y) produced warnings. warn_logtransform_infinite logical whether warning issued log(y) produced infinite values treated NA. warn_window_toosmall logical whether warning issued one data point window set window_width_n, window_width, window_width_n_frac, NA returned.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/calc_deriv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate derivatives of vector of data — calc_deriv","text":"vector values plain (percapita = FALSE)         per-capita (percapita = TRUE) difference         (return = \"difference\") derivative         (return = \"derivative\") y values. Vector         length y,  NA values         ends","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/calc_deriv.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate derivatives of vector of data — calc_deriv","text":"per-capita derivatives, trans_y = 'linear'          trans_y = 'log' approach value time resolution          increases. instance, assume exponential growth \\(N = e^rt\\)          per-capita growth rate \\(r\\). trans_y = 'linear', note \\(dN/dt = r e^rt = r N\\).          can calculate per-capita growth rate \\(r = dN/dt * 1/N\\). trans_y = 'log', note \\(log(N) = log(e^rt) = rt\\).          can calculate per-capita growth rate slope linear          fit \\(log(N)\\) time, \\(r = log(N)/t\\).","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/doubling_time.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate doubling time equivalent of per-capita growth rate — doubling_time","title":"Calculate doubling time equivalent of per-capita growth rate — doubling_time","text":"Provided vector per-capita growth rates, function returns vector equivalent doubling times","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/doubling_time.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate doubling time equivalent of per-capita growth rate — doubling_time","text":"","code":"doubling_time(y, x_scale = 1)"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/doubling_time.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate doubling time equivalent of per-capita growth rate — doubling_time","text":"y Vector per-capita derivative data calculate equivalent doubling time x_scale Numeric scale per-capita derivative values Set x_scale ratio units y desired units. E.g. y per-second, desired doubling time minutes, x_scale = 60 (since 60 seconds 1 minute).","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/doubling_time.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate doubling time equivalent of per-capita growth rate — doubling_time","text":"vector values doubling time equivalent         per-capita growth rate supplied y","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/example_design_tidy.html","id":null,"dir":"Reference","previous_headings":"","what":"Design for example growth curve data A tidy-shaped dataset with the experimental design (i.e. plate layout) for the example data included with gcplyr. — example_design_tidy","title":"Design for example growth curve data A tidy-shaped dataset with the experimental design (i.e. plate layout) for the example data included with gcplyr. — example_design_tidy","text":"Wells A1...A8 F1...F8 contain 48 different simulated bacterial strains growing alone. Wells G1...G8 L1...L8 contain 48 bacterial strains identical layout, time growing presence phage","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/example_design_tidy.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Design for example growth curve data A tidy-shaped dataset with the experimental design (i.e. plate layout) for the example data included with gcplyr. — example_design_tidy","text":"","code":"example_design_tidy"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/example_design_tidy.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Design for example growth curve data A tidy-shaped dataset with the experimental design (i.e. plate layout) for the example data included with gcplyr. — example_design_tidy","text":"dataframe 96 rows 3 variables: Well well plate Bacteria_strain numbered bacterial strain growing well Phage Whether bacteria simulated growing phages","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/example_widedata.html","id":null,"dir":"Reference","previous_headings":"","what":"Example noisy growth curve data in wide format — example_widedata","title":"Example noisy growth curve data in wide format — example_widedata","text":"dataset containing example growth 96 wells simulated bacteria  bacteria phages Wells A1...A8 F1...F8 contain 48 different simulated bacterial strains growing alone. Wells G1...G8 L1...L8 contain 48 bacterial strains identical layout, time growing presence phage","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/example_widedata.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Example noisy growth curve data in wide format — example_widedata","text":"","code":"example_widedata"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/example_widedata.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Example noisy growth curve data in wide format — example_widedata","text":"dataframe 97 rows 97 variables: time time, seconds, since growth curve began A1, A2...H11, H12 bacterial density given well","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/example_widedata.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Example noisy growth curve data in wide format — example_widedata","text":"Bacterial populations exhibit diauxic growth approach carrying capacity, also evolve resistance face selection phage population. data includes simulated noise approximate noise generated data collection plate readers","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/example_widedata_noiseless.html","id":null,"dir":"Reference","previous_headings":"","what":"Example growth curve data in wide format — example_widedata_noiseless","title":"Example growth curve data in wide format — example_widedata_noiseless","text":"dataset containing example growth 96 wells simulated bacteria  bacteria phages Wells A1...A8 F1...F8 contain 48 different simulated bacterial strains growing alone. Wells G1...G8 L1...L8 contain 48 bacterial strains identical layout, time growing presence phage","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/example_widedata_noiseless.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Example growth curve data in wide format — example_widedata_noiseless","text":"","code":"example_widedata_noiseless"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/example_widedata_noiseless.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Example growth curve data in wide format — example_widedata_noiseless","text":"dataframe 97 rows 97 variables: time time, seconds, since growth curve began A1, A2...H11, H12 bacterial density given well","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/example_widedata_noiseless.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Example growth curve data in wide format — example_widedata_noiseless","text":"Bacterial populations exhibit diauxic growth approach carrying capacity, also evolve resistance face selection phage population. data include simulated noise","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/extr_val.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract parts of an object — extr_val","title":"Extract parts of an object — extr_val","text":"wrapper [ handling NA's use dplyr::summarize()","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/extr_val.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract parts of an object — extr_val","text":"","code":"extr_val(x, i, allNA_NA = TRUE, na.rm = TRUE)"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/extr_val.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract parts of an object — extr_val","text":"x object extract element(s) index specifying element extract. allNA_NA logical indicating whether NA returned (.na()) == TRUE. na.rm logical indicating whether missing index values removed.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/extr_val.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract parts of an object — extr_val","text":"all_NA = FALSE na.rm = FALSE, identical    x[]. all_NA = FALSE na.rm = TRUE, identical    x[[!.na()]]. all_NA = TRUE, identical x[] unless    (.na()) == TRUE, case returns NA","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/first_peak.html","id":null,"dir":"Reference","previous_headings":"","what":"Find the first local maxima of a numeric vector — first_peak","title":"Find the first local maxima of a numeric vector — first_peak","text":"function deprecated favor identical new function first_maxima","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/first_peak.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find the first local maxima of a numeric vector — first_peak","text":"","code":"first_peak(   y,   x = NULL,   window_width = NULL,   window_width_n = NULL,   window_height = NULL,   return = \"index\",   return_endpoints = TRUE,   ... )"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/first_peak.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Find the first local maxima of a numeric vector — first_peak","text":"y Numeric vector y values identify local extrema x Optional numeric vector corresponding x values window_width Width window (units x) used search local extrema. narrower width sensitive narrow local maxima/minima, wider width less sensitive local maxima/minima. window_width_n maximum number data points single extrema-search step allowed take. example, maxima-finding, function pass valley consisting window_width_n data points. smaller window_width_n sensitive narrow local maxima/minima, larger window_width_n less sensitive narrow local maxima/minima. provided, defaults ~0.2*length(y) window_height maximum change y single extrema-search step allowed take.  example, maxima-finding, function pass valley deeper window_height. smaller window_height sensitive shallow local maxima/minima, larger window_height less sensitive shallow maxima/minima. return One c(\"index\", \"x\", \"y\"), determining whether function return index, x value, y value associated first maxima y values return_endpoints first last value y allowed returned? ... parameters pass find_local_extrema","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/first_peak.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Find the first local maxima of a numeric vector — first_peak","text":"return = \"index\", vector indices corresponding           local extrema data return = \"x\", vector x values corresponding           local extrema data return = \"y\", vector y values corresponding           local extrema data","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/first_peak.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Find the first local maxima of a numeric vector — first_peak","text":"function takes vector y values returns index (default) first local maxima. serves shortcut find_local_extrema(return_maxima = TRUE, return_minima = FALSE)[1] none window_width, window_width_n, window_height provided, default value window_width_n used.","code":""},{"path":[]},{"path":"https://mikeblazanin.github.io/gcplyr/reference/from_excel.html","id":null,"dir":"Reference","previous_headings":"","what":"A function that converts base-26 Excel-style letters to numbers — from_excel","title":"A function that converts base-26 Excel-style letters to numbers — from_excel","text":"function converts base-26 Excel-style letters numbers","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/from_excel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A function that converts base-26 Excel-style letters to numbers — from_excel","text":"","code":"from_excel(x)"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/from_excel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A function that converts base-26 Excel-style letters to numbers — from_excel","text":"x vector column names Excel-style base-26 letter format (values already base-10 returned -)","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/from_excel.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A function that converts base-26 Excel-style letters to numbers — from_excel","text":"vector numbers base-10","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/gc_smooth.spline.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit a Smoothing Spline — gc_smooth.spline","title":"Fit a Smoothing Spline — gc_smooth.spline","text":"function wrapper smooth.spline, fits cubic smoothing spline supplied data, includes option remove NA values, returns values original order.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/gc_smooth.spline.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit a Smoothing Spline — gc_smooth.spline","text":"","code":"gc_smooth.spline(x, y = NULL, ..., na.rm = TRUE)"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/gc_smooth.spline.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit a Smoothing Spline — gc_smooth.spline","text":"x vector giving values predictor variable. y vector giving values response variable. y missing NULL, responses assumed specified x, x index vector. ... Additional arguments passed smooth.spline. na.rm logical whether NA's removed analyzing. Required TRUE x y values NA.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/gc_smooth.spline.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit a Smoothing Spline — gc_smooth.spline","text":"Similar smooth.spline, object class         \"smooth.spline\" many components. Differs         x, y, w NA's indices x y         NA inputs, x, y, w returned match input         x order length","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/gc_smooth.spline.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fit a Smoothing Spline — gc_smooth.spline","text":"See smooth.spline","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/import_blockdesigns.html","id":null,"dir":"Reference","previous_headings":"","what":"Import blockdesigns — import_blockdesigns","title":"Import blockdesigns — import_blockdesigns","text":"Function import block-shaped designs files return tidy designs. function acts wrapper calls read_blocks, paste_blocks, trans_block_to_wide, trans_wide_to_tidy, separate_tidy","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/import_blockdesigns.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Import blockdesigns — import_blockdesigns","text":"","code":"import_blockdesigns(   files,   block_names = NULL,   block_name_header = \"block_name\",   join_as_cols = TRUE,   sep = NULL,   values_colname = \"Designs\",   into = NULL,   keep_blocknames = !join_as_cols,   warn_joinrows_nointo = TRUE,   join_designs = NULL,   ... )"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/import_blockdesigns.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Import blockdesigns — import_blockdesigns","text":"files vector filepaths relative current working directory filepath single plate read read read_blocks. block_names Vector names corresponding design element (block). Inferred filenames, specified. keep_blocknames = TRUE, output column containing values, column name specified block_name_header. join_as_cols = TRUE, block_names also used output column names separated design column. block_name_header keep_blocknames = TRUE, column name column containing block_names. join_as_cols logical indicating whether blocks (multiple) joined columns (.e. describe plate) tidy output. FALSE, blocks joined rows (.e. describe different plates) tidy output. sep designs pasted together, specifies string split apart via separate_tidy. values_colname join_as_cols = FALSE sep specified, design values column named values_colname. cases, see Value section. sep specified, sets names columns splitting (see Value section behavior set). keep_blocknames logical indicating whether column containing block_names (inferred file names) retained output. default, blocknames retained join_as_cols = FALSE. warn_joinrows_nointo logical indicating whether warning raised multiple blocks joined rows (join_as_cols = FALSE) sep specified, specified. join_designs Deprecated, use join_as_cols instead ... arguments pass read_blocks, paste_blocks, trans_block_to_wide, trans_wide_to_tidy, separate_tidy. See Details information","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/import_blockdesigns.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Import blockdesigns — import_blockdesigns","text":"tidy-shaped data.frame containing design information         files. always includes \"Well\" column. keep_blocknames = TRUE, includes column         column name specified block_name_header containing         block_names (block names inferred file names). layout design values varies depending inputs: join_as_cols = TRUE, block joined column,         columns named according block_names (block         names inferred file names). case, sep         specified, column split sep columns named         splitting corresponding block name sep (post-split         column names can alternatively specified directly via ). Otherwise, join_as_cols = FALSE, block joined         rows, column containing design values named         values_colname. case, sep specified,         single design column split sep columns         named splitting values_colname (post-split column names         can alternatively specified directly via ).","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/import_blockdesigns.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Import blockdesigns — import_blockdesigns","text":"common arguments may want provide via              ... include: startrow, endrow, startcol, endcol,              sheet - specifying location design information              inside files read_blocks. wellnames_sep - specifying character (\"\"              none) used pasting together rownames              column names. Note chosen match              well names measures. - specifying column names resulting              using separate_tidy values_colname column. Note import_blockdesigns currently handle              metadata specified via metadata argument              read_blocks. find needing control, can run              steps manually, first reading read_blocks,              pasting needed paste_blocks,              transforming tidy trans_block_to_wide              trans_wide_to_tidy, separating needed              separate_tidy.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/import_blockmeasures.html","id":null,"dir":"Reference","previous_headings":"","what":"Import blockmeasures — import_blockmeasures","title":"Import blockmeasures — import_blockmeasures","text":"Function import blockmeasures files return widemeasures function acts wrapper call read_blocks, uninterleave, trans_block_to_wide one go","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/import_blockmeasures.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Import blockmeasures — import_blockmeasures","text":"","code":"import_blockmeasures(   files,   num_plates = 1,   plate_names = NULL,   wellnames_sep = \"\",   ... )"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/import_blockmeasures.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Import blockmeasures — import_blockmeasures","text":"files Vector filenames (strings), block-shaped file containing measures data. File formats can .csv, .xls, .xlsx num_plates Number plates. multiple plates uninterleave used separate blockmeasures plates accordingly plate_names (optional) Names put onto plates output wellnames_sep String use separator well names rowname column name ... arguments pass read_blocks, uninterleave, trans_block_to_wide","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/import_blockmeasures.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Import blockmeasures — import_blockmeasures","text":"num_plates = 1, wide-shaped data.frame         containing measures data. num_plates greater one, list         data.frame's, data.frame wide-shaped.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/import_blockmeasures.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Import blockmeasures — import_blockmeasures","text":"Common arguments may want provide via ...              include: startrow, endrow, startcol, endcol,              sheet - specifying location design information              inside files read_blocks metadata - specifying metadata read_blocks See read_blocks details find needing control, can run              steps manually, first reading read_blocks,              separating plates needed uninterleave,              transforming wide trans_block_to_wide.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/lag_time.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate lag time — lag_time","title":"Calculate lag time — lag_time","text":"Lag time calculated projecting tangent line point maximum (per-capita) derivative backwards find time intersects minimum y-value","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/lag_time.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate lag time — lag_time","text":"","code":"lag_time(   x = NULL,   y = NULL,   deriv = NULL,   blank = NULL,   trans_y = \"log\",   na.rm = TRUE,   slope = NULL,   x1 = NULL,   y1 = NULL,   y0 = NULL,   warn_logtransform_warnings = TRUE,   warn_logtransform_infinite = TRUE,   warn_min_y_mismatch = TRUE,   warn_multiple_maxderiv = TRUE,   warn_one_lag = TRUE,   warn_no_lag = TRUE,   warn_blank_length = TRUE )"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/lag_time.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate lag time — lag_time","text":"x Vector x values (typically time) y Vector y values (typically density) deriv Vector derivative values (typically per-capita derivative) blank y-value associated \"blank\" density 0. required trans_y = TRUE. vector blank values may specified slope, x1, y1, y0 provided vectors trans_y One c(\"linear\", \"log\") specifying                 transformation y-values. 'log' default, producing calculations                 lag time assuming transition exponential growth 'linear' available alternate uses na.rm logical indicating whether missing values values become NA infinite log-transformation removed slope Slope project x1,y1 y0 (typically per-capita growth rate). provided, calculated max(deriv) x1 x value (typically time) project slope . provided, calculated x[.max(deriv)]. y1 y value (typically density) project slope . provided, calculated y[.max(deriv)]. y0 y value (typically density) find intersection slope x1, y1 . provided, calculated min(y) warn_logtransform_warnings logical whether warning issued log(y) produced warnings. warn_logtransform_infinite logical whether warning issued log(y) produced infinite values treated NA. warn_min_y_mismatch logical whether warning issued min(y) equal min(y[!.na(x)]). warn_multiple_maxderiv logical whether warning issued multiple points deriv tied highest, first used. warn_one_lag logical whether warning issued , , inputs vectorized, one lag time value returned. warn_no_lag logical whether warning issued calculated lag time less minimum value x. warn_blank_length logical whether warning issued unexpected number blank values provided first used","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/lag_time.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate lag time — lag_time","text":"Typically scalar lag time units x. See Details cases value vector.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/lag_time.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate lag time — lag_time","text":"typical uses, simply supply x, y, deriv (using per-capita derivative trans_y = 'log'). Advanced users may wish use alternate values slope tangent line (slope), origination point tangent line (x1, y1), minimum y-value y0. specified, values override default calculations. slope, x1, y1, y0 provided, lag_time vectorized inputs return vector lag time values.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/make_design.html","id":null,"dir":"Reference","previous_headings":"","what":"Make design data.frame(s) — make_design","title":"Make design data.frame(s) — make_design","text":"function easily input experimental design elements later merging read data","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/make_design.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make design data.frame(s) — make_design","text":"","code":"make_design(   nrows = NULL,   ncols = NULL,   block_row_names = NULL,   block_col_names = NULL,   block_name_header = \"block_name\",   output_format = \"tidy\",   wellnames_numeric = FALSE,   wellnames_sep = \"\",   wellnames_colname = \"Well\",   colnames_first = FALSE,   lookup_tbl_start = 1,   pattern_split = \"\",   ... )"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/make_design.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make design data.frame(s) — make_design","text":"nrows, ncols Number rows columns plate data block_row_names, block_col_names Names rows, columns plate blockmeasures data block_name_header name field containing block_names output_format One c(\"blocks\", \"blocks_pasted\", \"wide\", \"tidy\") denoting format resulting data.frame easy merging tidymeasures, leave default 'tidy'. human-readability confirm design correct, choose 'blocks' 'blocks_pasted'. writing block-shaped file(s), choose 'blocks' 'blocks_pasted'. wellnames_numeric block_row_names block_col_names specified, names generated automatically according wellnames_numeric. wellnames_numeric TRUE, rows columns numbered \"R\" \"C\" prefixes, respectively. wellnames_numeric FALSE, rows lettered Z, columns numbered wellnames_sep string used concatenating rownames column names create well names, output_format = \"wide\" output_format = \"tidy\" wellnames_colname Header newly-created column containing well names, output_format = \"tidy\" colnames_first wellnames created output_format = \"wide\" output_format = \"tidy\" paste-ing rownames column names, column names come first. lookup_tbl_start Value lookup table split pattern values corresponds first value vector. Lookup table default c(1,2,...,8,9,,B,...Y,Z,,b,...,y,z). , example, lookup_tbl_start = \"\", lookup table now c(,B,...Y,Z,,b,...,y,z) pattern_split character split pattern elements provided ... , already vector ... ... argument must named, must list            five elements: 1. vector values 2. vector rows pattern applied 3. vector columns pattern applied 4. string vector denoting pattern                 values filled rows columns specified. string, split pattern_split.                 Pattern used indices values vector. 0's refer NA. pattern recycled necessary                 fill wells rows columns specified. 5. logical whether pattern filled byrow","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/make_design.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Make design data.frame(s) — make_design","text":"Depends output_format: output_format = \"blocks\", list data.frame's         data.frame block-shaped containing         information single design element output_format = \"blocks_pasted\", single         data.frame containing paste-ed information         design elements output_format = \"wide\", wide-shaped data.frame         containing design elements output_format = \"tidy\", tidy-shaped data.frame         containing design elements","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/make_design.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Make design data.frame(s) — make_design","text":"Note either nrows block_row_names must provided either ncols block_col_names must provided","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/make_design.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Make design data.frame(s) — make_design","text":"","code":"make_design(nrows = 8, ncols = 12,             design_element_name = list(c(\"A\", \"B\", \"C\"),                                        2:7,                                        2:11,                                        \"112301\",                                         TRUE)) #>    Well design_element_name #> 1    A1                <NA> #> 2    A2                <NA> #> 3    A3                <NA> #> 4    A4                <NA> #> 5    A5                <NA> #> 6    A6                <NA> #> 7    A7                <NA> #> 8    A8                <NA> #> 9    A9                <NA> #> 10  A10                <NA> #> 11  A11                <NA> #> 12  A12                <NA> #> 13   B1                <NA> #> 14   B2                   A #> 15   B3                   A #> 16   B4                   B #> 17   B5                   C #> 18   B6                <NA> #> 19   B7                   A #> 20   B8                   A #> 21   B9                   A #> 22  B10                   B #> 23  B11                   C #> 24  B12                <NA> #> 25   C1                <NA> #> 26   C2                <NA> #> 27   C3                   A #> 28   C4                   A #> 29   C5                   A #> 30   C6                   B #> 31   C7                   C #> 32   C8                <NA> #> 33   C9                   A #> 34  C10                   A #> 35  C11                   A #> 36  C12                <NA> #> 37   D1                <NA> #> 38   D2                   B #> 39   D3                   C #> 40   D4                <NA> #> 41   D5                   A #> 42   D6                   A #> 43   D7                   A #> 44   D8                   B #> 45   D9                   C #> 46  D10                <NA> #> 47  D11                   A #> 48  D12                <NA> #> 49   E1                <NA> #> 50   E2                   A #> 51   E3                   A #> 52   E4                   B #> 53   E5                   C #> 54   E6                <NA> #> 55   E7                   A #> 56   E8                   A #> 57   E9                   A #> 58  E10                   B #> 59  E11                   C #> 60  E12                <NA> #> 61   F1                <NA> #> 62   F2                <NA> #> 63   F3                   A #> 64   F4                   A #> 65   F5                   A #> 66   F6                   B #> 67   F7                   C #> 68   F8                <NA> #> 69   F9                   A #> 70  F10                   A #> 71  F11                   A #> 72  F12                <NA> #> 73   G1                <NA> #> 74   G2                   B #> 75   G3                   C #> 76   G4                <NA> #> 77   G5                   A #> 78   G6                   A #> 79   G7                   A #> 80   G8                   B #> 81   G9                   C #> 82  G10                <NA> #> 83  G11                   A #> 84  G12                <NA> #> 85   H1                <NA> #> 86   H2                <NA> #> 87   H3                <NA> #> 88   H4                <NA> #> 89   H5                <NA> #> 90   H6                <NA> #> 91   H7                <NA> #> 92   H8                <NA> #> 93   H9                <NA> #> 94  H10                <NA> #> 95  H11                <NA> #> 96  H12                <NA>                            ## To be reminded what arguments are needed, use make_designpattern: make_design(nrows = 8, ncols = 12,             design_element_name = make_designpattern(                  values = c(\"A\", \"B\", \"C\"),                  rows = 2:7,                   cols = 2:11,                  pattern = \"112301\",                  byrow = TRUE))               #>    Well design_element_name #> 1    A1                <NA> #> 2    A2                <NA> #> 3    A3                <NA> #> 4    A4                <NA> #> 5    A5                <NA> #> 6    A6                <NA> #> 7    A7                <NA> #> 8    A8                <NA> #> 9    A9                <NA> #> 10  A10                <NA> #> 11  A11                <NA> #> 12  A12                <NA> #> 13   B1                <NA> #> 14   B2                   A #> 15   B3                   A #> 16   B4                   B #> 17   B5                   C #> 18   B6                <NA> #> 19   B7                   A #> 20   B8                   A #> 21   B9                   A #> 22  B10                   B #> 23  B11                   C #> 24  B12                <NA> #> 25   C1                <NA> #> 26   C2                <NA> #> 27   C3                   A #> 28   C4                   A #> 29   C5                   A #> 30   C6                   B #> 31   C7                   C #> 32   C8                <NA> #> 33   C9                   A #> 34  C10                   A #> 35  C11                   A #> 36  C12                <NA> #> 37   D1                <NA> #> 38   D2                   B #> 39   D3                   C #> 40   D4                <NA> #> 41   D5                   A #> 42   D6                   A #> 43   D7                   A #> 44   D8                   B #> 45   D9                   C #> 46  D10                <NA> #> 47  D11                   A #> 48  D12                <NA> #> 49   E1                <NA> #> 50   E2                   A #> 51   E3                   A #> 52   E4                   B #> 53   E5                   C #> 54   E6                <NA> #> 55   E7                   A #> 56   E8                   A #> 57   E9                   A #> 58  E10                   B #> 59  E11                   C #> 60  E12                <NA> #> 61   F1                <NA> #> 62   F2                <NA> #> 63   F3                   A #> 64   F4                   A #> 65   F5                   A #> 66   F6                   B #> 67   F7                   C #> 68   F8                <NA> #> 69   F9                   A #> 70  F10                   A #> 71  F11                   A #> 72  F12                <NA> #> 73   G1                <NA> #> 74   G2                   B #> 75   G3                   C #> 76   G4                <NA> #> 77   G5                   A #> 78   G6                   A #> 79   G7                   A #> 80   G8                   B #> 81   G9                   C #> 82  G10                <NA> #> 83  G11                   A #> 84  G12                <NA> #> 85   H1                <NA> #> 86   H2                <NA> #> 87   H3                <NA> #> 88   H4                <NA> #> 89   H5                <NA> #> 90   H6                <NA> #> 91   H7                <NA> #> 92   H8                <NA> #> 93   H9                <NA> #> 94  H10                <NA> #> 95  H11                <NA> #> 96  H12                <NA>"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/make_designpattern.html","id":null,"dir":"Reference","previous_headings":"","what":"Make design pattern — make_designpattern","title":"Make design pattern — make_designpattern","text":"helper function use make_design","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/make_designpattern.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make design pattern — make_designpattern","text":"","code":"make_designpattern(   values,   rows,   cols,   pattern = 1:length(values),   byrow = TRUE )  mdp(values, rows, cols, pattern = 1:length(values), byrow = TRUE)"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/make_designpattern.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make design pattern — make_designpattern","text":"values Vector values use rows Vector rows pattern applies cols Vector cols pattern applies pattern Numeric pattern , numbers refer entries values byrow logical whether pattern created row","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/make_designpattern.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Make design pattern — make_designpattern","text":"list(values, rows, cols, pattern, byrow)","code":""},{"path":[]},{"path":"https://mikeblazanin.github.io/gcplyr/reference/make_designpattern.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Make design pattern — make_designpattern","text":"","code":"make_design(nrows = 8, ncols = 12,             design_element_name = make_designpattern(                  values = c(\"A\", \"B\", \"C\"),                  rows = 2:7,                   cols = 2:11,                  pattern = \"112301\",                  byrow = TRUE)) #>    Well design_element_name #> 1    A1                <NA> #> 2    A2                <NA> #> 3    A3                <NA> #> 4    A4                <NA> #> 5    A5                <NA> #> 6    A6                <NA> #> 7    A7                <NA> #> 8    A8                <NA> #> 9    A9                <NA> #> 10  A10                <NA> #> 11  A11                <NA> #> 12  A12                <NA> #> 13   B1                <NA> #> 14   B2                   A #> 15   B3                   A #> 16   B4                   B #> 17   B5                   C #> 18   B6                <NA> #> 19   B7                   A #> 20   B8                   A #> 21   B9                   A #> 22  B10                   B #> 23  B11                   C #> 24  B12                <NA> #> 25   C1                <NA> #> 26   C2                <NA> #> 27   C3                   A #> 28   C4                   A #> 29   C5                   A #> 30   C6                   B #> 31   C7                   C #> 32   C8                <NA> #> 33   C9                   A #> 34  C10                   A #> 35  C11                   A #> 36  C12                <NA> #> 37   D1                <NA> #> 38   D2                   B #> 39   D3                   C #> 40   D4                <NA> #> 41   D5                   A #> 42   D6                   A #> 43   D7                   A #> 44   D8                   B #> 45   D9                   C #> 46  D10                <NA> #> 47  D11                   A #> 48  D12                <NA> #> 49   E1                <NA> #> 50   E2                   A #> 51   E3                   A #> 52   E4                   B #> 53   E5                   C #> 54   E6                <NA> #> 55   E7                   A #> 56   E8                   A #> 57   E9                   A #> 58  E10                   B #> 59  E11                   C #> 60  E12                <NA> #> 61   F1                <NA> #> 62   F2                <NA> #> 63   F3                   A #> 64   F4                   A #> 65   F5                   A #> 66   F6                   B #> 67   F7                   C #> 68   F8                <NA> #> 69   F9                   A #> 70  F10                   A #> 71  F11                   A #> 72  F12                <NA> #> 73   G1                <NA> #> 74   G2                   B #> 75   G3                   C #> 76   G4                <NA> #> 77   G5                   A #> 78   G6                   A #> 79   G7                   A #> 80   G8                   B #> 81   G9                   C #> 82  G10                <NA> #> 83  G11                   A #> 84  G12                <NA> #> 85   H1                <NA> #> 86   H2                <NA> #> 87   H3                <NA> #> 88   H4                <NA> #> 89   H5                <NA> #> 90   H6                <NA> #> 91   H7                <NA> #> 92   H8                <NA> #> 93   H9                <NA> #> 94  H10                <NA> #> 95  H11                <NA> #> 96  H12                <NA>"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/make_example.html","id":null,"dir":"Reference","previous_headings":"","what":"Create R objects or files as seen in vignette examples — make_example","title":"Create R objects or files as seen in vignette examples — make_example","text":"function makes easy generate R objects files created vignette examples. Note function counted produce output across different versions gcplyr, frequently changed match examples vignettes.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/make_example.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create R objects or files as seen in vignette examples — make_example","text":"","code":"make_example(vignette, example, dir = \".\")"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/make_example.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create R objects or files as seen in vignette examples — make_example","text":"vignette Number vignette example object file created . example Number example object file created . dir directory files saved .","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/make_example.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create R objects or files as seen in vignette examples — make_example","text":"R object, names files files written","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/make_tidydesign.html","id":null,"dir":"Reference","previous_headings":"","what":"Make tidy design data.frames — make_tidydesign","title":"Make tidy design data.frames — make_tidydesign","text":"function easily input experimental design elements later merging read data","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/make_tidydesign.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make tidy design data.frames — make_tidydesign","text":"","code":"make_tidydesign(   nrows = NULL,   ncols = NULL,   block_row_names = NULL,   block_col_names = NULL,   wellnames_sep = \"\",   wellnames_colname = \"Well\",   wellnames_Excel = TRUE,   lookup_tbl_start = 1,   pattern_split = \"\",   colnames_first = FALSE,   ... )"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/make_tidydesign.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make tidy design data.frames — make_tidydesign","text":"nrows, ncols Number rows columns plate data block_row_names, block_col_names Names rows, columns plate blockmeasures data wellnames_sep string used concatenating rownames column names create well names wellnames_colname Header newly-created column containing well names wellnames_Excel block_row_names block_col_names specified, rows columns named using Excel-style base-26 lettering rows numbering columns? FALSE, rows columns numbered \"R\" \"C\" prefix. lookup_tbl_start Value lookup table split pattern values corresponds first value vector. Lookup table default c(1,2,...,8,9,,B,...Y,Z,,b,...,y,z). , example, lookup_tbl_start = \"\", lookup table now c(,B,...Y,Z,,b,...,y,z) pattern_split character split pattern elements provided ... colnames_first wellnames created paste-ing rownames column names, column names come first ... ... argument must list five elements: 1. vector values 2. vector rows pattern applied 3. vector columns pattern applied 4. string pattern , numbers refer               indices values vector 0's refer NA pattern split using pattern_split,               defaults every character 5. logical whether pattern filled byrow","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/make_tidydesign.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Make tidy design data.frames — make_tidydesign","text":"tidy-shaped data.frame containing design elements","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/make_tidydesign.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Make tidy design data.frames — make_tidydesign","text":"Note either nrows block_row_names must provided either ncols block_col_names must provided Examples: my_example <- make_tidydesign(nrows = 8, ncols = 12,         design_element_name = list(c(\"Value1\", \"Value2\", \"Value3\"),                           rowstart:rowend, colstart:colend,                           \"111222333000\", TRUE) make easier pass arguments, use make_designpattern: my_example <- make_tidydesign(nrows = 8, ncols = 12,       design_element_name = make_designpattern(values = c(\"L\", \"G\", \"C\"),                                                 rows = 2:7, cols = 2:11,                                                 pattern = \"11223300\",                                                 byrow = TRUE))","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/makemethod_train_smooth_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Create method argument for train of growth curve smoothers — makemethod_train_smooth_data","title":"Create method argument for train of growth curve smoothers — makemethod_train_smooth_data","text":"function generates list compatible used method argument train. enables users call train directly smooth_data smoothing functions.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/makemethod_train_smooth_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create method argument for train of growth curve smoothers — makemethod_train_smooth_data","text":"","code":"makemethod_train_smooth_data(sm_method, tuneGrid = NULL)"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/makemethod_train_smooth_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create method argument for train of growth curve smoothers — makemethod_train_smooth_data","text":"sm_method Argument specifying smoothing method used. Options include \"moving-average\", \"moving-median\", \"loess\", \"gam\", \"smooth.spline\". tuneGrid data frame possible tuning value. columns named tuning parameters. Note , using train, tuneGrid must passed function well directly train.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/makemethod_train_smooth_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create method argument for train of growth curve smoothers — makemethod_train_smooth_data","text":"list can used method argument         train. Contains elements:         library, type, prob, fit,         parameters, grid, fit, predict. See documentation using custom model model         train details.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/merge_dfs.html","id":null,"dir":"Reference","previous_headings":"","what":"Collapse a list of dataframes, or merge two dataframes together — merge_dfs","title":"Collapse a list of dataframes, or merge two dataframes together — merge_dfs","text":"function essentially wrapper dplyr's mutate-joins (default, full_join). typical use function merge designs measures data, use collapse functionality merge list data.frames single data.frame. Merging done column names match x y.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/merge_dfs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Collapse a list of dataframes, or merge two dataframes together — merge_dfs","text":"","code":"merge_dfs(   x,   y = NULL,   by = NULL,   drop = FALSE,   collapse = FALSE,   names_to = NA,   join = \"full\",   warn_morerows = TRUE,   ... )"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/merge_dfs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Collapse a list of dataframes, or merge two dataframes together — merge_dfs","text":"x First data.frame, list data frames, joined y Second data.frame, list data frames, joined character vector variables join , passed directly join function drop complete_cases resulting data.frame returned? collapse logical indicating whether x y list containing data frames merged together merged names_to Column name names(x) names(y) entered collapse = TRUE. value NA names(x) names(y) put column returned data.frame join Type join used merge x y. Options 'full' (default), 'inner', 'left', 'right'. full join keeps observations x   y left join keeps observations x right join keeps observations y inner join keeps observations found   x y (inner joins appropriate   cases observations frequently dropped). See full_join, left_join, right_join, inner_join details warn_morerows logical, warning passed output rows x rows y? ... arguments pass underlying join function. See full_join, left_join, right_join, inner_join options.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/merge_dfs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Collapse a list of dataframes, or merge two dataframes together — merge_dfs","text":"Data.frame containing merged output x         y","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/paste_blocks.html","id":null,"dir":"Reference","previous_headings":"","what":"Paste a list of blocks into a single block — paste_blocks","title":"Paste a list of blocks into a single block — paste_blocks","text":"function uses paste concatenate -location entries list data.frames together (.e. first row-first column values pasted together, second row-first column values pasted together, etc.)","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/paste_blocks.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Paste a list of blocks into a single block — paste_blocks","text":"","code":"paste_blocks(blocks, sep = \"_\", nested_metadata = NULL)"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/paste_blocks.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Paste a list of blocks into a single block — paste_blocks","text":"blocks Blocks, either single data.frame list data.frames sep String use separator output pasted values nested_metadata logical indicating existence nested metadata blockmeasures list, e.g. typically output read_blocks. NULL, attempt infer existence nested metadata","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/paste_blocks.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Paste a list of blocks into a single block — paste_blocks","text":"nested_metadata = TRUE (inferred TRUE), list         containing list containing: 1. data.frame         pasted data values blocks, 2. vector         pasted metadata values blocks nested_metadata = FALSE (inferred FALSE), list         containing data.frame's pasted values         blocks","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/predict_interpolation.html","id":null,"dir":"Reference","previous_headings":"","what":"Predict data by linear interpolation from existing data — predict_interpolation","title":"Predict data by linear interpolation from existing data — predict_interpolation","text":"Predict data linear interpolation existing data","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/predict_interpolation.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Predict data by linear interpolation from existing data — predict_interpolation","text":"","code":"predict_interpolation(   x,   y,   newdata,   extrapolate_predictions = TRUE,   na.rm = TRUE )"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/predict_interpolation.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Predict data by linear interpolation from existing data — predict_interpolation","text":"x vector known predictor values. y vector known response values. newdata vector new predictor values response value predicted extrapolate_predictions Boolean indicating whether values newdata domain x predicted (extrapolating slope endpoints x). FALSE, values returned NA. na.rm logical whether NA's removed making predictions","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/predict_interpolation.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Predict data by linear interpolation from existing data — predict_interpolation","text":"vector response values predictor value         newdata","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/print_df.html","id":null,"dir":"Reference","previous_headings":"","what":"Nicely print the contents of a data.frame — print_df","title":"Nicely print the contents of a data.frame — print_df","text":"function uses write.table print input data.frame nicely-formatted manner easy read","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/print_df.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Nicely print the contents of a data.frame — print_df","text":"","code":"print_df(x, col.names = FALSE, row.names = FALSE)"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/print_df.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Nicely print the contents of a data.frame — print_df","text":"x data.frame printed col.names Boolean whether column names printed row.names Boolean whether row names printed","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/read_blocks.html","id":null,"dir":"Reference","previous_headings":"","what":"Read blocks — read_blocks","title":"Read blocks — read_blocks","text":"function reads blocks R environment","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/read_blocks.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read blocks — read_blocks","text":"","code":"read_blocks(   files,   filetype = NULL,   startrow = NULL,   endrow = NULL,   startcol = NULL,   endcol = NULL,   sheet = NULL,   metadata = NULL,   block_names = NULL,   block_names_header = \"block_name\",   block_names_dot = FALSE,   block_names_path = TRUE,   block_names_ext = FALSE,   header = NA,   sider = NA,   wellnames_numeric = FALSE,   na.strings = c(\"NA\", \"\"),   extension,   block_name_header,   ... )"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/read_blocks.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read blocks — read_blocks","text":"files vector filepaths relative current working directory filepath single plate read filetype (optional) type(s) files. Options include: \"csv\", \"xls\", \"xlsx\". \"tbl\" \"table\" use read.table read file,                  \"csv2\" use read.csv2, \"delim\"                  use read.delim, \"delim2\" use read.delim2. none provided, read_blocks infer filetype(s)                  extension(s) files. extension                  \"csv\", \"xls\", \"xlsx\", use \"table\". startrow, endrow, startcol, endcol (optional) rows columns measures data located files. Can vector list length files, single value applies files. Values can numeric string automatically converted numeric from_excel. provided, data presumed begin first row column file(s) end last row column file(s). sheet (optional) data .xls .xlsx files, sheet located . Defaults first sheet specified metadata (optional) non-spectrophotometric data associated read blockmeasures. named list item list either: vector length 2, list containing two vectors. former case, vector provide row column metadata located blockmeasures input files. latter case, first vector provide rows metadata located corresponding input files, second vector provide columns metadata located corresponding input files. (case typically used reading multiple blocks single file.) block_names (optional) vector names corresponding plate files. provided, block_names inferred filenames block_names_header name metadata field containing block_names block_names_dot block_names inferred filenames, leading './' () retained block_names_path block_names inferred filenames, path () retained block_names_ext block_names inferred filenames, file extension () retained header TRUE, FALSE, NA, vector values, indicating whether file(s) contains column names first line. header = NA attempt infer presence column names. header = FALSE column names inferred header = NA, column names generated automatically according wellnames_numeric sider TRUE, FALSE, NA, vector values, indicating whether file(s) contains row names first column. sider = NA attempt infer presence row names. sider = FALSE row names inferred sider = NA, row names generated automatically according wellnames_numeric wellnames_numeric row names column names provided input dataframe specified header sider, names generated automatically according wellnames_numeric. wellnames_numeric TRUE, rows columns numbered \"R\" \"C\" prefixes, respectively. wellnames_numeric FALSE, rows lettered Z, columns numbered na.strings character vector strings interpreted NA values read.csv, read_xls, read_xlsx, read.table extension Deprecated, use filetype instead block_name_header Deprecated, use block_names_header instead ... arguments passed read.csv, read_xls, read_xlsx, read.table","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/read_blocks.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Read blocks — read_blocks","text":"list entry list containing block data frame         followed block_names (filenames, block_names         provided) specified metadata.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/read_blocks.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Read blocks — read_blocks","text":"metadata, read_blocks can handle arbitrary number additional  pieces information extract blockcurve file metadata.  pieces information specified named list vectors  vector c(row, column) information  pulled input files. metadata returned second list element  blockcurve, e.g.: [[1]] [1] \"data\" #1 [2] \"metadata\"  [2][1] name #1 [2][2] date-time #1 [2][3] temp #1 [[2]] [1] \"data\" #2 [2] \"metadata\"  [2][1] name #2 [2][2] date-time #2 [2][3] temp #2 ... Calling uninterleave output read_blocks works block data  associated metadata uninterleave operates highest  level entries list ([[1]] [[2]] level items),  leaving meta-data associated block data trans_block_to_wide integrates metadata  wide-shaped dataframe produces","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/read_tidys.html","id":null,"dir":"Reference","previous_headings":"","what":"Read tidy-shaped files — read_tidys","title":"Read tidy-shaped files — read_tidys","text":"function imports tidy-shaped files R. Largely acts wrapper read.csv, read_xls, read_xls, read_xlsx, can handle multiple files additional options taking subsets rows/columns rather entire file adding filename run names added column output.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/read_tidys.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read tidy-shaped files — read_tidys","text":"","code":"read_tidys(   files,   filetype = NULL,   startrow = NULL,   endrow = NULL,   startcol = NULL,   endcol = NULL,   sheet = NULL,   run_names = NULL,   run_names_header = NULL,   run_names_dot = FALSE,   run_names_path = TRUE,   run_names_ext = FALSE,   na.strings = c(\"NA\", \"\"),   extension,   names_to_col,   ... )"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/read_tidys.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read tidy-shaped files — read_tidys","text":"files vector filepaths (relative current working directory) one tidy-shaped data file filetype (optional) type(s) files. Options include: \"csv\", \"xls\", \"xlsx\". \"tbl\" \"table\" use read.table read file,                  \"csv2\" use read.csv2, \"delim\"                  use read.delim, \"delim2\" use read.delim2. none provided, read_tidys infer filetype(s)                  extension(s) files. extension                  \"csv\", \"xls\", \"xlsx\", use \"table\". startrow, endrow, startcol, endcol (optional) rows columns data located files. Can vector list length files, single value applies files. Values can numeric string automatically converted numeric from_excel. provided, data presumed begin first row column file(s) end last row column file(s). sheet sheet input files data located (input files .xls .xlsx). specified defaults first run_names Names give tidy files read . default uses file names specified. names may added resulting data frame depending value names_to_col argument run_names_header run names (provided run_names inferred files) added column output? run_names_header TRUE, added column name \"run_name\" run_names_header FALSE, added. run_names_header string, added column name string specified run_names_header. run_names_header NULL, added multiple tidy data.frames read. case, column name \"run_name\" run_names_dot run_names inferred filenames, leading './' () retained run_names_path run_names inferred filenames, path () retained run_names_ext run_names inferred filenames, file extension () retained na.strings character vector strings interpreted NA values read.csv, read_xls, read_xlsx, read.table extension Deprecated, use filetype instead names_to_col Deprecated, use run_names_header instead ... arguments passed read.csv, read_xls, read_xlsx, read.table sheet","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/read_tidys.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Read tidy-shaped files — read_tidys","text":"dataframe containing single tidy data.frame,         list tidy-shaped data.frames named filename","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/read_tidys.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Read tidy-shaped files — read_tidys","text":"startrow, endrow, startcol, endcol, sheet filetype can either single value applies files vectors lists length files Note startrow always assumed header","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/read_wides.html","id":null,"dir":"Reference","previous_headings":"","what":"Read wides — read_wides","title":"Read wides — read_wides","text":"function imports widemeasures files R environment","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/read_wides.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read wides — read_wides","text":"","code":"read_wides(   files,   filetype = NULL,   startrow = NULL,   endrow = NULL,   startcol = NULL,   endcol = NULL,   header = TRUE,   sheet = NULL,   run_names = NULL,   run_names_header = \"file\",   run_names_dot = FALSE,   run_names_path = TRUE,   run_names_ext = FALSE,   metadata = NULL,   na.strings = c(\"NA\", \"\"),   extension,   names_to_col,   ... )"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/read_wides.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read wides — read_wides","text":"files vector filepaths (relative current working directory) one widemeasures set data filetype (optional) type(s) files. Options include: \"csv\", \"xls\", \"xlsx\". \"tbl\" \"table\" use read.table read file,                  \"csv2\" use read.csv2, \"delim\"                  use read.delim, \"delim2\" use read.delim2. none provided, read_wides infer filetype(s)                  extension(s) files. extension                  \"csv\", \"xls\", \"xlsx\", use \"table\". startrow, endrow, startcol, endcol (optional) rows columns data located files. Can vector list length files, single value applies files. Values can numeric string automatically converted numeric from_excel. provided, data presumed begin first row column file(s) end last row column file(s). header logical whether header data. FALSE columns simply numbered. TRUE, first row data (startrow specified) used column names sheet sheet input files data located (input files .xls .xlsx). specified defaults first sheet run_names Names give widemeasures read . default uses file names specified run_names_header run names (provided run_names inferred files) added column widemeasures? run_names_header NULL, . run_names_header string, string column header column names stored run_names_dot run_names inferred filenames, leading './' () retained run_names_path run_names inferred filenames, path () retained run_names_ext run_names inferred filenames, file extension () retained metadata (optional) non-spectrophotometric data associated read widemeasures. named list item list either: vector length 2, list containing two vectors. former case, vector provide row column metadata located blockmeasures input files. latter case, first vector provide rows metadata located corresponding input files, second vector provide columns metadata located corresponding input files. (case typically used reading multiple blocks single file.) na.strings character vector strings interpreted NA values read.csv, read_xls, read_xlsx, read.table extension Deprecated, use filetype instead names_to_col Deprecated, use run_names_header instead ... arguments passed read.csv, read_xls, read_xlsx, read.table","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/read_wides.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Read wides — read_wides","text":"dataframe containing single widemeasures,         list widemeasures named filename","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/read_wides.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Read wides — read_wides","text":"startrow, endrow, startcol, endcol, timecol, sheet filetype can either single value applies files vectors lists length files,","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/separate_tidy.html","id":null,"dir":"Reference","previous_headings":"","what":"Separate a column into multiple columns — separate_tidy","title":"Separate a column into multiple columns — separate_tidy","text":"function primarily wrapper separate, turns single character column multiple columns","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/separate_tidy.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Separate a column into multiple columns — separate_tidy","text":"","code":"separate_tidy(   data,   col,   into = NULL,   sep = \"_\",   coerce_NA = TRUE,   na.strings = \"NA\",   message_inferred_into = TRUE,   ... )"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/separate_tidy.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Separate a column into multiple columns — separate_tidy","text":"data data frame col Column name position character vector new column names. Use NA omit variable output. NULL, separate_tidy attempt infer new column names splitting column name col sep Separator columns passed separate: character, sep interpreted regular expression. numeric, sep interpreted character positions            split . Positive values start 1 far-left            string; negative values start -1 far-right            string. length sep one less            coerce_NA logical dictating strings matching na.strings coerced  NA values separating. na.strings character vector strings interpreted NA values coerce_NA == TRUE message_inferred_into logical whether column names printed message inferred ... arguments passed separate","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/separate_tidy.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Separate a column into multiple columns — separate_tidy","text":"data frame containing new columns place col","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/smooth_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Smooth data — smooth_data","title":"Smooth data — smooth_data","text":"function calls functions smooth growth curve data","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/smooth_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Smooth data — smooth_data","text":"","code":"smooth_data(   ...,   x = NULL,   y = NULL,   sm_method,   subset_by = NULL,   return_fitobject = FALSE,   warn_ungrouped = TRUE,   warn_gam_no_s = TRUE )"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/smooth_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Smooth data — smooth_data","text":"... Arguments passed loess, gam, moving_average, moving_median, smooth.spline. Typically includes tuning parameter(s), cases required. See Details information. x (often optional) vector predictor values smooth along (e.g. time) y vector response values smoothed (e.g. density). NULL, formula data *must* provided via ... sm_method Argument specifying smoothing method used smooth data. Options include \"moving-average\", \"moving-median\", \"loess\", \"gam\", \"smooth.spline\". subset_by optional vector long y. y split unique values vector smoothed data group calculated independently others. provides internally-implemented approach similar group_by mutate return_fitobject logical whether entire object returned fitting function returned. FALSE, just fitted values returned. warn_ungrouped logical whether warning issued smooth_data called ungrouped data subset_by = NULL. warn_gam_no_s logical whether warning issued gam used without s() formula.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/smooth_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Smooth data — smooth_data","text":"return_fitobject == FALSE: vector, length y, now-smoothed y values return_fitobject == TRUE: list length unique(subset_by) element         object class returned smoothing method         (typically named list-like object)","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/smooth_data.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Smooth data — smooth_data","text":"moving_average moving_median,            passing window_width window_width_n via            ... required. window_width sets width            moving window units x,            window_width_n sets width units number            data points. Larger values either produce            \"smoothed\" data. loess, span argument sets fraction            data points included calculation.            typically best specify, since default 0.75 often            large growth curves data. Larger values span            produce \"smoothed\" data gam, arguments gam            s can provided via .... frequently,            k argument s sets number            \"knots\" spline-fitting can use. Smaller values            \"smoothed\". using sm_method = \"gam\", advanced users may also modify            parameters s(), including smoothing basis            bs. bases can thin plate (bs = \"tp\",            default), cubic regressions (bs = \"cr\"), many            options (see s). recommend leaving default            thin plate regressions, whose main drawback            computationally intensive calculate. growth curves data,            unlikely relevant. alternative passing y, advanced needs            loess gam, formula data            can passed smooth_data via ... argument            (lieu y). case, formula specify response (e.g. density)            predictors. gam smoothing, formula            typically format: y ~ s(x), uses            s smooth data. data argument            data.frame containing variables formula.            cases, subset_by can still specified vector            length nrow(data)","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/solve_linear.html","id":null,"dir":"Reference","previous_headings":"","what":"Return missing information about a line — solve_linear","title":"Return missing information about a line — solve_linear","text":"Takes set inputs sufficient information infer line returns information provided (either slope, x point line, y point line)","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/solve_linear.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Return missing information about a line — solve_linear","text":"","code":"solve_linear(   x1,   y1,   x2 = NULL,   y2 = NULL,   x3 = NULL,   y3 = NULL,   m = NULL,   named = TRUE )"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/solve_linear.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Return missing information about a line — solve_linear","text":"x1, y1 point line x2, y2 additional point line x3, y3 additional point line m slope line named logical indicating whether returned value(s) named according (m, x2, y2, x3, y3)","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/solve_linear.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Return missing information about a line — solve_linear","text":"named vector missing information line: m x2 provided, y2 returned m y2 provided, x2 returned x2 y2 provided, neither x3         y3 provided, m returned x2 y2 provided one x3         y3 provided, (y3 x3)         returned","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/solve_linear.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Return missing information about a line — solve_linear","text":"Note requirement          x1 < x2 < x3: points can order          along line. solve_linear works vectors inputs solve          multiple lines , ith element          argument corresponds ith output. Note          lines must missing information. Input vectors          recycled necessary.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/to_excel.html","id":null,"dir":"Reference","previous_headings":"","what":"A function that converts numbers into base-26 Excel-style letters — to_excel","title":"A function that converts numbers into base-26 Excel-style letters — to_excel","text":"function converts numbers base-26 Excel-style letters","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/to_excel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A function that converts numbers into base-26 Excel-style letters — to_excel","text":"","code":"to_excel(x)"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/to_excel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A function that converts numbers into base-26 Excel-style letters — to_excel","text":"x vector numbers base-10","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/to_excel.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A function that converts numbers into base-26 Excel-style letters — to_excel","text":"vector letters Excel-style base-26 format","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/train_smooth_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Test efficacy of different smoothing parameters — train_smooth_data","title":"Test efficacy of different smoothing parameters — train_smooth_data","text":"function based train, runs models (case different smoothing algorithms) data across different parameter values (case different smoothness parameters).","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/train_smooth_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Test efficacy of different smoothing parameters — train_smooth_data","text":"","code":"train_smooth_data(   ...,   x = NULL,   y = NULL,   sm_method,   preProcess = NULL,   weights = NULL,   metric = ifelse(is.factor(y), \"Accuracy\", \"RMSE\"),   maximize = ifelse(metric %in% c(\"RMSE\", \"logLoss\", \"MAE\", \"logLoss\"), FALSE, TRUE),   trControl = caret::trainControl(method = \"cv\"),   tuneGrid = NULL,   tuneLength = ifelse(trControl$method == \"none\", 1, 3),   return_trainobject = FALSE )"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/train_smooth_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Test efficacy of different smoothing parameters — train_smooth_data","text":"... Arguments passed smooth_data. arguments overlap tuned. x vector predictor values smooth along (e.g. time) y vector response values smoothed (e.g. density). sm_method Argument specifying smoothing method used. Options include \"moving-average\", \"moving-median\", \"loess\", \"gam\", \"smooth.spline\". preProcess string vector defines pre-processing predictor data. default pre-processing. See train details. weights numeric vector case weights. argument currently affect train_smooth_data models. metric string specifies summary metric used select optimal model. default, possible values \"RMSE\" \"Rsquared\" regression. See train details. maximize logical: metric maximized minimized? trControl list values define function acts. See train trainControl details. tuneGrid data frame possible tuning values, named list containing vectors possible tuning values. data frame, columns named tuning parameters. list, elements list named tuning parameters. list, expand.grid used make possible combinations tuning parameter values. tuneLength integer denoting amount granularity tuning parameter grid. default, argument number levels tuning parameter generated. trControl option search = \"random\", maximum number tuning parameter combinations generated random search. (NOTE: given, argument must named.) return_trainobject logical indicating whether entire result train returned, results element.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/train_smooth_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Test efficacy of different smoothing parameters — train_smooth_data","text":"return_trainobject = FALSE (default), data frame         values tuning parameter combinations         training error rate combination (.e. results         element output train). return_trainobject = TRUE, output train","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/train_smooth_data.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Test efficacy of different smoothing parameters — train_smooth_data","text":"See train information. default method k-fold cross-validation          (trControl = caret::trainControl(method = \"cv\")). less variable, computationally costly, cross-validation,          users may choose increase number folds. can          done altering number argument          trainControl, setting method = \"LOOCV\"          leave one cross-validation number folds          equal number data points. less variable, computationally costly, cross-validation,          users may alternatively choose method = \"repeatedcv\"          repeated k-fold cross-validation. control, advanced users may wish call          train directly, using          makemethod_train_smooth_data specify method          argument.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/trans_block_to_wide.html","id":null,"dir":"Reference","previous_headings":"","what":"Transform blocks to wides — trans_block_to_wide","title":"Transform blocks to wides — trans_block_to_wide","text":"Takes blocks returns wide format","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/trans_block_to_wide.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Transform blocks to wides — trans_block_to_wide","text":"","code":"trans_block_to_wide(   blocks,   wellnames_sep = \"\",   nested_metadata = NULL,   colnames_first = FALSE )"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/trans_block_to_wide.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Transform blocks to wides — trans_block_to_wide","text":"blocks Blocks, either single dataframe list dataframes wellnames_sep String use separator well names row name column name (ordered according colnames_first nested_metadata logical indicating existence nested metadata blockmeasures list, e.g. typically output read_blocks. NULL, attempt infer existence nested metadata colnames_first wellnames created paste-ing rownames column names, column names come first?","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/trans_block_to_wide.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Transform blocks to wides — trans_block_to_wide","text":"single wide-shaped dataframe","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/trans_wide_to_tidy.html","id":null,"dir":"Reference","previous_headings":"","what":"Pivot wide-shaped into tidy — trans_wide_to_tidy","title":"Pivot wide-shaped into tidy — trans_wide_to_tidy","text":"Essentially wrapper pivot_longer works single wide-shaped dataframe well list wide-shaped dataframe's","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/trans_wide_to_tidy.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pivot wide-shaped into tidy — trans_wide_to_tidy","text":"","code":"trans_wide_to_tidy(   wides,   data_cols = NA,   id_cols = NA,   names_to = \"Well\",   values_to = \"Measurements\",   values_to_numeric = TRUE,   ... )"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/trans_wide_to_tidy.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pivot wide-shaped into tidy — trans_wide_to_tidy","text":"wides single wide-shaped dataframe, list wide-shaped dataframe's data_cols, id_cols Specifies columns data vs ID's (pivot_longer parlance). can single vector (applied dataframes) list vectors, vector corresponding -index dataframe wides Entries NA list used neither data_cols id_cols specified, user must provide arguments pivot_longer via ... least cols argument arguments provided via ... used wides dataframe's names_to, values_to Specifies output column names created pivot_longer. can provided vectors length wides values_to_numeric logical indicating whether values coerced numeric. See may overridden arguments passed ... ... arguments passed pivot_longer Note including values_transform override behavior values_to_numeric","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/trans_wide_to_tidy.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pivot wide-shaped into tidy — trans_wide_to_tidy","text":"Pivoted longer dataframe (wides single dataframe)         list pivoted longer dataframes (wides         list dataframes)","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/uninterleave.html","id":null,"dir":"Reference","previous_headings":"","what":"Uninterleave list — uninterleave","title":"Uninterleave list — uninterleave","text":"Takes list actually interleaved elements multiple sources uninterleaves separate sources. instance, list blockmeasures actually corresponds two different plates can split two lists, blockmeasures corresponding single plate. Uninterleave assumes desired sub-groups perfectly interleaved input (e.g. items belong sub-groups 1,2,3,1,2,3,...)","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/uninterleave.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Uninterleave list — uninterleave","text":"","code":"uninterleave(interleaved_list, n)"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/uninterleave.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Uninterleave list — uninterleave","text":"interleaved_list list R objects n many output sub lists (.e. many groups interleaved list divided )","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/uninterleave.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Uninterleave list — uninterleave","text":"list lists R objects","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/write_blocks.html","id":null,"dir":"Reference","previous_headings":"","what":"Write block designs to csv — write_blocks","title":"Write block designs to csv — write_blocks","text":"function writes block-shaped lists (created read_blocks make_design) csv files, including data metadata variety output formats","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/write_blocks.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Write block designs to csv — write_blocks","text":"","code":"write_blocks(   blocks,   file,   output_format = \"multiple\",   block_name_location = NULL,   block_name_header = \"block_name\",   paste_sep = \"_\",   filename_sep = \"_\",   na = \"\",   dir = NULL,   ... )"},{"path":"https://mikeblazanin.github.io/gcplyr/reference/write_blocks.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Write block designs to csv — write_blocks","text":"blocks list block-shaped data written file file NULL, character string naming file write ,             vector character strings naming files write . file name required output_format = \"single\" file name can specified output_format = \"pasted\",             file can set NULL long             block_name_location = \"filename\" (pasted             block_name metadata used file name) File names can specified output_format = \"multiple\",             file can set NULL long             block_name_location = \"filename\" (            block_name metadata used file names) output_format One \"single\", \"pasted\", \"multiple\". \"single\" write blocks single                      csv file, empty row successive                      blocks. \"pasted\" paste blocks together using                      paste_sep, write now-pasted                      block single csv file. \"multiple\" write block csv file. block_name_location Either NULL, 'filename' 'file'. NULL, block_name_location                           automatically selected based                           output_format.                           output_format = 'single'                           output_format = 'pasted',                           block_name_location defaults 'file'.                           output_format = 'multiple',                           block_name_location defaults 'filename' 'filename', block_name metadata                           used output file name(s)                           file name(s) provided, appended                           file name(s) provided. 'file', block_name metadata                           included row output file. block_name_header name field containing block_names paste_sep output_format = 'pasted', character used paste together blocks. filename_sep character used paste together filenames block_name_location = 'filename'. na string use missing values data. dir directory file(s) written . dir = NULL, writes current working directory. (Can used file = NULL) ... arguments passed write.table","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/reference/write_blocks.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Write block designs to csv — write_blocks","text":"Nothing, R objects written files","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/news/index.html","id":"gcplyr-1120","dir":"Changelog","previous_headings":"","what":"gcplyr 1.12.0","title":"gcplyr 1.12.0","text":"Bug fix read_ import_ functions leading empty rows xlsx xls files dropped automatically, startrow endrow argument values incorrect Bug fix smooth_data, moving_average, moving_median failing group data NA x- y-values Bug fix read_ functions failing attempting read single column data Bug fix smooth_data error arise sm_method ‘gam’ mgcv wasn’t installed Documentation vignette improvements","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/news/index.html","id":"gcplyr-1110","dir":"Changelog","previous_headings":"","what":"gcplyr 1.11.0","title":"gcplyr 1.11.0","text":"CRAN release: 2025-01-16 Bug fix lag_time returning incorrect values trans_y = “log” y values provided already normalized (.e. blank value subtracted). lag_time now takes blank argument, required trans_y = “log” New vignette section subtracting blanks","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/news/index.html","id":"gcplyr-1100","dir":"Changelog","previous_headings":"","what":"gcplyr 1.10.0","title":"gcplyr 1.10.0","text":"CRAN release: 2024-07-09 join_designs argument import_blockdesigns renamed join_as_cols clarity Citation load message now point BMC Bioinformatics paper package: Blazanin, M. gcplyr: R package microbial growth curve data analysis. BMC Bioinformatics 25, 232 (2024). https://doi.org/10.1186/s12859-024-05817-3 New functions centroid, centroid_x, centroid_y, centroid_both calculate center--mass centroid area curve, can used metric microbial growth import_blockdesigns now separates designs joined rows sep argument specified separate_tidy now prints message inferred column names Various documentation vignette improvements","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/news/index.html","id":"gcplyr-190","dir":"Changelog","previous_headings":"","what":"gcplyr 1.9.0","title":"gcplyr 1.9.0","text":"CRAN release: 2024-03-11 Bug fix lag_time incorrectly calculating y0 minimum y value deriv NA. now calculates minimum y value regardless deriv value Bug fix lag_time NA returned one non-NA data point, now returns x value single data point lag_time returns NA, now always returns numeric NA Bug fix import_blockdesigns separating designs read single file Bug fix import_blockdesigns designs joined columns read single file Bug fix import_blockdesigns arguments passed via … previously passed separate_tidy import_blockdesigns new argument join_designs controls whether multiple imported designs handled referring plate (joined columns), different plates (joined rows) import_blockdesigns now option keep block_names column output solve_linear now correctly handles case x1 == x2 == x3 New arguments window_width_frac window_width_n_frac window-using functions (including find_local_extrema related functions, calc_deriv, moving_average, moving_median). arguments allow width window specified fraction total range data total number data points, respectively moving_average moving_median new arguments, x y, can used instead formula data new function predict_interpolation works like stats::predict linearly interpolating existing data. function can used predict function output moving_average moving_median New functions train_smooth_data makemethod_train_smooth_data enable users test different tuning parameter values smooth_data via caret::train Many functions now warn_* arguments, allowing users silence specific warnings Bug fix auc warning incorrectly issued xlim inside range x values inside range x values NA x y values removed moving_average moving_median now warn x values unique Improved warnings calc_deriv window wide enough lag_time now warns estimated lag time less minimum non-NA value x internal functions renamed consistent style clear error messages Various documentation vignette improvements","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/news/index.html","id":"gcplyr-180","dir":"Changelog","previous_headings":"","what":"gcplyr 1.8.0","title":"gcplyr 1.8.0","text":"CRAN release: 2024-01-30 read_ import_ functions can now use utils::read.table file types, including csv, csv2, delim, delim2 extension argument read_ import_ functions deprecated, new argument name filetype block_name_header argument read_blocks deprecated, new argument name block_names_header names_to_col argument read_wides read_tidys deprecated, new argument name run_names_header read_ import_ functions new arguments (_dot, _path, _ext), users can set determine file names/paths saved resulting object smooth_data new smoothing method: smooth.spline. method uses stats::smooth.spline via gcplyr wrapper function gc_smooth.spline area curve function auc now subset argument new data object included package: example_design_tidy. object tidy-shaped contains plate layout design example_widedata example_widedata_noiseless datasets included gcplyr find_local_extrema find_threshold_crosses now consistent handling subset argument, including treating NA’s subset FALSE warning Bug fix reading files failed extension specified user extension inferred filename .xls, .xlsx, .csv, .tbl Bug fix extr_val na.rm = TRUE working correctly Improved error message user specifies argument length 0 Various backend improvements, including renaming internal functions consistent style renaming internal objects unique less ambiguous error messages Various vignette improvements","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/news/index.html","id":"gcplyr-171","dir":"Changelog","previous_headings":"","what":"gcplyr 1.7.1","title":"gcplyr 1.7.1","text":"CRAN release: 2023-11-03 Fixed broken links vignettes","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/news/index.html","id":"gcplyr-170","dir":"Changelog","previous_headings":"","what":"gcplyr 1.7.0","title":"gcplyr 1.7.0","text":"read_blocks now returns blocks whose row.names always character vector merge_dfs can now inner, left, right joins (addition original capacity full joins) Strings coerced NA can now specified separate_tidy directory write files can now specified write_blocks read_blocks metadata field name block names stored can now specified via block_name_header argument new vignette demonstrating work multiple plates Examples throughout vignettes now created make_example function streamlined readability read_blocks, read_wides, read_tidys, make_design now provide better error messages inputs range merge_dfs now provides message number dropped rows drop = TRUE Fix bug read_blocks arguments read.csv passed via … Fix bug merge_dfs drop incomplete cases unless x y specified Vignettes now numbered sorted correctly CRAN Various minor documentation improvements Various backend improvements","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/news/index.html","id":"gcplyr-160","dir":"Changelog","previous_headings":"","what":"gcplyr 1.6.0","title":"gcplyr 1.6.0","text":"CRAN release: 2023-09-13 behavior smooth_data return_fitobject = TRUE changed. now returns list containing output smoothing method directly (previously returned objects modified output smoothing method always first element ‘fitted’ values second element ‘residuals’)","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/news/index.html","id":"gcplyr-152","dir":"Changelog","previous_headings":"","what":"gcplyr 1.5.2","title":"gcplyr 1.5.2","text":"CRAN release: 2023-05-03 Citation load message now point bioRxiv preprint package: Blazanin, Michael. 2023. gcplyr: R package microbial growth curve data analysis. bioRxiv doi: 10.1101/2023.04.30.538883.","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/news/index.html","id":"gcplyr-151","dir":"Changelog","previous_headings":"","what":"gcplyr 1.5.1","title":"gcplyr 1.5.1","text":"CRAN release: 2023-04-14 “Dealing noise” vignette rewritten much concise minor fixes CRAN checks","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/news/index.html","id":"gcplyr-150","dir":"Changelog","previous_headings":"","what":"gcplyr 1.5.0","title":"gcplyr 1.5.0","text":"Several fixes bugs calc_deriv returning incorrect values trans_y = ‘log’ either blank specified fitting used (.e. window_width window_width_n NULL) Bug fixes better warning messages lag_time, especially relating negative infinite y-values following log-transformation New function: solve_linear, enables easy calculation slope two points, finding additional point known line New functions: which_min_gc, which_max_gc, min_gc, max_gc, extr_val. serve versions base functions .min, .max, min, max, [] (respectively) better defaults handling edge cases (often related NA values) growth curve analyses dplyr::summarize auc function two new arguments. ‘blank’ allows setting blank value, ‘neg.rm’ gives users choice handle -zero values Various documentation improvements manual vignettes","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/news/index.html","id":"gcplyr-141","dir":"Changelog","previous_headings":"","what":"gcplyr 1.4.1","title":"gcplyr 1.4.1","text":"Bug fix calc_deriv nearly values become NA log-transformation","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/news/index.html","id":"gcplyr-140","dir":"Changelog","previous_headings":"","what":"gcplyr 1.4.0","title":"gcplyr 1.4.0","text":"planned changes smooth_data return_fitobject = TRUE: forthcoming version (first version released Sep 1, 2023), return_fitobject = TRUE return list object created underlying method directly. current behavior modifies generated object ‘fitted’ always first element ‘residuals’ always second element mdp() new function, simply shorthand alias make_designpattern() Column numbers row numbers read_* import_* functions can now specified using mix base-10 numbers base-26 Excel-style letters separate_tidy now coerces strings “NA” NA values default Bug fix make_design NA values returned “NA” (string) instead NA (missing value indicator) output_format = ‘tidy’ multiple design columns Bug fix make_design pattern just “1” Bug fix error arose calc_deriv trans_y = ‘log’ used y values 0. calc_deriv now handles resulting NA/NaN values raises warning Bug fixes first_maxima first_minima Added warning using make_design ’s likely setting custom lookup_tbl_start forgotten Improved documentation make_designpattern","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/news/index.html","id":"gcplyr-130","dir":"Changelog","previous_headings":"","what":"gcplyr 1.3.0","title":"gcplyr 1.3.0","text":"New function lag_time calculate lag time New function doubling_time convert per-capita growth rate equivalent doubling time smooth_data calc_deriv now pass warning used outside dplyr::mutate ungrouped data make_design better warning messages common mistakes Major edits vignettes Various documentation improvements","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/news/index.html","id":"gcplyr-120","dir":"Changelog","previous_headings":"","what":"gcplyr 1.2.0","title":"gcplyr 1.2.0","text":"function first_peak renamed first_maxima. first_peak continue function normally long time warning use first_maxima instead. New functions added shortcuts common use cases: first_minima first_above Bug fixes find_threshold_crossings related return_endpoints = TRUE Bug fixes find_threshold_crossings find_local_extrema input values NA Style content improvements vignettes Help pages improved","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/news/index.html","id":"gcplyr-110","dir":"Changelog","previous_headings":"","what":"gcplyr 1.1.0","title":"gcplyr 1.1.0","text":"CRAN release: 2023-02-03 default behavior write_blocks changed: users now required specify file argument either NULL, file name, vector file names. old default naming, specify file = NULL. change required CRAN compatibility. Minor changes citation Tweaked documentation CRAN compatibility","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/news/index.html","id":"gcplyr-102","dir":"Changelog","previous_headings":"","what":"gcplyr 1.0.2","title":"gcplyr 1.0.2","text":"Tweaks CITATION CRAN compatibility","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/news/index.html","id":"gcplyr-101","dir":"Changelog","previous_headings":"","what":"gcplyr 1.0.1","title":"gcplyr 1.0.1","text":"Readability improvements “Dealing noise” vignette Minor tweaks several vignettes reduce build time CRAN compatibility","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/news/index.html","id":"gcplyr-100","dir":"Changelog","previous_headings":"","what":"gcplyr 1.0.0","title":"gcplyr 1.0.0","text":"minor documentation tweaks CRAN compatibility since 0.12.3. version 1.0.0 first released CRAN denotes gcplyr stable going forward","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/news/index.html","id":"gcplyr-0123","dir":"Changelog","previous_headings":"","what":"gcplyr 0.12.3","title":"gcplyr 0.12.3","text":"Tweaks CRAN compatibility, largely minor documentation changes","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/news/index.html","id":"gcplyr-0122","dir":"Changelog","previous_headings":"","what":"gcplyr 0.12.2","title":"gcplyr 0.12.2","text":"Improved clarity vignettes, especially calculating derivatives analyzing data pages New vignette dealing noise data Small tweaks documentation","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/news/index.html","id":"gcplyr-0121","dir":"Changelog","previous_headings":"","what":"gcplyr 0.12.1","title":"gcplyr 0.12.1","text":"Minor bug fixes","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/news/index.html","id":"gcplyr-012","dir":"Changelog","previous_headings":"","what":"gcplyr 0.12","title":"gcplyr 0.12","text":"new citation. Run citation(“gcplyr”) see new version smooth_data methods moving-average moving-median now accept new smoothing parameter: window_width find_local_extrema now arguments window_width, window_width_n, window_height (naming consistency smooth_data calc_deriv arguments). Arguments width_limit, width_limit_n, height_limit deprecated. calc_deriv can now calculate derivatives using linear fit multiple data points determined arguments window_width /window_width_n. per-capita derivatives, y-values can fit -supplied divided mid-point y-value, can fit log-transformation gcplyr-workflow vignette split multiple smaller vignettes new data.frame included gcplyr: example_data_noiseless. data example_data include simulated noise present example_data. small numerical changes example_data values occurred re-generation example_data. Packages mgcv readxl now Suggests (previously Imports), errors thrown installed required gcplyr functionality find_local_extrema now much faster","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/news/index.html","id":"gcplyr-0112","dir":"Changelog","previous_headings":"","what":"gcplyr 0.11.2","title":"gcplyr 0.11.2","text":"new vignette section running statistics vignette, use dplyr::mutate smoothing derivatives sections","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/news/index.html","id":"gcplyr-0111","dir":"Changelog","previous_headings":"","what":"gcplyr 0.11.1","title":"gcplyr 0.11.1","text":"updates vignette README","code":""},{"path":"https://mikeblazanin.github.io/gcplyr/news/index.html","id":"gcplyr-011","dir":"Changelog","previous_headings":"","what":"gcplyr 0.11","title":"gcplyr 0.11","text":"first public release gcplyr Open Beta. Documentation complete, although planned additions vignette completed included . Functions arguments largely stabilized, although small changes may occur going forward following user feedback. Internal tests mostly complete, although additional edge cases may added bugs reported.","code":""}]
